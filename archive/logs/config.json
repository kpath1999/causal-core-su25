[
  {
    "task_name": "reaching",
    "fractional_reward_weight": "1.0",
    "dense_reward_weights": "[100000  50000  25000  10000]",
    "activate_sparse_reward": "False",
    "variables_space": "space_a_b",
    "joint_positions": "None",
    "default_goal_60": "[0.   0.   0.08]",
    "default_goal_120": "[0.   0.   0.08]",
    "default_goal_300": "[0.   0.   0.08]"
  },
  {
    "skip_frame": 5,
    "action_mode": "joint_positions",
    "observation_mode": "structured",
    "normalize_actions": true,
    "normalize_observations": true,
    "max_episode_length": 1500,
    "wrappers": {
      "curriculum_environment": {
        "actor_params": {
          "goal_actor": {},
          "physical_properties_actor": {
            "group": "tool"
          },
          "visual_actor": {},
          "joints_actor": {},
          "random_actor": {}
        },
        "actives": [
          [
            0,
            500000,
            1,
            0
          ],
          [
            200000,
            1000000,
            1,
            1
          ],
          [
            500000,
            1500000,
            1,
            2
          ],
          [
            800000,
            2000000,
            1,
            3
          ],
          [
            1200000,
            2500000,
            1,
            4
          ],
          [
            1800000,
            10000000,
            1,
            5
          ]
        ]
      },
      "her_environment": {
        "activate_sparse_reward": false
      }
    }
  },
  {
    "learning_rate": 0.0003,
    "train_freq": [
      1,
      "step"
    ],
    "gradient_steps": 1,
    "learning_starts": 5000,
    "tensorboard_log": "runs/reaching_seed42_20250623_160409",
    "buffer_size": 1000000,
    "gamma": 0.98,
    "batch_size": 256,
    "ent_coef": "auto",
    "target_update_interval": 1,
    "tau": 0.005,
    "target_entropy": "auto"
  }
]