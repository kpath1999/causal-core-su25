ðŸš€ Initializing GraphBasedCurriculumManager with 50000 timesteps
ðŸŽ² Exploration rate: 0.95, Learning rate: 0.2
ðŸ—ï¸  Building intervention dependency graph...
ðŸ”§ Created intervention node: goal_basic with params: {}
ðŸ”§ Created intervention node: pose_position with params: {'positions': True, 'orientations': False}
ðŸ”§ Created intervention node: pose_full with params: {'positions': True, 'orientations': True}
ðŸ”§ Created intervention node: physics_friction with params: {'group': 'friction'}
ðŸ”§ Created intervention node: physics_mass with params: {'group': 'mass'}
ðŸ”§ Created intervention node: visual with params: {}
ðŸ”§ Created intervention node: random_full with params: {}
âž• Added node to graph: goal_basic
âž• Added node to graph: pose_position
âž• Added node to graph: pose_full
âž• Added node to graph: physics_friction
âž• Added node to graph: physics_mass
âž• Added node to graph: visual
âž• Added node to graph: random_full
ðŸ”— Setting up dependencies:
   goal_basic â†’ pose_position
âš”ï¸  Setting up conflicts:
   physics_mass âš”ï¸ physics_friction
âœ… Graph construction complete: 7 nodes, 3 edges

ðŸŽ“ Generating curriculum configuration...

ðŸŽ² Selecting active interventions...

ðŸ” Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   âœ… goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=0, success_rate=0.000000)
   âœ… pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   âœ… pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   âœ… physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   âœ… physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   âœ… visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   âœ… random_full is ELIGIBLE
ðŸŽ¯ Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
ðŸ“‹ Processing 7 eligible interventions...
   goal_basic: NEW intervention (score=âˆž)
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: goal_basic
   goal_basic: âœ… ACTIVATED with strength 1.000
   pose_position: NEW intervention (score=âˆž)
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_position
   pose_position: âœ… ACTIVATED with strength 1.000
   pose_full: NEW intervention (score=âˆž)
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_full
   pose_full: âœ… ACTIVATED with strength 1.000
   physics_friction: NEW intervention (score=âˆž)
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: physics_friction
   physics_friction: âœ… ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=âˆž)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
   physics_mass: âš”ï¸  CONFLICT with ['physics_friction'] - skipping
   visual: NEW intervention (score=âˆž)
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: visual
   visual: âœ… ACTIVATED with strength 1.000
   random_full: NEW intervention (score=âˆž)
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: random_full
   random_full: âœ… ACTIVATED with strength 1.000

ðŸŽ‰ FINAL SELECTION: 6 interventions activated
   ðŸš€ goal_basic (strength: 1.000)
   ðŸš€ pose_position (strength: 1.000)
   ðŸš€ pose_full (strength: 1.000)
   ðŸš€ physics_friction (strength: 1.000)
   ðŸš€ visual (strength: 1.000)
   ðŸš€ random_full (strength: 1.000)
ðŸ”§ Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
âœ… Curriculum config ready: 6 actors, 6 active nodes
ðŸ”„ Curriculum callback initialized: adaptation every 30 episodes
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Logging to baseline_picking_her_sac_curriculum\her_sac_curriculum_2
ðŸ“Š Episode completed: reward=0.012964, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.012964, episode_success=True, active_nodes=[]
   Episode 1: Baseline reward updated 0.000000 â†’ 0.012964
ðŸ“Š Episode completed: reward=0.021572, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.021572, episode_success=True, active_nodes=[]
   Episode 2: Baseline reward updated 0.012964 â†’ 0.017268
ðŸ“Š Episode completed: reward=0.011025, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.011025, episode_success=True, active_nodes=[]
   Episode 3: Baseline reward updated 0.017268 â†’ 0.015187
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0114   |
| time/              |          |
|    episodes        | 4        |
|    fps             | 177      |
|    time_elapsed    | 4        |
|    total_timesteps | 804      |
---------------------------------
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 4: Baseline reward updated 0.015187 â†’ 0.011390
ðŸ“Š Episode completed: reward=0.011391, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.011391, episode_success=True, active_nodes=[]
   Episode 5: Baseline reward updated 0.011390 â†’ 0.011390
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 6: Baseline reward updated 0.011390 â†’ 0.009492
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 7: Baseline reward updated 0.009492 â†’ 0.008136
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.00712  |
| time/              |          |
|    episodes        | 8        |
|    fps             | 47       |
|    time_elapsed    | 33       |
|    total_timesteps | 1608     |
| train/             |          |
|    actor_loss      | -38.2    |
|    critic_loss     | 87.1     |
|    ent_coef        | 0.869    |
|    ent_coef_loss   | -1.38    |
|    learning_rate   | 0.00025  |
|    n_updates       | 607      |
---------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 8: Baseline reward updated 0.008136 â†’ 0.007119
ðŸ“Š Episode completed: reward=0.100298, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.100298, episode_success=True, active_nodes=[]
   Episode 9: Baseline reward updated 0.007119 â†’ 0.017472
ðŸ“Š Episode completed: reward=0.012852, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.012852, episode_success=True, active_nodes=[]
   Episode 10: Baseline reward updated 0.017472 â†’ 0.017010
ðŸ“Š Episode completed: reward=0.001078, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.001078, episode_success=True, active_nodes=[]
   Episode 11: Baseline reward updated 0.017010 â†’ 0.015822
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0143   |
| time/              |          |
|    episodes        | 12       |
|    fps             | 30       |
|    time_elapsed    | 80       |
|    total_timesteps | 2412     |
| train/             |          |
|    actor_loss      | -141     |
|    critic_loss     | 173      |
|    ent_coef        | 0.791    |
|    ent_coef_loss   | 0.0765   |
|    learning_rate   | 0.00025  |
|    n_updates       | 1411     |
---------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 12: Baseline reward updated 0.015822 â†’ 0.013664
ðŸ“Š Episode completed: reward=0.027717, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.027717, episode_success=True, active_nodes=[]
   Episode 13: Baseline reward updated 0.013664 â†’ 0.015334
ðŸ“Š Episode completed: reward=0.356540, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.356540, episode_success=True, active_nodes=[]
   Episode 14: Baseline reward updated 0.015334 â†’ 0.050988
ðŸ“Š Episode completed: reward=0.016303, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.016303, episode_success=True, active_nodes=[]
   Episode 15: Baseline reward updated 0.050988 â†’ 0.051479
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0357   |
| time/              |          |
|    episodes        | 16       |
|    fps             | 26       |
|    time_elapsed    | 120      |
|    total_timesteps | 3216     |
| train/             |          |
|    actor_loss      | -448     |
|    critic_loss     | 1.63e+03 |
|    ent_coef        | 0.925    |
|    ent_coef_loss   | 0.714    |
|    learning_rate   | 0.00025  |
|    n_updates       | 2215     |
---------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 16: Baseline reward updated 0.051479 â†’ 0.051479
ðŸ“Š Episode completed: reward=0.665082, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.665082, episode_success=True, active_nodes=[]
   Episode 17: Baseline reward updated 0.051479 â†’ 0.117987
ðŸ“Š Episode completed: reward=0.148452, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.148452, episode_success=True, active_nodes=[]
   Episode 18: Baseline reward updated 0.117987 â†’ 0.132832
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 19: Baseline reward updated 0.132832 â†’ 0.122802
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0693    |
| time/              |           |
|    episodes        | 20        |
|    fps             | 23        |
|    time_elapsed    | 169       |
|    total_timesteps | 4020      |
| train/             |           |
|    actor_loss      | -1.04e+03 |
|    critic_loss     | 1.45e+04  |
|    ent_coef        | 1.21      |
|    ent_coef_loss   | -3.46     |
|    learning_rate   | 0.00025   |
|    n_updates       | 3019      |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 20: Baseline reward updated 0.122802 â†’ 0.121517
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 21: Baseline reward updated 0.121517 â†’ 0.121409
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 22: Baseline reward updated 0.121409 â†’ 0.121409
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 23: Baseline reward updated 0.121409 â†’ 0.118638
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.079     |
| time/              |           |
|    episodes        | 24        |
|    fps             | 22        |
|    time_elapsed    | 216       |
|    total_timesteps | 4824      |
| train/             |           |
|    actor_loss      | -2.72e+03 |
|    critic_loss     | 1.21e+05  |
|    ent_coef        | 1.58      |
|    ent_coef_loss   | -9.57     |
|    learning_rate   | 0.00025   |
|    n_updates       | 3823      |
----------------------------------
ðŸ“Š Episode completed: reward=0.510618, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.510618, episode_success=True, active_nodes=[]
   Episode 24: Baseline reward updated 0.118638 â†’ 0.134045
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.001407, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.001407, episode_success=True, active_nodes=[]
   Episode 25: Baseline reward updated 0.134045 â†’ 0.132556
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 26: Baseline reward updated 0.132556 â†’ 0.132556
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 27: Baseline reward updated 0.132556 â†’ 0.066048
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0678    |
| time/              |           |
|    episodes        | 28        |
|    fps             | 20        |
|    time_elapsed    | 268       |
|    total_timesteps | 5628      |
| train/             |           |
|    actor_loss      | -6.95e+03 |
|    critic_loss     | 1.45e+06  |
|    ent_coef        | 2.1       |
|    ent_coef_loss   | -24.2     |
|    learning_rate   | 0.00025   |
|    n_updates       | 4627      |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 28: Baseline reward updated 0.066048 â†’ 0.051203
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 29: Baseline reward updated 0.051203 â†’ 0.051203

ðŸ”„ CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
ðŸ”„ Adapting curriculum...

ðŸŽ“ Generating curriculum configuration...

ðŸŽ² Selecting active interventions...

ðŸ” Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   âœ… goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=0, success_rate=0.000000)
   âœ… pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   âœ… pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   âœ… physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   âœ… physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   âœ… visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   âœ… random_full is ELIGIBLE
ðŸŽ¯ Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
ðŸ“‹ Processing 7 eligible interventions...
   goal_basic: NEW intervention (score=âˆž)
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: goal_basic
   goal_basic: âœ… ACTIVATED with strength 1.000
   pose_position: NEW intervention (score=âˆž)
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_position
   pose_position: âœ… ACTIVATED with strength 1.000
   pose_full: NEW intervention (score=âˆž)
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_full
   pose_full: âœ… ACTIVATED with strength 1.000
   physics_friction: NEW intervention (score=âˆž)
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: physics_friction
   physics_friction: âœ… ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=âˆž)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
   physics_mass: âš”ï¸  CONFLICT with ['physics_friction'] - skipping
   visual: NEW intervention (score=âˆž)
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: visual
   visual: âœ… ACTIVATED with strength 1.000
   random_full: NEW intervention (score=âˆž)
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: random_full
   random_full: âœ… ACTIVATED with strength 1.000

ðŸŽ‰ FINAL SELECTION: 6 interventions activated
   ðŸš€ goal_basic (strength: 1.000)
   ðŸš€ pose_position (strength: 1.000)
   ðŸš€ pose_full (strength: 1.000)
   ðŸš€ physics_friction (strength: 1.000)
   ðŸš€ visual (strength: 1.000)
   ðŸš€ random_full (strength: 1.000)
ðŸ”§ Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
âœ… Curriculum config ready: 6 actors, 6 active nodes
ðŸ”§ Updating curriculum wrapper...
ðŸ”§ Updating internal curriculum object...
ðŸ”§ Reinitializing curriculum actors...
[34m[1mwandb[0m: [33mWARNING[0m Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
âœ… Curriculum updated successfully!
   ðŸ“Š Active interventions: 6
   ðŸŽ¯ Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   ðŸŽ² Exploration rate: 0.9472
   ðŸ“ˆ Baseline reward: 0.051203
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 30: Baseline reward updated 0.051203 â†’ 0.051203
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 31: Baseline reward updated 0.051203 â†’ 0.051203
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 2
ðŸŽ¯ Node goal_basic: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 2
ðŸŽ¯ Node pose_position: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 2
ðŸŽ¯ Node pose_full: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 2
ðŸŽ¯ Node physics_friction: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 2
ðŸŽ¯ Node visual: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 2
ðŸŽ¯ Node random_full: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0593   |
| time/              |          |
|    episodes        | 32       |
|    fps             | 20       |
|    time_elapsed    | 313      |
|    total_timesteps | 6432     |
| train/             |          |
|    actor_loss      | -1.5e+04 |
|    critic_loss     | 8.03e+06 |
|    ent_coef        | 2.71     |
|    ent_coef_loss   | -46.3    |
|    learning_rate   | 0.00025  |
|    n_updates       | 5431     |
---------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 32: Baseline reward updated 0.051203 â†’ 0.051203
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 3
ðŸŽ¯ Node goal_basic: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 3
ðŸŽ¯ Node pose_position: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 3
ðŸŽ¯ Node pose_full: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 3
ðŸŽ¯ Node physics_friction: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 3
ðŸŽ¯ Node visual: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 3
ðŸŽ¯ Node random_full: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
ðŸ“Š Episode completed: reward=0.005459, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.005459, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 33: Baseline reward updated 0.051203 â†’ 0.051748
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.001365, Times activated: 4
ðŸŽ¯ Node goal_basic: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.001365, Times activated: 4
ðŸŽ¯ Node pose_position: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.001365, Times activated: 4
ðŸŽ¯ Node pose_full: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.001365, Times activated: 4
ðŸŽ¯ Node physics_friction: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.001365, Times activated: 4
ðŸŽ¯ Node visual: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.001365, Times activated: 4
ðŸŽ¯ Node random_full: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
ðŸ“Š Episode completed: reward=0.004722, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.004722, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 34: Baseline reward updated 0.051748 â†’ 0.001159
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.002036, Times activated: 5
ðŸŽ¯ Node goal_basic: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.002036, Times activated: 5
ðŸŽ¯ Node pose_position: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.002036, Times activated: 5
ðŸŽ¯ Node pose_full: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.002036, Times activated: 5
ðŸŽ¯ Node physics_friction: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.002036, Times activated: 5
ðŸŽ¯ Node visual: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.002036, Times activated: 5
ðŸŽ¯ Node random_full: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 35: Baseline reward updated 0.001159 â†’ 0.001018
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.002036, Times activated: 6
ðŸŽ¯ Node goal_basic: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.002036, Times activated: 6
ðŸŽ¯ Node pose_position: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.002036, Times activated: 6
ðŸŽ¯ Node pose_full: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.002036, Times activated: 6
ðŸŽ¯ Node physics_friction: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.002036, Times activated: 6
ðŸŽ¯ Node visual: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.002036, Times activated: 6
ðŸŽ¯ Node random_full: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0558    |
| time/              |           |
|    episodes        | 36        |
|    fps             | 20        |
|    time_elapsed    | 356       |
|    total_timesteps | 7236      |
| train/             |           |
|    actor_loss      | -2.55e+04 |
|    critic_loss     | 3.3e+07   |
|    ent_coef        | 3.48      |
|    ent_coef_loss   | -57       |
|    learning_rate   | 0.00025   |
|    n_updates       | 6235      |
----------------------------------
ðŸ“Š Episode completed: reward=0.100792, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.100792, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 36: Baseline reward updated 0.001018 â†’ 0.011097
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.022195, Times activated: 7
ðŸŽ¯ Node goal_basic: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.022195, Times activated: 7
ðŸŽ¯ Node pose_position: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.022195, Times activated: 7
ðŸŽ¯ Node pose_full: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.022195, Times activated: 7
ðŸŽ¯ Node physics_friction: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.022195, Times activated: 7
ðŸŽ¯ Node visual: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.022195, Times activated: 7
ðŸŽ¯ Node random_full: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
ðŸ“Š Episode completed: reward=0.000001, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000001, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 37: Baseline reward updated 0.011097 â†’ 0.011097
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.022195, Times activated: 8
ðŸŽ¯ Node goal_basic: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.022195, Times activated: 8
ðŸŽ¯ Node pose_position: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.022195, Times activated: 8
ðŸŽ¯ Node pose_full: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.022195, Times activated: 8
ðŸŽ¯ Node physics_friction: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.022195, Times activated: 8
ðŸŽ¯ Node visual: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.022195, Times activated: 8
ðŸŽ¯ Node random_full: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
ðŸ“Š Episode completed: reward=0.031173, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.031173, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 38: Baseline reward updated 0.011097 â†’ 0.014215
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.027338, Times activated: 9
ðŸŽ¯ Node goal_basic: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.027338, Times activated: 9
ðŸŽ¯ Node pose_position: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.027338, Times activated: 9
ðŸŽ¯ Node pose_full: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.027338, Times activated: 9
ðŸŽ¯ Node physics_friction: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.027338, Times activated: 9
ðŸŽ¯ Node visual: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.027338, Times activated: 9
ðŸŽ¯ Node random_full: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
ðŸ“Š Episode completed: reward=0.200617, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.200617, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 39: Baseline reward updated 0.014215 â†’ 0.034276
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.066517, Times activated: 10
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.066517, Times activated: 10
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.066517, Times activated: 10
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.066517, Times activated: 10
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.066517, Times activated: 10
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.066517, Times activated: 10
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0573    |
| time/              |           |
|    episodes        | 40        |
|    fps             | 19        |
|    time_elapsed    | 402       |
|    total_timesteps | 8040      |
| train/             |           |
|    actor_loss      | -3.87e+04 |
|    critic_loss     | 8.33e+07  |
|    ent_coef        | 4.38      |
|    ent_coef_loss   | -72.6     |
|    learning_rate   | 0.00025   |
|    n_updates       | 7039      |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.052205, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.052205, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 40: Baseline reward updated 0.034276 â†’ 0.039497
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.076958, Times activated: 11
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.076958, Times activated: 11
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.076958, Times activated: 11
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.076958, Times activated: 11
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.076958, Times activated: 11
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.076958, Times activated: 11
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 41: Baseline reward updated 0.039497 â†’ 0.039497
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.056799, Times activated: 12
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.056799, Times activated: 12
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.056799, Times activated: 12
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.056799, Times activated: 12
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.056799, Times activated: 12
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.056799, Times activated: 12
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 42: Baseline reward updated 0.039497 â†’ 0.039497
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.056799, Times activated: 13
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.056799, Times activated: 13
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.056799, Times activated: 13
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.056799, Times activated: 13
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.056799, Times activated: 13
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.056799, Times activated: 13
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
ðŸ“Š Episode completed: reward=0.029870, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.029870, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 43: Baseline reward updated 0.039497 â†’ 0.041938
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.056538, Times activated: 14
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.056538, Times activated: 14
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.056538, Times activated: 14
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.056538, Times activated: 14
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.056538, Times activated: 14
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.056538, Times activated: 14
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0528    |
| time/              |           |
|    episodes        | 44        |
|    fps             | 20        |
|    time_elapsed    | 441       |
|    total_timesteps | 8844      |
| train/             |           |
|    actor_loss      | -5.86e+04 |
|    critic_loss     | 1.64e+08  |
|    ent_coef        | 5.47      |
|    ent_coef_loss   | -88.9     |
|    learning_rate   | 0.00025   |
|    n_updates       | 7843      |
----------------------------------
ðŸ“Š Episode completed: reward=0.000005, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000005, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 44: Baseline reward updated 0.041938 â†’ 0.041466
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.016416, Times activated: 15
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.016416, Times activated: 15
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.016416, Times activated: 15
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.016416, Times activated: 15
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.016416, Times activated: 15
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.016416, Times activated: 15
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 45: Baseline reward updated 0.041466 â†’ 0.041466
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.005975, Times activated: 16
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.005975, Times activated: 16
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.005975, Times activated: 16
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.005975, Times activated: 16
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.005975, Times activated: 16
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.005975, Times activated: 16
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 46: Baseline reward updated 0.041466 â†’ 0.031387
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.005975, Times activated: 17
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.005975, Times activated: 17
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.005975, Times activated: 17
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.005975, Times activated: 17
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.005975, Times activated: 17
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.005975, Times activated: 17
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 47: Baseline reward updated 0.031387 â†’ 0.031387
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.005975, Times activated: 18
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.005975, Times activated: 18
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.005975, Times activated: 18
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.005975, Times activated: 18
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.005975, Times activated: 18
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.005975, Times activated: 18
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0491   |
| time/              |          |
|    episodes        | 48       |
|    fps             | 20       |
|    time_elapsed    | 480      |
|    total_timesteps | 9648     |
| train/             |          |
|    actor_loss      | -7.5e+04 |
|    critic_loss     | 3.9e+08  |
|    ent_coef        | 6.76     |
|    ent_coef_loss   | -103     |
|    learning_rate   | 0.00025  |
|    n_updates       | 8647     |
---------------------------------
ðŸ“Š Episode completed: reward=0.036051, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.036051, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 48: Baseline reward updated 0.031387 â†’ 0.031875
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.007211, Times activated: 19
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.007211, Times activated: 19
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.007211, Times activated: 19
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.007211, Times activated: 19
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.007211, Times activated: 19
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.007211, Times activated: 19
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
ðŸ“Š Episode completed: reward=0.038879, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.038879, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 49: Baseline reward updated 0.031875 â†’ 0.015701
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.014986, Times activated: 20
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.014986, Times activated: 20
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.014986, Times activated: 20
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.014986, Times activated: 20
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.014986, Times activated: 20
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.014986, Times activated: 20
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.038990, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.038990, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 50: Baseline reward updated 0.015701 â†’ 0.014379
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.022784, Times activated: 21
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.022784, Times activated: 21
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.022784, Times activated: 21
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.022784, Times activated: 21
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.022784, Times activated: 21
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.022784, Times activated: 21
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.001756, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.001756, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 51: Baseline reward updated 0.014379 â†’ 0.014555
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.023135, Times activated: 22
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.023135, Times activated: 22
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.023135, Times activated: 22
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.023135, Times activated: 22
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.023135, Times activated: 22
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.023135, Times activated: 22
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0504    |
| time/              |           |
|    episodes        | 52        |
|    fps             | 19        |
|    time_elapsed    | 526       |
|    total_timesteps | 10452     |
| train/             |           |
|    actor_loss      | -9.32e+04 |
|    critic_loss     | 6.31e+08  |
|    ent_coef        | 8.37      |
|    ent_coef_loss   | -136      |
|    learning_rate   | 0.00025   |
|    n_updates       | 9451      |
----------------------------------
ðŸ“Š Episode completed: reward=0.180847, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.180847, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 52: Baseline reward updated 0.014555 â†’ 0.032640
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.059305, Times activated: 23
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.059305, Times activated: 23
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.059305, Times activated: 23
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.059305, Times activated: 23
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.059305, Times activated: 23
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.059305, Times activated: 23
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
ðŸ“Š Episode completed: reward=0.033781, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.033781, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 53: Baseline reward updated 0.032640 â†’ 0.033031
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.058851, Times activated: 24
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.058851, Times activated: 24
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.058851, Times activated: 24
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.058851, Times activated: 24
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.058851, Times activated: 24
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.058851, Times activated: 24
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
ðŸ“Š Episode completed: reward=0.073651, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.073651, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 54: Baseline reward updated 0.033031 â†’ 0.040396
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.065805, Times activated: 25
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.065805, Times activated: 25
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.065805, Times activated: 25
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.065805, Times activated: 25
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.065805, Times activated: 25
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.065805, Times activated: 25
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
ðŸ“Š Episode completed: reward=0.025576, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.025576, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 55: Baseline reward updated 0.040396 â†’ 0.042953
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.063122, Times activated: 26
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.063122, Times activated: 26
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.063122, Times activated: 26
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.063122, Times activated: 26
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.063122, Times activated: 26
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.063122, Times activated: 26
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0505    |
| time/              |           |
|    episodes        | 56        |
|    fps             | 19        |
|    time_elapsed    | 573       |
|    total_timesteps | 11256     |
| train/             |           |
|    actor_loss      | -1.17e+05 |
|    critic_loss     | 8.79e+08  |
|    ent_coef        | 10.5      |
|    ent_coef_loss   | -161      |
|    learning_rate   | 0.00025   |
|    n_updates       | 10255     |
----------------------------------
ðŸ“Š Episode completed: reward=0.077191, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.077191, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 56: Baseline reward updated 0.042953 â†’ 0.050672
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.078209, Times activated: 27
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.078209, Times activated: 27
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.078209, Times activated: 27
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.078209, Times activated: 27
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.078209, Times activated: 27
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.078209, Times activated: 27
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
ðŸ“Š Episode completed: reward=0.160712, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.160712, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 57: Baseline reward updated 0.050672 â†’ 0.066743
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.074182, Times activated: 28
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.074182, Times activated: 28
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.074182, Times activated: 28
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.074182, Times activated: 28
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.074182, Times activated: 28
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.074182, Times activated: 28
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 58: Baseline reward updated 0.066743 â†’ 0.063138
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.067426, Times activated: 29
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.067426, Times activated: 29
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.067426, Times activated: 29
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.067426, Times activated: 29
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.067426, Times activated: 29
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.067426, Times activated: 29
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
ðŸ“Š Episode completed: reward=0.193863, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.193863, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 59: Baseline reward updated 0.063138 â†’ 0.078637
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.091468, Times activated: 30
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.091468, Times activated: 30
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.091468, Times activated: 30
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.091468, Times activated: 30
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.091468, Times activated: 30
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.091468, Times activated: 30
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)

ðŸ”„ CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
ðŸ”„ Adapting curriculum...

ðŸŽ“ Generating curriculum configuration...

ðŸŽ² Selecting active interventions...

ðŸ” Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   âœ… goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=30, success_rate=0.091468)
   âœ… pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   âœ… pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   âœ… physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   âœ… physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   âœ… visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   âœ… random_full is ELIGIBLE
ðŸŽ¯ Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
ðŸ“‹ Processing 7 eligible interventions...
   goal_basic: avg_reward=0.091468, confidence=0.521379, score=1.655605
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: goal_basic
   goal_basic: âœ… ACTIVATED with strength 1.000
   pose_position: avg_reward=0.091468, confidence=0.521379, score=1.655605
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_position
   pose_position: âœ… ACTIVATED with strength 1.000
   pose_full: avg_reward=0.091468, confidence=0.521379, score=1.655605
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_full
   pose_full: âœ… ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.091468, confidence=0.521379, score=1.655605
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: physics_friction
   physics_friction: âœ… ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=âˆž)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
   physics_mass: âš”ï¸  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.091468, confidence=0.521379, score=1.655605
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: visual
   visual: âœ… ACTIVATED with strength 1.000
   random_full: avg_reward=0.091468, confidence=0.521379, score=1.655605
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: random_full
   random_full: âœ… ACTIVATED with strength 1.000

ðŸŽ‰ FINAL SELECTION: 6 interventions activated
   ðŸš€ goal_basic (strength: 1.000)
   ðŸš€ pose_position (strength: 1.000)
   ðŸš€ pose_full (strength: 1.000)
   ðŸš€ physics_friction (strength: 1.000)
   ðŸš€ visual (strength: 1.000)
   ðŸš€ random_full (strength: 1.000)
ðŸ”§ Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
âœ… Curriculum config ready: 6 actors, 6 active nodes
ðŸ”§ Updating curriculum wrapper...
ðŸ”§ Updating internal curriculum object...
ðŸ”§ Reinitializing curriculum actors...
âœ… Curriculum updated successfully!
   ðŸ“Š Active interventions: 6
   ðŸŽ¯ Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   ðŸŽ² Exploration rate: 0.9444
   ðŸ“ˆ Baseline reward: 0.078637
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0532    |
| time/              |           |
|    episodes        | 60        |
|    fps             | 19        |
|    time_elapsed    | 614       |
|    total_timesteps | 12060     |
| train/             |           |
|    actor_loss      | -1.39e+05 |
|    critic_loss     | 1.31e+09  |
|    ent_coef        | 13.1      |
|    ent_coef_loss   | -170      |
|    learning_rate   | 0.00025   |
|    n_updates       | 11059     |
----------------------------------
ðŸ“Š Episode completed: reward=0.008286, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.008286, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 60: Baseline reward updated 0.078637 â†’ 0.075566
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.088010, Times activated: 31
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.088010, Times activated: 31
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.088010, Times activated: 31
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.088010, Times activated: 31
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.088010, Times activated: 31
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.088010, Times activated: 31
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 61: Baseline reward updated 0.075566 â†’ 0.075391
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.072572, Times activated: 32
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.072572, Times activated: 32
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.072572, Times activated: 32
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.072572, Times activated: 32
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.072572, Times activated: 32
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.072572, Times activated: 32
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
ðŸ“Š Episode completed: reward=0.022052, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.022052, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 62: Baseline reward updated 0.075391 â†’ 0.059511
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.044840, Times activated: 33
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.044840, Times activated: 33
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.044840, Times activated: 33
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.044840, Times activated: 33
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.044840, Times activated: 33
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.044840, Times activated: 33
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
ðŸ“Š Episode completed: reward=0.243648, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.243648, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 63: Baseline reward updated 0.059511 â†’ 0.080498
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.093570, Times activated: 34
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.093570, Times activated: 34
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.093570, Times activated: 34
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.093570, Times activated: 34
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.093570, Times activated: 34
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.093570, Times activated: 34
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.054     |
| time/              |           |
|    episodes        | 64        |
|    fps             | 19        |
|    time_elapsed    | 654       |
|    total_timesteps | 12864     |
| train/             |           |
|    actor_loss      | -1.75e+05 |
|    critic_loss     | 1.85e+09  |
|    ent_coef        | 16        |
|    ent_coef_loss   | -188      |
|    learning_rate   | 0.00025   |
|    n_updates       | 11863     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 64: Baseline reward updated 0.080498 â†’ 0.073133
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.054797, Times activated: 35
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.054797, Times activated: 35
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.054797, Times activated: 35
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.054797, Times activated: 35
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.054797, Times activated: 35
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.054797, Times activated: 35
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
ðŸ“Š Episode completed: reward=0.511136, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.511136, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 65: Baseline reward updated 0.073133 â†’ 0.121689
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.155367, Times activated: 36
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.155367, Times activated: 36
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.155367, Times activated: 36
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.155367, Times activated: 36
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.155367, Times activated: 36
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.155367, Times activated: 36
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
ðŸ“Š Episode completed: reward=0.398641, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.398641, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 66: Baseline reward updated 0.121689 â†’ 0.153834
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.235095, Times activated: 37
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.235095, Times activated: 37
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.235095, Times activated: 37
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.235095, Times activated: 37
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.235095, Times activated: 37
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.235095, Times activated: 37
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=1.227558, success=True

ðŸ“ˆ Updating graph performance: episode_reward=1.227558, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 67: Baseline reward updated 0.153834 â†’ 0.260518
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.476197, Times activated: 38
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.476197, Times activated: 38
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.476197, Times activated: 38
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.476197, Times activated: 38
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.476197, Times activated: 38
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.476197, Times activated: 38
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0823    |
| time/              |           |
|    episodes        | 68        |
|    fps             | 19        |
|    time_elapsed    | 701       |
|    total_timesteps | 13668     |
| train/             |           |
|    actor_loss      | -2.02e+05 |
|    critic_loss     | 2.34e+09  |
|    ent_coef        | 19.7      |
|    ent_coef_loss   | -206      |
|    learning_rate   | 0.00025   |
|    n_updates       | 12667     |
----------------------------------
ðŸ“Š Episode completed: reward=0.002884, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.002884, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 68: Baseline reward updated 0.260518 â†’ 0.260807
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.428044, Times activated: 39
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.428044, Times activated: 39
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.428044, Times activated: 39
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.428044, Times activated: 39
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.428044, Times activated: 39
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.428044, Times activated: 39
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 69: Baseline reward updated 0.260807 â†’ 0.241420
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.428044, Times activated: 40
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.428044, Times activated: 40
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.428044, Times activated: 40
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.428044, Times activated: 40
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.428044, Times activated: 40
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.428044, Times activated: 40
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 70: Baseline reward updated 0.241420 â†’ 0.240592
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.325817, Times activated: 41
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.325817, Times activated: 41
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.325817, Times activated: 41
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.325817, Times activated: 41
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.325817, Times activated: 41
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.325817, Times activated: 41
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 71: Baseline reward updated 0.240592 â†’ 0.240592
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.246088, Times activated: 42
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.246088, Times activated: 42
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.246088, Times activated: 42
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.246088, Times activated: 42
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.246088, Times activated: 42
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.246088, Times activated: 42
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0777    |
| time/              |           |
|    episodes        | 72        |
|    fps             | 19        |
|    time_elapsed    | 743       |
|    total_timesteps | 14472     |
| train/             |           |
|    actor_loss      | -2.28e+05 |
|    critic_loss     | 3.42e+09  |
|    ent_coef        | 24.1      |
|    ent_coef_loss   | -228      |
|    learning_rate   | 0.00025   |
|    n_updates       | 13471     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 72: Baseline reward updated 0.240592 â†’ 0.238387
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000577, Times activated: 43
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000577, Times activated: 43
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000577, Times activated: 43
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000577, Times activated: 43
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000577, Times activated: 43
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000577, Times activated: 43
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 73: Baseline reward updated 0.238387 â†’ 0.214022
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 44
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 44
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 44
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 44
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 44
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 44
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
ðŸ“Š Episode completed: reward=0.123864, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.123864, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 74: Baseline reward updated 0.214022 â†’ 0.226408
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.024773, Times activated: 45
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.024773, Times activated: 45
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.024773, Times activated: 45
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.024773, Times activated: 45
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.024773, Times activated: 45
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.024773, Times activated: 45
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
ðŸ“Š Episode completed: reward=0.008742, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.008742, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 75: Baseline reward updated 0.226408 â†’ 0.176169
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.026521, Times activated: 46
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.026521, Times activated: 46
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.026521, Times activated: 46
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.026521, Times activated: 46
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.026521, Times activated: 46
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.026521, Times activated: 46
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0765    |
| time/              |           |
|    episodes        | 76        |
|    fps             | 19        |
|    time_elapsed    | 785       |
|    total_timesteps | 15276     |
| train/             |           |
|    actor_loss      | -2.27e+05 |
|    critic_loss     | 3.36e+09  |
|    ent_coef        | 29.5      |
|    ent_coef_loss   | -234      |
|    learning_rate   | 0.00025   |
|    n_updates       | 14275     |
----------------------------------
ðŸ“Š Episode completed: reward=0.085126, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.085126, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 76: Baseline reward updated 0.176169 â†’ 0.144817
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.043546, Times activated: 47
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.043546, Times activated: 47
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.043546, Times activated: 47
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.043546, Times activated: 47
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.043546, Times activated: 47
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.043546, Times activated: 47
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
ðŸ“Š Episode completed: reward=0.072760, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.072760, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 77: Baseline reward updated 0.144817 â†’ 0.029338
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.058098, Times activated: 48
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.058098, Times activated: 48
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.058098, Times activated: 48
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.058098, Times activated: 48
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.058098, Times activated: 48
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.058098, Times activated: 48
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
ðŸ“Š Episode completed: reward=1.207320, success=True

ðŸ“ˆ Updating graph performance: episode_reward=1.207320, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 78: Baseline reward updated 0.029338 â†’ 0.149781
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.299562, Times activated: 49
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.299562, Times activated: 49
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.299562, Times activated: 49
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.299562, Times activated: 49
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.299562, Times activated: 49
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.299562, Times activated: 49
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
ðŸ“Š Episode completed: reward=0.647630, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.647630, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 79: Baseline reward updated 0.149781 â†’ 0.214544
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.404316, Times activated: 50
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.404316, Times activated: 50
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.404316, Times activated: 50
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.404316, Times activated: 50
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.404316, Times activated: 50
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.404316, Times activated: 50
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0978    |
| time/              |           |
|    episodes        | 80        |
|    fps             | 19        |
|    time_elapsed    | 829       |
|    total_timesteps | 16080     |
| train/             |           |
|    actor_loss      | -2.89e+05 |
|    critic_loss     | 4.99e+09  |
|    ent_coef        | 36.2      |
|    ent_coef_loss   | -261      |
|    learning_rate   | 0.00025   |
|    n_updates       | 15079     |
----------------------------------
ðŸ“Š Episode completed: reward=0.081927, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.081927, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 80: Baseline reward updated 0.214544 â†’ 0.222737
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.418953, Times activated: 51
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.418953, Times activated: 51
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.418953, Times activated: 51
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.418953, Times activated: 51
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.418953, Times activated: 51
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.418953, Times activated: 51
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 81: Baseline reward updated 0.222737 â†’ 0.222737
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.401927, Times activated: 52
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.401927, Times activated: 52
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.401927, Times activated: 52
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.401927, Times activated: 52
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.401927, Times activated: 52
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.401927, Times activated: 52
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
ðŸ“Š Episode completed: reward=0.000016, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000016, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 82: Baseline reward updated 0.222737 â†’ 0.222738
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.387379, Times activated: 53
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.387379, Times activated: 53
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.387379, Times activated: 53
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.387379, Times activated: 53
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.387379, Times activated: 53
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.387379, Times activated: 53
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 83: Baseline reward updated 0.222738 â†’ 0.222739
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.145915, Times activated: 54
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.145915, Times activated: 54
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.145915, Times activated: 54
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.145915, Times activated: 54
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.145915, Times activated: 54
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.145915, Times activated: 54
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0932    |
| time/              |           |
|    episodes        | 84        |
|    fps             | 19        |
|    time_elapsed    | 881       |
|    total_timesteps | 16884     |
| train/             |           |
|    actor_loss      | -2.66e+05 |
|    critic_loss     | 5.17e+09  |
|    ent_coef        | 44.3      |
|    ent_coef_loss   | -264      |
|    learning_rate   | 0.00025   |
|    n_updates       | 15883     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 84: Baseline reward updated 0.222739 â†’ 0.210352
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.016389, Times activated: 55
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.016389, Times activated: 55
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.016389, Times activated: 55
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.016389, Times activated: 55
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.016389, Times activated: 55
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.016389, Times activated: 55
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 85: Baseline reward updated 0.210352 â†’ 0.209478
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000003, Times activated: 56
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000003, Times activated: 56
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000003, Times activated: 56
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000003, Times activated: 56
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000003, Times activated: 56
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000003, Times activated: 56
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 86: Baseline reward updated 0.209478 â†’ 0.200965
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000003, Times activated: 57
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000003, Times activated: 57
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000003, Times activated: 57
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000003, Times activated: 57
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000003, Times activated: 57
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000003, Times activated: 57
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 87: Baseline reward updated 0.200965 â†’ 0.193689
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 58
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 58
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 58
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 58
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 58
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 58
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0889    |
| time/              |           |
|    episodes        | 88        |
|    fps             | 19        |
|    time_elapsed    | 923       |
|    total_timesteps | 17688     |
| train/             |           |
|    actor_loss      | -3.66e+05 |
|    critic_loss     | 9.28e+09  |
|    ent_coef        | 54        |
|    ent_coef_loss   | -278      |
|    learning_rate   | 0.00025   |
|    n_updates       | 16687     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000755, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000755, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 88: Baseline reward updated 0.193689 â†’ 0.073033
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000151, Times activated: 59
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000151, Times activated: 59
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000151, Times activated: 59
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000151, Times activated: 59
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000151, Times activated: 59
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000151, Times activated: 59
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
ðŸ“Š Episode completed: reward=0.003412, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.003412, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 89: Baseline reward updated 0.073033 â†’ 0.008611
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000833, Times activated: 60
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000833, Times activated: 60
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000833, Times activated: 60
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000833, Times activated: 60
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000833, Times activated: 60
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000833, Times activated: 60
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)

ðŸ”„ CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
ðŸ”„ Adapting curriculum...

ðŸŽ“ Generating curriculum configuration...

ðŸŽ² Selecting active interventions...

ðŸ” Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   âœ… goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.000833)
   âœ… pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   âœ… pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   âœ… physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   âœ… physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   âœ… visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   âœ… random_full is ELIGIBLE
ðŸŽ¯ Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
ðŸ“‹ Processing 7 eligible interventions...
   goal_basic: avg_reward=0.000833, confidence=0.423728, score=1.272018
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: goal_basic
   goal_basic: âœ… ACTIVATED with strength 1.000
   pose_position: avg_reward=0.000833, confidence=0.423728, score=1.272018
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_position
   pose_position: âœ… ACTIVATED with strength 1.000
   pose_full: avg_reward=0.000833, confidence=0.423728, score=1.272018
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_full
   pose_full: âœ… ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.000833, confidence=0.423728, score=1.272018
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: physics_friction
   physics_friction: âœ… ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=âˆž)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
   physics_mass: âš”ï¸  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.000833, confidence=0.423728, score=1.272018
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: visual
   visual: âœ… ACTIVATED with strength 1.000
   random_full: avg_reward=0.000833, confidence=0.423728, score=1.272018
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: random_full
   random_full: âœ… ACTIVATED with strength 1.000

ðŸŽ‰ FINAL SELECTION: 6 interventions activated
   ðŸš€ goal_basic (strength: 1.000)
   ðŸš€ pose_position (strength: 1.000)
   ðŸš€ pose_full (strength: 1.000)
   ðŸš€ physics_friction (strength: 1.000)
   ðŸš€ visual (strength: 1.000)
   ðŸš€ random_full (strength: 1.000)
ðŸ”§ Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
âœ… Curriculum config ready: 6 actors, 6 active nodes
ðŸ”§ Updating curriculum wrapper...
ðŸ”§ Updating internal curriculum object...
ðŸ”§ Reinitializing curriculum actors...
âœ… Curriculum updated successfully!
   ðŸ“Š Active interventions: 6
   ðŸŽ¯ Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   ðŸŽ² Exploration rate: 0.9416
   ðŸ“ˆ Baseline reward: 0.008611
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 90: Baseline reward updated 0.008611 â†’ 0.000418
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000833, Times activated: 61
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000833, Times activated: 61
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000833, Times activated: 61
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000833, Times activated: 61
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000833, Times activated: 61
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000833, Times activated: 61
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
ðŸ“Š Episode completed: reward=0.004987, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.004987, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 91: Baseline reward updated 0.000418 â†’ 0.000917
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.001831, Times activated: 62
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.001831, Times activated: 62
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.001831, Times activated: 62
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.001831, Times activated: 62
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.001831, Times activated: 62
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.001831, Times activated: 62
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0852    |
| time/              |           |
|    episodes        | 92        |
|    fps             | 19        |
|    time_elapsed    | 960       |
|    total_timesteps | 18492     |
| train/             |           |
|    actor_loss      | -3.39e+05 |
|    critic_loss     | 9.09e+09  |
|    ent_coef        | 65.8      |
|    ent_coef_loss   | -277      |
|    learning_rate   | 0.00025   |
|    n_updates       | 17491     |
----------------------------------
ðŸ“Š Episode completed: reward=0.002488, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.002488, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 92: Baseline reward updated 0.000917 â†’ 0.001164
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.002328, Times activated: 63
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.002328, Times activated: 63
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.002328, Times activated: 63
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.002328, Times activated: 63
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.002328, Times activated: 63
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.002328, Times activated: 63
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
ðŸ“Š Episode completed: reward=0.980391, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.980391, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 93: Baseline reward updated 0.001164 â†’ 0.099203
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.198256, Times activated: 64
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.198256, Times activated: 64
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.198256, Times activated: 64
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.198256, Times activated: 64
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.198256, Times activated: 64
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.198256, Times activated: 64
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 94: Baseline reward updated 0.099203 â†’ 0.099203
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.197573, Times activated: 65
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.197573, Times activated: 65
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.197573, Times activated: 65
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.197573, Times activated: 65
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.197573, Times activated: 65
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.197573, Times activated: 65
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 95: Baseline reward updated 0.099203 â†’ 0.099203
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.197573, Times activated: 66
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.197573, Times activated: 66
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.197573, Times activated: 66
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.197573, Times activated: 66
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.197573, Times activated: 66
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.197573, Times activated: 66
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0918    |
| time/              |           |
|    episodes        | 96        |
|    fps             | 19        |
|    time_elapsed    | 998       |
|    total_timesteps | 19296     |
| train/             |           |
|    actor_loss      | -3.59e+05 |
|    critic_loss     | 8.2e+09   |
|    ent_coef        | 80.1      |
|    ent_coef_loss   | -285      |
|    learning_rate   | 0.00025   |
|    n_updates       | 18295     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 96: Baseline reward updated 0.099203 â†’ 0.099203
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.196576, Times activated: 67
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.196576, Times activated: 67
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.196576, Times activated: 67
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.196576, Times activated: 67
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.196576, Times activated: 67
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.196576, Times activated: 67
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
ðŸ“Š Episode completed: reward=0.026716, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.026716, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 97: Baseline reward updated 0.099203 â†’ 0.101875
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.201421, Times activated: 68
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.201421, Times activated: 68
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.201421, Times activated: 68
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.201421, Times activated: 68
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.201421, Times activated: 68
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.201421, Times activated: 68
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.030207, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.030207, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 98: Baseline reward updated 0.101875 â†’ 0.104820
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.011385, Times activated: 69
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.011385, Times activated: 69
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.011385, Times activated: 69
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.011385, Times activated: 69
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.011385, Times activated: 69
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.011385, Times activated: 69
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
ðŸ“Š Episode completed: reward=0.057371, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.057371, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 99: Baseline reward updated 0.104820 â†’ 0.110216
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.022859, Times activated: 70
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.022859, Times activated: 70
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.022859, Times activated: 70
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.022859, Times activated: 70
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.022859, Times activated: 70
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.022859, Times activated: 70
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0893    |
| time/              |           |
|    episodes        | 100       |
|    fps             | 19        |
|    time_elapsed    | 1038      |
|    total_timesteps | 20100     |
| train/             |           |
|    actor_loss      | -3.85e+05 |
|    critic_loss     | 9.35e+09  |
|    ent_coef        | 97.3      |
|    ent_coef_loss   | -306      |
|    learning_rate   | 0.00025   |
|    n_updates       | 19099     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000813, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000813, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 100: Baseline reward updated 0.110216 â†’ 0.110297
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.023021, Times activated: 71
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.023021, Times activated: 71
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.023021, Times activated: 71
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.023021, Times activated: 71
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.023021, Times activated: 71
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.023021, Times activated: 71
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
ðŸ“Š Episode completed: reward=0.003152, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.003152, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 101: Baseline reward updated 0.110297 â†’ 0.110114
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.023652, Times activated: 72
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.023652, Times activated: 72
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.023652, Times activated: 72
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.023652, Times activated: 72
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.023652, Times activated: 72
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.023652, Times activated: 72
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 102: Baseline reward updated 0.110114 â†’ 0.109865
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.018309, Times activated: 73
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.018309, Times activated: 73
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.018309, Times activated: 73
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.018309, Times activated: 73
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.018309, Times activated: 73
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.018309, Times activated: 73
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 103: Baseline reward updated 0.109865 â†’ 0.011826
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.012267, Times activated: 74
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.012267, Times activated: 74
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.012267, Times activated: 74
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.012267, Times activated: 74
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.012267, Times activated: 74
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.012267, Times activated: 74
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0889    |
| time/              |           |
|    episodes        | 104       |
|    fps             | 19        |
|    time_elapsed    | 1086      |
|    total_timesteps | 20904     |
| train/             |           |
|    actor_loss      | -3.46e+05 |
|    critic_loss     | 8.57e+09  |
|    ent_coef        | 118       |
|    ent_coef_loss   | -282      |
|    learning_rate   | 0.00025   |
|    n_updates       | 19903     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 104: Baseline reward updated 0.011826 â†’ 0.011826
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000793, Times activated: 75
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000793, Times activated: 75
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000793, Times activated: 75
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000793, Times activated: 75
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000793, Times activated: 75
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000793, Times activated: 75
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
ðŸ“Š Episode completed: reward=0.000736, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000736, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 105: Baseline reward updated 0.011826 â†’ 0.011900
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000778, Times activated: 76
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000778, Times activated: 76
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000778, Times activated: 76
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000778, Times activated: 76
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000778, Times activated: 76
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000778, Times activated: 76
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 106: Baseline reward updated 0.011900 â†’ 0.011900
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000147, Times activated: 77
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000147, Times activated: 77
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000147, Times activated: 77
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000147, Times activated: 77
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000147, Times activated: 77
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000147, Times activated: 77
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 107: Baseline reward updated 0.011900 â†’ 0.009228
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000147, Times activated: 78
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000147, Times activated: 78
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000147, Times activated: 78
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000147, Times activated: 78
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000147, Times activated: 78
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000147, Times activated: 78
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0888    |
| time/              |           |
|    episodes        | 108       |
|    fps             | 19        |
|    time_elapsed    | 1127      |
|    total_timesteps | 21708     |
| train/             |           |
|    actor_loss      | -3.87e+05 |
|    critic_loss     | 1.19e+10  |
|    ent_coef        | 143       |
|    ent_coef_loss   | -292      |
|    learning_rate   | 0.00025   |
|    n_updates       | 20707     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 108: Baseline reward updated 0.009228 â†’ 0.006207
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000147, Times activated: 79
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000147, Times activated: 79
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000147, Times activated: 79
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000147, Times activated: 79
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000147, Times activated: 79
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000147, Times activated: 79
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 109: Baseline reward updated 0.006207 â†’ 0.000470
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000147, Times activated: 80
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000147, Times activated: 80
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000147, Times activated: 80
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000147, Times activated: 80
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000147, Times activated: 80
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000147, Times activated: 80
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 110: Baseline reward updated 0.000470 â†’ 0.000389
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 81
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 81
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 81
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 81
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 81
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 81
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 111: Baseline reward updated 0.000389 â†’ 0.000074
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 82
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 82
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 82
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 82
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 82
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 82
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0876    |
| time/              |           |
|    episodes        | 112       |
|    fps             | 19        |
|    time_elapsed    | 1170      |
|    total_timesteps | 22512     |
| train/             |           |
|    actor_loss      | -3.86e+05 |
|    critic_loss     | 1.33e+10  |
|    ent_coef        | 174       |
|    ent_coef_loss   | -302      |
|    learning_rate   | 0.00025   |
|    n_updates       | 21511     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 112: Baseline reward updated 0.000074 â†’ 0.000074
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 83
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 83
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 83
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 83
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 83
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 83
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 113: Baseline reward updated 0.000074 â†’ 0.000074
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 84
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 84
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 84
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 84
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 84
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 84
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 114: Baseline reward updated 0.000074 â†’ 0.000074
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 85
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 85
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 85
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 85
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 85
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 85
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 115: Baseline reward updated 0.000074 â†’ 0.000000
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 86
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 86
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 86
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 86
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 86
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 86
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0836    |
| time/              |           |
|    episodes        | 116       |
|    fps             | 19        |
|    time_elapsed    | 1216      |
|    total_timesteps | 23316     |
| train/             |           |
|    actor_loss      | -3.97e+05 |
|    critic_loss     | 8.6e+09   |
|    ent_coef        | 211       |
|    ent_coef_loss   | -279      |
|    learning_rate   | 0.00025   |
|    n_updates       | 22315     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 116: Baseline reward updated 0.000000 â†’ 0.000000
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 87
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 87
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 87
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 87
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 87
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 87
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
ðŸ“Š Episode completed: reward=0.030460, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.030460, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 117: Baseline reward updated 0.000000 â†’ 0.003046
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.006092, Times activated: 88
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.006092, Times activated: 88
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.006092, Times activated: 88
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.006092, Times activated: 88
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.006092, Times activated: 88
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.006092, Times activated: 88
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
ðŸ“Š Episode completed: reward=0.255239, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.255239, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 118: Baseline reward updated 0.003046 â†’ 0.028570
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.057140, Times activated: 89
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.057140, Times activated: 89
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.057140, Times activated: 89
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.057140, Times activated: 89
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.057140, Times activated: 89
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.057140, Times activated: 89
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
ðŸ“Š Episode completed: reward=0.012488, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.012488, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 119: Baseline reward updated 0.028570 â†’ 0.029819
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.059637, Times activated: 90
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.059637, Times activated: 90
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.059637, Times activated: 90
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.059637, Times activated: 90
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.059637, Times activated: 90
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.059637, Times activated: 90
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)

ðŸ”„ CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
ðŸ”„ Adapting curriculum...

ðŸŽ“ Generating curriculum configuration...

ðŸŽ² Selecting active interventions...

ðŸ” Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   âœ… goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.059637)
   âœ… pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   âœ… pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   âœ… physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   âœ… physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   âœ… visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   âœ… random_full is ELIGIBLE
ðŸŽ¯ Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
ðŸ“‹ Processing 7 eligible interventions...
   goal_basic: avg_reward=0.059637, confidence=0.437224, score=1.371310
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: goal_basic
   goal_basic: âœ… ACTIVATED with strength 1.000
   pose_position: avg_reward=0.059637, confidence=0.437224, score=1.371310
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_position
   pose_position: âœ… ACTIVATED with strength 1.000
   pose_full: avg_reward=0.059637, confidence=0.437224, score=1.371310
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_full
   pose_full: âœ… ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.059637, confidence=0.437224, score=1.371310
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: physics_friction
   physics_friction: âœ… ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=âˆž)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
   physics_mass: âš”ï¸  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.059637, confidence=0.437224, score=1.371310
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: visual
   visual: âœ… ACTIVATED with strength 1.000
   random_full: avg_reward=0.059637, confidence=0.437224, score=1.371310
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: random_full
   random_full: âœ… ACTIVATED with strength 1.000

ðŸŽ‰ FINAL SELECTION: 6 interventions activated
   ðŸš€ goal_basic (strength: 1.000)
   ðŸš€ pose_position (strength: 1.000)
   ðŸš€ pose_full (strength: 1.000)
   ðŸš€ physics_friction (strength: 1.000)
   ðŸš€ visual (strength: 1.000)
   ðŸš€ random_full (strength: 1.000)
ðŸ”§ Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
âœ… Curriculum config ready: 6 actors, 6 active nodes
ðŸ”§ Updating curriculum wrapper...
ðŸ”§ Updating internal curriculum object...
ðŸ”§ Reinitializing curriculum actors...
âœ… Curriculum updated successfully!
   ðŸ“Š Active interventions: 6
   ðŸŽ¯ Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   ðŸŽ² Exploration rate: 0.9388
   ðŸ“ˆ Baseline reward: 0.029819
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0787    |
| time/              |           |
|    episodes        | 120       |
|    fps             | 19        |
|    time_elapsed    | 1269      |
|    total_timesteps | 24120     |
| train/             |           |
|    actor_loss      | -4.46e+05 |
|    critic_loss     | 1.42e+10  |
|    ent_coef        | 255       |
|    ent_coef_loss   | -300      |
|    learning_rate   | 0.00025   |
|    n_updates       | 23119     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.021400, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.021400, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 120: Baseline reward updated 0.029819 â†’ 0.031959
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.063917, Times activated: 91
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.063917, Times activated: 91
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.063917, Times activated: 91
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.063917, Times activated: 91
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.063917, Times activated: 91
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.063917, Times activated: 91
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
ðŸ“Š Episode completed: reward=0.045957, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.045957, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 121: Baseline reward updated 0.031959 â†’ 0.036554
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.073109, Times activated: 92
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.073109, Times activated: 92
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.073109, Times activated: 92
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.073109, Times activated: 92
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.073109, Times activated: 92
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.073109, Times activated: 92
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 122: Baseline reward updated 0.036554 â†’ 0.036554
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.067017, Times activated: 93
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.067017, Times activated: 93
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.067017, Times activated: 93
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.067017, Times activated: 93
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.067017, Times activated: 93
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.067017, Times activated: 93
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
ðŸ“Š Episode completed: reward=0.000148, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000148, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 123: Baseline reward updated 0.036554 â†’ 0.036569
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.015999, Times activated: 94
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.015999, Times activated: 94
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.015999, Times activated: 94
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.015999, Times activated: 94
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.015999, Times activated: 94
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.015999, Times activated: 94
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0743    |
| time/              |           |
|    episodes        | 124       |
|    fps             | 18        |
|    time_elapsed    | 1314      |
|    total_timesteps | 24924     |
| train/             |           |
|    actor_loss      | -4.62e+05 |
|    critic_loss     | 1.43e+10  |
|    ent_coef        | 309       |
|    ent_coef_loss   | -284      |
|    learning_rate   | 0.00025   |
|    n_updates       | 23923     |
----------------------------------
ðŸ“Š Episode completed: reward=0.026449, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.026449, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 124: Baseline reward updated 0.036569 â†’ 0.039214
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.018791, Times activated: 95
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.018791, Times activated: 95
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.018791, Times activated: 95
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.018791, Times activated: 95
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.018791, Times activated: 95
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.018791, Times activated: 95
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
ðŸ“Š Episode completed: reward=0.050833, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.050833, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 125: Baseline reward updated 0.039214 â†’ 0.044297
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.024677, Times activated: 96
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.024677, Times activated: 96
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.024677, Times activated: 96
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.024677, Times activated: 96
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.024677, Times activated: 96
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.024677, Times activated: 96
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
ðŸ“Š Episode completed: reward=0.092653, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.092653, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 126: Baseline reward updated 0.044297 â†’ 0.053563
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.034017, Times activated: 97
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.034017, Times activated: 97
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.034017, Times activated: 97
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.034017, Times activated: 97
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.034017, Times activated: 97
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.034017, Times activated: 97
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 127: Baseline reward updated 0.053563 â†’ 0.050517
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.034017, Times activated: 98
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.034017, Times activated: 98
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.034017, Times activated: 98
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.034017, Times activated: 98
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.034017, Times activated: 98
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.034017, Times activated: 98
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0757    |
| time/              |           |
|    episodes        | 128       |
|    fps             | 18        |
|    time_elapsed    | 1358      |
|    total_timesteps | 25728     |
| train/             |           |
|    actor_loss      | -4.44e+05 |
|    critic_loss     | 1.1e+10   |
|    ent_coef        | 374       |
|    ent_coef_loss   | -281      |
|    learning_rate   | 0.00025   |
|    n_updates       | 24727     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 128: Baseline reward updated 0.050517 â†’ 0.024993
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.033987, Times activated: 99
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.033987, Times activated: 99
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.033987, Times activated: 99
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.033987, Times activated: 99
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.033987, Times activated: 99
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.033987, Times activated: 99
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
ðŸ“Š Episode completed: reward=0.010516, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.010516, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 129: Baseline reward updated 0.024993 â†’ 0.024796
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.030800, Times activated: 100
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.030800, Times activated: 100
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.030800, Times activated: 100
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.030800, Times activated: 100
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.030800, Times activated: 100
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.030800, Times activated: 100
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 130: Baseline reward updated 0.024796 â†’ 0.022656
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.020634, Times activated: 101
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.020634, Times activated: 101
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.020634, Times activated: 101
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.020634, Times activated: 101
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.020634, Times activated: 101
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.020634, Times activated: 101
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
ðŸ“Š Episode completed: reward=0.140889, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.140889, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 131: Baseline reward updated 0.022656 â†’ 0.032149
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.030281, Times activated: 102
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.030281, Times activated: 102
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.030281, Times activated: 102
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.030281, Times activated: 102
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.030281, Times activated: 102
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.030281, Times activated: 102
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0774    |
| time/              |           |
|    episodes        | 132       |
|    fps             | 18        |
|    time_elapsed    | 1409      |
|    total_timesteps | 26532     |
| train/             |           |
|    actor_loss      | -4.16e+05 |
|    critic_loss     | 1.17e+10  |
|    ent_coef        | 451       |
|    ent_coef_loss   | -299      |
|    learning_rate   | 0.00025   |
|    n_updates       | 25531     |
----------------------------------
ðŸ“Š Episode completed: reward=0.011189, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.011189, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 132: Baseline reward updated 0.032149 â†’ 0.033268
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.032519, Times activated: 103
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.032519, Times activated: 103
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.032519, Times activated: 103
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.032519, Times activated: 103
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.032519, Times activated: 103
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.032519, Times activated: 103
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
ðŸ“Š Episode completed: reward=0.025897, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.025897, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 133: Baseline reward updated 0.033268 â†’ 0.035843
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.037698, Times activated: 104
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.037698, Times activated: 104
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.037698, Times activated: 104
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.037698, Times activated: 104
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.037698, Times activated: 104
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.037698, Times activated: 104
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000867, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000867, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 134: Baseline reward updated 0.035843 â†’ 0.033284
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.035768, Times activated: 105
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.035768, Times activated: 105
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.035768, Times activated: 105
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.035768, Times activated: 105
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.035768, Times activated: 105
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.035768, Times activated: 105
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
ðŸ“Š Episode completed: reward=0.970089, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.970089, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 135: Baseline reward updated 0.033284 â†’ 0.125210
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.229786, Times activated: 106
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.229786, Times activated: 106
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.229786, Times activated: 106
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.229786, Times activated: 106
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.229786, Times activated: 106
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.229786, Times activated: 106
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0988    |
| time/              |           |
|    episodes        | 136       |
|    fps             | 18        |
|    time_elapsed    | 1453      |
|    total_timesteps | 27336     |
| train/             |           |
|    actor_loss      | -5.29e+05 |
|    critic_loss     | 1.59e+10  |
|    ent_coef        | 544       |
|    ent_coef_loss   | -278      |
|    learning_rate   | 0.00025   |
|    n_updates       | 26335     |
----------------------------------
ðŸ“Š Episode completed: reward=1.261031, success=True

ðŸ“ˆ Updating graph performance: episode_reward=1.261031, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 136: Baseline reward updated 0.125210 â†’ 0.242048
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.453815, Times activated: 107
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.453815, Times activated: 107
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.453815, Times activated: 107
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.453815, Times activated: 107
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.453815, Times activated: 107
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.453815, Times activated: 107
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.096810, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.096810, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 137: Baseline reward updated 0.242048 â†’ 0.251729
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.470939, Times activated: 108
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.470939, Times activated: 108
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.470939, Times activated: 108
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.470939, Times activated: 108
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.470939, Times activated: 108
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.470939, Times activated: 108
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
ðŸ“Š Episode completed: reward=0.011230, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.011230, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 138: Baseline reward updated 0.251729 â†’ 0.252852
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.468005, Times activated: 109
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.468005, Times activated: 109
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.468005, Times activated: 109
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.468005, Times activated: 109
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.468005, Times activated: 109
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.468005, Times activated: 109
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
ðŸ“Š Episode completed: reward=0.001182, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.001182, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 139: Baseline reward updated 0.252852 â†’ 0.251918
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.468068, Times activated: 110
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.468068, Times activated: 110
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.468068, Times activated: 110
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.468068, Times activated: 110
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.468068, Times activated: 110
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.468068, Times activated: 110
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0971    |
| time/              |           |
|    episodes        | 140       |
|    fps             | 18        |
|    time_elapsed    | 1496      |
|    total_timesteps | 28140     |
| train/             |           |
|    actor_loss      | -4.37e+05 |
|    critic_loss     | 1.33e+10  |
|    ent_coef        | 654       |
|    ent_coef_loss   | -265      |
|    learning_rate   | 0.00025   |
|    n_updates       | 27139     |
----------------------------------
ðŸ“Š Episode completed: reward=0.004404, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.004404, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 140: Baseline reward updated 0.251918 â†’ 0.252359
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.274931, Times activated: 111
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.274931, Times activated: 111
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.274931, Times activated: 111
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.274931, Times activated: 111
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.274931, Times activated: 111
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.274931, Times activated: 111
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
ðŸ“Š Episode completed: reward=0.006409, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.006409, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 141: Baseline reward updated 0.252359 â†’ 0.238911
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.024007, Times activated: 112
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.024007, Times activated: 112
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.024007, Times activated: 112
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.024007, Times activated: 112
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.024007, Times activated: 112
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.024007, Times activated: 112
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
ðŸ“Š Episode completed: reward=0.009936, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.009936, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 142: Baseline reward updated 0.238911 â†’ 0.238786
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.006632, Times activated: 113
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.006632, Times activated: 113
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.006632, Times activated: 113
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.006632, Times activated: 113
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.006632, Times activated: 113
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.006632, Times activated: 113
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
ðŸ“Š Episode completed: reward=0.004708, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.004708, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 143: Baseline reward updated 0.238786 â†’ 0.236667
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.005328, Times activated: 114
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.005328, Times activated: 114
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.005328, Times activated: 114
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.005328, Times activated: 114
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.005328, Times activated: 114
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.005328, Times activated: 114
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0971    |
| time/              |           |
|    episodes        | 144       |
|    fps             | 18        |
|    time_elapsed    | 1543      |
|    total_timesteps | 28944     |
| train/             |           |
|    actor_loss      | -4.52e+05 |
|    critic_loss     | 1.22e+10  |
|    ent_coef        | 783       |
|    ent_coef_loss   | -228      |
|    learning_rate   | 0.00025   |
|    n_updates       | 27943     |
----------------------------------
ðŸ“Š Episode completed: reward=0.001642, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.001642, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 144: Baseline reward updated 0.236667 â†’ 0.236744
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.005420, Times activated: 115
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.005420, Times activated: 115
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.005420, Times activated: 115
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.005420, Times activated: 115
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.005420, Times activated: 115
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.005420, Times activated: 115
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 145: Baseline reward updated 0.236744 â†’ 0.139735
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.004539, Times activated: 116
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.004539, Times activated: 116
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.004539, Times activated: 116
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.004539, Times activated: 116
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.004539, Times activated: 116
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.004539, Times activated: 116
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
ðŸ“Š Episode completed: reward=0.004205, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.004205, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 146: Baseline reward updated 0.139735 â†’ 0.014053
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.004098, Times activated: 117
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.004098, Times activated: 117
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.004098, Times activated: 117
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.004098, Times activated: 117
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.004098, Times activated: 117
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.004098, Times activated: 117
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
ðŸ“Š Episode completed: reward=0.028618, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.028618, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 147: Baseline reward updated 0.014053 â†’ 0.007233
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.007835, Times activated: 118
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.007835, Times activated: 118
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.007835, Times activated: 118
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.007835, Times activated: 118
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.007835, Times activated: 118
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.007835, Times activated: 118
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.097     |
| time/              |           |
|    episodes        | 148       |
|    fps             | 18        |
|    time_elapsed    | 1588      |
|    total_timesteps | 29748     |
| train/             |           |
|    actor_loss      | -4.88e+05 |
|    critic_loss     | 9.85e+09  |
|    ent_coef        | 935       |
|    ent_coef_loss   | -220      |
|    learning_rate   | 0.00025   |
|    n_updates       | 28747     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 148: Baseline reward updated 0.007233 â†’ 0.006110
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.006893, Times activated: 119
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.006893, Times activated: 119
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.006893, Times activated: 119
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.006893, Times activated: 119
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.006893, Times activated: 119
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.006893, Times activated: 119
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
ðŸ“Š Episode completed: reward=0.521702, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.521702, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 149: Baseline reward updated 0.006110 â†’ 0.058162
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.110905, Times activated: 120
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.110905, Times activated: 120
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.110905, Times activated: 120
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.110905, Times activated: 120
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.110905, Times activated: 120
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.110905, Times activated: 120
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)

ðŸ”„ CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
ðŸ”„ Adapting curriculum...

ðŸŽ“ Generating curriculum configuration...

ðŸŽ² Selecting active interventions...

ðŸ” Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   âœ… goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.110905)
   âœ… pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   âœ… pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   âœ… physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   âœ… physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   âœ… visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   âœ… random_full is ELIGIBLE
ðŸŽ¯ Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
ðŸ“‹ Processing 7 eligible interventions...
   goal_basic: avg_reward=0.110905, confidence=0.447390, score=1.453075
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: goal_basic
   goal_basic: âœ… ACTIVATED with strength 1.000
   pose_position: avg_reward=0.110905, confidence=0.447390, score=1.453075
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_position
   pose_position: âœ… ACTIVATED with strength 1.000
   pose_full: avg_reward=0.110905, confidence=0.447390, score=1.453075
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_full
   pose_full: âœ… ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.110905, confidence=0.447390, score=1.453075
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: physics_friction
   physics_friction: âœ… ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=âˆž)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
   physics_mass: âš”ï¸  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.110905, confidence=0.447390, score=1.453075
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: visual
   visual: âœ… ACTIVATED with strength 1.000
   random_full: avg_reward=0.110905, confidence=0.447390, score=1.453075
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: random_full
   random_full: âœ… ACTIVATED with strength 1.000

ðŸŽ‰ FINAL SELECTION: 6 interventions activated
   ðŸš€ goal_basic (strength: 1.000)
   ðŸš€ pose_position (strength: 1.000)
   ðŸš€ pose_full (strength: 1.000)
   ðŸš€ physics_friction (strength: 1.000)
   ðŸš€ visual (strength: 1.000)
   ðŸš€ random_full (strength: 1.000)
ðŸ”§ Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
âœ… Curriculum config ready: 6 actors, 6 active nodes
ðŸ”§ Updating curriculum wrapper...
ðŸ”§ Updating internal curriculum object...
ðŸ”§ Reinitializing curriculum actors...
âœ… Curriculum updated successfully!
   ðŸ“Š Active interventions: 6
   ðŸŽ¯ Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   ðŸŽ² Exploration rate: 0.9359
   ðŸ“ˆ Baseline reward: 0.058162
ðŸ“Š Episode completed: reward=0.401109, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.401109, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 150: Baseline reward updated 0.058162 â†’ 0.097833
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.191127, Times activated: 121
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.191127, Times activated: 121
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.191127, Times activated: 121
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.191127, Times activated: 121
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.191127, Times activated: 121
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.191127, Times activated: 121
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
ðŸ“Š Episode completed: reward=0.140064, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.140064, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 151: Baseline reward updated 0.097833 â†’ 0.111198
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.218299, Times activated: 122
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.218299, Times activated: 122
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.218299, Times activated: 122
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.218299, Times activated: 122
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.218299, Times activated: 122
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.218299, Times activated: 122
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.106     |
| time/              |           |
|    episodes        | 152       |
|    fps             | 18        |
|    time_elapsed    | 1639      |
|    total_timesteps | 30552     |
| train/             |           |
|    actor_loss      | -4.35e+05 |
|    critic_loss     | 2.73e+10  |
|    ent_coef        | 1.11e+03  |
|    ent_coef_loss   | -194      |
|    learning_rate   | 0.00025   |
|    n_updates       | 29551     |
----------------------------------
ðŸ“Š Episode completed: reward=0.130756, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.130756, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 152: Baseline reward updated 0.111198 â†’ 0.123280
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.238726, Times activated: 123
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.238726, Times activated: 123
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.238726, Times activated: 123
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.238726, Times activated: 123
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.238726, Times activated: 123
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.238726, Times activated: 123
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
ðŸ“Š Episode completed: reward=0.193382, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.193382, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 153: Baseline reward updated 0.123280 â†’ 0.142148
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.277403, Times activated: 124
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.277403, Times activated: 124
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.277403, Times activated: 124
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.277403, Times activated: 124
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.277403, Times activated: 124
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.277403, Times activated: 124
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
ðŸ“Š Episode completed: reward=0.034141, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.034141, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 154: Baseline reward updated 0.142148 â†’ 0.145398
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.179890, Times activated: 125
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.179890, Times activated: 125
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.179890, Times activated: 125
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.179890, Times activated: 125
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.179890, Times activated: 125
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.179890, Times activated: 125
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
ðŸ“Š Episode completed: reward=0.029054, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.029054, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 155: Baseline reward updated 0.145398 â†’ 0.148303
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.105479, Times activated: 126
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.105479, Times activated: 126
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.105479, Times activated: 126
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.105479, Times activated: 126
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.105479, Times activated: 126
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.105479, Times activated: 126
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.108    |
| time/              |          |
|    episodes        | 156      |
|    fps             | 18       |
|    time_elapsed    | 1685     |
|    total_timesteps | 31356    |
| train/             |          |
|    actor_loss      | -4.1e+05 |
|    critic_loss     | 1.47e+10 |
|    ent_coef        | 1.3e+03  |
|    ent_coef_loss   | -147     |
|    learning_rate   | 0.00025  |
|    n_updates       | 30355    |
---------------------------------
ðŸ“Š Episode completed: reward=0.107341, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.107341, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 156: Baseline reward updated 0.148303 â†’ 0.158617
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.098935, Times activated: 127
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.098935, Times activated: 127
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.098935, Times activated: 127
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.098935, Times activated: 127
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.098935, Times activated: 127
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.098935, Times activated: 127
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
ðŸ“Š Episode completed: reward=0.005784, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.005784, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 157: Baseline reward updated 0.158617 â†’ 0.156333
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.073940, Times activated: 128
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.073940, Times activated: 128
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.073940, Times activated: 128
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.073940, Times activated: 128
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.073940, Times activated: 128
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.073940, Times activated: 128
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 158: Baseline reward updated 0.156333 â†’ 0.156333
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.035264, Times activated: 129
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.035264, Times activated: 129
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.035264, Times activated: 129
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.035264, Times activated: 129
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.035264, Times activated: 129
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.035264, Times activated: 129
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
ðŸ“Š Episode completed: reward=0.196334, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.196334, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 159: Baseline reward updated 0.156333 â†’ 0.123797
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.067703, Times activated: 130
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.067703, Times activated: 130
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.067703, Times activated: 130
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.067703, Times activated: 130
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.067703, Times activated: 130
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.067703, Times activated: 130
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.106     |
| time/              |           |
|    episodes        | 160       |
|    fps             | 18        |
|    time_elapsed    | 1726      |
|    total_timesteps | 32160     |
| train/             |           |
|    actor_loss      | -4.85e+05 |
|    critic_loss     | 1.45e+10  |
|    ent_coef        | 1.51e+03  |
|    ent_coef_loss   | -132      |
|    learning_rate   | 0.00025   |
|    n_updates       | 31159     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 160: Baseline reward updated 0.123797 â†’ 0.083686
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.061892, Times activated: 131
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.061892, Times activated: 131
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.061892, Times activated: 131
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.061892, Times activated: 131
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.061892, Times activated: 131
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.061892, Times activated: 131
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 161: Baseline reward updated 0.083686 â†’ 0.069679
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.040424, Times activated: 132
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.040424, Times activated: 132
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.040424, Times activated: 132
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.040424, Times activated: 132
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.040424, Times activated: 132
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.040424, Times activated: 132
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 162: Baseline reward updated 0.069679 â†’ 0.056604
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.039267, Times activated: 133
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.039267, Times activated: 133
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.039267, Times activated: 133
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.039267, Times activated: 133
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.039267, Times activated: 133
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.039267, Times activated: 133
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 163: Baseline reward updated 0.056604 â†’ 0.037265
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.039267, Times activated: 134
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.039267, Times activated: 134
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.039267, Times activated: 134
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.039267, Times activated: 134
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.039267, Times activated: 134
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.039267, Times activated: 134
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.104     |
| time/              |           |
|    episodes        | 164       |
|    fps             | 18        |
|    time_elapsed    | 1771      |
|    total_timesteps | 32964     |
| train/             |           |
|    actor_loss      | -5.39e+05 |
|    critic_loss     | 1.68e+10  |
|    ent_coef        | 1.74e+03  |
|    ent_coef_loss   | -111      |
|    learning_rate   | 0.00025   |
|    n_updates       | 31963     |
----------------------------------
ðŸ“Š Episode completed: reward=0.038771, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.038771, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 164: Baseline reward updated 0.037265 â†’ 0.037728
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.007754, Times activated: 135
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.007754, Times activated: 135
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.007754, Times activated: 135
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.007754, Times activated: 135
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.007754, Times activated: 135
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.007754, Times activated: 135
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 165: Baseline reward updated 0.037728 â†’ 0.034823
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.007754, Times activated: 136
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.007754, Times activated: 136
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.007754, Times activated: 136
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.007754, Times activated: 136
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.007754, Times activated: 136
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.007754, Times activated: 136
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
ðŸ“Š Episode completed: reward=0.023678, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.023678, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 166: Baseline reward updated 0.034823 â†’ 0.026457
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.012490, Times activated: 137
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.012490, Times activated: 137
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.012490, Times activated: 137
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.012490, Times activated: 137
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.012490, Times activated: 137
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.012490, Times activated: 137
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.015789, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.015789, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 167: Baseline reward updated 0.026457 â†’ 0.027457
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.015648, Times activated: 138
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.015648, Times activated: 138
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.015648, Times activated: 138
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.015648, Times activated: 138
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.015648, Times activated: 138
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.015648, Times activated: 138
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0834    |
| time/              |           |
|    episodes        | 168       |
|    fps             | 18        |
|    time_elapsed    | 1811      |
|    total_timesteps | 33768     |
| train/             |           |
|    actor_loss      | -4.49e+05 |
|    critic_loss     | 9.77e+09  |
|    ent_coef        | 2.01e+03  |
|    ent_coef_loss   | -88.4     |
|    learning_rate   | 0.00025   |
|    n_updates       | 32767     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.043065, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.043065, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 168: Baseline reward updated 0.027457 â†’ 0.031764
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.024261, Times activated: 139
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.024261, Times activated: 139
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.024261, Times activated: 139
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.024261, Times activated: 139
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.024261, Times activated: 139
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.024261, Times activated: 139
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
ðŸ“Š Episode completed: reward=0.186323, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.186323, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 169: Baseline reward updated 0.031764 â†’ 0.030763
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.053771, Times activated: 140
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.053771, Times activated: 140
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.053771, Times activated: 140
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.053771, Times activated: 140
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.053771, Times activated: 140
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.053771, Times activated: 140
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 170: Baseline reward updated 0.030763 â†’ 0.030763
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.053771, Times activated: 141
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.053771, Times activated: 141
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.053771, Times activated: 141
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.053771, Times activated: 141
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.053771, Times activated: 141
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.053771, Times activated: 141
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.061025, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.061025, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 171: Baseline reward updated 0.030763 â†’ 0.036865
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.061240, Times activated: 142
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.061240, Times activated: 142
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.061240, Times activated: 142
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.061240, Times activated: 142
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.061240, Times activated: 142
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.061240, Times activated: 142
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0859   |
| time/              |          |
|    episodes        | 172      |
|    fps             | 18       |
|    time_elapsed    | 1850     |
|    total_timesteps | 34572    |
| train/             |          |
|    actor_loss      | -4.8e+05 |
|    critic_loss     | 1.47e+10 |
|    ent_coef        | 2.32e+03 |
|    ent_coef_loss   | -81.9    |
|    learning_rate   | 0.00025  |
|    n_updates       | 33571    |
---------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 172: Baseline reward updated 0.036865 â†’ 0.036865
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.058083, Times activated: 143
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.058083, Times activated: 143
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.058083, Times activated: 143
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.058083, Times activated: 143
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.058083, Times activated: 143
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.058083, Times activated: 143
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 173: Baseline reward updated 0.036865 â†’ 0.036865
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.049470, Times activated: 144
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.049470, Times activated: 144
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.049470, Times activated: 144
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.049470, Times activated: 144
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.049470, Times activated: 144
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.049470, Times activated: 144
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 174: Baseline reward updated 0.036865 â†’ 0.032988
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.012205, Times activated: 145
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.012205, Times activated: 145
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.012205, Times activated: 145
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.012205, Times activated: 145
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.012205, Times activated: 145
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.012205, Times activated: 145
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 175: Baseline reward updated 0.032988 â†’ 0.032988
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.012205, Times activated: 146
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.012205, Times activated: 146
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.012205, Times activated: 146
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.012205, Times activated: 146
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.012205, Times activated: 146
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.012205, Times activated: 146
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0868    |
| time/              |           |
|    episodes        | 176       |
|    fps             | 18        |
|    time_elapsed    | 1889      |
|    total_timesteps | 35376     |
| train/             |           |
|    actor_loss      | -4.24e+05 |
|    critic_loss     | 1.83e+10  |
|    ent_coef        | 2.68e+03  |
|    ent_coef_loss   | -55.9     |
|    learning_rate   | 0.00025   |
|    n_updates       | 34375     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.307742, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.307742, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 176: Baseline reward updated 0.032988 â†’ 0.061394
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.061548, Times activated: 147
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.061548, Times activated: 147
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.061548, Times activated: 147
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.061548, Times activated: 147
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.061548, Times activated: 147
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.061548, Times activated: 147
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
ðŸ“Š Episode completed: reward=0.031673, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.031673, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 177: Baseline reward updated 0.061394 â†’ 0.062983
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.067883, Times activated: 148
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.067883, Times activated: 148
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.067883, Times activated: 148
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.067883, Times activated: 148
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.067883, Times activated: 148
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.067883, Times activated: 148
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
ðŸ“Š Episode completed: reward=0.257322, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.257322, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 178: Baseline reward updated 0.062983 â†’ 0.084408
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.119347, Times activated: 149
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.119347, Times activated: 149
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.119347, Times activated: 149
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.119347, Times activated: 149
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.119347, Times activated: 149
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.119347, Times activated: 149
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=1.205853, success=True

ðŸ“ˆ Updating graph performance: episode_reward=1.205853, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 179: Baseline reward updated 0.084408 â†’ 0.186362
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.360518, Times activated: 150
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.360518, Times activated: 150
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.360518, Times activated: 150
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.360518, Times activated: 150
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.360518, Times activated: 150
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.360518, Times activated: 150
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)

ðŸ”„ CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
ðŸ”„ Adapting curriculum...

ðŸŽ“ Generating curriculum configuration...

ðŸŽ² Selecting active interventions...

ðŸ” Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   âœ… goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.360518)
   âœ… pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   âœ… pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   âœ… physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   âœ… physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   âœ… visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   âœ… random_full is ELIGIBLE
ðŸŽ¯ Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
ðŸ“‹ Processing 7 eligible interventions...
   goal_basic: avg_reward=0.360518, confidence=0.455517, score=1.727068
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: goal_basic
   goal_basic: âœ… ACTIVATED with strength 1.000
   pose_position: avg_reward=0.360518, confidence=0.455517, score=1.727068
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_position
   pose_position: âœ… ACTIVATED with strength 1.000
   pose_full: avg_reward=0.360518, confidence=0.455517, score=1.727068
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_full
   pose_full: âœ… ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.360518, confidence=0.455517, score=1.727068
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: physics_friction
   physics_friction: âœ… ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=âˆž)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
   physics_mass: âš”ï¸  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.360518, confidence=0.455517, score=1.727068
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: visual
   visual: âœ… ACTIVATED with strength 1.000
   random_full: avg_reward=0.360518, confidence=0.455517, score=1.727068
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: random_full
   random_full: âœ… ACTIVATED with strength 1.000

ðŸŽ‰ FINAL SELECTION: 6 interventions activated
   ðŸš€ goal_basic (strength: 1.000)
   ðŸš€ pose_position (strength: 1.000)
   ðŸš€ pose_full (strength: 1.000)
   ðŸš€ physics_friction (strength: 1.000)
   ðŸš€ visual (strength: 1.000)
   ðŸš€ random_full (strength: 1.000)
ðŸ”§ Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
âœ… Curriculum config ready: 6 actors, 6 active nodes
ðŸ”§ Updating curriculum wrapper...
ðŸ”§ Updating internal curriculum object...
ðŸ”§ Reinitializing curriculum actors...
âœ… Curriculum updated successfully!
   ðŸ“Š Active interventions: 6
   ðŸŽ¯ Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   ðŸŽ² Exploration rate: 0.9331
   ðŸ“ˆ Baseline reward: 0.186362
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.098     |
| time/              |           |
|    episodes        | 180       |
|    fps             | 18        |
|    time_elapsed    | 1931      |
|    total_timesteps | 36180     |
| train/             |           |
|    actor_loss      | -4.05e+05 |
|    critic_loss     | 9.69e+09  |
|    ent_coef        | 3.1e+03   |
|    ent_coef_loss   | -46.8     |
|    learning_rate   | 0.00025   |
|    n_updates       | 35179     |
----------------------------------
ðŸ“Š Episode completed: reward=1.632383, success=True

ðŸ“ˆ Updating graph performance: episode_reward=1.632383, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 180: Baseline reward updated 0.186362 â†’ 0.349600
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.686995, Times activated: 151
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.686995, Times activated: 151
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.686995, Times activated: 151
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.686995, Times activated: 151
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.686995, Times activated: 151
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.686995, Times activated: 151
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
ðŸ“Š Episode completed: reward=0.642162, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.642162, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 181: Baseline reward updated 0.349600 â†’ 0.407714
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.753879, Times activated: 152
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.753879, Times activated: 152
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.753879, Times activated: 152
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.753879, Times activated: 152
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.753879, Times activated: 152
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.753879, Times activated: 152
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 182: Baseline reward updated 0.407714 â†’ 0.407714
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.747544, Times activated: 153
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.747544, Times activated: 153
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.747544, Times activated: 153
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.747544, Times activated: 153
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.747544, Times activated: 153
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.747544, Times activated: 153
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.025365, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.025365, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 183: Baseline reward updated 0.407714 â†’ 0.410250
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.701153, Times activated: 154
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.701153, Times activated: 154
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.701153, Times activated: 154
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.701153, Times activated: 154
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.701153, Times activated: 154
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.701153, Times activated: 154
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.105     |
| time/              |           |
|    episodes        | 184       |
|    fps             | 18        |
|    time_elapsed    | 1978      |
|    total_timesteps | 36984     |
| train/             |           |
|    actor_loss      | -5.38e+05 |
|    critic_loss     | 1.67e+10  |
|    ent_coef        | 3.54e+03  |
|    ent_coef_loss   | -38.9     |
|    learning_rate   | 0.00025   |
|    n_updates       | 35983     |
----------------------------------
ðŸ“Š Episode completed: reward=0.029861, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.029861, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 184: Baseline reward updated 0.410250 â†’ 0.413236
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.465954, Times activated: 155
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.465954, Times activated: 155
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.465954, Times activated: 155
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.465954, Times activated: 155
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.465954, Times activated: 155
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.465954, Times activated: 155
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
ðŸ“Š Episode completed: reward=0.024048, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.024048, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 185: Baseline reward updated 0.413236 â†’ 0.415641
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.144287, Times activated: 156
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.144287, Times activated: 156
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.144287, Times activated: 156
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.144287, Times activated: 156
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.144287, Times activated: 156
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.144287, Times activated: 156
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.037822, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.037822, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 186: Baseline reward updated 0.415641 â†’ 0.388649
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.023419, Times activated: 157
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.023419, Times activated: 157
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.023419, Times activated: 157
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.023419, Times activated: 157
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.023419, Times activated: 157
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.023419, Times activated: 157
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
ðŸ“Š Episode completed: reward=0.054971, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.054971, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 187: Baseline reward updated 0.388649 â†’ 0.390979
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.034413, Times activated: 158
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.034413, Times activated: 158
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.034413, Times activated: 158
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.034413, Times activated: 158
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.034413, Times activated: 158
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.034413, Times activated: 158
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.106     |
| time/              |           |
|    episodes        | 188       |
|    fps             | 18        |
|    time_elapsed    | 2024      |
|    total_timesteps | 37788     |
| train/             |           |
|    actor_loss      | -4.73e+05 |
|    critic_loss     | 1.5e+10   |
|    ent_coef        | 4e+03     |
|    ent_coef_loss   | -15.7     |
|    learning_rate   | 0.00025   |
|    n_updates       | 36787     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 188: Baseline reward updated 0.390979 â†’ 0.365247
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.029340, Times activated: 159
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.029340, Times activated: 159
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.029340, Times activated: 159
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.029340, Times activated: 159
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.029340, Times activated: 159
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.029340, Times activated: 159
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 189: Baseline reward updated 0.365247 â†’ 0.244661
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.023368, Times activated: 160
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.023368, Times activated: 160
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.023368, Times activated: 160
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.023368, Times activated: 160
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.023368, Times activated: 160
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.023368, Times activated: 160
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
ðŸ“Š Episode completed: reward=0.266884, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.266884, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 190: Baseline reward updated 0.244661 â†’ 0.108111
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.071935, Times activated: 161
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.071935, Times activated: 161
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.071935, Times activated: 161
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.071935, Times activated: 161
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.071935, Times activated: 161
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.071935, Times activated: 161
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
ðŸ“Š Episode completed: reward=0.025756, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.025756, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 191: Baseline reward updated 0.108111 â†’ 0.046471
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.069522, Times activated: 162
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.069522, Times activated: 162
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.069522, Times activated: 162
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.069522, Times activated: 162
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.069522, Times activated: 162
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.069522, Times activated: 162
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.109    |
| time/              |          |
|    episodes        | 192      |
|    fps             | 18       |
|    time_elapsed    | 2066     |
|    total_timesteps | 38592    |
| train/             |          |
|    actor_loss      | -4.4e+05 |
|    critic_loss     | 1.05e+10 |
|    ent_coef        | 4.47e+03 |
|    ent_coef_loss   | -24.5    |
|    learning_rate   | 0.00025  |
|    n_updates       | 37591    |
---------------------------------
ðŸ“Š Episode completed: reward=0.000322, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000322, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 192: Baseline reward updated 0.046471 â†’ 0.046503
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.058592, Times activated: 163
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.058592, Times activated: 163
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.058592, Times activated: 163
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.058592, Times activated: 163
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.058592, Times activated: 163
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.058592, Times activated: 163
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
ðŸ“Š Episode completed: reward=0.008974, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.008974, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 193: Baseline reward updated 0.046503 â†’ 0.044864
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.060387, Times activated: 164
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.060387, Times activated: 164
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.060387, Times activated: 164
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.060387, Times activated: 164
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.060387, Times activated: 164
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.060387, Times activated: 164
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.034258, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.034258, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 194: Baseline reward updated 0.044864 â†’ 0.045304
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.067239, Times activated: 165
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.067239, Times activated: 165
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.067239, Times activated: 165
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.067239, Times activated: 165
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.067239, Times activated: 165
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.067239, Times activated: 165
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
ðŸ“Š Episode completed: reward=0.019627, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.019627, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 195: Baseline reward updated 0.045304 â†’ 0.044861
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.017787, Times activated: 166
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.017787, Times activated: 166
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.017787, Times activated: 166
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.017787, Times activated: 166
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.017787, Times activated: 166
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.017787, Times activated: 166
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.101    |
| time/              |          |
|    episodes        | 196      |
|    fps             | 18       |
|    time_elapsed    | 2100     |
|    total_timesteps | 39396    |
| train/             |          |
|    actor_loss      | -4.1e+05 |
|    critic_loss     | 1.23e+10 |
|    ent_coef        | 4.89e+03 |
|    ent_coef_loss   | -8.69    |
|    learning_rate   | 0.00025  |
|    n_updates       | 38395    |
---------------------------------
ðŸ“Š Episode completed: reward=0.112557, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.112557, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 196: Baseline reward updated 0.044861 â†’ 0.052335
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.035148, Times activated: 167
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.035148, Times activated: 167
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.035148, Times activated: 167
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.035148, Times activated: 167
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.035148, Times activated: 167
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.035148, Times activated: 167
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 197: Baseline reward updated 0.052335 â†’ 0.046838
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.035083, Times activated: 168
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.035083, Times activated: 168
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.035083, Times activated: 168
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.035083, Times activated: 168
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.035083, Times activated: 168
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.035083, Times activated: 168
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
ðŸ“Š Episode completed: reward=0.287306, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.287306, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 198: Baseline reward updated 0.046838 â†’ 0.075568
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.090750, Times activated: 169
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.090750, Times activated: 169
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.090750, Times activated: 169
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.090750, Times activated: 169
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.090750, Times activated: 169
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.090750, Times activated: 169
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
ðŸ“Š Episode completed: reward=0.002035, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.002035, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 199: Baseline reward updated 0.075568 â†’ 0.075772
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.084305, Times activated: 170
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.084305, Times activated: 170
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.084305, Times activated: 170
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.084305, Times activated: 170
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.084305, Times activated: 170
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.084305, Times activated: 170
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.103     |
| time/              |           |
|    episodes        | 200       |
|    fps             | 18        |
|    time_elapsed    | 2138      |
|    total_timesteps | 40200     |
| train/             |           |
|    actor_loss      | -4.16e+05 |
|    critic_loss     | 9.08e+09  |
|    ent_coef        | 5.19e+03  |
|    ent_coef_loss   | -4.27     |
|    learning_rate   | 0.00025   |
|    n_updates       | 39199     |
----------------------------------
ðŸ“Š Episode completed: reward=0.001385, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.001385, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 200: Baseline reward updated 0.075772 â†’ 0.049222
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.080657, Times activated: 171
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.080657, Times activated: 171
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.080657, Times activated: 171
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.080657, Times activated: 171
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.080657, Times activated: 171
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.080657, Times activated: 171
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
ðŸ“Š Episode completed: reward=0.000227, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000227, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 201: Baseline reward updated 0.049222 â†’ 0.046669
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.058191, Times activated: 172
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.058191, Times activated: 172
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.058191, Times activated: 172
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.058191, Times activated: 172
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.058191, Times activated: 172
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.058191, Times activated: 172
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
ðŸ“Š Episode completed: reward=0.009083, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.009083, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 202: Baseline reward updated 0.046669 â†’ 0.047545
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.060007, Times activated: 173
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.060007, Times activated: 173
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.060007, Times activated: 173
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.060007, Times activated: 173
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.060007, Times activated: 173
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.060007, Times activated: 173
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.011106, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.011106, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 203: Baseline reward updated 0.047545 â†’ 0.047758
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.004767, Times activated: 174
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.004767, Times activated: 174
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.004767, Times activated: 174
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.004767, Times activated: 174
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.004767, Times activated: 174
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.004767, Times activated: 174
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.109     |
| time/              |           |
|    episodes        | 204       |
|    fps             | 18        |
|    time_elapsed    | 2178      |
|    total_timesteps | 41004     |
| train/             |           |
|    actor_loss      | -4.88e+05 |
|    critic_loss     | 9.76e+09  |
|    ent_coef        | 5.24e+03  |
|    ent_coef_loss   | 3.84      |
|    learning_rate   | 0.00025   |
|    n_updates       | 40003     |
----------------------------------
ðŸ“Š Episode completed: reward=0.577836, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.577836, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 204: Baseline reward updated 0.047758 â†’ 0.102116
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.119927, Times activated: 175
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.119927, Times activated: 175
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.119927, Times activated: 175
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.119927, Times activated: 175
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.119927, Times activated: 175
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.119927, Times activated: 175
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 205: Baseline reward updated 0.102116 â†’ 0.100154
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.119650, Times activated: 176
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.119650, Times activated: 176
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.119650, Times activated: 176
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.119650, Times activated: 176
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.119650, Times activated: 176
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.119650, Times activated: 176
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 206: Baseline reward updated 0.100154 â†’ 0.088898
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.119605, Times activated: 177
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.119605, Times activated: 177
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.119605, Times activated: 177
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.119605, Times activated: 177
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.119605, Times activated: 177
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.119605, Times activated: 177
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 207: Baseline reward updated 0.088898 â†’ 0.088898
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.117788, Times activated: 178
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.117788, Times activated: 178
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.117788, Times activated: 178
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.117788, Times activated: 178
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.117788, Times activated: 178
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.117788, Times activated: 178
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.109     |
| time/              |           |
|    episodes        | 208       |
|    fps             | 18        |
|    time_elapsed    | 2225      |
|    total_timesteps | 41808     |
| train/             |           |
|    actor_loss      | -4.89e+05 |
|    critic_loss     | 1.6e+10   |
|    ent_coef        | 5.13e+03  |
|    ent_coef_loss   | -0.0354   |
|    learning_rate   | 0.00025   |
|    n_updates       | 40807     |
----------------------------------
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 208: Baseline reward updated 0.088898 â†’ 0.060167
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.115567, Times activated: 179
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.115567, Times activated: 179
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.115567, Times activated: 179
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.115567, Times activated: 179
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.115567, Times activated: 179
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.115567, Times activated: 179
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 209: Baseline reward updated 0.060167 â†’ 0.059964
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 180
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 180
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 180
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 180
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 180
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 180
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)

ðŸ”„ CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
ðŸ”„ Adapting curriculum...

ðŸŽ“ Generating curriculum configuration...

ðŸŽ² Selecting active interventions...

ðŸ” Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   âœ… goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.000000)
   âœ… pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   âœ… pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   âœ… physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   âœ… physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   âœ… visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   âœ… random_full is ELIGIBLE
ðŸŽ¯ Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
ðŸ“‹ Processing 7 eligible interventions...
   goal_basic: avg_reward=0.000000, confidence=0.462270, score=1.386809
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: goal_basic
   goal_basic: âœ… ACTIVATED with strength 1.000
   pose_position: avg_reward=0.000000, confidence=0.462270, score=1.386809
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_position
   pose_position: âœ… ACTIVATED with strength 1.000
   pose_full: avg_reward=0.000000, confidence=0.462270, score=1.386809
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_full
   pose_full: âœ… ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.000000, confidence=0.462270, score=1.386809
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: physics_friction
   physics_friction: âœ… ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=âˆž)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
   physics_mass: âš”ï¸  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.000000, confidence=0.462270, score=1.386809
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: visual
   visual: âœ… ACTIVATED with strength 1.000
   random_full: avg_reward=0.000000, confidence=0.462270, score=1.386809
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: random_full
   random_full: âœ… ACTIVATED with strength 1.000

ðŸŽ‰ FINAL SELECTION: 6 interventions activated
   ðŸš€ goal_basic (strength: 1.000)
   ðŸš€ pose_position (strength: 1.000)
   ðŸš€ pose_full (strength: 1.000)
   ðŸš€ physics_friction (strength: 1.000)
   ðŸš€ visual (strength: 1.000)
   ðŸš€ random_full (strength: 1.000)
ðŸ”§ Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
âœ… Curriculum config ready: 6 actors, 6 active nodes
ðŸ”§ Updating curriculum wrapper...
ðŸ”§ Updating internal curriculum object...
ðŸ”§ Reinitializing curriculum actors...
âœ… Curriculum updated successfully!
   ðŸ“Š Active interventions: 6
   ðŸŽ¯ Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   ðŸŽ² Exploration rate: 0.9304
   ðŸ“ˆ Baseline reward: 0.059964
ðŸ“Š Episode completed: reward=0.015555, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.015555, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 210: Baseline reward updated 0.059964 â†’ 0.061381
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.003111, Times activated: 181
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.003111, Times activated: 181
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.003111, Times activated: 181
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.003111, Times activated: 181
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.003111, Times activated: 181
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.003111, Times activated: 181
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.012837, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.012837, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 211: Baseline reward updated 0.061381 â†’ 0.062642
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.005678, Times activated: 182
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.005678, Times activated: 182
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.005678, Times activated: 182
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.005678, Times activated: 182
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.005678, Times activated: 182
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.005678, Times activated: 182
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.109     |
| time/              |           |
|    episodes        | 212       |
|    fps             | 18        |
|    time_elapsed    | 2268      |
|    total_timesteps | 42612     |
| train/             |           |
|    actor_loss      | -3.56e+05 |
|    critic_loss     | 7.11e+09  |
|    ent_coef        | 5.03e+03  |
|    ent_coef_loss   | -3.71     |
|    learning_rate   | 0.00025   |
|    n_updates       | 41611     |
----------------------------------
ðŸ“Š Episode completed: reward=0.004916, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.004916, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 212: Baseline reward updated 0.062642 â†’ 0.062225
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.006662, Times activated: 183
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.006662, Times activated: 183
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.006662, Times activated: 183
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.006662, Times activated: 183
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.006662, Times activated: 183
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.006662, Times activated: 183
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
ðŸ“Š Episode completed: reward=0.102006, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.102006, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 213: Baseline reward updated 0.062225 â†’ 0.071315
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.027063, Times activated: 184
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.027063, Times activated: 184
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.027063, Times activated: 184
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.027063, Times activated: 184
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.027063, Times activated: 184
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.027063, Times activated: 184
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
ðŸ“Š Episode completed: reward=0.018248, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.018248, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 214: Baseline reward updated 0.071315 â†’ 0.015356
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.030712, Times activated: 185
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.030712, Times activated: 185
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.030712, Times activated: 185
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.030712, Times activated: 185
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.030712, Times activated: 185
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.030712, Times activated: 185
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
ðŸ“Š Episode completed: reward=0.175099, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.175099, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 215: Baseline reward updated 0.015356 â†’ 0.032866
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.062621, Times activated: 186
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.062621, Times activated: 186
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.062621, Times activated: 186
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.062621, Times activated: 186
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.062621, Times activated: 186
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.062621, Times activated: 186
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.117     |
| time/              |           |
|    episodes        | 216       |
|    fps             | 18        |
|    time_elapsed    | 2314      |
|    total_timesteps | 43416     |
| train/             |           |
|    actor_loss      | -4.26e+05 |
|    critic_loss     | 1.06e+10  |
|    ent_coef        | 5.11e+03  |
|    ent_coef_loss   | 1.24      |
|    learning_rate   | 0.00025   |
|    n_updates       | 42415     |
----------------------------------
ðŸ“Š Episode completed: reward=0.490746, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.490746, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 216: Baseline reward updated 0.032866 â†’ 0.081941
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.158203, Times activated: 187
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.158203, Times activated: 187
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.158203, Times activated: 187
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.158203, Times activated: 187
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.158203, Times activated: 187
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.158203, Times activated: 187
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
ðŸ“Š Episode completed: reward=0.108767, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.108767, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 217: Baseline reward updated 0.081941 â†’ 0.092817
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.178973, Times activated: 188
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.178973, Times activated: 188
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.178973, Times activated: 188
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.178973, Times activated: 188
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.178973, Times activated: 188
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.178973, Times activated: 188
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
ðŸ“Š Episode completed: reward=0.067003, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.067003, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 218: Baseline reward updated 0.092817 â†’ 0.099518
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.171973, Times activated: 189
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.171973, Times activated: 189
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.171973, Times activated: 189
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.171973, Times activated: 189
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.171973, Times activated: 189
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.171973, Times activated: 189
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
ðŸ“Š Episode completed: reward=1.858594, success=True

ðŸ“ˆ Updating graph performance: episode_reward=1.858594, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 219: Baseline reward updated 0.099518 â†’ 0.285377
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.540042, Times activated: 190
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.540042, Times activated: 190
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.540042, Times activated: 190
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.540042, Times activated: 190
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.540042, Times activated: 190
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.540042, Times activated: 190
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.15      |
| time/              |           |
|    episodes        | 220       |
|    fps             | 18        |
|    time_elapsed    | 2362      |
|    total_timesteps | 44220     |
| train/             |           |
|    actor_loss      | -4.72e+05 |
|    critic_loss     | 1.8e+10   |
|    ent_coef        | 5.34e+03  |
|    ent_coef_loss   | 0.652     |
|    learning_rate   | 0.00025   |
|    n_updates       | 43219     |
----------------------------------
ðŸ“Š Episode completed: reward=1.650443, success=True

ðŸ“ˆ Updating graph performance: episode_reward=1.650443, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 220: Baseline reward updated 0.285377 â†’ 0.448866
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.835111, Times activated: 191
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.835111, Times activated: 191
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.835111, Times activated: 191
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.835111, Times activated: 191
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.835111, Times activated: 191
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.835111, Times activated: 191
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
ðŸ“Š Episode completed: reward=0.978346, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.978346, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 221: Baseline reward updated 0.448866 â†’ 0.545417
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.932631, Times activated: 192
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.932631, Times activated: 192
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.932631, Times activated: 192
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.932631, Times activated: 192
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.932631, Times activated: 192
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.932631, Times activated: 192
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 222: Baseline reward updated 0.545417 â†’ 0.544925
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.910877, Times activated: 193
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.910877, Times activated: 193
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.910877, Times activated: 193
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.910877, Times activated: 193
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.910877, Times activated: 193
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.910877, Times activated: 193
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 223: Baseline reward updated 0.544925 â†’ 0.534725
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.897477, Times activated: 194
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.897477, Times activated: 194
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.897477, Times activated: 194
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.897477, Times activated: 194
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.897477, Times activated: 194
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.897477, Times activated: 194
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.16      |
| time/              |           |
|    episodes        | 224       |
|    fps             | 18        |
|    time_elapsed    | 2409      |
|    total_timesteps | 45024     |
| train/             |           |
|    actor_loss      | -4.52e+05 |
|    critic_loss     | 1.35e+10  |
|    ent_coef        | 5.3e+03   |
|    ent_coef_loss   | -0.0339   |
|    learning_rate   | 0.00025   |
|    n_updates       | 44023     |
----------------------------------
ðŸ“Š Episode completed: reward=0.084203, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.084203, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 224: Baseline reward updated 0.534725 â†’ 0.541320
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.542598, Times activated: 195
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.542598, Times activated: 195
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.542598, Times activated: 195
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.542598, Times activated: 195
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.542598, Times activated: 195
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.542598, Times activated: 195
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
ðŸ“Š Episode completed: reward=0.021830, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.021830, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 225: Baseline reward updated 0.541320 â†’ 0.525993
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.216876, Times activated: 196
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.216876, Times activated: 196
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.216876, Times activated: 196
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.216876, Times activated: 196
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.216876, Times activated: 196
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.216876, Times activated: 196
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
ðŸ“Š Episode completed: reward=0.008150, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.008150, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 226: Baseline reward updated 0.525993 â†’ 0.477734
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.022837, Times activated: 197
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.022837, Times activated: 197
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.022837, Times activated: 197
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.022837, Times activated: 197
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.022837, Times activated: 197
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.022837, Times activated: 197
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
ðŸ“Š Episode completed: reward=0.007036, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.007036, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 227: Baseline reward updated 0.477734 â†’ 0.467560
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.024244, Times activated: 198
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.024244, Times activated: 198
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.024244, Times activated: 198
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.024244, Times activated: 198
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.024244, Times activated: 198
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.024244, Times activated: 198
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.161     |
| time/              |           |
|    episodes        | 228       |
|    fps             | 18        |
|    time_elapsed    | 2459      |
|    total_timesteps | 45828     |
| train/             |           |
|    actor_loss      | -5.08e+05 |
|    critic_loss     | 1.26e+10  |
|    ent_coef        | 5.28e+03  |
|    ent_coef_loss   | -1.79     |
|    learning_rate   | 0.00025   |
|    n_updates       | 44827     |
----------------------------------
ðŸ“Š Episode completed: reward=0.194129, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.194129, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 228: Baseline reward updated 0.467560 â†’ 0.480273
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.063070, Times activated: 199
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.063070, Times activated: 199
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.063070, Times activated: 199
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.063070, Times activated: 199
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.063070, Times activated: 199
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.063070, Times activated: 199
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 229: Baseline reward updated 0.480273 â†’ 0.294414
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.046229, Times activated: 200
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.046229, Times activated: 200
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.046229, Times activated: 200
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.046229, Times activated: 200
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.046229, Times activated: 200
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.046229, Times activated: 200
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 230: Baseline reward updated 0.294414 â†’ 0.129369
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.041863, Times activated: 201
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.041863, Times activated: 201
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.041863, Times activated: 201
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.041863, Times activated: 201
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.041863, Times activated: 201
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.041863, Times activated: 201
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 231: Baseline reward updated 0.129369 â†’ 0.031535
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.040233, Times activated: 202
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.040233, Times activated: 202
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.040233, Times activated: 202
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.040233, Times activated: 202
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.040233, Times activated: 202
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.040233, Times activated: 202
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.16      |
| time/              |           |
|    episodes        | 232       |
|    fps             | 18        |
|    time_elapsed    | 2500      |
|    total_timesteps | 46632     |
| train/             |           |
|    actor_loss      | -5.57e+05 |
|    critic_loss     | 1.14e+10  |
|    ent_coef        | 5.3e+03   |
|    ent_coef_loss   | -2.89     |
|    learning_rate   | 0.00025   |
|    n_updates       | 45631     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.021839, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.021839, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 232: Baseline reward updated 0.031535 â†’ 0.033719
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.043194, Times activated: 203
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.043194, Times activated: 203
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.043194, Times activated: 203
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.043194, Times activated: 203
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.043194, Times activated: 203
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.043194, Times activated: 203
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
ðŸ“Š Episode completed: reward=0.097112, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.097112, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 233: Baseline reward updated 0.033719 â†’ 0.043430
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.023790, Times activated: 204
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.023790, Times activated: 204
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.023790, Times activated: 204
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.023790, Times activated: 204
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.023790, Times activated: 204
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.023790, Times activated: 204
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 234: Baseline reward updated 0.043430 â†’ 0.035010
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.023790, Times activated: 205
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.023790, Times activated: 205
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.023790, Times activated: 205
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.023790, Times activated: 205
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.023790, Times activated: 205
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.023790, Times activated: 205
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
ðŸ“Š Episode completed: reward=0.271736, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.271736, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 235: Baseline reward updated 0.035010 â†’ 0.060000
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.078137, Times activated: 206
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.078137, Times activated: 206
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.078137, Times activated: 206
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.078137, Times activated: 206
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.078137, Times activated: 206
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.078137, Times activated: 206
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.142     |
| time/              |           |
|    episodes        | 236       |
|    fps             | 18        |
|    time_elapsed    | 2538      |
|    total_timesteps | 47436     |
| train/             |           |
|    actor_loss      | -4.48e+05 |
|    critic_loss     | 1.73e+10  |
|    ent_coef        | 5.3e+03   |
|    ent_coef_loss   | -0.173    |
|    learning_rate   | 0.00025   |
|    n_updates       | 46435     |
----------------------------------
ðŸ“Š Episode completed: reward=0.080955, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.080955, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 236: Baseline reward updated 0.060000 â†’ 0.067281
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.094328, Times activated: 207
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.094328, Times activated: 207
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.094328, Times activated: 207
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.094328, Times activated: 207
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.094328, Times activated: 207
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.094328, Times activated: 207
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
ðŸ“Š Episode completed: reward=0.077665, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.077665, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 237: Baseline reward updated 0.067281 â†’ 0.074344
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.105494, Times activated: 208
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.105494, Times activated: 208
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.105494, Times activated: 208
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.105494, Times activated: 208
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.105494, Times activated: 208
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.105494, Times activated: 208
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
ðŸ“Š Episode completed: reward=0.066917, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.066917, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 238: Baseline reward updated 0.074344 â†’ 0.061622
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.099455, Times activated: 209
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.099455, Times activated: 209
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.099455, Times activated: 209
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.099455, Times activated: 209
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.099455, Times activated: 209
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.099455, Times activated: 209
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
ðŸ“Š Episode completed: reward=0.061312, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.061312, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 239: Baseline reward updated 0.061622 â†’ 0.067754
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.111717, Times activated: 210
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.111717, Times activated: 210
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.111717, Times activated: 210
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.111717, Times activated: 210
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.111717, Times activated: 210
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.111717, Times activated: 210
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)

ðŸ”„ CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
ðŸ”„ Adapting curriculum...

ðŸŽ“ Generating curriculum configuration...

ðŸŽ² Selecting active interventions...

ðŸ” Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   âœ… goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.111717)
   âœ… pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   âœ… pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   âœ… physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   âœ… physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   âœ… visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   âœ… random_full is ELIGIBLE
ðŸŽ¯ Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
ðŸ“‹ Processing 7 eligible interventions...
   goal_basic: avg_reward=0.111717, confidence=0.468037, score=1.515828
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: goal_basic
   goal_basic: âœ… ACTIVATED with strength 1.000
   pose_position: avg_reward=0.111717, confidence=0.468037, score=1.515828
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_position
   pose_position: âœ… ACTIVATED with strength 1.000
   pose_full: avg_reward=0.111717, confidence=0.468037, score=1.515828
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: pose_full
   pose_full: âœ… ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.111717, confidence=0.468037, score=1.515828
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: physics_friction
   physics_friction: âœ… ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=âˆž)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
   physics_mass: âš”ï¸  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.111717, confidence=0.468037, score=1.515828
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: visual
   visual: âœ… ACTIVATED with strength 1.000
   random_full: avg_reward=0.111717, confidence=0.468037, score=1.515828
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
ðŸŽ­ Creating actor instance for: random_full
   random_full: âœ… ACTIVATED with strength 1.000

ðŸŽ‰ FINAL SELECTION: 6 interventions activated
   ðŸš€ goal_basic (strength: 1.000)
   ðŸš€ pose_position (strength: 1.000)
   ðŸš€ pose_full (strength: 1.000)
   ðŸš€ physics_friction (strength: 1.000)
   ðŸš€ visual (strength: 1.000)
   ðŸš€ random_full (strength: 1.000)
ðŸ”§ Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
âœ… Curriculum config ready: 6 actors, 6 active nodes
ðŸ”§ Updating curriculum wrapper...
ðŸ”§ Updating internal curriculum object...
ðŸ”§ Reinitializing curriculum actors...
âœ… Curriculum updated successfully!
   ðŸ“Š Active interventions: 6
   ðŸŽ¯ Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   ðŸŽ² Exploration rate: 0.9276
   ðŸ“ˆ Baseline reward: 0.067754
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.143     |
| time/              |           |
|    episodes        | 240       |
|    fps             | 18        |
|    time_elapsed    | 2581      |
|    total_timesteps | 48240     |
| train/             |           |
|    actor_loss      | -5.82e+05 |
|    critic_loss     | 1.58e+10  |
|    ent_coef        | 5.29e+03  |
|    ent_coef_loss   | 2.04      |
|    learning_rate   | 0.00025   |
|    n_updates       | 47239     |
----------------------------------
ðŸ“Š Episode completed: reward=0.081696, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.081696, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 240: Baseline reward updated 0.067754 â†’ 0.075923
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.073709, Times activated: 211
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.073709, Times activated: 211
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.073709, Times activated: 211
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.073709, Times activated: 211
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.073709, Times activated: 211
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.073709, Times activated: 211
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
ðŸ“Š Episode completed: reward=0.201440, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.201440, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 241: Baseline reward updated 0.075923 â†’ 0.096067
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.097806, Times activated: 212
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.097806, Times activated: 212
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.097806, Times activated: 212
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.097806, Times activated: 212
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.097806, Times activated: 212
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.097806, Times activated: 212
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
ðŸ“Š Episode completed: reward=0.024661, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.024661, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 242: Baseline reward updated 0.096067 â†’ 0.096349
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.087205, Times activated: 213
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.087205, Times activated: 213
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.087205, Times activated: 213
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.087205, Times activated: 213
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.087205, Times activated: 213
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.087205, Times activated: 213
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
ðŸ“Š Episode completed: reward=0.004470, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.004470, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 243: Baseline reward updated 0.096349 â†’ 0.087085
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.074716, Times activated: 214
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.074716, Times activated: 214
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.074716, Times activated: 214
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.074716, Times activated: 214
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.074716, Times activated: 214
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.074716, Times activated: 214
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.147     |
| time/              |           |
|    episodes        | 244       |
|    fps             | 18        |
|    time_elapsed    | 2632      |
|    total_timesteps | 49044     |
| train/             |           |
|    actor_loss      | -4.06e+05 |
|    critic_loss     | 8.73e+09  |
|    ent_coef        | 5.28e+03  |
|    ent_coef_loss   | -3.29     |
|    learning_rate   | 0.00025   |
|    n_updates       | 48043     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
ðŸ“Š Episode completed: reward=0.176748, success=True

ðŸ“ˆ Updating graph performance: episode_reward=0.176748, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 244: Baseline reward updated 0.087085 â†’ 0.104760
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.097803, Times activated: 215
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.097803, Times activated: 215
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.097803, Times activated: 215
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.097803, Times activated: 215
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.097803, Times activated: 215
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.097803, Times activated: 215
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 245: Baseline reward updated 0.104760 â†’ 0.077586
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.081464, Times activated: 216
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.081464, Times activated: 216
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.081464, Times activated: 216
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.081464, Times activated: 216
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.081464, Times activated: 216
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.081464, Times activated: 216
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 246: Baseline reward updated 0.077586 â†’ 0.069491
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.041176, Times activated: 217
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.041176, Times activated: 217
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.041176, Times activated: 217
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.041176, Times activated: 217
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.041176, Times activated: 217
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.041176, Times activated: 217
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
ðŸ“Š Episode completed: reward=0.000000, success=False

ðŸ“ˆ Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 247: Baseline reward updated 0.069491 â†’ 0.061724
ðŸ“Š Node goal_basic: Updated performance - Recent avg reward: 0.036244, Times activated: 218
ðŸŽ¯ Node goal_basic: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
ðŸ“Š Node pose_position: Updated performance - Recent avg reward: 0.036244, Times activated: 218
ðŸŽ¯ Node pose_position: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
ðŸ“Š Node pose_full: Updated performance - Recent avg reward: 0.036244, Times activated: 218
ðŸŽ¯ Node pose_full: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
ðŸ“Š Node physics_friction: Updated performance - Recent avg reward: 0.036244, Times activated: 218
ðŸŽ¯ Node physics_friction: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
ðŸ“Š Node visual: Updated performance - Recent avg reward: 0.036244, Times activated: 218
ðŸŽ¯ Node visual: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
ðŸ“Š Node random_full: Updated performance - Recent avg reward: 0.036244, Times activated: 218
ðŸŽ¯ Node random_full: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.147     |
| time/              |           |
|    episodes        | 248       |
|    fps             | 18        |
|    time_elapsed    | 2669      |
|    total_timesteps | 49848     |
| train/             |           |
|    actor_loss      | -5.88e+05 |
|    critic_loss     | 1.51e+10  |
|    ent_coef        | 5.25e+03  |
|    ent_coef_loss   | 1.88      |
|    learning_rate   | 0.00025   |
|    n_updates       | 48847     |
----------------------------------
Traceback (most recent call last):
  File "her_sac.py", line 175, in <module>
    wandb_config=wandb_config
  File "her_sac.py", line 128, in train_policy
    callback=callbacks)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\sac\sac.py", line 301, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\off_policy_algorithm.py", line 375, in learn
    callback.on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\callbacks.py", line 91, in on_training_end
    self._on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\callbacks.py", line 201, in _on_training_end
    callback.on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\callbacks.py", line 91, in on_training_end
    self._on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\integration\sb3\sb3.py", line 147, in _on_training_end
    self.save_model()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\integration\sb3\sb3.py", line 151, in save_model
    wandb.save(self.path, base_path=self.model_save_path)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 2027, in save
    policy,
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 2088, in _save
    target_path.symlink_to(source_path)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\pathlib.py", line 1337, in symlink_to
    self._accessor.symlink(target, self, target_is_directory)
OSError: symbolic link privilege not held
