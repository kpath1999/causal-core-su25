2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_setup.py:_flush():79] Current SDK version is 0.18.7
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_setup.py:_flush():79] Configure stats pid to 10296
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_setup.py:_flush():79] Loading settings from C:\Users\Admin\.config\wandb\settings
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_setup.py:_flush():79] Loading settings from C:\Users\Admin\Documents\school_projects\causal-core-su25\wandb\settings
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program_relpath': 'her_sac.py', 'program_abspath': 'C:\\Users\\Admin\\Documents\\school_projects\\causal-core-su25\\her_sac.py', 'program': 'her_sac.py'}
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_setup.py:_flush():79] Applying login settings: {}
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_init.py:_log_setup():533] Logging user logs to C:\Users\Admin\Documents\school_projects\causal-core-su25\wandb\run-20250603_161814-bgou324y\logs\debug.log
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_init.py:_log_setup():534] Logging internal logs to C:\Users\Admin\Documents\school_projects\causal-core-su25\wandb\run-20250603_161814-bgou324y\logs\debug-internal.log
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_init.py:init():619] calling init triggers
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_init.py:init():627] wandb.init called with sweep_config: {}
config: {'task_name': 'picking', 'maximum_episode_length': 200, 'skip_frame': 3, 'seed_num': 0, 'total_time_steps': 50000, 'graph_curriculum_enabled': True, 'n_sampled_goal': 2, 'goal_selection_strategy': 'future', 'gamma': 0.98, 'tau': 0.01, 'ent_coef': 'auto', 'target_entropy': -9, 'learning_rate': 0.00025, 'buffer_size': 500000, 'learning_starts': 1000, 'batch_size': 128, 'tensorboard_log': 'baseline_picking_her_sac_curriculum'}
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_init.py:init():669] starting backend
2025-06-03 16:18:14,219 INFO    MainThread:10296 [wandb_init.py:init():673] sending inform_init request
2025-06-03 16:18:14,235 INFO    MainThread:10296 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn, using: spawn
2025-06-03 16:18:14,236 INFO    MainThread:10296 [wandb_init.py:init():686] backend started and connected
2025-06-03 16:18:14,247 INFO    MainThread:10296 [wandb_init.py:init():781] updated telemetry
2025-06-03 16:18:14,358 INFO    MainThread:10296 [wandb_init.py:init():814] communicating run to backend with 90.0 second timeout
2025-06-03 16:18:14,632 INFO    MainThread:10296 [wandb_init.py:init():867] starting run threads in backend
2025-06-03 16:18:15,296 INFO    MainThread:10296 [wandb_run.py:_console_start():2456] atexit reg
2025-06-03 16:18:15,296 INFO    MainThread:10296 [wandb_run.py:_redirect():2305] redirect: wrap_raw
2025-06-03 16:18:15,296 INFO    MainThread:10296 [wandb_run.py:_redirect():2370] Wrapping output streams.
2025-06-03 16:18:15,297 INFO    MainThread:10296 [wandb_run.py:_redirect():2395] Redirects installed.
2025-06-03 16:18:15,299 INFO    MainThread:10296 [wandb_init.py:init():911] run started, returning control to user process
2025-06-03 16:18:15,822 INFO    MainThread:10296 [wandb_run.py:_tensorboard_callback():1544] tensorboard callback: baseline_picking_her_sac_curriculum\her_sac_curriculum_2, True
2025-06-03 16:18:15,872 INFO    MainThread:10296 [wandb_watch.py:_watch():71] Watching
2025-06-03 16:18:15,876 INFO    MainThread:10296 [wandb_run.py:_config_callback():1387] config_cb None None {'algo': 'SAC', 'policy_class': "<class 'stable_baselines3.sac.policies.MultiInputPolicy'>", 'device': 'cpu', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001EE8D86CAC8>', '_vec_normalize_env': 'None', 'verbose': 1, 'policy_kwargs': "{'net_arch': [256, 256], 'use_sde': False}", 'observation_space': 'Dict(achieved_goal:Box(6,), desired_goal:Box(6,), observation:Box(56,))', 'action_space': 'Box(9,)', 'n_envs': 1, 'num_timesteps': 0, '_total_timesteps': 50000, '_num_timesteps_at_start': 0, 'eval_env': 'None', 'seed': 0, 'action_noise': 'None', 'start_time': 1748981895.6420805, 'policy': 'MultiInputPolicy(\n  (actor): Actor(\n    (features_extractor): CombinedExtractor(\n      (extractors): ModuleDict(\n        (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n        (desired_goal): Flatten(start_dim=1, end_dim=-1)\n        (observation): Flatten(start_dim=1, end_dim=-1)\n      )\n    )\n    (latent_pi): Sequential(\n      (0): Linear(in_features=68, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n    )\n    (mu): Linear(in_features=256, out_features=9, bias=True)\n    (log_std): Linear(in_features=256, out_features=9, bias=True)\n  )\n  (critic): ContinuousCritic(\n    (features_extractor): CombinedExtractor(\n      (extractors): ModuleDict(\n        (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n        (desired_goal): Flatten(start_dim=1, end_dim=-1)\n        (observation): Flatten(start_dim=1, end_dim=-1)\n      )\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=77, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    (qf1): Sequential(\n      (0): Linear(in_features=77, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n  )\n  (critic_target): ContinuousCritic(\n    (features_extractor): CombinedExtractor(\n      (extractors): ModuleDict(\n        (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n        (desired_goal): Flatten(start_dim=1, end_dim=-1)\n        (observation): Flatten(start_dim=1, end_dim=-1)\n      )\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=77, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    (qf1): Sequential(\n      (0): Linear(in_features=77, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n  )\n)', 'lr_schedule': '<function constant_fn.<locals>.func at 0x000001EE8C07C678>', '_last_obs': "OrderedDict([('achieved_goal', array([[-0.06426357, -0.06116914,  0.17556817,  0.02758888,  0.0306833 ,\n         0.24056817]])), ('desired_goal', array([[-0.03944146, -0.03944146,  0.21354938,  0.03944146,  0.03944146,\n         0.27854938]])), ('observation', array([[ 1.00000000e+00,  2.21789883e-01,  4.33500479e-01,\n        -2.61799388e-01,  2.21789883e-01,  4.33500479e-01,\n        -2.61799388e-01,  2.21789883e-01,  4.33500479e-01,\n        -2.61799388e-01,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00, -1.18900000e-01,  3.17274170e-01,\n        -7.76548340e-01,  3.34217491e-01, -5.56666645e-02,\n        -7.76548340e-01, -2.15317491e-01, -2.61607506e-01,\n        -7.76548340e-01,  1.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00, -3.66746952e-02,\n        -3.04858377e-02, -1.67727339e-01,  0.00000000e+00,\n         0.00000000e+00, -4.00820298e-02,  9.16156694e-02,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         2.00000000e+01,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n        -1.58024600e-02,  0.00000000e+00,  0.00000000e+00,\n         9.92431275e-02, -1.22801323e-02]]))])", '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_logger': '<stable_baselines3.common.logger.Logger object at 0x000001EE8D81BC88>', '_custom_logger': 'False', 'gradient_steps': 1, 'optimize_memory_usage': 'False', 'replay_buffer_class': "<class 'stable_baselines3.her.her_replay_buffer.HerReplayBuffer'>", 'replay_buffer_kwargs': "{'n_sampled_goal': 2, 'goal_selection_strategy': 'future', 'max_episode_length': 200}", '_episode_storage': 'None', 'remove_time_limit_termination': 'False', 'train_freq': "TrainFreq(frequency=1, unit=<TrainFrequencyUnit.STEP: 'step'>)", 'actor': 'Actor(\n  (features_extractor): CombinedExtractor(\n    (extractors): ModuleDict(\n      (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n      (desired_goal): Flatten(start_dim=1, end_dim=-1)\n      (observation): Flatten(start_dim=1, end_dim=-1)\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=68, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n  )\n  (mu): Linear(in_features=256, out_features=9, bias=True)\n  (log_std): Linear(in_features=256, out_features=9, bias=True)\n)', 'replay_buffer': '<stable_baselines3.her.her_replay_buffer.HerReplayBuffer object at 0x000001EE8BC26E48>', 'use_sde_at_warmup': 'False', 'log_ent_coef': 'tensor([0.], requires_grad=True)', 'target_update_interval': 1, 'ent_coef_optimizer': 'Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: False\n    lr: 0.00025\n    maximize: False\n    weight_decay: 0\n)', 'critic': 'ContinuousCritic(\n  (features_extractor): CombinedExtractor(\n    (extractors): ModuleDict(\n      (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n      (desired_goal): Flatten(start_dim=1, end_dim=-1)\n      (observation): Flatten(start_dim=1, end_dim=-1)\n    )\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=77, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=77, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n)', 'critic_target': 'ContinuousCritic(\n  (features_extractor): CombinedExtractor(\n    (extractors): ModuleDict(\n      (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n      (desired_goal): Flatten(start_dim=1, end_dim=-1)\n      (observation): Flatten(start_dim=1, end_dim=-1)\n    )\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=77, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=77, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n)'}
2025-06-03 17:02:51,642 WARNING MsgRouterThr:10296 [router.py:message_loop():75] message_loop has been closed
