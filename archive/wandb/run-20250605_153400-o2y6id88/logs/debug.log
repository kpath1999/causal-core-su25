2025-06-05 15:34:00,583 INFO    MainThread:6180 [wandb_setup.py:_flush():79] Current SDK version is 0.18.7
2025-06-05 15:34:00,583 INFO    MainThread:6180 [wandb_setup.py:_flush():79] Configure stats pid to 6180
2025-06-05 15:34:00,583 INFO    MainThread:6180 [wandb_setup.py:_flush():79] Loading settings from C:\Users\Admin\.config\wandb\settings
2025-06-05 15:34:00,583 INFO    MainThread:6180 [wandb_setup.py:_flush():79] Loading settings from C:\Users\Admin\Documents\school_projects\causal-core-su25\wandb\settings
2025-06-05 15:34:00,588 INFO    MainThread:6180 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2025-06-05 15:34:00,588 INFO    MainThread:6180 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2025-06-05 15:34:00,588 INFO    MainThread:6180 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program_relpath': 'her_sac.py', 'program_abspath': 'C:\\Users\\Admin\\Documents\\school_projects\\causal-core-su25\\her_sac.py', 'program': 'her_sac.py'}
2025-06-05 15:34:00,588 INFO    MainThread:6180 [wandb_setup.py:_flush():79] Applying login settings: {}
2025-06-05 15:34:00,589 INFO    MainThread:6180 [wandb_init.py:_log_setup():533] Logging user logs to C:\Users\Admin\Documents\school_projects\causal-core-su25\wandb\run-20250605_153400-o2y6id88\logs\debug.log
2025-06-05 15:34:00,589 INFO    MainThread:6180 [wandb_init.py:_log_setup():534] Logging internal logs to C:\Users\Admin\Documents\school_projects\causal-core-su25\wandb\run-20250605_153400-o2y6id88\logs\debug-internal.log
2025-06-05 15:34:00,589 INFO    MainThread:6180 [wandb_init.py:init():619] calling init triggers
2025-06-05 15:34:00,590 INFO    MainThread:6180 [wandb_init.py:init():627] wandb.init called with sweep_config: {}
config: {'task_name': 'picking', 'maximum_episode_length': 200, 'skip_frame': 3, 'seed_num': 0, 'total_time_steps': 50000, 'graph_curriculum_enabled': True, 'n_sampled_goal': 2, 'goal_selection_strategy': 'future', 'gamma': 0.98, 'tau': 0.01, 'ent_coef': 'auto', 'target_entropy': -9, 'learning_rate': 0.00025, 'buffer_size': 500000, 'learning_starts': 1000, 'batch_size': 128, 'tensorboard_log': 'baseline_picking_her_sac_curriculum'}
2025-06-05 15:34:00,590 INFO    MainThread:6180 [wandb_init.py:init():669] starting backend
2025-06-05 15:34:00,590 INFO    MainThread:6180 [wandb_init.py:init():673] sending inform_init request
2025-06-05 15:34:00,596 INFO    MainThread:6180 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn, using: spawn
2025-06-05 15:34:00,596 INFO    MainThread:6180 [wandb_init.py:init():686] backend started and connected
2025-06-05 15:34:00,605 INFO    MainThread:6180 [wandb_init.py:init():781] updated telemetry
2025-06-05 15:34:00,703 INFO    MainThread:6180 [wandb_init.py:init():814] communicating run to backend with 90.0 second timeout
2025-06-05 15:34:01,093 INFO    MainThread:6180 [wandb_init.py:init():867] starting run threads in backend
2025-06-05 15:34:01,871 INFO    MainThread:6180 [wandb_run.py:_console_start():2456] atexit reg
2025-06-05 15:34:01,872 INFO    MainThread:6180 [wandb_run.py:_redirect():2305] redirect: wrap_raw
2025-06-05 15:34:01,873 INFO    MainThread:6180 [wandb_run.py:_redirect():2370] Wrapping output streams.
2025-06-05 15:34:01,873 INFO    MainThread:6180 [wandb_run.py:_redirect():2395] Redirects installed.
2025-06-05 15:34:01,881 INFO    MainThread:6180 [wandb_init.py:init():911] run started, returning control to user process
2025-06-05 15:34:02,340 INFO    MainThread:6180 [wandb_run.py:_tensorboard_callback():1544] tensorboard callback: baseline_picking_her_sac_curriculum\her_sac_curriculum_4, True
2025-06-05 15:34:02,384 INFO    MainThread:6180 [wandb_watch.py:_watch():71] Watching
2025-06-05 15:34:02,385 INFO    MainThread:6180 [wandb_run.py:_config_callback():1387] config_cb None None {'algo': 'SAC', 'policy_class': "<class 'stable_baselines3.sac.policies.MultiInputPolicy'>", 'device': 'cpu', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001CBB2332408>', '_vec_normalize_env': 'None', 'verbose': 1, 'policy_kwargs': "{'net_arch': [256, 256], 'use_sde': False}", 'observation_space': 'Dict(achieved_goal:Box(6,), desired_goal:Box(6,), observation:Box(56,))', 'action_space': 'Box(9,)', 'n_envs': 1, 'num_timesteps': 0, '_total_timesteps': 50000, '_num_timesteps_at_start': 0, 'eval_env': 'None', 'seed': 0, 'action_noise': 'None', 'start_time': 1749152042.2746782, 'policy': 'MultiInputPolicy(\n  (actor): Actor(\n    (features_extractor): CombinedExtractor(\n      (extractors): ModuleDict(\n        (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n        (desired_goal): Flatten(start_dim=1, end_dim=-1)\n        (observation): Flatten(start_dim=1, end_dim=-1)\n      )\n    )\n    (latent_pi): Sequential(\n      (0): Linear(in_features=68, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n    )\n    (mu): Linear(in_features=256, out_features=9, bias=True)\n    (log_std): Linear(in_features=256, out_features=9, bias=True)\n  )\n  (critic): ContinuousCritic(\n    (features_extractor): CombinedExtractor(\n      (extractors): ModuleDict(\n        (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n        (desired_goal): Flatten(start_dim=1, end_dim=-1)\n        (observation): Flatten(start_dim=1, end_dim=-1)\n      )\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=77, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    (qf1): Sequential(\n      (0): Linear(in_features=77, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n  )\n  (critic_target): ContinuousCritic(\n    (features_extractor): CombinedExtractor(\n      (extractors): ModuleDict(\n        (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n        (desired_goal): Flatten(start_dim=1, end_dim=-1)\n        (observation): Flatten(start_dim=1, end_dim=-1)\n      )\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=77, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    (qf1): Sequential(\n      (0): Linear(in_features=77, out_features=256, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n  )\n)', 'lr_schedule': '<function constant_fn.<locals>.func at 0x000001CBB2318B88>', '_last_obs': "OrderedDict([('achieved_goal', array([[-3.25000000e-02, -3.25000000e-02, -3.46944695e-18,\n         3.25000000e-02,  3.25000000e-02,  6.50000000e-02]])), ('desired_goal', array([[-0.0325, -0.0325,  0.1175,  0.0325,  0.0325,  0.1825]])), ('observation', array([[ 1.        ,  0.22178988,  0.43350048, -0.26179939,  0.22178988,\n         0.43350048, -0.26179939,  0.22178988,  0.43350048, -0.26179939,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        , -0.1189    ,\n         0.31727417, -0.77654834,  0.33421749, -0.05566666, -0.77654834,\n        -0.21531749, -0.26160751, -0.77654834,  1.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        , -0.87      ,\n         0.        ,  0.        ,  0.        ,  0.1       ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        20.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        , -0.4       ,  0.        ,  0.        ,  0.        ,\n         0.1       ]]))])", '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_logger': '<stable_baselines3.common.logger.Logger object at 0x000001CBB2332348>', '_custom_logger': 'False', 'gradient_steps': 1, 'optimize_memory_usage': 'False', 'replay_buffer_class': "<class 'stable_baselines3.her.her_replay_buffer.HerReplayBuffer'>", 'replay_buffer_kwargs': "{'n_sampled_goal': 2, 'goal_selection_strategy': 'future', 'max_episode_length': 200}", '_episode_storage': 'None', 'remove_time_limit_termination': 'False', 'train_freq': "TrainFreq(frequency=1, unit=<TrainFrequencyUnit.STEP: 'step'>)", 'actor': 'Actor(\n  (features_extractor): CombinedExtractor(\n    (extractors): ModuleDict(\n      (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n      (desired_goal): Flatten(start_dim=1, end_dim=-1)\n      (observation): Flatten(start_dim=1, end_dim=-1)\n    )\n  )\n  (latent_pi): Sequential(\n    (0): Linear(in_features=68, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n  )\n  (mu): Linear(in_features=256, out_features=9, bias=True)\n  (log_std): Linear(in_features=256, out_features=9, bias=True)\n)', 'replay_buffer': '<stable_baselines3.her.her_replay_buffer.HerReplayBuffer object at 0x000001CBB2332608>', 'use_sde_at_warmup': 'False', 'log_ent_coef': 'tensor([0.], requires_grad=True)', 'target_update_interval': 1, 'ent_coef_optimizer': 'Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: False\n    lr: 0.00025\n    maximize: False\n    weight_decay: 0\n)', 'critic': 'ContinuousCritic(\n  (features_extractor): CombinedExtractor(\n    (extractors): ModuleDict(\n      (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n      (desired_goal): Flatten(start_dim=1, end_dim=-1)\n      (observation): Flatten(start_dim=1, end_dim=-1)\n    )\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=77, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=77, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n)', 'critic_target': 'ContinuousCritic(\n  (features_extractor): CombinedExtractor(\n    (extractors): ModuleDict(\n      (achieved_goal): Flatten(start_dim=1, end_dim=-1)\n      (desired_goal): Flatten(start_dim=1, end_dim=-1)\n      (observation): Flatten(start_dim=1, end_dim=-1)\n    )\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=77, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=77, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=256, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=1, bias=True)\n  )\n)'}
2025-06-05 16:14:47,756 WARNING MsgRouterThr:6180 [router.py:message_loop():75] message_loop has been closed
