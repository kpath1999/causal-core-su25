🚀 Initializing GraphBasedCurriculumManager with 50000 timesteps
📋 Experimental design: 50 baseline episodes, 25 episodes per intervention test
🏗️ Building intervention dependency graph...
🔧 Created intervention node: goal_basic with params: {}
🔧 Created intervention node: pose_position with params: {'positions': True, 'orientations': False}
🔧 Created intervention node: pose_full with params: {'positions': True, 'orientations': True}
🔧 Created intervention node: physics_friction with params: {'group': 'friction'}
🔧 Created intervention node: physics_mass with params: {'group': 'mass'}
🔧 Created intervention node: visual with params: {}
🔧 Created intervention node: random_full with params: {}
➕ Added node to graph: goal_basic
➕ Added node to graph: pose_position
➕ Added node to graph: pose_full
➕ Added node to graph: physics_friction
➕ Added node to graph: physics_mass
➕ Added node to graph: visual
➕ Added node to graph: random_full
🔗 Setting up dependencies:
   goal_basic → pose_position
⚔️ Setting up conflicts:
   physics_mass ⚔️ physics_friction
   pose_position ⚔️ pose_full
🧪 Intervention test order: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
✅ Graph construction complete: 7 nodes, 5 edges

🎓 CURRICULUM CONFIG GENERATION (Episode 0)
   📊 BASELINE PERIOD: No interventions active
🔄 Curriculum callback initialized: adaptation every 30 episodes
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Logging to baseline_picking_her_sac_curriculum\her_sac_curriculum_3

📊 EPISODE COMPLETED:
   Episode: 1
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 0)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 2
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 1)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 3
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 2)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 4        |
|    fps             | 328      |
|    time_elapsed    | 2        |
|    total_timesteps | 804      |
---------------------------------

📊 EPISODE COMPLETED:
   Episode: 4
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 3)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 5
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 4)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 6
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 5)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 7
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 6)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 8        |
|    fps             | 50       |
|    time_elapsed    | 31       |
|    total_timesteps | 1608     |
| train/             |          |
|    actor_loss      | -32.1    |
|    critic_loss     | 37.3     |
|    ent_coef        | 0.87     |
|    ent_coef_loss   | -1.33    |
|    learning_rate   | 0.00025  |
|    n_updates       | 607      |
---------------------------------

📊 EPISODE COMPLETED:
   Episode: 8
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 7)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 9
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 8)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 10
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 9)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
🎯 Node goal_basic: Insufficient data for causal impact (intervention: 0, baseline: 10)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 10)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_full: Insufficient data for causal impact (intervention: 0, baseline: 10)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 10)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 10)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 10)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 10)

📊 EPISODE COMPLETED:
   Episode: 11
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 10)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 12       |
|    fps             | 32       |
|    time_elapsed    | 74       |
|    total_timesteps | 2412     |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 200      |
|    ent_coef        | 0.824    |
|    ent_coef_loss   | 0.462    |
|    learning_rate   | 0.00025  |
|    n_updates       | 1411     |
---------------------------------

📊 EPISODE COMPLETED:
   Episode: 12
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 11)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 13
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 12)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 14
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 13)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 15
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 14)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 16       |
|    fps             | 27       |
|    time_elapsed    | 116      |
|    total_timesteps | 3216     |
| train/             |          |
|    actor_loss      | -706     |
|    critic_loss     | 7.81e+03 |
|    ent_coef        | 1.03     |
|    ent_coef_loss   | -0.439   |
|    learning_rate   | 0.00025  |
|    n_updates       | 2215     |
---------------------------------

📊 EPISODE COMPLETED:
   Episode: 16
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 15)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 17
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 16)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 18
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 17)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 19
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 18)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 20        |
|    fps             | 24        |
|    time_elapsed    | 161       |
|    total_timesteps | 4020      |
| train/             |           |
|    actor_loss      | -2.71e+03 |
|    critic_loss     | 1.64e+05  |
|    ent_coef        | 1.4       |
|    ent_coef_loss   | -8.76     |
|    learning_rate   | 0.00025   |
|    n_updates       | 3019      |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 20
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 19)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
🎯 Node goal_basic: Insufficient data for causal impact (intervention: 0, baseline: 20)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 20)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_full: Insufficient data for causal impact (intervention: 0, baseline: 20)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 20)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 20)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 20)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 20)

📊 EPISODE COMPLETED:
   Episode: 21
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 20)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 22
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 21)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 23
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 22)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 24        |
|    fps             | 23        |
|    time_elapsed    | 205       |
|    total_timesteps | 4824      |
| train/             |           |
|    actor_loss      | -8.82e+03 |
|    critic_loss     | 2.35e+06  |
|    ent_coef        | 1.89      |
|    ent_coef_loss   | -28.6     |
|    learning_rate   | 0.00025   |
|    n_updates       | 3823      |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 24
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 23)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 25
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 24)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 26
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 25)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 27
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 26)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 28        |
|    fps             | 23        |
|    time_elapsed    | 244       |
|    total_timesteps | 5628      |
| train/             |           |
|    actor_loss      | -1.96e+04 |
|    critic_loss     | 1.73e+07  |
|    ent_coef        | 2.54      |
|    ent_coef_loss   | -58.7     |
|    learning_rate   | 0.00025   |
|    n_updates       | 4627      |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 28
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 27)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 29
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 28)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

🔄 CURRICULUM ADAPTATION TRIGGERED
🔄 Adapting curriculum...

🎓 CURRICULUM CONFIG GENERATION (Episode 29)
   📊 BASELINE PERIOD: No interventions active
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
[34m[1mwandb[0m: [33mWARNING[0m Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
✅ Curriculum updated successfully!
   📊 Active interventions: 0
   🎯 Active nodes: []
   📈 Baseline reward: 0.000000
   🧪 Episode count: 29

📊 EPISODE COMPLETED:
   Episode: 30
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 29)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
🎯 Node goal_basic: Insufficient data for causal impact (intervention: 0, baseline: 30)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 30)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_full: Insufficient data for causal impact (intervention: 0, baseline: 30)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 30)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 30)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 30)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 30)

📊 EPISODE COMPLETED:
   Episode: 31
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 30)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 32        |
|    fps             | 22        |
|    time_elapsed    | 280       |
|    total_timesteps | 6432      |
| train/             |           |
|    actor_loss      | -3.04e+04 |
|    critic_loss     | 3.46e+07  |
|    ent_coef        | 3.19      |
|    ent_coef_loss   | -70       |
|    learning_rate   | 0.00025   |
|    n_updates       | 5431      |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 32
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 31)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 33
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 32)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 34
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 33)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 35
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 34)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 36        |
|    fps             | 22        |
|    time_elapsed    | 321       |
|    total_timesteps | 7236      |
| train/             |           |
|    actor_loss      | -5.06e+04 |
|    critic_loss     | 1.09e+08  |
|    ent_coef        | 4.02      |
|    ent_coef_loss   | -99.4     |
|    learning_rate   | 0.00025   |
|    n_updates       | 6235      |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 36
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 35)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 37
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 36)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 38
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 37)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 39
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 38)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 40       |
|    fps             | 22       |
|    time_elapsed    | 359      |
|    total_timesteps | 8040     |
| train/             |          |
|    actor_loss      | -7.5e+04 |
|    critic_loss     | 2.72e+08 |
|    ent_coef        | 5.03     |
|    ent_coef_loss   | -135     |
|    learning_rate   | 0.00025  |
|    n_updates       | 7039     |
---------------------------------

📊 EPISODE COMPLETED:
   Episode: 40
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 39)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
🎯 Node goal_basic: Insufficient data for causal impact (intervention: 0, baseline: 40)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 40)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_full: Insufficient data for causal impact (intervention: 0, baseline: 40)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 40)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 40)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 40)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 40)

📊 EPISODE COMPLETED:
   Episode: 41
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 40)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 42
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 41)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 43
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 42)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 44        |
|    fps             | 22        |
|    time_elapsed    | 396       |
|    total_timesteps | 8844      |
| train/             |           |
|    actor_loss      | -9.66e+04 |
|    critic_loss     | 6.01e+08  |
|    ent_coef        | 6.27      |
|    ent_coef_loss   | -153      |
|    learning_rate   | 0.00025   |
|    n_updates       | 7843      |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 44
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 43)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 45
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 44)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 46
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 45)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 47
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 46)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 48        |
|    fps             | 22        |
|    time_elapsed    | 434       |
|    total_timesteps | 9648      |
| train/             |           |
|    actor_loss      | -1.31e+05 |
|    critic_loss     | 8.45e+08  |
|    ent_coef        | 7.75      |
|    ent_coef_loss   | -174      |
|    learning_rate   | 0.00025   |
|    n_updates       | 8647      |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 48
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 47)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 49
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 48)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 50
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 49)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
🎯 Node goal_basic: Insufficient data for causal impact (intervention: 0, baseline: 50)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 50)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_full: Insufficient data for causal impact (intervention: 0, baseline: 50)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 50)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 50)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 50)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 50)

📊 EPISODE COMPLETED:
   Episode: 51
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 50)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 52        |
|    fps             | 22        |
|    time_elapsed    | 472       |
|    total_timesteps | 10452     |
| train/             |           |
|    actor_loss      | -1.27e+05 |
|    critic_loss     | 1.1e+09   |
|    ent_coef        | 9.5       |
|    ent_coef_loss   | -190      |
|    learning_rate   | 0.00025   |
|    n_updates       | 9451      |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 52
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 51)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 53
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 52)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 54
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 53)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 55
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 54)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0        |
| time/              |          |
|    episodes        | 56       |
|    fps             | 22       |
|    time_elapsed    | 508      |
|    total_timesteps | 11256    |
| train/             |          |
|    actor_loss      | -1.7e+05 |
|    critic_loss     | 2.01e+09 |
|    ent_coef        | 11.7     |
|    ent_coef_loss   | -208     |
|    learning_rate   | 0.00025  |
|    n_updates       | 10255    |
---------------------------------

📊 EPISODE COMPLETED:
   Episode: 56
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 55)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 57
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 56)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 58
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 57)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 59
   Reward: 0.000000
   Success: False
   Active interventions: []

📈 PERFORMANCE UPDATE (Episode 58)
   Reward: 0.000000, Success: False
   Active interventions: []
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

🔄 CURRICULUM ADAPTATION TRIGGERED
🔄 Adapting curriculum...

🎓 CURRICULUM CONFIG GENERATION (Episode 59)

🧪 EXPERIMENTAL PHASE SELECTION (Episode 59)

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=False
      Prerequisites: goal_basic(satisfied=False, data_points=0, causal_impact=0.000000)
   ❌ pose_position is NOT eligible
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
🔬 INTERVENTION TEST PHASE:
   Test cycle: 0
   Testing intervention: goal_basic
   Episodes in current test: 9/25
   Eligible interventions: ['goal_basic', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
🎭 Creating actor instance for: goal_basic
   🚀 SELECTED: goal_basic (strength: 0.7)
   🔧 Building curriculum configuration:
      goal_basic: frequency=1, strength=0.700
   ✅ Config ready: 1 actors, 1 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 1
   🎯 Active nodes: ['goal_basic']
   📈 Baseline reward: 0.000000
   🧪 Episode count: 59
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 60        |
|    fps             | 22        |
|    time_elapsed    | 546       |
|    total_timesteps | 12060     |
| train/             |           |
|    actor_loss      | -2.01e+05 |
|    critic_loss     | 2.02e+09  |
|    ent_coef        | 14.3      |
|    ent_coef_loss   | -213      |
|    learning_rate   | 0.00025   |
|    n_updates       | 11059     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 60
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 59)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=1
🎯 Node goal_basic: Insufficient data for causal impact (intervention: 1, baseline: 59)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 60)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_full: Insufficient data for causal impact (intervention: 0, baseline: 60)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 60)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 60)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 60)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 60)

📊 EPISODE COMPLETED:
   Episode: 61
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 60)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=2
📈 Node goal_basic: Success rate updated to 0.000000 (based on 2 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 62
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 61)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=3
📈 Node goal_basic: Success rate updated to 0.000000 (based on 3 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 63
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 62)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=4
📈 Node goal_basic: Success rate updated to 0.000000 (based on 4 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 64        |
|    fps             | 21        |
|    time_elapsed    | 587       |
|    total_timesteps | 12864     |
| train/             |           |
|    actor_loss      | -2.34e+05 |
|    critic_loss     | 2.57e+09  |
|    ent_coef        | 17.4      |
|    ent_coef_loss   | -229      |
|    learning_rate   | 0.00025   |
|    n_updates       | 11863     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 64
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 63)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=5
📈 Node goal_basic: Success rate updated to 0.000000 (based on 5 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 65
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 64)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=6
📈 Node goal_basic: Success rate updated to 0.000000 (based on 6 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 66
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 65)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=7
📈 Node goal_basic: Success rate updated to 0.000000 (based on 7 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 67
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 66)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=8
📈 Node goal_basic: Success rate updated to 0.000000 (based on 8 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 68        |
|    fps             | 21        |
|    time_elapsed    | 624       |
|    total_timesteps | 13668     |
| train/             |           |
|    actor_loss      | -2.88e+05 |
|    critic_loss     | 4.09e+09  |
|    ent_coef        | 21.2      |
|    ent_coef_loss   | -250      |
|    learning_rate   | 0.00025   |
|    n_updates       | 12667     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 68
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 67)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=9
📈 Node goal_basic: Success rate updated to 0.000000 (based on 9 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 69
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 68)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=10
📈 Node goal_basic: Success rate updated to 0.000000 (based on 10 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 70
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 69)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=11
📈 Node goal_basic: Success rate updated to 0.000000 (based on 11 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=11)
   Baseline mean: 0.000000 (n=59)
   Causal impact: 0.000000
   Effect size: 0.000
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 70)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_full: Insufficient data for causal impact (intervention: 0, baseline: 70)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 70)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 70)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 70)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 70)

📊 EPISODE COMPLETED:
   Episode: 71
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 70)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=12
📈 Node goal_basic: Success rate updated to 0.000000 (based on 12 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0         |
| time/              |           |
|    episodes        | 72        |
|    fps             | 21        |
|    time_elapsed    | 663       |
|    total_timesteps | 14472     |
| train/             |           |
|    actor_loss      | -2.92e+05 |
|    critic_loss     | 5.69e+09  |
|    ent_coef        | 25.9      |
|    ent_coef_loss   | -253      |
|    learning_rate   | 0.00025   |
|    n_updates       | 13471     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 72
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 71)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=13
📈 Node goal_basic: Success rate updated to 0.000000 (based on 13 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 73
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 72)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=14
📈 Node goal_basic: Success rate updated to 0.000000 (based on 14 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 74
   Reward: 0.000511
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 73)
   Reward: 0.000511, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000000 → 0.000026
📊 Node goal_basic: ACTIVE episode - reward=0.000511, total activations=15
📈 Node goal_basic: Success rate updated to 0.000051 (based on 15 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000511
📊 Node pose_full: INACTIVE episode - baseline reward=0.000511
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000511
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000511
📊 Node visual: INACTIVE episode - baseline reward=0.000511
📊 Node random_full: INACTIVE episode - baseline reward=0.000511

📊 EPISODE COMPLETED:
   Episode: 75
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 74)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000026 → 0.000026
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=16
📈 Node goal_basic: Success rate updated to 0.000051 (based on 16 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 6.72e-06  |
| time/              |           |
|    episodes        | 76        |
|    fps             | 21        |
|    time_elapsed    | 709       |
|    total_timesteps | 15276     |
| train/             |           |
|    actor_loss      | -3.12e+05 |
|    critic_loss     | 5.5e+09   |
|    ent_coef        | 31.5      |
|    ent_coef_loss   | -272      |
|    learning_rate   | 0.00025   |
|    n_updates       | 14275     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 76
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 75)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000026 → 0.000026
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=17
📈 Node goal_basic: Success rate updated to 0.000051 (based on 17 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 77
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 76)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000026 → 0.000026
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=18
📈 Node goal_basic: Success rate updated to 0.000051 (based on 18 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 78
   Reward: 0.006723
   Success: True
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 77)
   Reward: 0.006723, Success: True
   Active interventions: ['goal_basic']
   Baseline reward: 0.000026 → 0.000362
📊 Node goal_basic: ACTIVE episode - reward=0.006723, total activations=19
📈 Node goal_basic: Success rate updated to 0.000723 (based on 19 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.006723
📊 Node pose_full: INACTIVE episode - baseline reward=0.006723
📊 Node physics_friction: INACTIVE episode - baseline reward=0.006723
📊 Node physics_mass: INACTIVE episode - baseline reward=0.006723
📊 Node visual: INACTIVE episode - baseline reward=0.006723
📊 Node random_full: INACTIVE episode - baseline reward=0.006723

📊 EPISODE COMPLETED:
   Episode: 79
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 78)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000362 → 0.000362
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=20
📈 Node goal_basic: Success rate updated to 0.000723 (based on 20 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 9.04e-05  |
| time/              |           |
|    episodes        | 80        |
|    fps             | 21        |
|    time_elapsed    | 755       |
|    total_timesteps | 16080     |
| train/             |           |
|    actor_loss      | -3.83e+05 |
|    critic_loss     | 7.45e+09  |
|    ent_coef        | 38.6      |
|    ent_coef_loss   | -281      |
|    learning_rate   | 0.00025   |
|    n_updates       | 15079     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 80
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 79)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000362 → 0.000362
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=21
📈 Node goal_basic: Success rate updated to 0.000723 (based on 21 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000723 (n=21)
   Baseline mean: 0.000000 (n=59)
   Causal impact: 0.000723
   Effect size: 0.361
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 80)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_full: Insufficient data for causal impact (intervention: 0, baseline: 80)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 80)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 80)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 80)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 80)

📊 EPISODE COMPLETED:
   Episode: 81
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 80)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.000362 → 0.000362
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=22
📈 Node goal_basic: Success rate updated to 0.000723 (based on 22 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 82
   Reward: 0.002281
   Success: True
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 81)
   Reward: 0.002281, Success: True
   Active interventions: ['goal_basic']
   Baseline reward: 0.000362 → 0.000476
📊 Node goal_basic: ACTIVE episode - reward=0.002281, total activations=23
📈 Node goal_basic: Success rate updated to 0.000951 (based on 23 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.002281
📊 Node pose_full: INACTIVE episode - baseline reward=0.002281
📊 Node physics_friction: INACTIVE episode - baseline reward=0.002281
📊 Node physics_mass: INACTIVE episode - baseline reward=0.002281
📊 Node visual: INACTIVE episode - baseline reward=0.002281
📊 Node random_full: INACTIVE episode - baseline reward=0.002281

📊 EPISODE COMPLETED:
   Episode: 83
   Reward: 0.028984
   Success: True
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 82)
   Reward: 0.028984, Success: True
   Active interventions: ['goal_basic']
   Baseline reward: 0.000476 → 0.001925
📊 Node goal_basic: ACTIVE episode - reward=0.028984, total activations=24
📈 Node goal_basic: Success rate updated to 0.003850 (based on 24 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.028984
📊 Node pose_full: INACTIVE episode - baseline reward=0.028984
📊 Node physics_friction: INACTIVE episode - baseline reward=0.028984
📊 Node physics_mass: INACTIVE episode - baseline reward=0.028984
📊 Node visual: INACTIVE episode - baseline reward=0.028984
📊 Node random_full: INACTIVE episode - baseline reward=0.028984
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.000465  |
| time/              |           |
|    episodes        | 84        |
|    fps             | 21        |
|    time_elapsed    | 797       |
|    total_timesteps | 16884     |
| train/             |           |
|    actor_loss      | -4.08e+05 |
|    critic_loss     | 9.11e+09  |
|    ent_coef        | 47.1      |
|    ent_coef_loss   | -304      |
|    learning_rate   | 0.00025   |
|    n_updates       | 15883     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 84
   Reward: 0.000524
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 83)
   Reward: 0.000524, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.001925 → 0.001951
📊 Node goal_basic: ACTIVE episode - reward=0.000524, total activations=25
📈 Node goal_basic: Success rate updated to 0.003851 (based on 25 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000524
📊 Node pose_full: INACTIVE episode - baseline reward=0.000524
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000524
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000524
📊 Node visual: INACTIVE episode - baseline reward=0.000524
📊 Node random_full: INACTIVE episode - baseline reward=0.000524

📊 EPISODE COMPLETED:
   Episode: 85
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 84)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.001951 → 0.001951
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=26
📈 Node goal_basic: Success rate updated to 0.003851 (based on 26 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 86
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 85)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.001951 → 0.001951
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=27
📈 Node goal_basic: Success rate updated to 0.003851 (based on 27 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 87
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 86)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.001951 → 0.001951
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=28
📈 Node goal_basic: Success rate updated to 0.003851 (based on 28 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.000443  |
| time/              |           |
|    episodes        | 88        |
|    fps             | 21        |
|    time_elapsed    | 840       |
|    total_timesteps | 17688     |
| train/             |           |
|    actor_loss      | -4.26e+05 |
|    critic_loss     | 1.06e+10  |
|    ent_coef        | 57.3      |
|    ent_coef_loss   | -314      |
|    learning_rate   | 0.00025   |
|    n_updates       | 16687     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 88
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 87)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.001951 → 0.001951
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=29
📈 Node goal_basic: Success rate updated to 0.003179 (based on 29 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 89
   Reward: 0.000000
   Success: False
   Active interventions: ['goal_basic']

📈 PERFORMANCE UPDATE (Episode 88)
   Reward: 0.000000, Success: False
   Active interventions: ['goal_basic']
   Baseline reward: 0.001951 → 0.001951
📊 Node goal_basic: ACTIVE episode - reward=0.000000, total activations=30
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

🔄 CURRICULUM ADAPTATION TRIGGERED
🔄 Adapting curriculum...

🎓 CURRICULUM CONFIG GENERATION (Episode 89)

🧪 EXPERIMENTAL PHASE SELECTION (Episode 89)

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=False
      Prerequisites: goal_basic(satisfied=False, data_points=30, causal_impact=0.000723)
   ❌ pose_position is NOT eligible
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
🔬 INTERVENTION TEST PHASE:
   Test cycle: 1
   Testing intervention: pose_full
   Episodes in current test: 14/25
   Eligible interventions: ['goal_basic', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
   ⚔️ Intervention pose_full has conflicts: ['pose_position']
🎭 Creating actor instance for: pose_full
   🚀 SELECTED: pose_full (strength: 0.7)
   🔧 Building curriculum configuration:
      pose_full: frequency=1, strength=0.700
   ✅ Config ready: 1 actors, 1 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 1
   🎯 Active nodes: ['pose_full']
   📈 Baseline reward: 0.001951
   🧪 Episode count: 89

📊 EPISODE COMPLETED:
   Episode: 90
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 89)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.001951 → 0.001951
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.000000 (n=60)
   Causal impact: 0.003179
   Effect size: 0.368
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 90)
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=1
🎯 Node pose_full: Insufficient data for causal impact (intervention: 1, baseline: 89)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 90)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 90)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 90)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 90)

📊 EPISODE COMPLETED:
   Episode: 91
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 90)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.001951 → 0.001951
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=2
📈 Node pose_full: Success rate updated to 0.000000 (based on 2 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.000424  |
| time/              |           |
|    episodes        | 92        |
|    fps             | 20        |
|    time_elapsed    | 888       |
|    total_timesteps | 18492     |
| train/             |           |
|    actor_loss      | -4.19e+05 |
|    critic_loss     | 9.12e+09  |
|    ent_coef        | 69.6      |
|    ent_coef_loss   | -310      |
|    learning_rate   | 0.00025   |
|    n_updates       | 17491     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 92
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 91)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.001951 → 0.001951
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=3
📈 Node pose_full: Success rate updated to 0.000000 (based on 3 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 93
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 92)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.001951 → 0.001951
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=4
📈 Node pose_full: Success rate updated to 0.000000 (based on 4 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 94
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 93)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.001951 → 0.001926
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=5
📈 Node pose_full: Success rate updated to 0.000000 (based on 5 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 95
   Reward: 0.000051
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 94)
   Reward: 0.000051, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.001926 → 0.001928
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000051
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000051
📊 Node pose_full: ACTIVE episode - reward=0.000051, total activations=6
📈 Node pose_full: Success rate updated to 0.000008 (based on 6 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000051
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000051
📊 Node visual: INACTIVE episode - baseline reward=0.000051
📊 Node random_full: INACTIVE episode - baseline reward=0.000051
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.000407  |
| time/              |           |
|    episodes        | 96        |
|    fps             | 20        |
|    time_elapsed    | 931       |
|    total_timesteps | 19296     |
| train/             |           |
|    actor_loss      | -5.22e+05 |
|    critic_loss     | 1.11e+10  |
|    ent_coef        | 84.8      |
|    ent_coef_loss   | -324      |
|    learning_rate   | 0.00025   |
|    n_updates       | 18295     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 96
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 95)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.001928 → 0.001928
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=7
📈 Node pose_full: Success rate updated to 0.000007 (based on 7 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 97
   Reward: 0.002941
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 96)
   Reward: 0.002941, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.001928 → 0.002075
📊 Node goal_basic: INACTIVE episode - baseline reward=0.002941
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.002941
📊 Node pose_full: ACTIVE episode - reward=0.002941, total activations=8
📈 Node pose_full: Success rate updated to 0.000374 (based on 8 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.002941
📊 Node physics_mass: INACTIVE episode - baseline reward=0.002941
📊 Node visual: INACTIVE episode - baseline reward=0.002941
📊 Node random_full: INACTIVE episode - baseline reward=0.002941

📊 EPISODE COMPLETED:
   Episode: 98
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 97)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.002075 → 0.001739
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=9
📈 Node pose_full: Success rate updated to 0.000332 (based on 9 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 99
   Reward: 0.012217
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 98)
   Reward: 0.012217, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.001739 → 0.002350
📊 Node goal_basic: INACTIVE episode - baseline reward=0.012217
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.012217
📊 Node pose_full: ACTIVE episode - reward=0.012217, total activations=10
📈 Node pose_full: Success rate updated to 0.001521 (based on 10 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.012217
📊 Node physics_mass: INACTIVE episode - baseline reward=0.012217
📊 Node visual: INACTIVE episode - baseline reward=0.012217
📊 Node random_full: INACTIVE episode - baseline reward=0.012217
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.000757  |
| time/              |           |
|    episodes        | 100       |
|    fps             | 20        |
|    time_elapsed    | 971       |
|    total_timesteps | 20100     |
| train/             |           |
|    actor_loss      | -5.33e+05 |
|    critic_loss     | 9.79e+09  |
|    ent_coef        | 103       |
|    ent_coef_loss   | -333      |
|    learning_rate   | 0.00025   |
|    n_updates       | 19099     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 100
   Reward: 0.021474
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 99)
   Reward: 0.021474, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.002350 → 0.003424
📊 Node goal_basic: INACTIVE episode - baseline reward=0.021474
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.003668 (n=70)
   Causal impact: -0.000489
   Effect size: 0.057
📊 Node pose_position: INACTIVE episode - baseline reward=0.021474
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 100)
📊 Node pose_full: ACTIVE episode - reward=0.021474, total activations=11
📈 Node pose_full: Success rate updated to 0.003668 (based on 11 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003668 (n=11)
   Baseline mean: 0.003179 (n=89)
   Causal impact: 0.000489
   Effect size: 0.057
📊 Node physics_friction: INACTIVE episode - baseline reward=0.021474
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 100)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.021474
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 100)
📊 Node visual: INACTIVE episode - baseline reward=0.021474
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 100)
📊 Node random_full: INACTIVE episode - baseline reward=0.021474
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 100)

📊 EPISODE COMPLETED:
   Episode: 101
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 100)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.003424 → 0.003424
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=12
📈 Node pose_full: Success rate updated to 0.003668 (based on 12 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 102
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 101)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.003424 → 0.003310
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=13
📈 Node pose_full: Success rate updated to 0.003668 (based on 13 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 103
   Reward: 0.038942
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 102)
   Reward: 0.038942, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.003310 → 0.003807
📊 Node goal_basic: INACTIVE episode - baseline reward=0.038942
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.038942
📊 Node pose_full: ACTIVE episode - reward=0.038942, total activations=14
📈 Node pose_full: Success rate updated to 0.007562 (based on 14 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.038942
📊 Node physics_mass: INACTIVE episode - baseline reward=0.038942
📊 Node visual: INACTIVE episode - baseline reward=0.038942
📊 Node random_full: INACTIVE episode - baseline reward=0.038942
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00157   |
| time/              |           |
|    episodes        | 104       |
|    fps             | 20        |
|    time_elapsed    | 1010      |
|    total_timesteps | 20904     |
| train/             |           |
|    actor_loss      | -5.05e+05 |
|    critic_loss     | 1.19e+10  |
|    ent_coef        | 125       |
|    ent_coef_loss   | -335      |
|    learning_rate   | 0.00025   |
|    n_updates       | 19903     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 104
   Reward: 0.041977
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 103)
   Reward: 0.041977, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.003807 → 0.005880
📊 Node goal_basic: INACTIVE episode - baseline reward=0.041977
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.041977
📊 Node pose_full: ACTIVE episode - reward=0.041977, total activations=15
📈 Node pose_full: Success rate updated to 0.011760 (based on 15 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.041977
📊 Node physics_mass: INACTIVE episode - baseline reward=0.041977
📊 Node visual: INACTIVE episode - baseline reward=0.041977
📊 Node random_full: INACTIVE episode - baseline reward=0.041977

📊 EPISODE COMPLETED:
   Episode: 105
   Reward: 0.000259
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 104)
   Reward: 0.000259, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.005880 → 0.005893
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000259
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000259
📊 Node pose_full: ACTIVE episode - reward=0.000259, total activations=16
📈 Node pose_full: Success rate updated to 0.011781 (based on 16 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000259
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000259
📊 Node visual: INACTIVE episode - baseline reward=0.000259
📊 Node random_full: INACTIVE episode - baseline reward=0.000259

📊 EPISODE COMPLETED:
   Episode: 106
   Reward: 0.101527
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 105)
   Reward: 0.101527, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.005893 → 0.010969
📊 Node goal_basic: INACTIVE episode - baseline reward=0.101527
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.101527
📊 Node pose_full: ACTIVE episode - reward=0.101527, total activations=17
📈 Node pose_full: Success rate updated to 0.021934 (based on 17 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.101527
📊 Node physics_mass: INACTIVE episode - baseline reward=0.101527
📊 Node visual: INACTIVE episode - baseline reward=0.101527
📊 Node random_full: INACTIVE episode - baseline reward=0.101527

📊 EPISODE COMPLETED:
   Episode: 107
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 106)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.010969 → 0.010969
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=18
📈 Node pose_full: Success rate updated to 0.021640 (based on 18 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00302   |
| time/              |           |
|    episodes        | 108       |
|    fps             | 20        |
|    time_elapsed    | 1054      |
|    total_timesteps | 21708     |
| train/             |           |
|    actor_loss      | -5.95e+05 |
|    critic_loss     | 1.06e+10  |
|    ent_coef        | 152       |
|    ent_coef_loss   | -335      |
|    learning_rate   | 0.00025   |
|    n_updates       | 20707     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 108
   Reward: 0.043515
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 107)
   Reward: 0.043515, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.010969 → 0.013145
📊 Node goal_basic: INACTIVE episode - baseline reward=0.043515
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.043515
📊 Node pose_full: ACTIVE episode - reward=0.043515, total activations=19
📈 Node pose_full: Success rate updated to 0.025991 (based on 19 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.043515
📊 Node physics_mass: INACTIVE episode - baseline reward=0.043515
📊 Node visual: INACTIVE episode - baseline reward=0.043515
📊 Node random_full: INACTIVE episode - baseline reward=0.043515

📊 EPISODE COMPLETED:
   Episode: 109
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 108)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.013145 → 0.013145
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=20
📈 Node pose_full: Success rate updated to 0.024769 (based on 20 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 110
   Reward: 0.005412
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 109)
   Reward: 0.005412, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.013145 → 0.013416
📊 Node goal_basic: INACTIVE episode - baseline reward=0.005412
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.023163 (n=80)
   Causal impact: -0.019984
   Effect size: 0.627
   🎯 SIGNIFICANT EFFECT detected for goal_basic: impact=-0.019984, effect_size=0.627
📊 Node pose_position: INACTIVE episode - baseline reward=0.005412
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 110)
📊 Node pose_full: ACTIVE episode - reward=0.005412, total activations=21
📈 Node pose_full: Success rate updated to 0.023163 (based on 21 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.023163 (n=21)
   Baseline mean: 0.003179 (n=89)
   Causal impact: 0.019984
   Effect size: 0.627
   🎯 SIGNIFICANT EFFECT detected for pose_full: impact=0.019984, effect_size=0.627
📊 Node physics_friction: INACTIVE episode - baseline reward=0.005412
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 0, baseline: 110)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.005412
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 110)
📊 Node visual: INACTIVE episode - baseline reward=0.005412
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 110)
📊 Node random_full: INACTIVE episode - baseline reward=0.005412
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 110)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 111
   Reward: 0.014738
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 110)
   Reward: 0.014738, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.013416 → 0.014153
📊 Node goal_basic: INACTIVE episode - baseline reward=0.014738
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.014738
📊 Node pose_full: ACTIVE episode - reward=0.014738, total activations=22
📈 Node pose_full: Success rate updated to 0.024637 (based on 22 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.014738
📊 Node physics_mass: INACTIVE episode - baseline reward=0.014738
📊 Node visual: INACTIVE episode - baseline reward=0.014738
📊 Node random_full: INACTIVE episode - baseline reward=0.014738
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.00322  |
| time/              |          |
|    episodes        | 112      |
|    fps             | 20       |
|    time_elapsed    | 1095     |
|    total_timesteps | 22512    |
| train/             |          |
|    actor_loss      | -6.1e+05 |
|    critic_loss     | 1.43e+10 |
|    ent_coef        | 184      |
|    ent_coef_loss   | -333     |
|    learning_rate   | 0.00025  |
|    n_updates       | 21511    |
---------------------------------

📊 EPISODE COMPLETED:
   Episode: 112
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 111)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.014153 → 0.014153
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=23
📈 Node pose_full: Success rate updated to 0.024637 (based on 23 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 113
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 112)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.014153 → 0.014153
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=24
📈 Node pose_full: Success rate updated to 0.020743 (based on 24 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 114
   Reward: 0.014039
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 113)
   Reward: 0.014039, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.014153 → 0.014855
📊 Node goal_basic: INACTIVE episode - baseline reward=0.014039
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.014039
📊 Node pose_full: ACTIVE episode - reward=0.014039, total activations=25
📈 Node pose_full: Success rate updated to 0.017949 (based on 25 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.014039
📊 Node physics_mass: INACTIVE episode - baseline reward=0.014039
📊 Node visual: INACTIVE episode - baseline reward=0.014039
📊 Node random_full: INACTIVE episode - baseline reward=0.014039

📊 EPISODE COMPLETED:
   Episode: 115
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 114)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.014855 → 0.014852
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=26
📈 Node pose_full: Success rate updated to 0.017923 (based on 26 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 116       |
|    fps             | 20        |
|    time_elapsed    | 1135      |
|    total_timesteps | 23316     |
| train/             |           |
|    actor_loss      | -6.03e+05 |
|    critic_loss     | 1.1e+10   |
|    ent_coef        | 223       |
|    ent_coef_loss   | -330      |
|    learning_rate   | 0.00025   |
|    n_updates       | 22315     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 116
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 115)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.014852 → 0.014852
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=27
📈 Node pose_full: Success rate updated to 0.007770 (based on 27 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 117
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 116)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.014852 → 0.014705
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=28
📈 Node pose_full: Success rate updated to 0.007770 (based on 28 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 118
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 117)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.014705 → 0.014705
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=29
📈 Node pose_full: Success rate updated to 0.003419 (based on 29 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 119
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 118)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.014705 → 0.014094
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=30
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

🔄 CURRICULUM ADAPTATION TRIGGERED
🔄 Adapting curriculum...

🎓 CURRICULUM CONFIG GENERATION (Episode 119)

🧪 EXPERIMENTAL PHASE SELECTION (Episode 119)

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=False
      Prerequisites: goal_basic(satisfied=False, data_points=30, causal_impact=-0.019984)
   ❌ pose_position is NOT eligible
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
🔬 INTERVENTION TEST PHASE:
   Test cycle: 2
   Testing intervention: physics_friction
   Episodes in current test: 19/25
   Eligible interventions: ['goal_basic', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
   ⚔️ Intervention physics_friction has conflicts: ['physics_mass']
🎭 Creating actor instance for: physics_friction
   🚀 SELECTED: physics_friction (strength: 0.7)
   🔧 Building curriculum configuration:
      physics_friction: frequency=1, strength=0.700
   ✅ Config ready: 1 actors, 1 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 1
   🎯 Active nodes: ['physics_friction']
   📈 Baseline reward: 0.014094
   🧪 Episode count: 119
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 120       |
|    fps             | 20        |
|    time_elapsed    | 1179      |
|    total_timesteps | 24120     |
| train/             |           |
|    actor_loss      | -6.36e+05 |
|    critic_loss     | 1.2e+10   |
|    ent_coef        | 269       |
|    ent_coef_loss   | -322      |
|    learning_rate   | 0.00025   |
|    n_updates       | 23119     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 120
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 119)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.014094 → 0.013020
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.002878 (n=90)
   Causal impact: 0.000301
   Effect size: 0.035
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 120)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.003179 (n=90)
   Causal impact: 0.000240
   Effect size: 0.028
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=1
🎯 Node physics_friction: Insufficient data for causal impact (intervention: 1, baseline: 119)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 120)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 120)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 120)

📊 EPISODE COMPLETED:
   Episode: 121
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 120)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.013020 → 0.013020
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=2
📈 Node physics_friction: Success rate updated to 0.000000 (based on 2 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 122
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 121)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.013020 → 0.013020
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=3
📈 Node physics_friction: Success rate updated to 0.000000 (based on 3 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 123
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 122)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.013020 → 0.011073
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=4
📈 Node physics_friction: Success rate updated to 0.000000 (based on 4 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 124       |
|    fps             | 20        |
|    time_elapsed    | 1221      |
|    total_timesteps | 24924     |
| train/             |           |
|    actor_loss      | -5.56e+05 |
|    critic_loss     | 1.12e+10  |
|    ent_coef        | 323       |
|    ent_coef_loss   | -298      |
|    learning_rate   | 0.00025   |
|    n_updates       | 23923     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 124
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 123)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.011073 → 0.008974
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=5
📈 Node physics_friction: Success rate updated to 0.000000 (based on 5 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 125
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 124)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.008974 → 0.008962
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=6
📈 Node physics_friction: Success rate updated to 0.000000 (based on 6 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 126
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 125)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.008962 → 0.003885
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=7
📈 Node physics_friction: Success rate updated to 0.000000 (based on 7 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 127
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 126)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.003885 → 0.003885
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=8
📈 Node physics_friction: Success rate updated to 0.000000 (based on 8 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.00336  |
| time/              |          |
|    episodes        | 128      |
|    fps             | 20       |
|    time_elapsed    | 1263     |
|    total_timesteps | 25728    |
| train/             |          |
|    actor_loss      | -6.4e+05 |
|    critic_loss     | 8.57e+09 |
|    ent_coef        | 389      |
|    ent_coef_loss   | -293     |
|    learning_rate   | 0.00025  |
|    n_updates       | 24727    |
---------------------------------

📊 EPISODE COMPLETED:
   Episode: 128
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 127)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.003885 → 0.001709
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=9
📈 Node physics_friction: Success rate updated to 0.000000 (based on 9 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 129
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 128)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.001709 → 0.001709
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=10
📈 Node physics_friction: Success rate updated to 0.000000 (based on 10 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 130
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 129)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.001709 → 0.001439
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.000000 (n=100)
   Causal impact: 0.003179
   Effect size: 0.368
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 130)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.000000 (n=100)
   Causal impact: 0.003419
   Effect size: 0.598
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=11
📈 Node physics_friction: Success rate updated to 0.000000 (based on 11 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=11)
   Baseline mean: 0.003419 (n=119)
   Causal impact: -0.003419
   Effect size: 0.598
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 130)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 130)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 130)

📊 EPISODE COMPLETED:
   Episode: 131
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 130)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.001439 → 0.000702
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=12
📈 Node physics_friction: Success rate updated to 0.000000 (based on 12 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 132       |
|    fps             | 20        |
|    time_elapsed    | 1303      |
|    total_timesteps | 26532     |
| train/             |           |
|    actor_loss      | -6.35e+05 |
|    critic_loss     | 1.09e+10  |
|    ent_coef        | 467       |
|    ent_coef_loss   | -276      |
|    learning_rate   | 0.00025   |
|    n_updates       | 25531     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 132
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 131)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000702 → 0.000702
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=13
📈 Node physics_friction: Success rate updated to 0.000000 (based on 13 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 133
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 132)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000702 → 0.000702
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=14
📈 Node physics_friction: Success rate updated to 0.000000 (based on 14 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 134
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 133)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000702 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=15
📈 Node physics_friction: Success rate updated to 0.000000 (based on 15 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 135
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 134)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=16
📈 Node physics_friction: Success rate updated to 0.000000 (based on 16 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 136       |
|    fps             | 20        |
|    time_elapsed    | 1347      |
|    total_timesteps | 27336     |
| train/             |           |
|    actor_loss      | -6.56e+05 |
|    critic_loss     | 1.25e+10  |
|    ent_coef        | 558       |
|    ent_coef_loss   | -265      |
|    learning_rate   | 0.00025   |
|    n_updates       | 26335     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 136
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 135)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=17
📈 Node physics_friction: Success rate updated to 0.000000 (based on 17 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 137
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 136)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=18
📈 Node physics_friction: Success rate updated to 0.000000 (based on 18 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 138
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 137)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=19
📈 Node physics_friction: Success rate updated to 0.000000 (based on 19 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 139
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 138)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=20
📈 Node physics_friction: Success rate updated to 0.000000 (based on 20 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 140       |
|    fps             | 20        |
|    time_elapsed    | 1388      |
|    total_timesteps | 28140     |
| train/             |           |
|    actor_loss      | -7.02e+05 |
|    critic_loss     | 1.55e+10  |
|    ent_coef        | 662       |
|    ent_coef_loss   | -236      |
|    learning_rate   | 0.00025   |
|    n_updates       | 27139     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 140
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 139)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.000000 (n=110)
   Causal impact: 0.003179
   Effect size: 0.368
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 140)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.000000 (n=110)
   Causal impact: 0.003419
   Effect size: 0.598
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=21
📈 Node physics_friction: Success rate updated to 0.000000 (based on 21 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=21)
   Baseline mean: 0.003419 (n=119)
   Causal impact: -0.003419
   Effect size: 0.598
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 140)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 140)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 140)

📊 EPISODE COMPLETED:
   Episode: 141
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 140)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=22
📈 Node physics_friction: Success rate updated to 0.000000 (based on 22 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 142
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 141)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=23
📈 Node physics_friction: Success rate updated to 0.000000 (based on 23 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 143
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 142)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=24
📈 Node physics_friction: Success rate updated to 0.000000 (based on 24 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 144       |
|    fps             | 20        |
|    time_elapsed    | 1430      |
|    total_timesteps | 28944     |
| train/             |           |
|    actor_loss      | -6.73e+05 |
|    critic_loss     | 1.15e+10  |
|    ent_coef        | 776       |
|    ent_coef_loss   | -187      |
|    learning_rate   | 0.00025   |
|    n_updates       | 27943     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 144
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 143)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=25
📈 Node physics_friction: Success rate updated to 0.000000 (based on 25 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 145
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 144)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=26
📈 Node physics_friction: Success rate updated to 0.000000 (based on 26 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 146
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 145)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=27
📈 Node physics_friction: Success rate updated to 0.000000 (based on 27 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 147
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 146)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=28
📈 Node physics_friction: Success rate updated to 0.000000 (based on 28 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 148       |
|    fps             | 20        |
|    time_elapsed    | 1473      |
|    total_timesteps | 29748     |
| train/             |           |
|    actor_loss      | -6.96e+05 |
|    critic_loss     | 9.09e+09  |
|    ent_coef        | 899       |
|    ent_coef_loss   | -143      |
|    learning_rate   | 0.00025   |
|    n_updates       | 28747     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 148
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 147)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=29
📈 Node physics_friction: Success rate updated to 0.000000 (based on 29 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 149
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 148)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=30
📈 Node physics_friction: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

🔄 CURRICULUM ADAPTATION TRIGGERED
🔄 Adapting curriculum...

🎓 CURRICULUM CONFIG GENERATION (Episode 149)

🧪 EXPERIMENTAL PHASE SELECTION (Episode 149)

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, data_points=30, causal_impact=0.003179)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
🔬 INTERVENTION TEST PHASE:
   Test cycle: 3
   Testing intervention: physics_friction
   Episodes in current test: 24/25
   Eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
   ⚔️ Intervention physics_friction has conflicts: ['physics_mass']
🎭 Creating actor instance for: physics_friction
   🚀 SELECTED: physics_friction (strength: 0.7)
   🔧 Building curriculum configuration:
      physics_friction: frequency=1, strength=0.700
   ✅ Config ready: 1 actors, 1 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 1
   🎯 Active nodes: ['physics_friction']
   📈 Baseline reward: 0.000000
   🧪 Episode count: 149

📊 EPISODE COMPLETED:
   Episode: 150
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 149)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.000000 (n=120)
   Causal impact: 0.003179
   Effect size: 0.368
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 150)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.000000 (n=120)
   Causal impact: 0.003419
   Effect size: 0.598
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=31
📈 Node physics_friction: Success rate updated to 0.000000 (based on 31 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=31)
   Baseline mean: 0.003419 (n=119)
   Causal impact: -0.003419
   Effect size: 0.598
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 150)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 150)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 150)

📊 EPISODE COMPLETED:
   Episode: 151
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 150)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=32
📈 Node physics_friction: Success rate updated to 0.000000 (based on 32 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 152       |
|    fps             | 20        |
|    time_elapsed    | 1511      |
|    total_timesteps | 30552     |
| train/             |           |
|    actor_loss      | -6.55e+05 |
|    critic_loss     | 1.27e+10  |
|    ent_coef        | 1.04e+03  |
|    ent_coef_loss   | -122      |
|    learning_rate   | 0.00025   |
|    n_updates       | 29551     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 152
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 151)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=33
📈 Node physics_friction: Success rate updated to 0.000000 (based on 33 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 153
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 152)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=34
📈 Node physics_friction: Success rate updated to 0.000000 (based on 34 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 154
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 153)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=35
📈 Node physics_friction: Success rate updated to 0.000000 (based on 35 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 155
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 154)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=36
📈 Node physics_friction: Success rate updated to 0.000000 (based on 36 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 156       |
|    fps             | 20        |
|    time_elapsed    | 1548      |
|    total_timesteps | 31356     |
| train/             |           |
|    actor_loss      | -8.08e+05 |
|    critic_loss     | 1.1e+10   |
|    ent_coef        | 1.21e+03  |
|    ent_coef_loss   | -116      |
|    learning_rate   | 0.00025   |
|    n_updates       | 30355     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 156
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 155)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=37
📈 Node physics_friction: Success rate updated to 0.000000 (based on 37 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 157
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 156)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=38
📈 Node physics_friction: Success rate updated to 0.000000 (based on 38 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 158
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 157)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=39
📈 Node physics_friction: Success rate updated to 0.000000 (based on 39 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 159
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 158)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=40
📈 Node physics_friction: Success rate updated to 0.000000 (based on 40 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 160       |
|    fps             | 20        |
|    time_elapsed    | 1586      |
|    total_timesteps | 32160     |
| train/             |           |
|    actor_loss      | -7.39e+05 |
|    critic_loss     | 8.3e+09   |
|    ent_coef        | 1.41e+03  |
|    ent_coef_loss   | -100      |
|    learning_rate   | 0.00025   |
|    n_updates       | 31159     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 160
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 159)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.000000 (n=130)
   Causal impact: 0.003179
   Effect size: 0.368
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 160)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.000000 (n=130)
   Causal impact: 0.003419
   Effect size: 0.598
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=41
📈 Node physics_friction: Success rate updated to 0.000000 (based on 41 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=41)
   Baseline mean: 0.003419 (n=119)
   Causal impact: -0.003419
   Effect size: 0.598
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 160)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 160)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 160)

📊 EPISODE COMPLETED:
   Episode: 161
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 160)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=42
📈 Node physics_friction: Success rate updated to 0.000000 (based on 42 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 162
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 161)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=43
📈 Node physics_friction: Success rate updated to 0.000000 (based on 43 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 163
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 162)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=44
📈 Node physics_friction: Success rate updated to 0.000000 (based on 44 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 164       |
|    fps             | 20        |
|    time_elapsed    | 1624      |
|    total_timesteps | 32964     |
| train/             |           |
|    actor_loss      | -6.94e+05 |
|    critic_loss     | 1.01e+10  |
|    ent_coef        | 1.66e+03  |
|    ent_coef_loss   | -106      |
|    learning_rate   | 0.00025   |
|    n_updates       | 31963     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 164
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 163)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=45
📈 Node physics_friction: Success rate updated to 0.000000 (based on 45 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 165
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 164)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=46
📈 Node physics_friction: Success rate updated to 0.000000 (based on 46 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 166
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 165)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=47
📈 Node physics_friction: Success rate updated to 0.000000 (based on 47 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 167
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 166)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=48
📈 Node physics_friction: Success rate updated to 0.000000 (based on 48 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 168       |
|    fps             | 20        |
|    time_elapsed    | 1664      |
|    total_timesteps | 33768     |
| train/             |           |
|    actor_loss      | -6.81e+05 |
|    critic_loss     | 9.38e+09  |
|    ent_coef        | 1.94e+03  |
|    ent_coef_loss   | -77.2     |
|    learning_rate   | 0.00025   |
|    n_updates       | 32767     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 168
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 167)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=49
📈 Node physics_friction: Success rate updated to 0.000000 (based on 49 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 169
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 168)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=50
📈 Node physics_friction: Success rate updated to 0.000000 (based on 50 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 170
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 169)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.000000 (n=140)
   Causal impact: 0.003179
   Effect size: 0.368
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 170)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.000000 (n=140)
   Causal impact: 0.003419
   Effect size: 0.598
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=51
📈 Node physics_friction: Success rate updated to 0.000000 (based on 51 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=51)
   Baseline mean: 0.003419 (n=119)
   Causal impact: -0.003419
   Effect size: 0.598
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 170)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
🎯 Node visual: Insufficient data for causal impact (intervention: 0, baseline: 170)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 170)

📊 EPISODE COMPLETED:
   Episode: 171
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 170)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=52
📈 Node physics_friction: Success rate updated to 0.000000 (based on 52 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.00336  |
| time/              |          |
|    episodes        | 172      |
|    fps             | 20       |
|    time_elapsed    | 1704     |
|    total_timesteps | 34572    |
| train/             |          |
|    actor_loss      | -8.3e+05 |
|    critic_loss     | 7.48e+09 |
|    ent_coef        | 2.27e+03 |
|    ent_coef_loss   | -56.5    |
|    learning_rate   | 0.00025  |
|    n_updates       | 33571    |
---------------------------------

📊 EPISODE COMPLETED:
   Episode: 172
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 171)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=53
📈 Node physics_friction: Success rate updated to 0.000000 (based on 53 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 173
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 172)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=54
📈 Node physics_friction: Success rate updated to 0.000000 (based on 54 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 174
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 173)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=55
📈 Node physics_friction: Success rate updated to 0.000000 (based on 55 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 175
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 174)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=56
📈 Node physics_friction: Success rate updated to 0.000000 (based on 56 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00336   |
| time/              |           |
|    episodes        | 176       |
|    fps             | 20        |
|    time_elapsed    | 1746      |
|    total_timesteps | 35376     |
| train/             |           |
|    actor_loss      | -7.55e+05 |
|    critic_loss     | 6.54e+09  |
|    ent_coef        | 2.63e+03  |
|    ent_coef_loss   | -61.6     |
|    learning_rate   | 0.00025   |
|    n_updates       | 34375     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 176
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 175)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=57
📈 Node physics_friction: Success rate updated to 0.000000 (based on 57 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 177
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 176)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=58
📈 Node physics_friction: Success rate updated to 0.000000 (based on 58 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 178
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 177)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=59
📈 Node physics_friction: Success rate updated to 0.000000 (based on 59 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 179
   Reward: 0.000000
   Success: False
   Active interventions: ['physics_friction']

📈 PERFORMANCE UPDATE (Episode 178)
   Reward: 0.000000, Success: False
   Active interventions: ['physics_friction']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: ACTIVE episode - reward=0.000000, total activations=60
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

🔄 CURRICULUM ADAPTATION TRIGGERED
🔄 Adapting curriculum...

🎓 CURRICULUM CONFIG GENERATION (Episode 179)

🧪 EXPERIMENTAL PHASE SELECTION (Episode 179)

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, data_points=30, causal_impact=0.003179)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
🔬 INTERVENTION TEST PHASE:
   Test cycle: 5
   Testing intervention: visual
   Episodes in current test: 4/25
   Eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
🎭 Creating actor instance for: visual
   🚀 SELECTED: visual (strength: 0.7)
   🔧 Building curriculum configuration:
      visual: frequency=1, strength=0.700
   ✅ Config ready: 1 actors, 1 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 1
   🎯 Active nodes: ['visual']
   📈 Baseline reward: 0.000000
   🧪 Episode count: 179
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00329   |
| time/              |           |
|    episodes        | 180       |
|    fps             | 20        |
|    time_elapsed    | 1788      |
|    total_timesteps | 36180     |
| train/             |           |
|    actor_loss      | -6.91e+05 |
|    critic_loss     | 7.9e+09   |
|    ent_coef        | 3e+03     |
|    ent_coef_loss   | -24.9     |
|    learning_rate   | 0.00025   |
|    n_updates       | 35179     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 180
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 179)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.000000 (n=150)
   Causal impact: 0.003179
   Effect size: 0.368
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 180)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.000000 (n=150)
   Causal impact: 0.003419
   Effect size: 0.598
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=60)
   Baseline mean: 0.002878 (n=120)
   Causal impact: -0.002878
   Effect size: 0.500
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 180)
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=1
🎯 Node visual: Insufficient data for causal impact (intervention: 1, baseline: 179)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 180)

📊 EPISODE COMPLETED:
   Episode: 181
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 180)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=2
📈 Node visual: Success rate updated to 0.000000 (based on 2 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 182
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 181)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=3
📈 Node visual: Success rate updated to 0.000000 (based on 3 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 183
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 182)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=4
📈 Node visual: Success rate updated to 0.000000 (based on 4 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00297   |
| time/              |           |
|    episodes        | 184       |
|    fps             | 20        |
|    time_elapsed    | 1830      |
|    total_timesteps | 36984     |
| train/             |           |
|    actor_loss      | -6.64e+05 |
|    critic_loss     | 8.99e+09  |
|    ent_coef        | 3.3e+03   |
|    ent_coef_loss   | -20.6     |
|    learning_rate   | 0.00025   |
|    n_updates       | 35983     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 184
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 183)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=5
📈 Node visual: Success rate updated to 0.000000 (based on 5 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 185
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 184)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=6
📈 Node visual: Success rate updated to 0.000000 (based on 6 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 186
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 185)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=7
📈 Node visual: Success rate updated to 0.000000 (based on 7 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 187
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 186)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=8
📈 Node visual: Success rate updated to 0.000000 (based on 8 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00297   |
| time/              |           |
|    episodes        | 188       |
|    fps             | 20        |
|    time_elapsed    | 1870      |
|    total_timesteps | 37788     |
| train/             |           |
|    actor_loss      | -5.69e+05 |
|    critic_loss     | 4.94e+09  |
|    ent_coef        | 3.57e+03  |
|    ent_coef_loss   | -7.42     |
|    learning_rate   | 0.00025   |
|    n_updates       | 36787     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 188
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 187)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=9
📈 Node visual: Success rate updated to 0.000000 (based on 9 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 189
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 188)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=10
📈 Node visual: Success rate updated to 0.000000 (based on 10 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 190
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 189)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.000000 (n=160)
   Causal impact: 0.003179
   Effect size: 0.368
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 190)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.000000 (n=160)
   Causal impact: 0.003419
   Effect size: 0.598
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=60)
   Baseline mean: 0.000000 (n=130)
   Causal impact: 0.000000
   Effect size: 0.000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 190)
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=11
📈 Node visual: Success rate updated to 0.000000 (based on 11 intervention episodes)
🎯 Node visual: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=11)
   Baseline mean: 0.000000 (n=179)
   Causal impact: 0.000000
   Effect size: 0.000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 190)

📊 EPISODE COMPLETED:
   Episode: 191
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 190)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=12
📈 Node visual: Success rate updated to 0.000000 (based on 12 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00297   |
| time/              |           |
|    episodes        | 192       |
|    fps             | 20        |
|    time_elapsed    | 1913      |
|    total_timesteps | 38592     |
| train/             |           |
|    actor_loss      | -6.97e+05 |
|    critic_loss     | 7.11e+09  |
|    ent_coef        | 3.75e+03  |
|    ent_coef_loss   | -6.01     |
|    learning_rate   | 0.00025   |
|    n_updates       | 37591     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 192
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 191)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=13
📈 Node visual: Success rate updated to 0.000000 (based on 13 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 193
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 192)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=14
📈 Node visual: Success rate updated to 0.000000 (based on 14 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 194
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 193)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=15
📈 Node visual: Success rate updated to 0.000000 (based on 15 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 195
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 194)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=16
📈 Node visual: Success rate updated to 0.000000 (based on 16 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00297   |
| time/              |           |
|    episodes        | 196       |
|    fps             | 20        |
|    time_elapsed    | 1954      |
|    total_timesteps | 39396     |
| train/             |           |
|    actor_loss      | -6.75e+05 |
|    critic_loss     | 4.45e+09  |
|    ent_coef        | 3.86e+03  |
|    ent_coef_loss   | 0.287     |
|    learning_rate   | 0.00025   |
|    n_updates       | 38395     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 196
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 195)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=17
📈 Node visual: Success rate updated to 0.000000 (based on 17 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 197
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 196)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=18
📈 Node visual: Success rate updated to 0.000000 (based on 18 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 198
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 197)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=19
📈 Node visual: Success rate updated to 0.000000 (based on 19 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 199
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 198)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=20
📈 Node visual: Success rate updated to 0.000000 (based on 20 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0026   |
| time/              |          |
|    episodes        | 200      |
|    fps             | 20       |
|    time_elapsed    | 1998     |
|    total_timesteps | 40200    |
| train/             |          |
|    actor_loss      | -7.5e+05 |
|    critic_loss     | 9.84e+09 |
|    ent_coef        | 3.87e+03 |
|    ent_coef_loss   | 0.0897   |
|    learning_rate   | 0.00025  |
|    n_updates       | 39199    |
---------------------------------

📊 EPISODE COMPLETED:
   Episode: 200
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 199)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.000000 (n=170)
   Causal impact: 0.003179
   Effect size: 0.368
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 200)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.000000 (n=170)
   Causal impact: 0.003419
   Effect size: 0.598
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=60)
   Baseline mean: 0.000000 (n=140)
   Causal impact: 0.000000
   Effect size: 0.000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 200)
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=21
📈 Node visual: Success rate updated to 0.000000 (based on 21 intervention episodes)
🎯 Node visual: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=21)
   Baseline mean: 0.000000 (n=179)
   Causal impact: 0.000000
   Effect size: 0.000
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
🎯 Node random_full: Insufficient data for causal impact (intervention: 0, baseline: 200)

📊 EPISODE COMPLETED:
   Episode: 201
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 200)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=22
📈 Node visual: Success rate updated to 0.000000 (based on 22 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 202
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 201)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=23
📈 Node visual: Success rate updated to 0.000000 (based on 23 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 203
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 202)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=24
📈 Node visual: Success rate updated to 0.000000 (based on 24 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00179   |
| time/              |           |
|    episodes        | 204       |
|    fps             | 20        |
|    time_elapsed    | 2047      |
|    total_timesteps | 41004     |
| train/             |           |
|    actor_loss      | -7.11e+05 |
|    critic_loss     | 5.59e+09  |
|    ent_coef        | 3.81e+03  |
|    ent_coef_loss   | -1.33     |
|    learning_rate   | 0.00025   |
|    n_updates       | 40003     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 204
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 203)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=25
📈 Node visual: Success rate updated to 0.000000 (based on 25 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 205
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 204)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=26
📈 Node visual: Success rate updated to 0.000000 (based on 26 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 206
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 205)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=27
📈 Node visual: Success rate updated to 0.000000 (based on 27 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 207
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 206)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=28
📈 Node visual: Success rate updated to 0.000000 (based on 28 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.000342  |
| time/              |           |
|    episodes        | 208       |
|    fps             | 19        |
|    time_elapsed    | 2094      |
|    total_timesteps | 41808     |
| train/             |           |
|    actor_loss      | -7.67e+05 |
|    critic_loss     | 8.46e+09  |
|    ent_coef        | 3.77e+03  |
|    ent_coef_loss   | -3.35     |
|    learning_rate   | 0.00025   |
|    n_updates       | 40807     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 208
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 207)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=29
📈 Node visual: Success rate updated to 0.000000 (based on 29 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

📊 EPISODE COMPLETED:
   Episode: 209
   Reward: 0.000000
   Success: False
   Active interventions: ['visual']

📈 PERFORMANCE UPDATE (Episode 208)
   Reward: 0.000000, Success: False
   Active interventions: ['visual']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: ACTIVE episode - reward=0.000000, total activations=30
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000

🔄 CURRICULUM ADAPTATION TRIGGERED
🔄 Adapting curriculum...

🎓 CURRICULUM CONFIG GENERATION (Episode 209)

🧪 EXPERIMENTAL PHASE SELECTION (Episode 209)

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, data_points=30, causal_impact=0.003179)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
🔬 INTERVENTION TEST PHASE:
   Test cycle: 6
   Testing intervention: random_full
   Episodes in current test: 9/25
   Eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
🎭 Creating actor instance for: random_full
   🚀 SELECTED: random_full (strength: 0.7)
   🔧 Building curriculum configuration:
      random_full: frequency=1, strength=0.700
   ✅ Config ready: 1 actors, 1 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 1
   🎯 Active nodes: ['random_full']
   📈 Baseline reward: 0.000000
   🧪 Episode count: 209

📊 EPISODE COMPLETED:
   Episode: 210
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 209)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.000000 (n=180)
   Causal impact: 0.003179
   Effect size: 0.368
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 210)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.000000 (n=180)
   Causal impact: 0.003419
   Effect size: 0.598
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=60)
   Baseline mean: 0.000000 (n=150)
   Causal impact: 0.000000
   Effect size: 0.000
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 210)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
🎯 Node visual: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=30)
   Baseline mean: 0.000000 (n=180)
   Causal impact: 0.000000
   Effect size: 0.000
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=1
🎯 Node random_full: Insufficient data for causal impact (intervention: 1, baseline: 209)

📊 EPISODE COMPLETED:
   Episode: 211
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 210)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=2
📈 Node random_full: Success rate updated to 0.000000 (based on 2 intervention episodes)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00014   |
| time/              |           |
|    episodes        | 212       |
|    fps             | 19        |
|    time_elapsed    | 2136      |
|    total_timesteps | 42612     |
| train/             |           |
|    actor_loss      | -6.79e+05 |
|    critic_loss     | 4.67e+09  |
|    ent_coef        | 3.74e+03  |
|    ent_coef_loss   | 0.112     |
|    learning_rate   | 0.00025   |
|    n_updates       | 41611     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 212
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 211)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.000000 → 0.000000
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=3
📈 Node random_full: Success rate updated to 0.000000 (based on 3 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 213
   Reward: 0.000971
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 212)
   Reward: 0.000971, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.000000 → 0.000049
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000971
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000971
📊 Node pose_full: INACTIVE episode - baseline reward=0.000971
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000971
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000971
📊 Node visual: INACTIVE episode - baseline reward=0.000971
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000971, total activations=4
📈 Node random_full: Success rate updated to 0.000243 (based on 4 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 214
   Reward: 0.001604
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 213)
   Reward: 0.001604, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.000049 → 0.000129
📊 Node goal_basic: INACTIVE episode - baseline reward=0.001604
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.001604
📊 Node pose_full: INACTIVE episode - baseline reward=0.001604
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.001604
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.001604
📊 Node visual: INACTIVE episode - baseline reward=0.001604
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.001604, total activations=5
📈 Node random_full: Success rate updated to 0.000515 (based on 5 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 215
   Reward: 0.001527
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 214)
   Reward: 0.001527, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.000129 → 0.000205
📊 Node goal_basic: INACTIVE episode - baseline reward=0.001527
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.001527
📊 Node pose_full: INACTIVE episode - baseline reward=0.001527
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.001527
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.001527
📊 Node visual: INACTIVE episode - baseline reward=0.001527
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.001527, total activations=6
📈 Node random_full: Success rate updated to 0.000684 (based on 6 intervention episodes)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 4.1e-05   |
| time/              |           |
|    episodes        | 216       |
|    fps             | 19        |
|    time_elapsed    | 2177      |
|    total_timesteps | 43416     |
| train/             |           |
|    actor_loss      | -6.83e+05 |
|    critic_loss     | 5.49e+09  |
|    ent_coef        | 3.54e+03  |
|    ent_coef_loss   | -3.3      |
|    learning_rate   | 0.00025   |
|    n_updates       | 42415     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 216
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 215)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.000205 → 0.000205
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=7
📈 Node random_full: Success rate updated to 0.000586 (based on 7 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 217
   Reward: 0.009970
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 216)
   Reward: 0.009970, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.000205 → 0.000704
📊 Node goal_basic: INACTIVE episode - baseline reward=0.009970
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.009970
📊 Node pose_full: INACTIVE episode - baseline reward=0.009970
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.009970
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.009970
📊 Node visual: INACTIVE episode - baseline reward=0.009970
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.009970, total activations=8
📈 Node random_full: Success rate updated to 0.001759 (based on 8 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 218
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 217)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.000704 → 0.000704
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=9
📈 Node random_full: Success rate updated to 0.001564 (based on 9 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 219
   Reward: 0.004872
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 218)
   Reward: 0.004872, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.000704 → 0.000947
📊 Node goal_basic: INACTIVE episode - baseline reward=0.004872
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.004872
📊 Node pose_full: INACTIVE episode - baseline reward=0.004872
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.004872
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.004872
📊 Node visual: INACTIVE episode - baseline reward=0.004872
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.004872, total activations=10
📈 Node random_full: Success rate updated to 0.001894 (based on 10 intervention episodes)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.000205  |
| time/              |           |
|    episodes        | 220       |
|    fps             | 19        |
|    time_elapsed    | 2218      |
|    total_timesteps | 44220     |
| train/             |           |
|    actor_loss      | -6.55e+05 |
|    critic_loss     | 7.52e+09  |
|    ent_coef        | 3.48e+03  |
|    ent_coef_loss   | -0.715    |
|    learning_rate   | 0.00025   |
|    n_updates       | 43219     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 220
   Reward: 0.001561
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 219)
   Reward: 0.001561, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.000947 → 0.001025
📊 Node goal_basic: INACTIVE episode - baseline reward=0.001561
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.002051 (n=190)
   Causal impact: 0.001128
   Effect size: 0.131
📊 Node pose_position: INACTIVE episode - baseline reward=0.001561
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 220)
📊 Node pose_full: INACTIVE episode - baseline reward=0.001561
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.002051 (n=190)
   Causal impact: 0.001368
   Effect size: 0.239
📊 Node physics_friction: INACTIVE episode - baseline reward=0.001561
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=60)
   Baseline mean: 0.002051 (n=160)
   Causal impact: -0.002051
   Effect size: 0.686
📊 Node physics_mass: INACTIVE episode - baseline reward=0.001561
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 220)
📊 Node visual: INACTIVE episode - baseline reward=0.001561
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
🎯 Node visual: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=30)
   Baseline mean: 0.002051 (n=190)
   Causal impact: -0.002051
   Effect size: 0.686
📊 Node random_full: ACTIVE episode - reward=0.001561, total activations=11
📈 Node random_full: Success rate updated to 0.002051 (based on 11 intervention episodes)
🎯 Node random_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.002051 (n=11)
   Baseline mean: 0.000000 (n=209)
   Causal impact: 0.002051
   Effect size: 0.686
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 221
   Reward: 0.001199
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 220)
   Reward: 0.001199, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.001025 → 0.001085
📊 Node goal_basic: INACTIVE episode - baseline reward=0.001199
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.001199
📊 Node pose_full: INACTIVE episode - baseline reward=0.001199
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.001199
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.001199
📊 Node visual: INACTIVE episode - baseline reward=0.001199
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.001199, total activations=12
📈 Node random_full: Success rate updated to 0.002170 (based on 12 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 222
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 221)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.001085 → 0.001085
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=13
📈 Node random_full: Success rate updated to 0.002170 (based on 13 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 223
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 222)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.001085 → 0.001085
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=14
📈 Node random_full: Success rate updated to 0.002073 (based on 14 intervention episodes)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.000217  |
| time/              |           |
|    episodes        | 224       |
|    fps             | 19        |
|    time_elapsed    | 2259      |
|    total_timesteps | 45024     |
| train/             |           |
|    actor_loss      | -5.57e+05 |
|    critic_loss     | 9.16e+09  |
|    ent_coef        | 3.45e+03  |
|    ent_coef_loss   | -6.82     |
|    learning_rate   | 0.00025   |
|    n_updates       | 44023     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 224
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 223)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.001085 → 0.001085
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=15
📈 Node random_full: Success rate updated to 0.001913 (based on 15 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 225
   Reward: 0.041127
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 224)
   Reward: 0.041127, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.001085 → 0.003142
📊 Node goal_basic: INACTIVE episode - baseline reward=0.041127
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.041127
📊 Node pose_full: INACTIVE episode - baseline reward=0.041127
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.041127
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.041127
📊 Node visual: INACTIVE episode - baseline reward=0.041127
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.041127, total activations=16
📈 Node random_full: Success rate updated to 0.005873 (based on 16 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 226
   Reward: 0.102120
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 225)
   Reward: 0.102120, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.003142 → 0.008248
📊 Node goal_basic: INACTIVE episode - baseline reward=0.102120
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.102120
📊 Node pose_full: INACTIVE episode - baseline reward=0.102120
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.102120
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.102120
📊 Node visual: INACTIVE episode - baseline reward=0.102120
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.102120, total activations=17
📈 Node random_full: Success rate updated to 0.016085 (based on 17 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 227
   Reward: 0.045172
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 226)
   Reward: 0.045172, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.008248 → 0.010506
📊 Node goal_basic: INACTIVE episode - baseline reward=0.045172
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.045172
📊 Node pose_full: INACTIVE episode - baseline reward=0.045172
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.045172
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.045172
📊 Node visual: INACTIVE episode - baseline reward=0.045172
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.045172, total activations=18
📈 Node random_full: Success rate updated to 0.019605 (based on 18 intervention episodes)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00227   |
| time/              |           |
|    episodes        | 228       |
|    fps             | 19        |
|    time_elapsed    | 2295      |
|    total_timesteps | 45828     |
| train/             |           |
|    actor_loss      | -6.12e+05 |
|    critic_loss     | 6.87e+09  |
|    ent_coef        | 3.48e+03  |
|    ent_coef_loss   | 0.2       |
|    learning_rate   | 0.00025   |
|    n_updates       | 44827     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 228
   Reward: 0.016760
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 227)
   Reward: 0.016760, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.010506 → 0.011344
📊 Node goal_basic: INACTIVE episode - baseline reward=0.016760
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.016760
📊 Node pose_full: INACTIVE episode - baseline reward=0.016760
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.016760
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.016760
📊 Node visual: INACTIVE episode - baseline reward=0.016760
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.016760, total activations=19
📈 Node random_full: Success rate updated to 0.021281 (based on 19 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 229
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 228)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.011344 → 0.011344
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=20
📈 Node random_full: Success rate updated to 0.020794 (based on 20 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 230
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 229)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.011344 → 0.011344
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.020638 (n=200)
   Causal impact: -0.017459
   Effect size: 0.547
   🎯 SIGNIFICANT EFFECT detected for goal_basic: impact=-0.017459, effect_size=0.547
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 230)
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003419 (n=30)
   Baseline mean: 0.020638 (n=200)
   Causal impact: -0.017219
   Effect size: 0.540
   🎯 SIGNIFICANT EFFECT detected for pose_full: impact=-0.017219, effect_size=0.540
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=60)
   Baseline mean: 0.020638 (n=170)
   Causal impact: -0.020638
   Effect size: 0.647
   🎯 SIGNIFICANT EFFECT detected for physics_friction: impact=-0.020638, effect_size=0.647
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 230)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
🎯 Node visual: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=30)
   Baseline mean: 0.020638 (n=200)
   Causal impact: -0.020638
   Effect size: 0.647
   🎯 SIGNIFICANT EFFECT detected for visual: impact=-0.020638, effect_size=0.647
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=21
📈 Node random_full: Success rate updated to 0.020638 (based on 21 intervention episodes)
🎯 Node random_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.020638 (n=21)
   Baseline mean: 0.000000 (n=209)
   Causal impact: 0.020638
   Effect size: 0.647
   🎯 SIGNIFICANT EFFECT detected for random_full: impact=0.020638, effect_size=0.647

📊 EPISODE COMPLETED:
   Episode: 231
   Reward: 0.009686
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 230)
   Reward: 0.009686, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.011344 → 0.011828
📊 Node goal_basic: INACTIVE episode - baseline reward=0.009686
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.009686
📊 Node pose_full: INACTIVE episode - baseline reward=0.009686
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.009686
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.009686
📊 Node visual: INACTIVE episode - baseline reward=0.009686
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.009686, total activations=22
📈 Node random_full: Success rate updated to 0.021486 (based on 22 intervention episodes)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00376   |
| time/              |           |
|    episodes        | 232       |
|    fps             | 20        |
|    time_elapsed    | 2331      |
|    total_timesteps | 46632     |
| train/             |           |
|    actor_loss      | -7.22e+05 |
|    critic_loss     | 6.27e+09  |
|    ent_coef        | 3.56e+03  |
|    ent_coef_loss   | 2.86      |
|    learning_rate   | 0.00025   |
|    n_updates       | 45631     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 232
   Reward: 0.139641
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 231)
   Reward: 0.139641, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.011828 → 0.018811
📊 Node goal_basic: INACTIVE episode - baseline reward=0.139641
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.139641
📊 Node pose_full: INACTIVE episode - baseline reward=0.139641
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.139641
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.139641
📊 Node visual: INACTIVE episode - baseline reward=0.139641
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.139641, total activations=23
📈 Node random_full: Success rate updated to 0.035451 (based on 23 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 233
   Reward: 0.054027
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 232)
   Reward: 0.054027, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.018811 → 0.021463
📊 Node goal_basic: INACTIVE episode - baseline reward=0.054027
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.054027
📊 Node pose_full: INACTIVE episode - baseline reward=0.054027
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.054027
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.054027
📊 Node visual: INACTIVE episode - baseline reward=0.054027
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.054027, total activations=24
📈 Node random_full: Success rate updated to 0.040853 (based on 24 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 234
   Reward: 0.000000
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 233)
   Reward: 0.000000, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.021463 → 0.021383
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: INACTIVE episode - baseline reward=0.000000
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000000, total activations=25
📈 Node random_full: Success rate updated to 0.040853 (based on 25 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 235
   Reward: 0.010968
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 234)
   Reward: 0.010968, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.021383 → 0.021855
📊 Node goal_basic: INACTIVE episode - baseline reward=0.010968
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.010968
📊 Node pose_full: INACTIVE episode - baseline reward=0.010968
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.010968
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.010968
📊 Node visual: INACTIVE episode - baseline reward=0.010968
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.010968, total activations=26
📈 Node random_full: Success rate updated to 0.037837 (based on 26 intervention episodes)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00441   |
| time/              |           |
|    episodes        | 236       |
|    fps             | 20        |
|    time_elapsed    | 2367      |
|    total_timesteps | 47436     |
| train/             |           |
|    actor_loss      | -5.92e+05 |
|    critic_loss     | 6.56e+09  |
|    ent_coef        | 3.6e+03   |
|    ent_coef_loss   | 0.553     |
|    learning_rate   | 0.00025   |
|    n_updates       | 46435     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 236
   Reward: 0.000007
   Success: False
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 235)
   Reward: 0.000007, Success: False
   Active interventions: ['random_full']
   Baseline reward: 0.021855 → 0.021855
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000007
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000007
📊 Node pose_full: INACTIVE episode - baseline reward=0.000007
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000007
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000007
📊 Node visual: INACTIVE episode - baseline reward=0.000007
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.000007, total activations=27
📈 Node random_full: Success rate updated to 0.027626 (based on 27 intervention episodes)
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 237
   Reward: 0.040767
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 236)
   Reward: 0.040767, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.021855 → 0.023395
📊 Node goal_basic: INACTIVE episode - baseline reward=0.040767
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.040767
📊 Node pose_full: INACTIVE episode - baseline reward=0.040767
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.040767
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.040767
📊 Node visual: INACTIVE episode - baseline reward=0.040767
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.040767, total activations=28
📈 Node random_full: Success rate updated to 0.027186 (based on 28 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 238
   Reward: 0.026176
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 237)
   Reward: 0.026176, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.023395 → 0.024704
📊 Node goal_basic: INACTIVE episode - baseline reward=0.026176
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.026176
📊 Node pose_full: INACTIVE episode - baseline reward=0.026176
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.026176
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.026176
📊 Node visual: INACTIVE episode - baseline reward=0.026176
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.026176, total activations=29
📈 Node random_full: Success rate updated to 0.028127 (based on 29 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 239
   Reward: 0.006115
   Success: True
   Active interventions: ['random_full']

📈 PERFORMANCE UPDATE (Episode 238)
   Reward: 0.006115, Success: True
   Active interventions: ['random_full']
   Baseline reward: 0.024704 → 0.024766
📊 Node goal_basic: INACTIVE episode - baseline reward=0.006115
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.006115
📊 Node pose_full: INACTIVE episode - baseline reward=0.006115
📈 Node pose_full: Success rate updated to 0.003419 (based on 30 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.006115
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.006115
📊 Node visual: INACTIVE episode - baseline reward=0.006115
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: ACTIVE episode - reward=0.006115, total activations=30
📈 Node random_full: Success rate updated to 0.028739 (based on 30 intervention episodes)

🔄 CURRICULUM ADAPTATION TRIGGERED
🔄 Adapting curriculum...

🎓 CURRICULUM CONFIG GENERATION (Episode 239)

🧪 EXPERIMENTAL PHASE SELECTION (Episode 239)

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=False
      Prerequisites: goal_basic(satisfied=False, data_points=30, causal_impact=-0.017459)
   ❌ pose_position is NOT eligible
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
🔬 INTERVENTION TEST PHASE:
   Test cycle: 7
   Testing intervention: pose_full
   Episodes in current test: 14/25
   Eligible interventions: ['goal_basic', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
   ⚔️ Intervention pose_full has conflicts: ['pose_position']
🎭 Creating actor instance for: pose_full
   🚀 SELECTED: pose_full (strength: 0.7)
   🔧 Building curriculum configuration:
      pose_full: frequency=1, strength=0.700
   ✅ Config ready: 1 actors, 1 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 1
   🎯 Active nodes: ['pose_full']
   📈 Baseline reward: 0.024766
   🧪 Episode count: 239
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00514   |
| time/              |           |
|    episodes        | 240       |
|    fps             | 20        |
|    time_elapsed    | 2403      |
|    total_timesteps | 48240     |
| train/             |           |
|    actor_loss      | -6.78e+05 |
|    critic_loss     | 1.23e+10  |
|    ent_coef        | 3.63e+03  |
|    ent_coef_loss   | -5.84     |
|    learning_rate   | 0.00025   |
|    n_updates       | 47239     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 240
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 239)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.024766 → 0.024688
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
🎯 Node goal_basic: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.003179 (n=30)
   Baseline mean: 0.028739 (n=210)
   Causal impact: -0.025560
   Effect size: 0.624
   🎯 SIGNIFICANT EFFECT detected for goal_basic: impact=-0.025560, effect_size=0.624
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
🎯 Node pose_position: Insufficient data for causal impact (intervention: 0, baseline: 240)
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=31
📈 Node pose_full: Success rate updated to 0.002878 (based on 31 intervention episodes)
🎯 Node pose_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.002878 (n=31)
   Baseline mean: 0.028739 (n=209)
   Causal impact: -0.025861
   Effect size: 0.632
   🎯 SIGNIFICANT EFFECT detected for pose_full: impact=-0.025861, effect_size=0.632
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
🎯 Node physics_friction: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=60)
   Baseline mean: 0.028739 (n=180)
   Causal impact: -0.028739
   Effect size: 0.702
   🎯 SIGNIFICANT EFFECT detected for physics_friction: impact=-0.028739, effect_size=0.702
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
🎯 Node physics_mass: Insufficient data for causal impact (intervention: 0, baseline: 240)
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
🎯 Node visual: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.000000 (n=30)
   Baseline mean: 0.028739 (n=210)
   Causal impact: -0.028739
   Effect size: 0.702
   🎯 SIGNIFICANT EFFECT detected for visual: impact=-0.028739, effect_size=0.702
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
📈 Node random_full: Success rate updated to 0.028739 (based on 30 intervention episodes)
🎯 Node random_full: CAUSAL IMPACT ANALYSIS
   Intervention mean: 0.028739 (n=30)
   Baseline mean: 0.000000 (n=210)
   Causal impact: 0.028739
   Effect size: 0.702
   🎯 SIGNIFICANT EFFECT detected for random_full: impact=0.028739, effect_size=0.702

📊 EPISODE COMPLETED:
   Episode: 241
   Reward: 0.001715
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 240)
   Reward: 0.001715, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.024688 → 0.024714
📊 Node goal_basic: INACTIVE episode - baseline reward=0.001715
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.001715
📊 Node pose_full: ACTIVE episode - reward=0.001715, total activations=32
📈 Node pose_full: Success rate updated to 0.001575 (based on 32 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.001715
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.001715
📊 Node visual: INACTIVE episode - baseline reward=0.001715
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.001715
📈 Node random_full: Success rate updated to 0.028739 (based on 30 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 242
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 241)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.024714 → 0.024714
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=33
📈 Node pose_full: Success rate updated to 0.001575 (based on 33 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
📈 Node random_full: Success rate updated to 0.028739 (based on 30 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 243
   Reward: 0.049775
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 242)
   Reward: 0.049775, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.024714 → 0.027203
📊 Node goal_basic: INACTIVE episode - baseline reward=0.049775
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.049775
📊 Node pose_full: ACTIVE episode - reward=0.049775, total activations=34
📈 Node pose_full: Success rate updated to 0.006553 (based on 34 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.049775
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.049775
📊 Node visual: INACTIVE episode - baseline reward=0.049775
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.049775
📈 Node random_full: Success rate updated to 0.028739 (based on 30 intervention episodes)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.00566   |
| time/              |           |
|    episodes        | 244       |
|    fps             | 20        |
|    time_elapsed    | 2440      |
|    total_timesteps | 49044     |
| train/             |           |
|    actor_loss      | -6.66e+05 |
|    critic_loss     | 7.56e+09  |
|    ent_coef        | 3.69e+03  |
|    ent_coef_loss   | -0.717    |
|    learning_rate   | 0.00025   |
|    n_updates       | 48043     |
----------------------------------

📊 EPISODE COMPLETED:
   Episode: 244
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 243)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.027203 → 0.027203
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=35
📈 Node pose_full: Success rate updated to 0.005149 (based on 35 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
📈 Node random_full: Success rate updated to 0.028739 (based on 30 intervention episodes)
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 245
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 244)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.027203 → 0.025146
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=36
📈 Node pose_full: Success rate updated to 0.005149 (based on 36 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
📈 Node random_full: Success rate updated to 0.028739 (based on 30 intervention episodes)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!

📊 EPISODE COMPLETED:
   Episode: 246
   Reward: 0.000000
   Success: False
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 245)
   Reward: 0.000000, Success: False
   Active interventions: ['pose_full']
   Baseline reward: 0.025146 → 0.020040
📊 Node goal_basic: INACTIVE episode - baseline reward=0.000000
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.000000
📊 Node pose_full: ACTIVE episode - reward=0.000000, total activations=37
📈 Node pose_full: Success rate updated to 0.005149 (based on 37 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.000000
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.000000
📊 Node visual: INACTIVE episode - baseline reward=0.000000
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.000000
📈 Node random_full: Success rate updated to 0.028739 (based on 30 intervention episodes)

📊 EPISODE COMPLETED:
   Episode: 247
   Reward: 0.028878
   Success: True
   Active interventions: ['pose_full']

📈 PERFORMANCE UPDATE (Episode 246)
   Reward: 0.028878, Success: True
   Active interventions: ['pose_full']
   Baseline reward: 0.020040 → 0.019226
📊 Node goal_basic: INACTIVE episode - baseline reward=0.028878
📈 Node goal_basic: Success rate updated to 0.003179 (based on 30 intervention episodes)
📊 Node pose_position: INACTIVE episode - baseline reward=0.028878
📊 Node pose_full: ACTIVE episode - reward=0.028878, total activations=38
📈 Node pose_full: Success rate updated to 0.008037 (based on 38 intervention episodes)
📊 Node physics_friction: INACTIVE episode - baseline reward=0.028878
📈 Node physics_friction: Success rate updated to 0.000000 (based on 60 intervention episodes)
📊 Node physics_mass: INACTIVE episode - baseline reward=0.028878
📊 Node visual: INACTIVE episode - baseline reward=0.028878
📈 Node visual: Success rate updated to 0.000000 (based on 30 intervention episodes)
📊 Node random_full: INACTIVE episode - baseline reward=0.028878
📈 Node random_full: Success rate updated to 0.028739 (based on 30 intervention episodes)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.00669  |
| time/              |          |
|    episodes        | 248      |
|    fps             | 20       |
|    time_elapsed    | 2477     |
|    total_timesteps | 49848    |
| train/             |          |
|    actor_loss      | -8.2e+05 |
|    critic_loss     | 1.06e+10 |
|    ent_coef        | 3.78e+03 |
|    ent_coef_loss   | -1.98    |
|    learning_rate   | 0.00025  |
|    n_updates       | 48847    |
---------------------------------
Traceback (most recent call last):
  File "her_sac.py", line 175, in <module>
    wandb_config=wandb_config
  File "her_sac.py", line 128, in train_policy
    callback=callbacks)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\sac\sac.py", line 301, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\off_policy_algorithm.py", line 375, in learn
    callback.on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\callbacks.py", line 91, in on_training_end
    self._on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\callbacks.py", line 201, in _on_training_end
    callback.on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\callbacks.py", line 91, in on_training_end
    self._on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\integration\sb3\sb3.py", line 147, in _on_training_end
    self.save_model()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\integration\sb3\sb3.py", line 151, in save_model
    wandb.save(self.path, base_path=self.model_save_path)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 2027, in save
    policy,
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 2088, in _save
    target_path.symlink_to(source_path)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\pathlib.py", line 1337, in symlink_to
    self._accessor.symlink(target, self, target_is_directory)
OSError: symbolic link privilege not held
