2025-07-19 15:07:59,236 4037571 INFO [PRETRAINED] Using pretrained model path: ppo_pushing_sb3/final_model.zip
2025-07-19 15:07:59,238 4037571 INFO Starting with 7 interventions
2025-07-19 15:07:59,238 4037571 INFO ===final evaluation===
2025-07-19 15:08:09,749 4037571 INFO Final performance
2025-07-19 15:08:09,750 4037571 INFO average reward: 3.394 +/- 0.000
2025-07-19 15:08:09,750 4037571 INFO success rate: 1.000
2025-07-19 15:08:09,750 4037571 INFO average episode length: 501.0
2025-07-19 15:08:09,750 4037571 INFO initial performance: {'avg_reward': 3.393721938342554, 'reward_std': 4.440892098500626e-16, 'avg_length': 501.0, 'success_rate': 1.0, 'total_episodes': 10}
2025-07-19 15:08:09,750 4037571 INFO CURRICULUM STAGE 1/7
2025-07-19 15:08:09,751 4037571 INFO Remaining interventions: ['goal', 'mass', 'friction', 'visual', 'position', 'angle', 'random']
2025-07-19 15:08:09,751 4037571 INFO
Testing intervention 1/7: goal
2025-07-19 15:08:09,751 4037571 INFO testing intervention: goal
IntervenedCausalWorld created with goal intervention
Reset #1: goal intervention applied (success: True)
2025-07-19 15:08:10,769 4037571 INFO Episode 1: reward=-1.543, length=501, success=False
Reset #2: goal intervention applied (success: True)
2025-07-19 15:08:11,756 4037571 INFO Episode 2: reward=1.199, length=501, success=False
Reset #3: goal intervention applied (success: True)
2025-07-19 15:08:11,855 4037571 INFO Episode 3: reward=1.486, length=24, success=True
2025-07-19 15:08:18,003 4037571 INFO Results: avg_reward=0.694, success_rate=0.200, avg_length=407.2
2025-07-19 15:08:18,004 4037571 INFO
Testing intervention 2/7: mass
2025-07-19 15:08:18,004 4037571 INFO testing intervention: mass
IntervenedCausalWorld created with mass intervention
Reset #1: mass intervention applied (success: True)
2025-07-19 15:08:18,122 4037571 INFO Episode 1: reward=-1.248, length=30, success=True
Reset #2: mass intervention applied (success: True)
2025-07-19 15:08:18,233 4037571 INFO Episode 2: reward=-0.699, length=31, success=True
Reset #3: mass intervention applied (success: True)
2025-07-19 15:08:18,343 4037571 INFO Episode 3: reward=-0.522, length=31, success=True
2025-07-19 15:08:19,093 4037571 INFO Results: avg_reward=-0.700, success_rate=1.000, avg_length=30.2
2025-07-19 15:08:19,094 4037571 INFO
Testing intervention 3/7: friction
2025-07-19 15:08:19,094 4037571 INFO testing intervention: friction
IntervenedCausalWorld created with friction intervention
Reset #1: friction intervention applied (success: True)
2025-07-19 15:08:19,206 4037571 INFO Episode 1: reward=-0.773, length=27, success=True
Reset #2: friction intervention applied (success: True)
2025-07-19 15:08:19,311 4037571 INFO Episode 2: reward=-0.928, length=28, success=True
Reset #3: friction intervention applied (success: True)
2025-07-19 15:08:19,414 4037571 INFO Episode 3: reward=-0.766, length=27, success=True
2025-07-19 15:08:20,136 4037571 INFO Results: avg_reward=-0.834, success_rate=1.000, avg_length=27.4
2025-07-19 15:08:20,137 4037571 INFO
Testing intervention 4/7: visual
2025-07-19 15:08:20,137 4037571 INFO testing intervention: visual
IntervenedCausalWorld created with visual intervention
Reset #1: visual intervention applied (success: True)
2025-07-19 15:08:20,249 4037571 INFO Episode 1: reward=-0.773, length=27, success=True
Reset #2: visual intervention applied (success: True)
2025-07-19 15:08:20,353 4037571 INFO Episode 2: reward=-0.773, length=27, success=True
Reset #3: visual intervention applied (success: True)
2025-07-19 15:08:20,456 4037571 INFO Episode 3: reward=-0.773, length=27, success=True
2025-07-19 15:08:21,177 4037571 INFO Results: avg_reward=-0.773, success_rate=1.000, avg_length=27.0
2025-07-19 15:08:21,178 4037571 INFO
Testing intervention 5/7: position
2025-07-19 15:08:21,178 4037571 INFO testing intervention: position
IntervenedCausalWorld created with position intervention
Reset #1: position intervention applied (success: True)
2025-07-19 15:08:22,166 4037571 INFO Episode 1: reward=-0.243, length=501, success=False
Reset #2: position intervention applied (success: True)
2025-07-19 15:08:23,160 4037571 INFO Episode 2: reward=4.841, length=501, success=False
Reset #3: position intervention applied (success: True)
2025-07-19 15:08:24,206 4037571 INFO Episode 3: reward=-1.414, length=501, success=False
2025-07-19 15:08:28,294 4037571 INFO Results: avg_reward=-0.460, success_rate=0.300, avg_length=359.0
2025-07-19 15:08:28,294 4037571 INFO
Testing intervention 6/7: angle
2025-07-19 15:08:28,294 4037571 INFO testing intervention: angle
IntervenedCausalWorld created with angle intervention
Reset #1: angle intervention applied (success: True)
2025-07-19 15:08:29,301 4037571 INFO Episode 1: reward=-1.364, length=501, success=False
Reset #2: angle intervention applied (success: True)
2025-07-19 15:08:30,332 4037571 INFO Episode 2: reward=0.641, length=501, success=False
Reset #3: angle intervention applied (success: True)
2025-07-19 15:08:31,363 4037571 INFO Episode 3: reward=1.757, length=501, success=False
2025-07-19 15:08:38,521 4037571 INFO Results: avg_reward=-0.252, success_rate=0.000, avg_length=501.0
2025-07-19 15:08:38,522 4037571 INFO
Testing intervention 7/7: random
2025-07-19 15:08:38,522 4037571 INFO testing intervention: random
IntervenedCausalWorld created with random intervention
Reset #1: random intervention applied (success: True)
2025-07-19 15:08:39,505 4037571 INFO Episode 1: reward=-1.271, length=501, success=False
Reset #2: random intervention applied (success: True)
2025-07-19 15:08:40,511 4037571 INFO Episode 2: reward=3.268, length=501, success=False
Reset #3: random intervention applied (success: True)
2025-07-19 15:08:41,487 4037571 INFO Episode 3: reward=3.683, length=501, success=False
2025-07-19 15:08:48,606 4037571 INFO Results: avg_reward=1.579, success_rate=0.000, avg_length=501.0
2025-07-19 15:08:48,607 4037571 INFO best intervention for stage 1: random
2025-07-19 15:08:48,607 4037571 INFO average reward: 1.579
2025-07-19 15:08:48,607 4037571 INFO success rate: 0.000
2025-07-19 15:08:48,607 4037571 INFO average length: 501.0
2025-07-19 15:08:48,607 4037571 INFO === stage 1/7: training on random intervention ===
Logging to highest_reward_sequencing_logs/sb3_csv_logs_1_{'type': 'random', 'class': <class 'causal_world.intervention_actors.random_actor.RandomInterventionActorPolicy'>, 'params': {}}
IntervenedCausalWorld created with random intervention
Reset #1: random intervention applied (success: True)
Reset #2: random intervention applied (success: True)
Reset #3: random intervention applied (success: True)
------------------------------------
| custom/              |           |
|    intervention_type | random    |
|    stage             | 1         |
| rollout/             |           |
|    ep_len_mean       | 267       |
|    ep_rew_mean       | 2.0352743 |
| time/                |           |
|    fps               | 453       |
|    iterations        | 1         |
|    time_elapsed      | 9         |
|    total_timesteps   | 5050368   |
------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 282        |
|    ep_rew_mean          | 1.8775079  |
| time/                   |            |
|    fps                  | 282        |
|    iterations           | 2          |
|    time_elapsed         | 29         |
|    total_timesteps      | 5054464    |
| train/                  |            |
|    approx_kl            | 0.03358264 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -21.6      |
|    explained_variance   | 0.336      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.479     |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.0773    |
|    std                  | 2.68       |
|    value_loss           | 0.0988     |
----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 302        |
|    ep_rew_mean          | 1.8642348  |
| time/                   |            |
|    fps                  | 249        |
|    iterations           | 3          |
|    time_elapsed         | 49         |
|    total_timesteps      | 5058560    |
| train/                  |            |
|    approx_kl            | 0.04088657 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -21.7      |
|    explained_variance   | 0.635      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.526     |
|    n_updates            | 1185       |
|    policy_gradient_loss | -0.0794    |
|    std                  | 2.72       |
|    value_loss           | 0.0415     |
----------------------------------------
-----------------------------------------
| custom/                 |             |
|    intervention_type    | random      |
|    stage                | 1           |
| rollout/                |             |
|    ep_len_mean          | 319         |
|    ep_rew_mean          | 1.8797176   |
| time/                   |             |
|    fps                  | 235         |
|    iterations           | 4           |
|    time_elapsed         | 69          |
|    total_timesteps      | 5062656     |
| train/                  |             |
|    approx_kl            | 0.040596083 |
|    clip_fraction        | 0.476       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.9       |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0914     |
|    std                  | 2.76        |
|    value_loss           | 0.0317      |
-----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 339        |
|    ep_rew_mean          | 1.7659507  |
| time/                   |            |
|    fps                  | 228        |
|    iterations           | 5          |
|    time_elapsed         | 89         |
|    total_timesteps      | 5066752    |
| train/                  |            |
|    approx_kl            | 0.04988959 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.1      |
|    explained_variance   | 0.121      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.486     |
|    n_updates            | 1215       |
|    policy_gradient_loss | -0.0589    |
|    std                  | 2.84       |
|    value_loss           | 0.117      |
----------------------------------------
---------------------------------------
| custom/                 |           |
|    intervention_type    | random    |
|    stage                | 1         |
| rollout/                |           |
|    ep_len_mean          | 359       |
|    ep_rew_mean          | 1.7642426 |
| time/                   |           |
|    fps                  | 223       |
|    iterations           | 6         |
|    time_elapsed         | 109       |
|    total_timesteps      | 5070848   |
| train/                  |           |
|    approx_kl            | 0.0411368 |
|    clip_fraction        | 0.463     |
|    clip_range           | 0.2       |
|    entropy_loss         | -22.2     |
|    explained_variance   | 0.678     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.522    |
|    n_updates            | 1230      |
|    policy_gradient_loss | -0.0901   |
|    std                  | 2.86      |
|    value_loss           | 0.0648    |
---------------------------------------
-----------------------------------------
| custom/                 |             |
|    intervention_type    | random      |
|    stage                | 1           |
| rollout/                |             |
|    ep_len_mean          | 382         |
|    ep_rew_mean          | 1.7214574   |
| time/                   |             |
|    fps                  | 220         |
|    iterations           | 7           |
|    time_elapsed         | 130         |
|    total_timesteps      | 5074944     |
| train/                  |             |
|    approx_kl            | 0.051021874 |
|    clip_fraction        | 0.531       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.3       |
|    explained_variance   | 0.437       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.52       |
|    n_updates            | 1245        |
|    policy_gradient_loss | -0.0846     |
|    std                  | 2.91        |
|    value_loss           | 0.0965      |
-----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 400        |
|    ep_rew_mean          | 1.5748848  |
| time/                   |            |
|    fps                  | 218        |
|    iterations           | 8          |
|    time_elapsed         | 150        |
|    total_timesteps      | 5079040    |
| train/                  |            |
|    approx_kl            | 0.08102546 |
|    clip_fraction        | 0.598      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.5      |
|    explained_variance   | 0.486      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.542     |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0913    |
|    std                  | 2.96       |
|    value_loss           | 0.129      |
----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 420        |
|    ep_rew_mean          | 1.4576712  |
| time/                   |            |
|    fps                  | 216        |
|    iterations           | 9          |
|    time_elapsed         | 170        |
|    total_timesteps      | 5083136    |
| train/                  |            |
|    approx_kl            | 0.03957784 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.6      |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.537     |
|    n_updates            | 1275       |
|    policy_gradient_loss | -0.0924    |
|    std                  | 2.98       |
|    value_loss           | 0.0578     |
----------------------------------------
-----------------------------------------
| custom/                 |             |
|    intervention_type    | random      |
|    stage                | 1           |
| rollout/                |             |
|    ep_len_mean          | 440         |
|    ep_rew_mean          | 1.3762034   |
| time/                   |             |
|    fps                  | 215         |
|    iterations           | 10          |
|    time_elapsed         | 190         |
|    total_timesteps      | 5087232     |
| train/                  |             |
|    approx_kl            | 0.050730415 |
|    clip_fraction        | 0.538       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.604       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.568      |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.105      |
|    std                  | 3           |
|    value_loss           | 0.039       |
-----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 458        |
|    ep_rew_mean          | 1.2981023  |
| time/                   |            |
|    fps                  | 213        |
|    iterations           | 11         |
|    time_elapsed         | 210        |
|    total_timesteps      | 5091328    |
| train/                  |            |
|    approx_kl            | 0.04173594 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.7      |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.564     |
|    n_updates            | 1305       |
|    policy_gradient_loss | -0.0951    |
|    std                  | 3.03       |
|    value_loss           | 0.0494     |
----------------------------------------
-----------------------------------------
| custom/                 |             |
|    intervention_type    | random      |
|    stage                | 1           |
| rollout/                |             |
|    ep_len_mean          | 460         |
|    ep_rew_mean          | 1.0735073   |
| time/                   |             |
|    fps                  | 213         |
|    iterations           | 12          |
|    time_elapsed         | 230         |
|    total_timesteps      | 5095424     |
| train/                  |             |
|    approx_kl            | 0.048470315 |
|    clip_fraction        | 0.539       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.8       |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.564      |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0971     |
|    std                  | 3.07        |
|    value_loss           | 0.043       |
-----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 465        |
|    ep_rew_mean          | 1.158713   |
| time/                   |            |
|    fps                  | 212        |
|    iterations           | 13         |
|    time_elapsed         | 250        |
|    total_timesteps      | 5099520    |
| train/                  |            |
|    approx_kl            | 0.06387389 |
|    clip_fraction        | 0.575      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.9      |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.563     |
|    n_updates            | 1335       |
|    policy_gradient_loss | -0.106     |
|    std                  | 3.1        |
|    value_loss           | 0.0298     |
----------------------------------------
Traceback (most recent call last):
  File "highest_reward_sequencing.py", line 926, in <module>
    main()
  File "highest_reward_sequencing.py", line 773, in main
    cumulative_timesteps
  File "highest_reward_sequencing.py", line 571, in train_on_intervention
    stats = CallbackList[0].get_stats()
TypeError: 'ABCMeta' object is not subscriptable
