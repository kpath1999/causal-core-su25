2025-07-08 19:15:58,462 2112831 INFO [WANDB] Initialized with project: adaptive-curriculum-ppo-pushing and run name: adaptive_curriculum_ppo_pushing_seed0
2025-07-08 19:15:58,462 2112831 INFO [LOGDIR] Log directory: adaptive_curriculum_on_ppo
2025-07-08 19:15:58,462 2112831 INFO [CURRICULUM] Interventions: ['GoalInterventionActorPolicy', 'PhysicalPropertiesInterventionActorPolicy', 'VisualInterventionActorPolicy', 'JointsInterventionActorPolicy', 'RigidPoseInterventionActorPolicy', 'RandomInterventionActorPolicy']
[ADAPTIVE] Initialized with 6 interventions.
2025-07-08 19:15:58,480 2112831 INFO [ENV] Creating 16 parallel training environments for task: pushing
2025-07-08 19:16:03,195 2112831 INFO [ENV] Creating evaluation environment for task: pushing
2025-07-08 19:16:03,305 2112831 INFO [MODEL] PPO model loaded from: ppo_pushing_sb3/final_model.zip
2025-07-08 19:16:04,703 2112831 INFO [CALLBACKS] Callbacks set up: ['CheckpointCallback', 'EvalCallback', 'AdaptiveCurriculumCallback', 'WandbCallback']
2025-07-08 19:16:04,704 2112831 INFO [TRAIN] Starting training for 3000000 timesteps...
Logging to adaptive_curriculum_on_ppo/adaptive_curriculum_on_ppo_4
/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/stable_baselines3/common/callbacks.py:337: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_monitor.VecMonitor object at 0x7fbd5d356550> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fbe032683d0>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
[ADAPTIVE] Episode 1 reward: 0.044508
[34m[1mwandb[0m: [33mWARNING[0m Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 251        |
|    ep_rew_mean     | 0.44771796 |
| time/              |            |
|    fps             | 1813       |
|    iterations      | 1          |
|    time_elapsed    | 2          |
|    total_timesteps | 4096       |
-----------------------------------
[ADAPTIVE] Episode 2 reward: -0.019474
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.54302555  |
| time/                   |             |
|    fps                  | 1407        |
|    iterations           | 2           |
|    time_elapsed         | 5           |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.020774283 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.6       |
|    explained_variance   | 0.319       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.444      |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 2.67        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 3 reward: 0.058256
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.50937486  |
| time/                   |             |
|    fps                  | 1436        |
|    iterations           | 3           |
|    time_elapsed         | 8           |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.015857464 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.6       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.452      |
|    n_updates            | 1185        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 2.69        |
|    value_loss           | 0.0826      |
-----------------------------------------
[ADAPTIVE] Episode 4 reward: 0.022794
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.71154886  |
| time/                   |             |
|    fps                  | 1335        |
|    iterations           | 4           |
|    time_elapsed         | 12          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.012181164 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.7       |
|    explained_variance   | 0.65        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.416      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 2.7         |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 5 reward: 0.065724
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7426218   |
| time/                   |             |
|    fps                  | 1347        |
|    iterations           | 5           |
|    time_elapsed         | 15          |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.013972141 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.7       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.458      |
|    n_updates            | 1215        |
|    policy_gradient_loss | -0.0345     |
|    std                  | 2.71        |
|    value_loss           | 0.0794      |
-----------------------------------------
[ADAPTIVE] Episode 6 reward: 0.046310
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8336002   |
| time/                   |             |
|    fps                  | 1306        |
|    iterations           | 6           |
|    time_elapsed         | 18          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.020464005 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.8       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.453      |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0381     |
|    std                  | 2.73        |
|    value_loss           | 0.0914      |
-----------------------------------------
[ADAPTIVE] Episode 7 reward: 0.086479
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96656466  |
| time/                   |             |
|    fps                  | 1313        |
|    iterations           | 7           |
|    time_elapsed         | 21          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.015610911 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.8       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.474      |
|    n_updates            | 1245        |
|    policy_gradient_loss | -0.0396     |
|    std                  | 2.75        |
|    value_loss           | 0.0793      |
-----------------------------------------
[ADAPTIVE] Episode 8 reward: 0.000106
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98293823  |
| time/                   |             |
|    fps                  | 1301        |
|    iterations           | 8           |
|    time_elapsed         | 25          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.015538834 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.9       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.464      |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.0328     |
|    std                  | 2.76        |
|    value_loss           | 0.069       |
-----------------------------------------
[ADAPTIVE] Episode 9 reward: 0.069685
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1524526   |
| time/                   |             |
|    fps                  | 1310        |
|    iterations           | 9           |
|    time_elapsed         | 28          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.015828885 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.9       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.463      |
|    n_updates            | 1275        |
|    policy_gradient_loss | -0.0393     |
|    std                  | 2.77        |
|    value_loss           | 0.078       |
-----------------------------------------
[ADAPTIVE] Episode 10 reward: 0.007708
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0824707   |
| time/                   |             |
|    fps                  | 1288        |
|    iterations           | 10          |
|    time_elapsed         | 31          |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 0.017265957 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22         |
|    explained_variance   | 0.628       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.452      |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 2.79        |
|    value_loss           | 0.0836      |
-----------------------------------------
[ADAPTIVE] Episode 11 reward: -0.014539
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1893039   |
| time/                   |             |
|    fps                  | 1294        |
|    iterations           | 11          |
|    time_elapsed         | 34          |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.021542298 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22         |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.443      |
|    n_updates            | 1305        |
|    policy_gradient_loss | -0.033      |
|    std                  | 2.81        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 12 reward: -0.070326
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1348537   |
| time/                   |             |
|    fps                  | 1280        |
|    iterations           | 12          |
|    time_elapsed         | 38          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.012048994 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.1       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.464      |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.03       |
|    std                  | 2.82        |
|    value_loss           | 0.0722      |
-----------------------------------------
[ADAPTIVE] Episode 13 reward: -0.039777
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0850974  |
| time/                   |            |
|    fps                  | 1287       |
|    iterations           | 13         |
|    time_elapsed         | 41         |
|    total_timesteps      | 53248      |
| train/                  |            |
|    approx_kl            | 0.01477824 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.1      |
|    explained_variance   | 0.575      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.442     |
|    n_updates            | 1335       |
|    policy_gradient_loss | -0.038     |
|    std                  | 2.83       |
|    value_loss           | 0.12       |
----------------------------------------
[ADAPTIVE] Episode 14 reward: -0.021250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0364498   |
| time/                   |             |
|    fps                  | 1280        |
|    iterations           | 14          |
|    time_elapsed         | 44          |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.013529695 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.1       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.453      |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.0357     |
|    std                  | 2.84        |
|    value_loss           | 0.0744      |
-----------------------------------------
[ADAPTIVE] Episode 15 reward: 0.016976
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1043496   |
| time/                   |             |
|    fps                  | 1288        |
|    iterations           | 15          |
|    time_elapsed         | 47          |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.019558478 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.2       |
|    explained_variance   | 0.673       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.462      |
|    n_updates            | 1365        |
|    policy_gradient_loss | -0.0387     |
|    std                  | 2.85        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 16 reward: -0.020608
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1040657   |
| time/                   |             |
|    fps                  | 1277        |
|    iterations           | 16          |
|    time_elapsed         | 51          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.016971081 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.2       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.471      |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0356     |
|    std                  | 2.88        |
|    value_loss           | 0.0724      |
-----------------------------------------
[ADAPTIVE] Episode 17 reward: 0.052910
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0130414   |
| time/                   |             |
|    fps                  | 1284        |
|    iterations           | 17          |
|    time_elapsed         | 54          |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.017253805 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.3       |
|    explained_variance   | 0.618       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.467      |
|    n_updates            | 1395        |
|    policy_gradient_loss | -0.039      |
|    std                  | 2.88        |
|    value_loss           | 0.0941      |
-----------------------------------------
[ADAPTIVE] Episode 18 reward: 0.012119
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1000907  |
| time/                   |            |
|    fps                  | 1268       |
|    iterations           | 18         |
|    time_elapsed         | 58         |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.01577152 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.3      |
|    explained_variance   | 0.65       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.45      |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0382    |
|    std                  | 2.91       |
|    value_loss           | 0.118      |
----------------------------------------
[ADAPTIVE] Episode 19 reward: -0.018569
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.141419    |
| time/                   |             |
|    fps                  | 1265        |
|    iterations           | 19          |
|    time_elapsed         | 61          |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.022263343 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.4       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.469      |
|    n_updates            | 1425        |
|    policy_gradient_loss | -0.0403     |
|    std                  | 2.92        |
|    value_loss           | 0.0836      |
-----------------------------------------
[ADAPTIVE] Episode 20 reward: 0.062665
[ADAPTIVE] Mean reward over last 20 episodes: 0.017085
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2471058  |
| time/                   |            |
|    fps                  | 1271       |
|    iterations           | 20         |
|    time_elapsed         | 64         |
|    total_timesteps      | 81920      |
| train/                  |            |
|    approx_kl            | 0.02762944 |
|    clip_fraction        | 0.185      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.5      |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.44      |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.0364    |
|    std                  | 2.95       |
|    value_loss           | 0.121      |
----------------------------------------
[ADAPTIVE] Episode 21 reward: 0.063045
[ADAPTIVE] Mean reward over last 20 episodes: 0.018012
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0500066   |
| time/                   |             |
|    fps                  | 1264        |
|    iterations           | 21          |
|    time_elapsed         | 68          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.020719958 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.5       |
|    explained_variance   | 0.597       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.46       |
|    n_updates            | 1455        |
|    policy_gradient_loss | -0.0328     |
|    std                  | 2.96        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 22 reward: -0.026625
[ADAPTIVE] Mean reward over last 20 episodes: 0.017654
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0539143   |
| time/                   |             |
|    fps                  | 1269        |
|    iterations           | 22          |
|    time_elapsed         | 70          |
|    total_timesteps      | 90112       |
| train/                  |             |
|    approx_kl            | 0.022521704 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.662       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.477      |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0399     |
|    std                  | 2.97        |
|    value_loss           | 0.0841      |
-----------------------------------------
[ADAPTIVE] Episode 23 reward: -0.078636
[ADAPTIVE] Mean reward over last 20 episodes: 0.010810
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9087077   |
| time/                   |             |
|    fps                  | 1265        |
|    iterations           | 23          |
|    time_elapsed         | 74          |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.015333629 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.504       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.409      |
|    n_updates            | 1485        |
|    policy_gradient_loss | -0.028      |
|    std                  | 2.98        |
|    value_loss           | 0.19        |
-----------------------------------------
[ADAPTIVE] Episode 24 reward: -0.030189
[ADAPTIVE] Mean reward over last 20 episodes: 0.008160
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.86970985  |
| time/                   |             |
|    fps                  | 1267        |
|    iterations           | 24          |
|    time_elapsed         | 77          |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.022468707 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.48       |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0388     |
|    std                  | 3           |
|    value_loss           | 0.0911      |
-----------------------------------------
[ADAPTIVE] Episode 25 reward: -0.021722
[ADAPTIVE] Mean reward over last 20 episodes: 0.003788
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96936834  |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 25          |
|    time_elapsed         | 81          |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.018136121 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.7       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.458      |
|    n_updates            | 1515        |
|    policy_gradient_loss | -0.0373     |
|    std                  | 3.02        |
|    value_loss           | 0.0974      |
-----------------------------------------
[ADAPTIVE] Episode 26 reward: -0.025693
[ADAPTIVE] Mean reward over last 20 episodes: 0.000188
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9557821   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 26          |
|    time_elapsed         | 84          |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.020904409 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.7       |
|    explained_variance   | 0.676       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.481      |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.0395     |
|    std                  | 3.04        |
|    value_loss           | 0.0787      |
-----------------------------------------
[ADAPTIVE] Episode 27 reward: 0.059015
[ADAPTIVE] Mean reward over last 20 episodes: -0.001185
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9789924   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 27          |
|    time_elapsed         | 87          |
|    total_timesteps      | 110592      |
| train/                  |             |
|    approx_kl            | 0.014926747 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.8       |
|    explained_variance   | 0.715       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.463      |
|    n_updates            | 1545        |
|    policy_gradient_loss | -0.039      |
|    std                  | 3.06        |
|    value_loss           | 0.0832      |
-----------------------------------------
[ADAPTIVE] Episode 28 reward: 0.081077
[ADAPTIVE] Mean reward over last 20 episodes: 0.002863
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1057986   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 28          |
|    time_elapsed         | 91          |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.019043531 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.9       |
|    explained_variance   | 0.612       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.458      |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0332     |
|    std                  | 3.08        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 29 reward: 0.015579
[ADAPTIVE] Mean reward over last 20 episodes: 0.000158
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2044342   |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 29          |
|    time_elapsed         | 94          |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.015171533 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.9       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.483      |
|    n_updates            | 1575        |
|    policy_gradient_loss | -0.0327     |
|    std                  | 3.1         |
|    value_loss           | 0.0748      |
-----------------------------------------
[ADAPTIVE] Episode 30 reward: -0.025975
[ADAPTIVE] Mean reward over last 20 episodes: -0.001526
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 1: PhysicalPropertiesInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 1
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1818559   |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 30          |
|    time_elapsed         | 97          |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.013834863 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23         |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.477      |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.03       |
|    std                  | 3.1         |
|    value_loss           | 0.0825      |
-----------------------------------------
[ADAPTIVE] Episode 31 reward: -0.027172
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.04637     |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 31          |
|    time_elapsed         | 100         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.018948209 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -23         |
|    explained_variance   | 0.713       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.465      |
|    n_updates            | 1605        |
|    policy_gradient_loss | -0.0324     |
|    std                  | 3.12        |
|    value_loss           | 0.0978      |
-----------------------------------------
[ADAPTIVE] Episode 32 reward: 0.006730
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1293664   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 32          |
|    time_elapsed         | 104         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.022299714 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23         |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.481      |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.04       |
|    std                  | 3.13        |
|    value_loss           | 0.0687      |
-----------------------------------------
[ADAPTIVE] Episode 33 reward: 0.010987
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.142485    |
| time/                   |             |
|    fps                  | 1264        |
|    iterations           | 33          |
|    time_elapsed         | 106         |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.020014219 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.1       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.489      |
|    n_updates            | 1635        |
|    policy_gradient_loss | -0.0388     |
|    std                  | 3.15        |
|    value_loss           | 0.0603      |
-----------------------------------------
[ADAPTIVE] Episode 34 reward: 0.009330
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2184403  |
| time/                   |            |
|    fps                  | 1260       |
|    iterations           | 34         |
|    time_elapsed         | 110        |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.01234639 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -23.1      |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.459     |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.0308    |
|    std                  | 3.16       |
|    value_loss           | 0.115      |
----------------------------------------
[ADAPTIVE] Episode 35 reward: 0.000244
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1629131   |
| time/                   |             |
|    fps                  | 1265        |
|    iterations           | 35          |
|    time_elapsed         | 113         |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.015124595 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.1       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.492      |
|    n_updates            | 1665        |
|    policy_gradient_loss | -0.0366     |
|    std                  | 3.17        |
|    value_loss           | 0.0656      |
-----------------------------------------
[ADAPTIVE] Episode 36 reward: -0.029698
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2759223   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 36          |
|    time_elapsed         | 117         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.017738424 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.2       |
|    explained_variance   | 0.623       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.48       |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0362     |
|    std                  | 3.18        |
|    value_loss           | 0.0813      |
-----------------------------------------
[ADAPTIVE] Episode 37 reward: 0.025118
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3670114   |
| time/                   |             |
|    fps                  | 1262        |
|    iterations           | 37          |
|    time_elapsed         | 120         |
|    total_timesteps      | 151552      |
| train/                  |             |
|    approx_kl            | 0.015437935 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.2       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.493      |
|    n_updates            | 1695        |
|    policy_gradient_loss | -0.0339     |
|    std                  | 3.2         |
|    value_loss           | 0.051       |
-----------------------------------------
[ADAPTIVE] Episode 38 reward: 0.080619
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3540545   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 38          |
|    time_elapsed         | 123         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.017791621 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.3       |
|    explained_variance   | 0.702       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.48       |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.0355     |
|    std                  | 3.23        |
|    value_loss           | 0.0981      |
-----------------------------------------
[ADAPTIVE] Episode 39 reward: -0.002963
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4777844   |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 39          |
|    time_elapsed         | 126         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.017675124 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.4       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.504      |
|    n_updates            | 1725        |
|    policy_gradient_loss | -0.0375     |
|    std                  | 3.25        |
|    value_loss           | 0.046       |
-----------------------------------------
[ADAPTIVE] Episode 40 reward: 0.040556
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5964024   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 40          |
|    time_elapsed         | 130         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.014996907 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.4       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.487      |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0326     |
|    std                  | 3.26        |
|    value_loss           | 0.0514      |
-----------------------------------------
[ADAPTIVE] Episode 41 reward: -0.131929
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6566216   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 41          |
|    time_elapsed         | 133         |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.024925523 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.4       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.479      |
|    n_updates            | 1755        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 3.28        |
|    value_loss           | 0.0571      |
-----------------------------------------
[ADAPTIVE] Episode 42 reward: 0.000997
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.7491887   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 42          |
|    time_elapsed         | 136         |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 0.020713516 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.5       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.499      |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0353     |
|    std                  | 3.31        |
|    value_loss           | 0.0633      |
-----------------------------------------
[ADAPTIVE] Episode 43 reward: 0.025390
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9818729   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 43          |
|    time_elapsed         | 139         |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.019455742 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.6       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.488      |
|    n_updates            | 1785        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 3.32        |
|    value_loss           | 0.0506      |
-----------------------------------------
[ADAPTIVE] Episode 44 reward: 0.016379
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9339751   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 44          |
|    time_elapsed         | 143         |
|    total_timesteps      | 180224      |
| train/                  |             |
|    approx_kl            | 0.015691953 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.6       |
|    explained_variance   | 0.535       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.496      |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.0355     |
|    std                  | 3.35        |
|    value_loss           | 0.074       |
-----------------------------------------
[ADAPTIVE] Episode 45 reward: 0.019962
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9969368   |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 45          |
|    time_elapsed         | 146         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.017251281 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.7       |
|    explained_variance   | 0.667       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.505      |
|    n_updates            | 1815        |
|    policy_gradient_loss | -0.0408     |
|    std                  | 3.36        |
|    value_loss           | 0.0589      |
-----------------------------------------
[ADAPTIVE] Episode 46 reward: -0.023597
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9612846   |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 46          |
|    time_elapsed         | 149         |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.017033175 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.7       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.487      |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.0342     |
|    std                  | 3.38        |
|    value_loss           | 0.0833      |
-----------------------------------------
[ADAPTIVE] Episode 47 reward: 0.023995
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9437975   |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 47          |
|    time_elapsed         | 152         |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.019540064 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.8       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.478      |
|    n_updates            | 1845        |
|    policy_gradient_loss | -0.0391     |
|    std                  | 3.4         |
|    value_loss           | 0.0709      |
-----------------------------------------
[ADAPTIVE] Episode 48 reward: -0.025910
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9119887   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 48          |
|    time_elapsed         | 156         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.012432542 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.8       |
|    explained_variance   | 0.598       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.449      |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.028      |
|    std                  | 3.41        |
|    value_loss           | 0.126       |
-----------------------------------------
[ADAPTIVE] Episode 49 reward: -0.006448
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8889604   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 49          |
|    time_elapsed         | 159         |
|    total_timesteps      | 200704      |
| train/                  |             |
|    approx_kl            | 0.018509286 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.8       |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.506      |
|    n_updates            | 1875        |
|    policy_gradient_loss | -0.036      |
|    std                  | 3.43        |
|    value_loss           | 0.0629      |
-----------------------------------------
[ADAPTIVE] Episode 50 reward: -0.057215
[ADAPTIVE] Mean reward over last 20 episodes: -0.002231
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9764335   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 50          |
|    time_elapsed         | 162         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.021141889 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.9       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.503      |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0351     |
|    std                  | 3.45        |
|    value_loss           | 0.0902      |
-----------------------------------------
[ADAPTIVE] Episode 51 reward: 0.015502
[ADAPTIVE] Mean reward over last 20 episodes: -0.000098
[ADAPTIVE] Plateau counter: 1/10
[ADAPTIVE] Episode 52 reward: 0.011444
[ADAPTIVE] Mean reward over last 20 episodes: 0.000138
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.140235    |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 51          |
|    time_elapsed         | 166         |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.016060244 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.9       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.503      |
|    n_updates            | 1905        |
|    policy_gradient_loss | -0.032      |
|    std                  | 3.48        |
|    value_loss           | 0.0567      |
-----------------------------------------
[ADAPTIVE] Episode 53 reward: 0.034515
[ADAPTIVE] Mean reward over last 20 episodes: 0.001315
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.3454647   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 52          |
|    time_elapsed         | 169         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.019535467 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24         |
|    explained_variance   | 0.67        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.496      |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.0308     |
|    std                  | 3.49        |
|    value_loss           | 0.0964      |
-----------------------------------------
[ADAPTIVE] Episode 54 reward: 0.033488
[ADAPTIVE] Mean reward over last 20 episodes: 0.002523
[ADAPTIVE] Plateau counter: 4/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.4336567  |
| time/                   |            |
|    fps                  | 1257       |
|    iterations           | 53         |
|    time_elapsed         | 172        |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.01249425 |
|    clip_fraction        | 0.153      |
|    clip_range           | 0.2        |
|    entropy_loss         | -24        |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.512     |
|    n_updates            | 1935       |
|    policy_gradient_loss | -0.0301    |
|    std                  | 3.5        |
|    value_loss           | 0.0416     |
----------------------------------------
[ADAPTIVE] Episode 55 reward: -0.043990
[ADAPTIVE] Mean reward over last 20 episodes: 0.000311
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.3651447   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 54          |
|    time_elapsed         | 175         |
|    total_timesteps      | 221184      |
| train/                  |             |
|    approx_kl            | 0.021179479 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.1       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.502      |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0379     |
|    std                  | 3.52        |
|    value_loss           | 0.0619      |
-----------------------------------------
[ADAPTIVE] Episode 56 reward: 0.091596
[ADAPTIVE] Mean reward over last 20 episodes: 0.006376
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.3565423   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 55          |
|    time_elapsed         | 179         |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.014651973 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.1       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 1965        |
|    policy_gradient_loss | -0.036      |
|    std                  | 3.54        |
|    value_loss           | 0.055       |
-----------------------------------------
[ADAPTIVE] Episode 57 reward: -0.049349
[ADAPTIVE] Mean reward over last 20 episodes: 0.002652
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.286869    |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 56          |
|    time_elapsed         | 182         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.018659763 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.2       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.52       |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0358     |
|    std                  | 3.55        |
|    value_loss           | 0.0508      |
-----------------------------------------
[ADAPTIVE] Episode 58 reward: -0.170047
[ADAPTIVE] Mean reward over last 20 episodes: -0.009881
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2682765   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 57          |
|    time_elapsed         | 185         |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.013829544 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.2       |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.503      |
|    n_updates            | 1995        |
|    policy_gradient_loss | -0.0306     |
|    std                  | 3.57        |
|    value_loss           | 0.0519      |
-----------------------------------------
[ADAPTIVE] Episode 59 reward: 0.035814
[ADAPTIVE] Mean reward over last 20 episodes: -0.007942
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2427466   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 58          |
|    time_elapsed         | 188         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.019396672 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.2       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.0351     |
|    std                  | 3.59        |
|    value_loss           | 0.068       |
-----------------------------------------
[ADAPTIVE] Episode 60 reward: 0.083788
[ADAPTIVE] Mean reward over last 20 episodes: -0.005781
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 2: VisualInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 2
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.0375683  |
| time/                   |            |
|    fps                  | 1256       |
|    iterations           | 59         |
|    time_elapsed         | 192        |
|    total_timesteps      | 241664     |
| train/                  |            |
|    approx_kl            | 0.01807819 |
|    clip_fraction        | 0.189      |
|    clip_range           | 0.2        |
|    entropy_loss         | -24.3      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.48      |
|    n_updates            | 2025       |
|    policy_gradient_loss | -0.0333    |
|    std                  | 3.6        |
|    value_loss           | 0.0872     |
----------------------------------------
[ADAPTIVE] Episode 61 reward: -0.013884
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1491785   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 60          |
|    time_elapsed         | 195         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.020539675 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.3       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.513      |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.0369     |
|    std                  | 3.62        |
|    value_loss           | 0.0687      |
-----------------------------------------
[ADAPTIVE] Episode 62 reward: 0.008602
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0605228   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 61          |
|    time_elapsed         | 198         |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.015211884 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.4       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.511      |
|    n_updates            | 2055        |
|    policy_gradient_loss | -0.0309     |
|    std                  | 3.65        |
|    value_loss           | 0.0654      |
-----------------------------------------
[ADAPTIVE] Episode 63 reward: -0.000390
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0686016   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 62          |
|    time_elapsed         | 201         |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.018577468 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.4       |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.499      |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.03       |
|    std                  | 3.66        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 64 reward: 0.039358
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0566406   |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 63          |
|    time_elapsed         | 205         |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.018885078 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.5       |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.512      |
|    n_updates            | 2085        |
|    policy_gradient_loss | -0.0348     |
|    std                  | 3.68        |
|    value_loss           | 0.0616      |
-----------------------------------------
[ADAPTIVE] Episode 65 reward: 0.006452
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0359018   |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 64          |
|    time_elapsed         | 208         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.017259154 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.5       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.494      |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.0267     |
|    std                  | 3.71        |
|    value_loss           | 0.0788      |
-----------------------------------------
[ADAPTIVE] Episode 66 reward: -0.054680
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0889428   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 65          |
|    time_elapsed         | 211         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.015997278 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.6       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 2115        |
|    policy_gradient_loss | -0.0349     |
|    std                  | 3.73        |
|    value_loss           | 0.0529      |
-----------------------------------------
[ADAPTIVE] Episode 67 reward: -0.029486
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8742692   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 66          |
|    time_elapsed         | 214         |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 0.018718526 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.6       |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.512      |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0322     |
|    std                  | 3.76        |
|    value_loss           | 0.0707      |
-----------------------------------------
[ADAPTIVE] Episode 68 reward: 0.077507
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9585935   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 67          |
|    time_elapsed         | 218         |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.019881234 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.7       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.499      |
|    n_updates            | 2145        |
|    policy_gradient_loss | -0.0333     |
|    std                  | 3.78        |
|    value_loss           | 0.0879      |
-----------------------------------------
[ADAPTIVE] Episode 69 reward: 0.021770
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9679551   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 68          |
|    time_elapsed         | 221         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.013537236 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.7       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.516      |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 3.79        |
|    value_loss           | 0.0559      |
-----------------------------------------
[ADAPTIVE] Episode 70 reward: -0.054339
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.977674    |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 69          |
|    time_elapsed         | 225         |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.019342989 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.8       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.504      |
|    n_updates            | 2175        |
|    policy_gradient_loss | -0.0284     |
|    std                  | 3.82        |
|    value_loss           | 0.0672      |
-----------------------------------------
[ADAPTIVE] Episode 71 reward: 0.030548
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9604491   |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 70          |
|    time_elapsed         | 228         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.016988203 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.9       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.513      |
|    n_updates            | 2190        |
|    policy_gradient_loss | -0.034      |
|    std                  | 3.85        |
|    value_loss           | 0.0684      |
-----------------------------------------
[ADAPTIVE] Episode 72 reward: 0.014672
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0359278   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 71          |
|    time_elapsed         | 230         |
|    total_timesteps      | 290816      |
| train/                  |             |
|    approx_kl            | 0.010960259 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.9       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.53       |
|    n_updates            | 2205        |
|    policy_gradient_loss | -0.029      |
|    std                  | 3.87        |
|    value_loss           | 0.0335      |
-----------------------------------------
[ADAPTIVE] Episode 73 reward: -0.008748
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2437792   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 72          |
|    time_elapsed         | 233         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.016838465 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25         |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.514      |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 3.89        |
|    value_loss           | 0.0576      |
-----------------------------------------
[ADAPTIVE] Episode 74 reward: -0.000316
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.33816     |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 73          |
|    time_elapsed         | 237         |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.016019644 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25         |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.532      |
|    n_updates            | 2235        |
|    policy_gradient_loss | -0.0323     |
|    std                  | 3.92        |
|    value_loss           | 0.0415      |
-----------------------------------------
[ADAPTIVE] Episode 75 reward: -0.059783
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.289259    |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 74          |
|    time_elapsed         | 240         |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.015547612 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.1       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 3.93        |
|    value_loss           | 0.0566      |
-----------------------------------------
[ADAPTIVE] Episode 76 reward: 0.021881
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2648854   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 75          |
|    time_elapsed         | 243         |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.015987333 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.1       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.531      |
|    n_updates            | 2265        |
|    policy_gradient_loss | -0.0337     |
|    std                  | 3.96        |
|    value_loss           | 0.0541      |
-----------------------------------------
[ADAPTIVE] Episode 77 reward: 0.013682
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1401234   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 76          |
|    time_elapsed         | 246         |
|    total_timesteps      | 311296      |
| train/                  |             |
|    approx_kl            | 0.011982983 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.2       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.477      |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.0269     |
|    std                  | 3.97        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 78 reward: 0.058203
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 2.156193  |
| time/                   |           |
|    fps                  | 1261      |
|    iterations           | 77        |
|    time_elapsed         | 250       |
|    total_timesteps      | 315392    |
| train/                  |           |
|    approx_kl            | 0.0174316 |
|    clip_fraction        | 0.191     |
|    clip_range           | 0.2       |
|    entropy_loss         | -25.2     |
|    explained_variance   | 0.716     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.516    |
|    n_updates            | 2295      |
|    policy_gradient_loss | -0.0296   |
|    std                  | 3.99      |
|    value_loss           | 0.0781    |
---------------------------------------
[ADAPTIVE] Episode 79 reward: 0.001330
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1106293   |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 78          |
|    time_elapsed         | 253         |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.012667289 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.2       |
|    explained_variance   | 0.688       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.517      |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.0308     |
|    std                  | 4           |
|    value_loss           | 0.0688      |
-----------------------------------------
[ADAPTIVE] Episode 80 reward: -0.057436
[ADAPTIVE] Mean reward over last 20 episodes: 0.000747
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9781046   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 79          |
|    time_elapsed         | 256         |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.020065632 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.3       |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.513      |
|    n_updates            | 2325        |
|    policy_gradient_loss | -0.0296     |
|    std                  | 4.04        |
|    value_loss           | 0.0794      |
-----------------------------------------
[ADAPTIVE] Episode 81 reward: 0.003828
[ADAPTIVE] Mean reward over last 20 episodes: 0.001633
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9014658   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 80          |
|    time_elapsed         | 260         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.010825807 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.3       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.521      |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.0277     |
|    std                  | 4.06        |
|    value_loss           | 0.0677      |
-----------------------------------------
[ADAPTIVE] Episode 82 reward: -0.038987
[ADAPTIVE] Mean reward over last 20 episodes: -0.000747
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8696911   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 81          |
|    time_elapsed         | 263         |
|    total_timesteps      | 331776      |
| train/                  |             |
|    approx_kl            | 0.014495917 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.4       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.505      |
|    n_updates            | 2355        |
|    policy_gradient_loss | -0.0294     |
|    std                  | 4.09        |
|    value_loss           | 0.0933      |
-----------------------------------------
[ADAPTIVE] Episode 83 reward: -0.055597
[ADAPTIVE] Mean reward over last 20 episodes: -0.003507
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9310107   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 82          |
|    time_elapsed         | 266         |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.012116797 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.4       |
|    explained_variance   | 0.665       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.509      |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.0323     |
|    std                  | 4.1         |
|    value_loss           | 0.0896      |
-----------------------------------------
[ADAPTIVE] Episode 84 reward: -0.017365
[ADAPTIVE] Mean reward over last 20 episodes: -0.006343
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9926268   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 83          |
|    time_elapsed         | 269         |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.017100349 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.5       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.522      |
|    n_updates            | 2385        |
|    policy_gradient_loss | -0.0254     |
|    std                  | 4.13        |
|    value_loss           | 0.0686      |
-----------------------------------------
[ADAPTIVE] Episode 85 reward: -0.019918
[ADAPTIVE] Mean reward over last 20 episodes: -0.007662
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.041513    |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 84          |
|    time_elapsed         | 273         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.011596739 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.5       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.53       |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 4.15        |
|    value_loss           | 0.0515      |
-----------------------------------------
[ADAPTIVE] Episode 86 reward: 0.024465
[ADAPTIVE] Mean reward over last 20 episodes: -0.003705
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.105191    |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 85          |
|    time_elapsed         | 275         |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.013937154 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.6       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.541      |
|    n_updates            | 2415        |
|    policy_gradient_loss | -0.0305     |
|    std                  | 4.17        |
|    value_loss           | 0.0573      |
-----------------------------------------
[ADAPTIVE] Episode 87 reward: -0.089779
[ADAPTIVE] Mean reward over last 20 episodes: -0.006719
[ADAPTIVE] Plateau counter: 7/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.1957073  |
| time/                   |            |
|    fps                  | 1260       |
|    iterations           | 86         |
|    time_elapsed         | 279        |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.02076029 |
|    clip_fraction        | 0.209      |
|    clip_range           | 0.2        |
|    entropy_loss         | -25.7      |
|    explained_variance   | 0.618      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.534     |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.0343    |
|    std                  | 4.22       |
|    value_loss           | 0.0788     |
----------------------------------------
[ADAPTIVE] Episode 88 reward: -0.054571
[ADAPTIVE] Mean reward over last 20 episodes: -0.013323
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.215868    |
| time/                   |             |
|    fps                  | 1262        |
|    iterations           | 87          |
|    time_elapsed         | 282         |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.011997826 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.7       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.533      |
|    n_updates            | 2445        |
|    policy_gradient_loss | -0.0325     |
|    std                  | 4.24        |
|    value_loss           | 0.0651      |
-----------------------------------------
[ADAPTIVE] Episode 89 reward: 0.025696
[ADAPTIVE] Mean reward over last 20 episodes: -0.013127
[ADAPTIVE] Plateau counter: 9/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.2313995  |
| time/                   |            |
|    fps                  | 1262       |
|    iterations           | 88         |
|    time_elapsed         | 285        |
|    total_timesteps      | 360448     |
| train/                  |            |
|    approx_kl            | 0.02008802 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | -25.8      |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.536     |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0335    |
|    std                  | 4.27       |
|    value_loss           | 0.0515     |
----------------------------------------
[ADAPTIVE] Episode 90 reward: 0.058291
[ADAPTIVE] Mean reward over last 20 episodes: -0.007495
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 3: JointsInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 3
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2642615   |
| time/                   |             |
|    fps                  | 1263        |
|    iterations           | 89          |
|    time_elapsed         | 288         |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.011327001 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.8       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.534      |
|    n_updates            | 2475        |
|    policy_gradient_loss | -0.03       |
|    std                  | 4.28        |
|    value_loss           | 0.0492      |
-----------------------------------------
[ADAPTIVE] Episode 91 reward: 0.035196
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1400537   |
| time/                   |             |
|    fps                  | 1263        |
|    iterations           | 90          |
|    time_elapsed         | 291         |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.016546417 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.9       |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.544      |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.0332     |
|    std                  | 4.31        |
|    value_loss           | 0.0639      |
-----------------------------------------
[ADAPTIVE] Episode 92 reward: 0.009683
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0931766   |
| time/                   |             |
|    fps                  | 1266        |
|    iterations           | 91          |
|    time_elapsed         | 294         |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.012317695 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -26         |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.53       |
|    n_updates            | 2505        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 4.34        |
|    value_loss           | 0.0555      |
-----------------------------------------
[ADAPTIVE] Episode 93 reward: 0.021190
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1495125   |
| time/                   |             |
|    fps                  | 1265        |
|    iterations           | 92          |
|    time_elapsed         | 297         |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.010695658 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26         |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.539      |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.0293     |
|    std                  | 4.36        |
|    value_loss           | 0.0553      |
-----------------------------------------
[ADAPTIVE] Episode 94 reward: 0.000938
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 2.0985575    |
| time/                   |              |
|    fps                  | 1268         |
|    iterations           | 93           |
|    time_elapsed         | 300          |
|    total_timesteps      | 380928       |
| train/                  |              |
|    approx_kl            | 0.0153713105 |
|    clip_fraction        | 0.215        |
|    clip_range           | 0.2          |
|    entropy_loss         | -26          |
|    explained_variance   | 0.782        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.557       |
|    n_updates            | 2535         |
|    policy_gradient_loss | -0.0358      |
|    std                  | 4.39         |
|    value_loss           | 0.0397       |
------------------------------------------
[ADAPTIVE] Episode 95 reward: 0.003817
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1772313   |
| time/                   |             |
|    fps                  | 1267        |
|    iterations           | 94          |
|    time_elapsed         | 303         |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.011552697 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.1       |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.543      |
|    n_updates            | 2550        |
|    policy_gradient_loss | -0.0295     |
|    std                  | 4.4         |
|    value_loss           | 0.0454      |
-----------------------------------------
[ADAPTIVE] Episode 96 reward: 0.048696
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.103196    |
| time/                   |             |
|    fps                  | 1242        |
|    iterations           | 95          |
|    time_elapsed         | 313         |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.009786437 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.1       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.522      |
|    n_updates            | 2565        |
|    policy_gradient_loss | -0.0264     |
|    std                  | 4.41        |
|    value_loss           | 0.0728      |
-----------------------------------------
[ADAPTIVE] Episode 97 reward: -0.110806
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.173254    |
| time/                   |             |
|    fps                  | 1243        |
|    iterations           | 96          |
|    time_elapsed         | 316         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.012944983 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.1       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.55       |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 4.42        |
|    value_loss           | 0.0484      |
-----------------------------------------
[ADAPTIVE] Episode 98 reward: -0.022164
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1050613   |
| time/                   |             |
|    fps                  | 1245        |
|    iterations           | 97          |
|    time_elapsed         | 319         |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.016497536 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.2       |
|    explained_variance   | 0.643       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.509      |
|    n_updates            | 2595        |
|    policy_gradient_loss | -0.0265     |
|    std                  | 4.45        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 99 reward: -0.010072
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1458642   |
| time/                   |             |
|    fps                  | 1246        |
|    iterations           | 98          |
|    time_elapsed         | 321         |
|    total_timesteps      | 401408      |
| train/                  |             |
|    approx_kl            | 0.013045518 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.2       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.538      |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.0349     |
|    std                  | 4.48        |
|    value_loss           | 0.0714      |
-----------------------------------------
[ADAPTIVE] Episode 100 reward: 0.021868
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1711786   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 99          |
|    time_elapsed         | 325         |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.017513916 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.3       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.551      |
|    n_updates            | 2625        |
|    policy_gradient_loss | -0.0304     |
|    std                  | 4.51        |
|    value_loss           | 0.0414      |
-----------------------------------------
[ADAPTIVE] Episode 101 reward: 0.006178
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.1471288  |
| time/                   |            |
|    fps                  | 1251       |
|    iterations           | 100        |
|    time_elapsed         | 327        |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.01342684 |
|    clip_fraction        | 0.174      |
|    clip_range           | 0.2        |
|    entropy_loss         | -26.3      |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.538     |
|    n_updates            | 2640       |
|    policy_gradient_loss | -0.0329    |
|    std                  | 4.53       |
|    value_loss           | 0.0665     |
----------------------------------------
[ADAPTIVE] Episode 102 reward: 0.040206
[ADAPTIVE] Episode 103 reward: 0.081741
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1297715   |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 101         |
|    time_elapsed         | 341         |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.012694037 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.4       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 2655        |
|    policy_gradient_loss | -0.032      |
|    std                  | 4.56        |
|    value_loss           | 0.0939      |
-----------------------------------------
[ADAPTIVE] Episode 104 reward: -0.051800
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.2455726  |
| time/                   |            |
|    fps                  | 1212       |
|    iterations           | 102        |
|    time_elapsed         | 344        |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.01670741 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -26.4      |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.559     |
|    n_updates            | 2670       |
|    policy_gradient_loss | -0.0341    |
|    std                  | 4.58       |
|    value_loss           | 0.0607     |
----------------------------------------
[ADAPTIVE] Episode 105 reward: 0.028034
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 2.1112716    |
| time/                   |              |
|    fps                  | 1214         |
|    iterations           | 103          |
|    time_elapsed         | 347          |
|    total_timesteps      | 421888       |
| train/                  |              |
|    approx_kl            | 0.0131432535 |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.2          |
|    entropy_loss         | -26.5        |
|    explained_variance   | 0.712        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.551       |
|    n_updates            | 2685         |
|    policy_gradient_loss | -0.03        |
|    std                  | 4.6          |
|    value_loss           | 0.051        |
------------------------------------------
[ADAPTIVE] Episode 106 reward: 0.023947
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 2.2045789    |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 104          |
|    time_elapsed         | 350          |
|    total_timesteps      | 425984       |
| train/                  |              |
|    approx_kl            | 0.0138251325 |
|    clip_fraction        | 0.177        |
|    clip_range           | 0.2          |
|    entropy_loss         | -26.5        |
|    explained_variance   | 0.715        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.539       |
|    n_updates            | 2700         |
|    policy_gradient_loss | -0.0313      |
|    std                  | 4.63         |
|    value_loss           | 0.0668       |
------------------------------------------
[ADAPTIVE] Episode 107 reward: 0.008644
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0992467   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 105         |
|    time_elapsed         | 353         |
|    total_timesteps      | 430080      |
| train/                  |             |
|    approx_kl            | 0.011945583 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.6       |
|    explained_variance   | 0.705       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.547      |
|    n_updates            | 2715        |
|    policy_gradient_loss | -0.0272     |
|    std                  | 4.65        |
|    value_loss           | 0.0496      |
-----------------------------------------
[ADAPTIVE] Episode 108 reward: 0.029117
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1191812   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 106         |
|    time_elapsed         | 356         |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.018378865 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.6       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.536      |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.0322     |
|    std                  | 4.68        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 109 reward: -0.040202
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.046071    |
| time/                   |             |
|    fps                  | 1219        |
|    iterations           | 107         |
|    time_elapsed         | 359         |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.019339127 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.7       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.547      |
|    n_updates            | 2745        |
|    policy_gradient_loss | -0.0322     |
|    std                  | 4.73        |
|    value_loss           | 0.0607      |
-----------------------------------------
[ADAPTIVE] Episode 110 reward: 0.012717
[ADAPTIVE] Mean reward over last 20 episodes: 0.006847
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9865329   |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 108         |
|    time_elapsed         | 362         |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.019054737 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.7       |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.544      |
|    n_updates            | 2760        |
|    policy_gradient_loss | -0.0295     |
|    std                  | 4.74        |
|    value_loss           | 0.0944      |
-----------------------------------------
[ADAPTIVE] Episode 111 reward: 0.030798
[ADAPTIVE] Mean reward over last 20 episodes: 0.006627
[ADAPTIVE] Plateau counter: 1/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.139557   |
| time/                   |            |
|    fps                  | 1224       |
|    iterations           | 109        |
|    time_elapsed         | 364        |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.01653162 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -26.8      |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.556     |
|    n_updates            | 2775       |
|    policy_gradient_loss | -0.0297    |
|    std                  | 4.78       |
|    value_loss           | 0.0532     |
----------------------------------------
[ADAPTIVE] Episode 112 reward: 0.008932
[ADAPTIVE] Mean reward over last 20 episodes: 0.006589
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1740644   |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 110         |
|    time_elapsed         | 367         |
|    total_timesteps      | 450560      |
| train/                  |             |
|    approx_kl            | 0.011434214 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.9       |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.529      |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0274     |
|    std                  | 4.81        |
|    value_loss           | 0.0672      |
-----------------------------------------
[ADAPTIVE] Episode 113 reward: 0.015907
[ADAPTIVE] Mean reward over last 20 episodes: 0.006325
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2644594   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 111         |
|    time_elapsed         | 370         |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.015049081 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.9       |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.584      |
|    n_updates            | 2805        |
|    policy_gradient_loss | -0.0324     |
|    std                  | 4.83        |
|    value_loss           | 0.0368      |
-----------------------------------------
[ADAPTIVE] Episode 114 reward: 0.026436
[ADAPTIVE] Mean reward over last 20 episodes: 0.007600
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1577938   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 112         |
|    time_elapsed         | 372         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.018203314 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.9       |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.545      |
|    n_updates            | 2820        |
|    policy_gradient_loss | -0.0249     |
|    std                  | 4.86        |
|    value_loss           | 0.0769      |
-----------------------------------------
[ADAPTIVE] Episode 115 reward: 0.033750
[ADAPTIVE] Mean reward over last 20 episodes: 0.009096
[ADAPTIVE] Plateau counter: 5/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 2.220383     |
| time/                   |              |
|    fps                  | 1232         |
|    iterations           | 113          |
|    time_elapsed         | 375          |
|    total_timesteps      | 462848       |
| train/                  |              |
|    approx_kl            | 0.0109349545 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.2          |
|    entropy_loss         | -27          |
|    explained_variance   | 0.74         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.54        |
|    n_updates            | 2835         |
|    policy_gradient_loss | -0.0269      |
|    std                  | 4.87         |
|    value_loss           | 0.0953       |
------------------------------------------
[ADAPTIVE] Episode 116 reward: 0.065818
[ADAPTIVE] Mean reward over last 20 episodes: 0.009953
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1374338   |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 114         |
|    time_elapsed         | 378         |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.018378334 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -27         |
|    explained_variance   | 0.627       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.497      |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.0297     |
|    std                  | 4.89        |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 117 reward: -0.034297
[ADAPTIVE] Mean reward over last 20 episodes: 0.013778
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0546565   |
| time/                   |             |
|    fps                  | 1236        |
|    iterations           | 115         |
|    time_elapsed         | 380         |
|    total_timesteps      | 471040      |
| train/                  |             |
|    approx_kl            | 0.014527628 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.1       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.558      |
|    n_updates            | 2865        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 4.92        |
|    value_loss           | 0.0813      |
-----------------------------------------
[ADAPTIVE] Episode 118 reward: -0.049605
[ADAPTIVE] Mean reward over last 20 episodes: 0.012406
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.994963    |
| time/                   |             |
|    fps                  | 1237        |
|    iterations           | 116         |
|    time_elapsed         | 383         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.010646565 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.1       |
|    explained_variance   | 0.601       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.52       |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 4.93        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 119 reward: -0.016534
[ADAPTIVE] Mean reward over last 20 episodes: 0.012083
[ADAPTIVE] Plateau counter: 9/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.8326674    |
| time/                   |              |
|    fps                  | 1240         |
|    iterations           | 117          |
|    time_elapsed         | 386          |
|    total_timesteps      | 479232       |
| train/                  |              |
|    approx_kl            | 0.0111983325 |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.2          |
|    entropy_loss         | -27.1        |
|    explained_variance   | 0.609        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.558       |
|    n_updates            | 2895         |
|    policy_gradient_loss | -0.029       |
|    std                  | 4.96         |
|    value_loss           | 0.0801       |
------------------------------------------
[ADAPTIVE] Episode 120 reward: 0.028185
[ADAPTIVE] Mean reward over last 20 episodes: 0.012399
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 4: RigidPoseInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 4
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8688531   |
| time/                   |             |
|    fps                  | 1241        |
|    iterations           | 118         |
|    time_elapsed         | 389         |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.018753525 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.2       |
|    explained_variance   | 0.683       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.551      |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 5           |
|    value_loss           | 0.0891      |
-----------------------------------------
[ADAPTIVE] Episode 121 reward: -0.012398
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.904982    |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 119         |
|    time_elapsed         | 391         |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.017130017 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.3       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.559      |
|    n_updates            | 2925        |
|    policy_gradient_loss | -0.0319     |
|    std                  | 5.02        |
|    value_loss           | 0.0742      |
-----------------------------------------
[ADAPTIVE] Episode 122 reward: 0.014183
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.715021    |
| time/                   |             |
|    fps                  | 1245        |
|    iterations           | 120         |
|    time_elapsed         | 394         |
|    total_timesteps      | 491520      |
| train/                  |             |
|    approx_kl            | 0.018424323 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.3       |
|    explained_variance   | 0.615       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.548      |
|    n_updates            | 2940        |
|    policy_gradient_loss | -0.0294     |
|    std                  | 5.06        |
|    value_loss           | 0.0922      |
-----------------------------------------
[ADAPTIVE] Episode 123 reward: -0.009046
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3795706   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 121         |
|    time_elapsed         | 397         |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.015852066 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.4       |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.522      |
|    n_updates            | 2955        |
|    policy_gradient_loss | -0.0286     |
|    std                  | 5.09        |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 124 reward: 0.066557
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.152381    |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 122         |
|    time_elapsed         | 400         |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.015157491 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.4       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.544      |
|    n_updates            | 2970        |
|    policy_gradient_loss | -0.0328     |
|    std                  | 5.1         |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 125 reward: -0.025575
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 0.8895015 |
| time/                   |           |
|    fps                  | 1250      |
|    iterations           | 123       |
|    time_elapsed         | 403       |
|    total_timesteps      | 503808    |
| train/                  |           |
|    approx_kl            | 0.0171938 |
|    clip_fraction        | 0.194     |
|    clip_range           | 0.2       |
|    entropy_loss         | -27.4     |
|    explained_variance   | 0.591     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.537    |
|    n_updates            | 2985      |
|    policy_gradient_loss | -0.0292   |
|    std                  | 5.11      |
|    value_loss           | 0.114     |
---------------------------------------
[ADAPTIVE] Episode 126 reward: -0.029512
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.44870457  |
| time/                   |             |
|    fps                  | 1251        |
|    iterations           | 124         |
|    time_elapsed         | 405         |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.012129105 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.5       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.53       |
|    n_updates            | 3000        |
|    policy_gradient_loss | -0.0301     |
|    std                  | 5.13        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 127 reward: -0.055807
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.17399196  |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 125         |
|    time_elapsed         | 408         |
|    total_timesteps      | 512000      |
| train/                  |             |
|    approx_kl            | 0.014250448 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.5       |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.549      |
|    n_updates            | 3015        |
|    policy_gradient_loss | -0.0314     |
|    std                  | 5.16        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 128 reward: 0.067839
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.112482846 |
| time/                   |             |
|    fps                  | 1253        |
|    iterations           | 126         |
|    time_elapsed         | 411         |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.018848855 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.5       |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.554      |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.025      |
|    std                  | 5.18        |
|    value_loss           | 0.0997      |
-----------------------------------------
[ADAPTIVE] Episode 129 reward: -0.047334
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 251           |
|    ep_rew_mean          | -0.0054320693 |
| time/                   |               |
|    fps                  | 1254          |
|    iterations           | 127           |
|    time_elapsed         | 414           |
|    total_timesteps      | 520192        |
| train/                  |               |
|    approx_kl            | 0.014814488   |
|    clip_fraction        | 0.189         |
|    clip_range           | 0.2           |
|    entropy_loss         | -27.6         |
|    explained_variance   | 0.604         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.506        |
|    n_updates            | 3045          |
|    policy_gradient_loss | -0.0334       |
|    std                  | 5.2           |
|    value_loss           | 0.165         |
-------------------------------------------
[ADAPTIVE] Episode 130 reward: 0.046624
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 251           |
|    ep_rew_mean          | -0.0013028414 |
| time/                   |               |
|    fps                  | 1253          |
|    iterations           | 128           |
|    time_elapsed         | 418           |
|    total_timesteps      | 524288        |
| train/                  |               |
|    approx_kl            | 0.018403139   |
|    clip_fraction        | 0.195         |
|    clip_range           | 0.2           |
|    entropy_loss         | -27.6         |
|    explained_variance   | 0.555         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.542        |
|    n_updates            | 3060          |
|    policy_gradient_loss | -0.0315       |
|    std                  | 5.23          |
|    value_loss           | 0.139         |
-------------------------------------------
[ADAPTIVE] Episode 131 reward: -0.083239
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.09039588 |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 129         |
|    time_elapsed         | 420         |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.024106562 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.7       |
|    explained_variance   | 0.571       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.538      |
|    n_updates            | 3075        |
|    policy_gradient_loss | -0.0345     |
|    std                  | 5.26        |
|    value_loss           | 0.119       |
-----------------------------------------
[ADAPTIVE] Episode 132 reward: 0.029149
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.12572658  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 130         |
|    time_elapsed         | 424         |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.012042057 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.7       |
|    explained_variance   | 0.712       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.549      |
|    n_updates            | 3090        |
|    policy_gradient_loss | -0.0265     |
|    std                  | 5.29        |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 133 reward: 0.014267
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 251           |
|    ep_rew_mean          | -0.0063703563 |
| time/                   |               |
|    fps                  | 1256          |
|    iterations           | 131           |
|    time_elapsed         | 427           |
|    total_timesteps      | 536576        |
| train/                  |               |
|    approx_kl            | 0.01778683    |
|    clip_fraction        | 0.206         |
|    clip_range           | 0.2           |
|    entropy_loss         | -27.8         |
|    explained_variance   | 0.777         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.572        |
|    n_updates            | 3105          |
|    policy_gradient_loss | -0.0358       |
|    std                  | 5.33          |
|    value_loss           | 0.0866        |
-------------------------------------------
[ADAPTIVE] Episode 134 reward: 0.057124
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | -0.065179855 |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 132          |
|    time_elapsed         | 430          |
|    total_timesteps      | 540672       |
| train/                  |              |
|    approx_kl            | 0.021603836  |
|    clip_fraction        | 0.244        |
|    clip_range           | 0.2          |
|    entropy_loss         | -27.8        |
|    explained_variance   | 0.683        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.552       |
|    n_updates            | 3120         |
|    policy_gradient_loss | -0.0331      |
|    std                  | 5.36         |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 135 reward: 0.010935
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.06357003 |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 133         |
|    time_elapsed         | 432         |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.01590585  |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.9       |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.552      |
|    n_updates            | 3135        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 5.42        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 136 reward: 0.050024
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.045901556 |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 134         |
|    time_elapsed         | 435         |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.012791481 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28         |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.567      |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.031      |
|    std                  | 5.44        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 137 reward: -0.020267
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.13107926 |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 135         |
|    time_elapsed         | 438         |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.015400309 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28         |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.543      |
|    n_updates            | 3165        |
|    policy_gradient_loss | -0.0289     |
|    std                  | 5.47        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 138 reward: -0.099652
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.26974657 |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 136         |
|    time_elapsed         | 441         |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.015650038 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.1       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.556      |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.031      |
|    std                  | 5.49        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 139 reward: 0.050556
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.38591722 |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 137         |
|    time_elapsed         | 445         |
|    total_timesteps      | 561152      |
| train/                  |             |
|    approx_kl            | 0.017017229 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.1       |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.573      |
|    n_updates            | 3195        |
|    policy_gradient_loss | -0.0288     |
|    std                  | 5.52        |
|    value_loss           | 0.0755      |
-----------------------------------------
[ADAPTIVE] Episode 140 reward: 0.057838
[ADAPTIVE] Mean reward over last 20 episodes: 0.004113
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.4549537  |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 138         |
|    time_elapsed         | 448         |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.013249424 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.2       |
|    explained_variance   | 0.621       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.558      |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.0276     |
|    std                  | 5.55        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 141 reward: 0.037370
[ADAPTIVE] Mean reward over last 20 episodes: 0.006602
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.47964036 |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 139         |
|    time_elapsed         | 452         |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.016470613 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.2       |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.534      |
|    n_updates            | 3225        |
|    policy_gradient_loss | -0.0241     |
|    std                  | 5.58        |
|    value_loss           | 0.175       |
-----------------------------------------
[ADAPTIVE] Episode 142 reward: 0.126516
[ADAPTIVE] Mean reward over last 20 episodes: 0.012218
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.5386811  |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 140         |
|    time_elapsed         | 455         |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.014755037 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.3       |
|    explained_variance   | 0.669       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.58       |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.0284     |
|    std                  | 5.63        |
|    value_loss           | 0.0997      |
-----------------------------------------
[ADAPTIVE] Episode 143 reward: 0.039301
[ADAPTIVE] Mean reward over last 20 episodes: 0.014636
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.4494196  |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 141         |
|    time_elapsed         | 458         |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.026333112 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.3       |
|    explained_variance   | 0.592       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.561      |
|    n_updates            | 3255        |
|    policy_gradient_loss | -0.0308     |
|    std                  | 5.67        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 144 reward: -0.020142
[ADAPTIVE] Mean reward over last 20 episodes: 0.010301
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.40858966 |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 142         |
|    time_elapsed         | 462         |
|    total_timesteps      | 581632      |
| train/                  |             |
|    approx_kl            | 0.013152582 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.4       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.556      |
|    n_updates            | 3270        |
|    policy_gradient_loss | -0.0281     |
|    std                  | 5.68        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 145 reward: -0.108135
[ADAPTIVE] Mean reward over last 20 episodes: 0.006173
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.2617768  |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 143         |
|    time_elapsed         | 465         |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.013430664 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.4       |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.563      |
|    n_updates            | 3285        |
|    policy_gradient_loss | -0.028      |
|    std                  | 5.71        |
|    value_loss           | 0.112       |
-----------------------------------------
[ADAPTIVE] Episode 146 reward: 0.136290
[ADAPTIVE] Mean reward over last 20 episodes: 0.014463
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.18347469 |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 144         |
|    time_elapsed         | 469         |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.013076326 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.5       |
|    explained_variance   | 0.59        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.529      |
|    n_updates            | 3300        |
|    policy_gradient_loss | -0.0307     |
|    std                  | 5.74        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 147 reward: -0.019104
[ADAPTIVE] Mean reward over last 20 episodes: 0.016298
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.10533465 |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 145         |
|    time_elapsed         | 472         |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.019765697 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.5       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.547      |
|    n_updates            | 3315        |
|    policy_gradient_loss | -0.0279     |
|    std                  | 5.77        |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 148 reward: -0.001697
[ADAPTIVE] Mean reward over last 20 episodes: 0.012821
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.11033194 |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 146         |
|    time_elapsed         | 475         |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.014323939 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.6       |
|    explained_variance   | 0.676       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.574      |
|    n_updates            | 3330        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 5.8         |
|    value_loss           | 0.112       |
-----------------------------------------
[ADAPTIVE] Episode 149 reward: -0.028539
[ADAPTIVE] Mean reward over last 20 episodes: 0.013761
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.27252686 |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 147         |
|    time_elapsed         | 478         |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.019662661 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.6       |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.54       |
|    n_updates            | 3345        |
|    policy_gradient_loss | -0.0286     |
|    std                  | 5.84        |
|    value_loss           | 0.129       |
-----------------------------------------
[ADAPTIVE] Episode 150 reward: 0.044162
[ADAPTIVE] Mean reward over last 20 episodes: 0.013638
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.27719793 |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 148         |
|    time_elapsed         | 481         |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.017161965 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.7       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.57       |
|    n_updates            | 3360        |
|    policy_gradient_loss | -0.0278     |
|    std                  | 5.89        |
|    value_loss           | 0.1         |
-----------------------------------------
[ADAPTIVE] Episode 151 reward: 0.036984
[ADAPTIVE] Mean reward over last 20 episodes: 0.019649
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.49250802 |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 149         |
|    time_elapsed         | 484         |
|    total_timesteps      | 610304      |
| train/                  |             |
|    approx_kl            | 0.017596569 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.7       |
|    explained_variance   | 0.546       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.535      |
|    n_updates            | 3375        |
|    policy_gradient_loss | -0.0264     |
|    std                  | 5.92        |
|    value_loss           | 0.171       |
-----------------------------------------
[ADAPTIVE] Episode 152 reward: 0.083350
[ADAPTIVE] Mean reward over last 20 episodes: 0.022359
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.50741595 |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 150         |
|    time_elapsed         | 487         |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.011654488 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.8       |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.557      |
|    n_updates            | 3390        |
|    policy_gradient_loss | -0.0256     |
|    std                  | 5.92        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 153 reward: 0.024841
[ADAPTIVE] Mean reward over last 20 episodes: 0.022888
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 5: RandomInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 154 reward: 0.115502
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.25540185 |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 151         |
|    time_elapsed         | 491         |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.011575777 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.8       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.578      |
|    n_updates            | 3405        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 5.95        |
|    value_loss           | 0.0877      |
-----------------------------------------
[ADAPTIVE] Episode 155 reward: 0.030776
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.091257475 |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 152         |
|    time_elapsed         | 494         |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.015399637 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.8       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.561      |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.0252     |
|    std                  | 5.96        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 156 reward: -0.016838
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.33839202  |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 153         |
|    time_elapsed         | 498         |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.013680769 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.8       |
|    explained_variance   | 0.565       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.536      |
|    n_updates            | 3435        |
|    policy_gradient_loss | -0.0247     |
|    std                  | 5.99        |
|    value_loss           | 0.173       |
-----------------------------------------
[ADAPTIVE] Episode 157 reward: -0.176065
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.3687432   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 154         |
|    time_elapsed         | 501         |
|    total_timesteps      | 630784      |
| train/                  |             |
|    approx_kl            | 0.021073082 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.9       |
|    explained_variance   | 0.371       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.519      |
|    n_updates            | 3450        |
|    policy_gradient_loss | -0.0281     |
|    std                  | 6.02        |
|    value_loss           | 0.253       |
-----------------------------------------
[ADAPTIVE] Episode 158 reward: 0.133772
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4536893   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 155         |
|    time_elapsed         | 504         |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.019058956 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.9       |
|    explained_variance   | 0.345       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.439      |
|    n_updates            | 3465        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 6.06        |
|    value_loss           | 0.511       |
-----------------------------------------
[ADAPTIVE] Episode 159 reward: 0.047071
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.6736095  |
| time/                   |            |
|    fps                  | 1259       |
|    iterations           | 156        |
|    time_elapsed         | 507        |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.01611262 |
|    clip_fraction        | 0.142      |
|    clip_range           | 0.2        |
|    entropy_loss         | -29        |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.552     |
|    n_updates            | 3480       |
|    policy_gradient_loss | -0.0257    |
|    std                  | 6.05       |
|    value_loss           | 0.122      |
----------------------------------------
[ADAPTIVE] Episode 160 reward: 0.000304
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.64549726  |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 157         |
|    time_elapsed         | 510         |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.021050975 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29         |
|    explained_variance   | -0.0941     |
|    learning_rate        | 0.00025     |
|    loss                 | -0.393      |
|    n_updates            | 3495        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 6.1         |
|    value_loss           | 0.341       |
-----------------------------------------
[ADAPTIVE] Episode 161 reward: -0.027506
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7672554   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 158         |
|    time_elapsed         | 513         |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.016175926 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29         |
|    explained_variance   | 0.292       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.528      |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.0252     |
|    std                  | 6.12        |
|    value_loss           | 0.298       |
-----------------------------------------
[ADAPTIVE] Episode 162 reward: -0.006721
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.80290633  |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 159         |
|    time_elapsed         | 517         |
|    total_timesteps      | 651264      |
| train/                  |             |
|    approx_kl            | 0.011339006 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.1       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.576      |
|    n_updates            | 3525        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 6.14        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 163 reward: 0.012387
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8951719   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 160         |
|    time_elapsed         | 519         |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.020638209 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.1       |
|    explained_variance   | 0.374       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.558      |
|    n_updates            | 3540        |
|    policy_gradient_loss | -0.0299     |
|    std                  | 6.2         |
|    value_loss           | 0.247       |
-----------------------------------------
[ADAPTIVE] Episode 164 reward: 0.002808
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9580836   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 161         |
|    time_elapsed         | 523         |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.016889118 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.2       |
|    explained_variance   | 0.517       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.552      |
|    n_updates            | 3555        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 6.24        |
|    value_loss           | 0.171       |
-----------------------------------------
[ADAPTIVE] Episode 165 reward: 0.042560
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.87196374 |
| time/                   |            |
|    fps                  | 1261       |
|    iterations           | 162        |
|    time_elapsed         | 525        |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.01662957 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -29.3      |
|    explained_variance   | 0.179      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.302     |
|    n_updates            | 3570       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 6.26       |
|    value_loss           | 1.02       |
----------------------------------------
[ADAPTIVE] Episode 166 reward: 0.053020
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8106869   |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 163         |
|    time_elapsed         | 529         |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.014630845 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.3       |
|    explained_variance   | 0.573       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.569      |
|    n_updates            | 3585        |
|    policy_gradient_loss | -0.0274     |
|    std                  | 6.28        |
|    value_loss           | 0.168       |
-----------------------------------------
[ADAPTIVE] Episode 167 reward: -0.025901
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.87774336  |
| time/                   |             |
|    fps                  | 1262        |
|    iterations           | 164         |
|    time_elapsed         | 531         |
|    total_timesteps      | 671744      |
| train/                  |             |
|    approx_kl            | 0.013212002 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.3       |
|    explained_variance   | 0.614       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.573      |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 6.32        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 168 reward: 0.016822
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.82658434  |
| time/                   |             |
|    fps                  | 1263        |
|    iterations           | 165         |
|    time_elapsed         | 535         |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.014969373 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.4       |
|    explained_variance   | 0.384       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.551      |
|    n_updates            | 3615        |
|    policy_gradient_loss | -0.0265     |
|    std                  | 6.38        |
|    value_loss           | 0.205       |
-----------------------------------------
[ADAPTIVE] Episode 169 reward: 0.053556
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0228117   |
| time/                   |             |
|    fps                  | 1264        |
|    iterations           | 166         |
|    time_elapsed         | 537         |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.018024592 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.5       |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.49       |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.028      |
|    std                  | 6.42        |
|    value_loss           | 0.336       |
-----------------------------------------
[ADAPTIVE] Episode 170 reward: 0.084515
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0256567   |
| time/                   |             |
|    fps                  | 1264        |
|    iterations           | 167         |
|    time_elapsed         | 541         |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.017785426 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.5       |
|    explained_variance   | 0.24        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.352      |
|    n_updates            | 3645        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 6.47        |
|    value_loss           | 0.55        |
-----------------------------------------
[ADAPTIVE] Episode 171 reward: 0.022448
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1524917   |
| time/                   |             |
|    fps                  | 1264        |
|    iterations           | 168         |
|    time_elapsed         | 544         |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.017073173 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.6       |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.495      |
|    n_updates            | 3660        |
|    policy_gradient_loss | -0.0316     |
|    std                  | 6.52        |
|    value_loss           | 0.362       |
-----------------------------------------
[ADAPTIVE] Episode 172 reward: -0.053940
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2747586   |
| time/                   |             |
|    fps                  | 1265        |
|    iterations           | 169         |
|    time_elapsed         | 547         |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.015030209 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.7       |
|    explained_variance   | 0.31        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.54       |
|    n_updates            | 3675        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 6.55        |
|    value_loss           | 0.205       |
-----------------------------------------
[ADAPTIVE] Episode 173 reward: 0.066534
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1870022   |
| time/                   |             |
|    fps                  | 1266        |
|    iterations           | 170         |
|    time_elapsed         | 550         |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.013398621 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.7       |
|    explained_variance   | 0.452       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.495      |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 6.59        |
|    value_loss           | 0.404       |
-----------------------------------------
[ADAPTIVE] Episode 174 reward: 0.028592
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0684236   |
| time/                   |             |
|    fps                  | 1266        |
|    iterations           | 171         |
|    time_elapsed         | 553         |
|    total_timesteps      | 700416      |
| train/                  |             |
|    approx_kl            | 0.018278476 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.8       |
|    explained_variance   | 0.283       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.482      |
|    n_updates            | 3705        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 6.65        |
|    value_loss           | 0.417       |
-----------------------------------------
[ADAPTIVE] Episode 175 reward: -0.015754
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.87643236  |
| time/                   |             |
|    fps                  | 1267        |
|    iterations           | 172         |
|    time_elapsed         | 555         |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.018401362 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.8       |
|    explained_variance   | 0.322       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.421      |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.025      |
|    std                  | 6.7         |
|    value_loss           | 0.609       |
-----------------------------------------
[ADAPTIVE] Episode 176 reward: -0.040017
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9920649   |
| time/                   |             |
|    fps                  | 1268        |
|    iterations           | 173         |
|    time_elapsed         | 558         |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.022792052 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.9       |
|    explained_variance   | 0.335       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.481      |
|    n_updates            | 3735        |
|    policy_gradient_loss | -0.0287     |
|    std                  | 6.75        |
|    value_loss           | 0.376       |
-----------------------------------------
[ADAPTIVE] Episode 177 reward: -0.041286
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.76399934 |
| time/                   |            |
|    fps                  | 1269       |
|    iterations           | 174        |
|    time_elapsed         | 561        |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.0180123  |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -30        |
|    explained_variance   | 0.466      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.555     |
|    n_updates            | 3750       |
|    policy_gradient_loss | -0.0265    |
|    std                  | 6.78       |
|    value_loss           | 0.224      |
----------------------------------------
[ADAPTIVE] Episode 178 reward: 0.047433
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67480105  |
| time/                   |             |
|    fps                  | 1269        |
|    iterations           | 175         |
|    time_elapsed         | 564         |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.015292734 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30         |
|    explained_variance   | 0.46        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.49       |
|    n_updates            | 3765        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 6.8         |
|    value_loss           | 0.305       |
-----------------------------------------
[ADAPTIVE] Episode 179 reward: -0.056359
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7122876   |
| time/                   |             |
|    fps                  | 1270        |
|    iterations           | 176         |
|    time_elapsed         | 567         |
|    total_timesteps      | 720896      |
| train/                  |             |
|    approx_kl            | 0.015829392 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30         |
|    explained_variance   | 0.344       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.548      |
|    n_updates            | 3780        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 6.83        |
|    value_loss           | 0.313       |
-----------------------------------------
[ADAPTIVE] Episode 180 reward: -0.041260
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.72593     |
| time/                   |             |
|    fps                  | 1271        |
|    iterations           | 177         |
|    time_elapsed         | 570         |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.013214672 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30         |
|    explained_variance   | 0.38        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.555      |
|    n_updates            | 3795        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 6.84        |
|    value_loss           | 0.224       |
-----------------------------------------
[ADAPTIVE] Episode 181 reward: 0.050312
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.8427098  |
| time/                   |            |
|    fps                  | 1271       |
|    iterations           | 178        |
|    time_elapsed         | 573        |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.01838062 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.1      |
|    explained_variance   | 0.39       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.548     |
|    n_updates            | 3810       |
|    policy_gradient_loss | -0.0268    |
|    std                  | 6.89       |
|    value_loss           | 0.283      |
----------------------------------------
[ADAPTIVE] Episode 182 reward: -0.021545
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.8118927  |
| time/                   |            |
|    fps                  | 1272       |
|    iterations           | 179        |
|    time_elapsed         | 576        |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.01849674 |
|    clip_fraction        | 0.18       |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.2      |
|    explained_variance   | 0.32       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.47      |
|    n_updates            | 3825       |
|    policy_gradient_loss | -0.0223    |
|    std                  | 6.94       |
|    value_loss           | 0.367      |
----------------------------------------
[ADAPTIVE] Episode 183 reward: 0.001607
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.59830856  |
| time/                   |             |
|    fps                  | 1272        |
|    iterations           | 180         |
|    time_elapsed         | 579         |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.020764608 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.2       |
|    explained_variance   | 0.542       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.595      |
|    n_updates            | 3840        |
|    policy_gradient_loss | -0.0273     |
|    std                  | 7           |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 184 reward: 0.021220
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7067291   |
| time/                   |             |
|    fps                  | 1273        |
|    iterations           | 181         |
|    time_elapsed         | 582         |
|    total_timesteps      | 741376      |
| train/                  |             |
|    approx_kl            | 0.016914584 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.3       |
|    explained_variance   | 0.14        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.37       |
|    n_updates            | 3855        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 7.03        |
|    value_loss           | 0.513       |
-----------------------------------------
[ADAPTIVE] Episode 185 reward: -0.058663
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6242975   |
| time/                   |             |
|    fps                  | 1274        |
|    iterations           | 182         |
|    time_elapsed         | 584         |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.016308237 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.3       |
|    explained_variance   | 0.18        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.494      |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 7.08        |
|    value_loss           | 0.334       |
-----------------------------------------
[ADAPTIVE] Episode 186 reward: 0.078378
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67843515  |
| time/                   |             |
|    fps                  | 1275        |
|    iterations           | 183         |
|    time_elapsed         | 587         |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.015935712 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.4       |
|    explained_variance   | 0.56        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.587      |
|    n_updates            | 3885        |
|    policy_gradient_loss | -0.0319     |
|    std                  | 7.1         |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 187 reward: 0.020827
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.51548064  |
| time/                   |             |
|    fps                  | 1276        |
|    iterations           | 184         |
|    time_elapsed         | 590         |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.017824233 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.4       |
|    explained_variance   | 0.412       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.586      |
|    n_updates            | 3900        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 7.15        |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 188 reward: 0.059762
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.58351773  |
| time/                   |             |
|    fps                  | 1276        |
|    iterations           | 185         |
|    time_elapsed         | 593         |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.016262481 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.5       |
|    explained_variance   | 0.326       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.562      |
|    n_updates            | 3915        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 7.19        |
|    value_loss           | 0.335       |
-----------------------------------------
[ADAPTIVE] Episode 189 reward: 0.008899
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8189724   |
| time/                   |             |
|    fps                  | 1277        |
|    iterations           | 186         |
|    time_elapsed         | 596         |
|    total_timesteps      | 761856      |
| train/                  |             |
|    approx_kl            | 0.017938834 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.5       |
|    explained_variance   | 0.387       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.429      |
|    n_updates            | 3930        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 7.22        |
|    value_loss           | 0.367       |
-----------------------------------------
[ADAPTIVE] Episode 190 reward: 0.061352
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9035331   |
| time/                   |             |
|    fps                  | 1279        |
|    iterations           | 187         |
|    time_elapsed         | 598         |
|    total_timesteps      | 765952      |
| train/                  |             |
|    approx_kl            | 0.013400197 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.6       |
|    explained_variance   | 0.472       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.576      |
|    n_updates            | 3945        |
|    policy_gradient_loss | -0.026      |
|    std                  | 7.25        |
|    value_loss           | 0.212       |
-----------------------------------------
[ADAPTIVE] Episode 191 reward: -0.056795
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.9064609  |
| time/                   |            |
|    fps                  | 1280       |
|    iterations           | 188        |
|    time_elapsed         | 601        |
|    total_timesteps      | 770048     |
| train/                  |            |
|    approx_kl            | 0.01636665 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.6      |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.563     |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.0265    |
|    std                  | 7.3        |
|    value_loss           | 0.236      |
----------------------------------------
[ADAPTIVE] Episode 192 reward: -0.103321
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9933461    |
| time/                   |              |
|    fps                  | 1281         |
|    iterations           | 189          |
|    time_elapsed         | 603          |
|    total_timesteps      | 774144       |
| train/                  |              |
|    approx_kl            | 0.0144309085 |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.2          |
|    entropy_loss         | -30.7        |
|    explained_variance   | 0.572        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.623       |
|    n_updates            | 3975         |
|    policy_gradient_loss | -0.0288      |
|    std                  | 7.32         |
|    value_loss           | 0.0936       |
------------------------------------------
[ADAPTIVE] Episode 193 reward: 0.074582
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0571961   |
| time/                   |             |
|    fps                  | 1282        |
|    iterations           | 190         |
|    time_elapsed         | 606         |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.019693678 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.7       |
|    explained_variance   | 0.324       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.477      |
|    n_updates            | 3990        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 7.36        |
|    value_loss           | 0.433       |
-----------------------------------------
[ADAPTIVE] Episode 194 reward: -0.034889
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0751362  |
| time/                   |            |
|    fps                  | 1283       |
|    iterations           | 191        |
|    time_elapsed         | 609        |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.01817067 |
|    clip_fraction        | 0.212      |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.7      |
|    explained_variance   | 0.411      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.554     |
|    n_updates            | 4005       |
|    policy_gradient_loss | -0.029     |
|    std                  | 7.4        |
|    value_loss           | 0.238      |
----------------------------------------
[ADAPTIVE] Episode 195 reward: -0.005917
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8972672   |
| time/                   |             |
|    fps                  | 1283        |
|    iterations           | 192         |
|    time_elapsed         | 612         |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.018996544 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.8       |
|    explained_variance   | 0.5         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.609      |
|    n_updates            | 4020        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 7.44        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 196 reward: 0.054358
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.75293136  |
| time/                   |             |
|    fps                  | 1284        |
|    iterations           | 193         |
|    time_elapsed         | 615         |
|    total_timesteps      | 790528      |
| train/                  |             |
|    approx_kl            | 0.015266327 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.9       |
|    explained_variance   | 0.625       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.622      |
|    n_updates            | 4035        |
|    policy_gradient_loss | -0.0295     |
|    std                  | 7.5         |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 197 reward: 0.082938
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.719273    |
| time/                   |             |
|    fps                  | 1285        |
|    iterations           | 194         |
|    time_elapsed         | 618         |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.015902558 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.9       |
|    explained_variance   | 0.4         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.577      |
|    n_updates            | 4050        |
|    policy_gradient_loss | -0.0245     |
|    std                  | 7.56        |
|    value_loss           | 0.259       |
-----------------------------------------
[ADAPTIVE] Episode 198 reward: -0.060144
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4888601    |
| time/                   |              |
|    fps                  | 1286         |
|    iterations           | 195          |
|    time_elapsed         | 620          |
|    total_timesteps      | 798720       |
| train/                  |              |
|    approx_kl            | 0.0153936455 |
|    clip_fraction        | 0.177        |
|    clip_range           | 0.2          |
|    entropy_loss         | -31          |
|    explained_variance   | 0.602        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.612       |
|    n_updates            | 4065         |
|    policy_gradient_loss | -0.0301      |
|    std                  | 7.62         |
|    value_loss           | 0.135        |
------------------------------------------
[ADAPTIVE] Episode 199 reward: -0.037079
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.39467523  |
| time/                   |             |
|    fps                  | 1287        |
|    iterations           | 196         |
|    time_elapsed         | 623         |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.012512383 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.1       |
|    explained_variance   | 0.531       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.621      |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.0263     |
|    std                  | 7.67        |
|    value_loss           | 0.156       |
-----------------------------------------
[ADAPTIVE] Episode 200 reward: 0.044294
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.42680076  |
| time/                   |             |
|    fps                  | 1287        |
|    iterations           | 197         |
|    time_elapsed         | 626         |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.013944373 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.1       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.485      |
|    n_updates            | 4095        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 7.7         |
|    value_loss           | 0.268       |
-----------------------------------------
[ADAPTIVE] Episode 201 reward: 0.028485
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.64392835  |
| time/                   |             |
|    fps                  | 1288        |
|    iterations           | 198         |
|    time_elapsed         | 629         |
|    total_timesteps      | 811008      |
| train/                  |             |
|    approx_kl            | 0.012892248 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.1       |
|    explained_variance   | 0.359       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.581      |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.0252     |
|    std                  | 7.74        |
|    value_loss           | 0.233       |
-----------------------------------------
[ADAPTIVE] Episode 202 reward: 0.001137
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.68382096 |
| time/                   |            |
|    fps                  | 1289       |
|    iterations           | 199        |
|    time_elapsed         | 632        |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.01620066 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -31.2      |
|    explained_variance   | 0.18       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.45      |
|    n_updates            | 4125       |
|    policy_gradient_loss | -0.0239    |
|    std                  | 7.75       |
|    value_loss           | 0.605      |
----------------------------------------
[ADAPTIVE] Episode 203 reward: 0.095408
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.51607776  |
| time/                   |             |
|    fps                  | 1290        |
|    iterations           | 200         |
|    time_elapsed         | 634         |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.016881693 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.2       |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.524      |
|    n_updates            | 4140        |
|    policy_gradient_loss | -0.027      |
|    std                  | 7.8         |
|    value_loss           | 0.333       |
-----------------------------------------
[ADAPTIVE] Episode 204 reward: 0.014965
[ADAPTIVE] Episode 205 reward: 0.078096
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9210393   |
| time/                   |             |
|    fps                  | 1291        |
|    iterations           | 201         |
|    time_elapsed         | 637         |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.018959284 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.3       |
|    explained_variance   | 0.364       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 4155        |
|    policy_gradient_loss | -0.0261     |
|    std                  | 7.87        |
|    value_loss           | 0.315       |
-----------------------------------------
[ADAPTIVE] Episode 206 reward: -0.036347
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.81471634  |
| time/                   |             |
|    fps                  | 1292        |
|    iterations           | 202         |
|    time_elapsed         | 640         |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.016163126 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.4       |
|    explained_variance   | 0.44        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.597      |
|    n_updates            | 4170        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 7.92        |
|    value_loss           | 0.234       |
-----------------------------------------
[ADAPTIVE] Episode 207 reward: -0.107598
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.70090574  |
| time/                   |             |
|    fps                  | 1293        |
|    iterations           | 203         |
|    time_elapsed         | 642         |
|    total_timesteps      | 831488      |
| train/                  |             |
|    approx_kl            | 0.015040621 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.4       |
|    explained_variance   | 0.438       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.605      |
|    n_updates            | 4185        |
|    policy_gradient_loss | -0.0254     |
|    std                  | 7.95        |
|    value_loss           | 0.215       |
-----------------------------------------
[ADAPTIVE] Episode 208 reward: -0.007045
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.71022385   |
| time/                   |              |
|    fps                  | 1293         |
|    iterations           | 204          |
|    time_elapsed         | 646          |
|    total_timesteps      | 835584       |
| train/                  |              |
|    approx_kl            | 0.0151782315 |
|    clip_fraction        | 0.188        |
|    clip_range           | 0.2          |
|    entropy_loss         | -31.4        |
|    explained_variance   | 0.243        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.358       |
|    n_updates            | 4200         |
|    policy_gradient_loss | -0.0244      |
|    std                  | 8            |
|    value_loss           | 0.76         |
------------------------------------------
[ADAPTIVE] Episode 209 reward: 0.017479
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76055425  |
| time/                   |             |
|    fps                  | 1294        |
|    iterations           | 205         |
|    time_elapsed         | 648         |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.017157136 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.5       |
|    explained_variance   | 0.281       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.595      |
|    n_updates            | 4215        |
|    policy_gradient_loss | -0.0283     |
|    std                  | 8.03        |
|    value_loss           | 0.25        |
-----------------------------------------
[ADAPTIVE] Episode 210 reward: -0.089799
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 0.6381666 |
| time/                   |           |
|    fps                  | 1294      |
|    iterations           | 206       |
|    time_elapsed         | 651       |
|    total_timesteps      | 843776    |
| train/                  |           |
|    approx_kl            | 0.0140731 |
|    clip_fraction        | 0.152     |
|    clip_range           | 0.2       |
|    entropy_loss         | -31.5     |
|    explained_variance   | 0.394     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.501    |
|    n_updates            | 4230      |
|    policy_gradient_loss | -0.024    |
|    std                  | 8.09      |
|    value_loss           | 0.415     |
---------------------------------------
[ADAPTIVE] Episode 211 reward: 0.019261
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6572746   |
| time/                   |             |
|    fps                  | 1295        |
|    iterations           | 207         |
|    time_elapsed         | 654         |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.013695645 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.6       |
|    explained_variance   | 0.619       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.642      |
|    n_updates            | 4245        |
|    policy_gradient_loss | -0.0315     |
|    std                  | 8.13        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 212 reward: -0.023154
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7910331   |
| time/                   |             |
|    fps                  | 1296        |
|    iterations           | 208         |
|    time_elapsed         | 657         |
|    total_timesteps      | 851968      |
| train/                  |             |
|    approx_kl            | 0.018957885 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.7       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.616      |
|    n_updates            | 4260        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 8.2         |
|    value_loss           | 0.157       |
-----------------------------------------
[ADAPTIVE] Episode 213 reward: -0.114913
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.78766173  |
| time/                   |             |
|    fps                  | 1296        |
|    iterations           | 209         |
|    time_elapsed         | 660         |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.016550831 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.7       |
|    explained_variance   | 0.34        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 4275        |
|    policy_gradient_loss | -0.0257     |
|    std                  | 8.24        |
|    value_loss           | 0.327       |
-----------------------------------------
[ADAPTIVE] Episode 214 reward: -0.061983
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.88179535  |
| time/                   |             |
|    fps                  | 1296        |
|    iterations           | 210         |
|    time_elapsed         | 663         |
|    total_timesteps      | 860160      |
| train/                  |             |
|    approx_kl            | 0.019650398 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.7       |
|    explained_variance   | 0.246       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.417      |
|    n_updates            | 4290        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 8.26        |
|    value_loss           | 0.634       |
-----------------------------------------
[ADAPTIVE] Episode 215 reward: 0.021128
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98404074  |
| time/                   |             |
|    fps                  | 1297        |
|    iterations           | 211         |
|    time_elapsed         | 665         |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.016964609 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.8       |
|    explained_variance   | 0.289       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.48       |
|    n_updates            | 4305        |
|    policy_gradient_loss | -0.027      |
|    std                  | 8.31        |
|    value_loss           | 0.48        |
-----------------------------------------
[ADAPTIVE] Episode 216 reward: 0.034012
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0207912   |
| time/                   |             |
|    fps                  | 1297        |
|    iterations           | 212         |
|    time_elapsed         | 669         |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.023618234 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.8       |
|    explained_variance   | 0.499       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.464      |
|    n_updates            | 4320        |
|    policy_gradient_loss | -0.0229     |
|    std                  | 8.37        |
|    value_loss           | 0.312       |
-----------------------------------------
[ADAPTIVE] Episode 217 reward: -0.061342
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0433385   |
| time/                   |             |
|    fps                  | 1298        |
|    iterations           | 213         |
|    time_elapsed         | 671         |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.012545315 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.9       |
|    explained_variance   | 0.55        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.65       |
|    n_updates            | 4335        |
|    policy_gradient_loss | -0.032      |
|    std                  | 8.43        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 218 reward: 0.070284
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98528314  |
| time/                   |             |
|    fps                  | 1299        |
|    iterations           | 214         |
|    time_elapsed         | 674         |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.014920685 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32         |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.574      |
|    n_updates            | 4350        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 8.48        |
|    value_loss           | 0.255       |
-----------------------------------------
[ADAPTIVE] Episode 219 reward: 0.026514
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8818337   |
| time/                   |             |
|    fps                  | 1300        |
|    iterations           | 215         |
|    time_elapsed         | 677         |
|    total_timesteps      | 880640      |
| train/                  |             |
|    approx_kl            | 0.019104645 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32         |
|    explained_variance   | 0.232       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.536      |
|    n_updates            | 4365        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 8.53        |
|    value_loss           | 0.437       |
-----------------------------------------
[ADAPTIVE] Episode 220 reward: 0.058503
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9246867   |
| time/                   |             |
|    fps                  | 1300        |
|    iterations           | 216         |
|    time_elapsed         | 680         |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.018237637 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.1       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.621      |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.0285     |
|    std                  | 8.58        |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 221 reward: -0.057985
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0715117   |
| time/                   |             |
|    fps                  | 1301        |
|    iterations           | 217         |
|    time_elapsed         | 683         |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.014945636 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.1       |
|    explained_variance   | 0.546       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.647      |
|    n_updates            | 4395        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 8.62        |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 222 reward: -0.086169
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0731916  |
| time/                   |            |
|    fps                  | 1302       |
|    iterations           | 218        |
|    time_elapsed         | 685        |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.01202256 |
|    clip_fraction        | 0.167      |
|    clip_range           | 0.2        |
|    entropy_loss         | -32.1      |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.00025    |
|    loss                 | -0.641     |
|    n_updates            | 4410       |
|    policy_gradient_loss | -0.0235    |
|    std                  | 8.63       |
|    value_loss           | 0.122      |
----------------------------------------
[ADAPTIVE] Episode 223 reward: -0.011306
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0841444   |
| time/                   |             |
|    fps                  | 1302        |
|    iterations           | 219         |
|    time_elapsed         | 688         |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.016582577 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.2       |
|    explained_variance   | 0.383       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.488      |
|    n_updates            | 4425        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 8.69        |
|    value_loss           | 0.34        |
-----------------------------------------
[ADAPTIVE] Episode 224 reward: 0.019879
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 1.2208467 |
| time/                   |           |
|    fps                  | 1303      |
|    iterations           | 220       |
|    time_elapsed         | 691       |
|    total_timesteps      | 901120    |
| train/                  |           |
|    approx_kl            | 0.0130255 |
|    clip_fraction        | 0.166     |
|    clip_range           | 0.2       |
|    entropy_loss         | -32.2     |
|    explained_variance   | 0.567     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.63     |
|    n_updates            | 4440      |
|    policy_gradient_loss | -0.0305   |
|    std                  | 8.71      |
|    value_loss           | 0.144     |
---------------------------------------
[ADAPTIVE] Episode 225 reward: -0.041982
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1810395  |
| time/                   |            |
|    fps                  | 1304       |
|    iterations           | 221        |
|    time_elapsed         | 694        |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.01319484 |
|    clip_fraction        | 0.145      |
|    clip_range           | 0.2        |
|    entropy_loss         | -32.3      |
|    explained_variance   | 0.266      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.598     |
|    n_updates            | 4455       |
|    policy_gradient_loss | -0.0251    |
|    std                  | 8.75       |
|    value_loss           | 0.297      |
----------------------------------------
[ADAPTIVE] Episode 226 reward: 0.004121
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1855807   |
| time/                   |             |
|    fps                  | 1305        |
|    iterations           | 222         |
|    time_elapsed         | 696         |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.012065981 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.3       |
|    explained_variance   | 0.54        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.612      |
|    n_updates            | 4470        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 8.79        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 227 reward: 0.038970
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3170019   |
| time/                   |             |
|    fps                  | 1305        |
|    iterations           | 223         |
|    time_elapsed         | 699         |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.014053546 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.3       |
|    explained_variance   | 0.332       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 4485        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 8.84        |
|    value_loss           | 0.381       |
-----------------------------------------
[ADAPTIVE] Episode 228 reward: -0.032692
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.296972    |
| time/                   |             |
|    fps                  | 1306        |
|    iterations           | 224         |
|    time_elapsed         | 702         |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.013718469 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.4       |
|    explained_variance   | 0.32        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.555      |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 8.89        |
|    value_loss           | 0.365       |
-----------------------------------------
[ADAPTIVE] Episode 229 reward: 0.018359
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1441747   |
| time/                   |             |
|    fps                  | 1306        |
|    iterations           | 225         |
|    time_elapsed         | 705         |
|    total_timesteps      | 921600      |
| train/                  |             |
|    approx_kl            | 0.013211752 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.5       |
|    explained_variance   | 0.31        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.475      |
|    n_updates            | 4515        |
|    policy_gradient_loss | -0.0242     |
|    std                  | 8.95        |
|    value_loss           | 0.504       |
-----------------------------------------
[ADAPTIVE] Episode 230 reward: -0.063768
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.94529414 |
| time/                   |            |
|    fps                  | 1307       |
|    iterations           | 226        |
|    time_elapsed         | 707        |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.01859203 |
|    clip_fraction        | 0.182      |
|    clip_range           | 0.2        |
|    entropy_loss         | -32.5      |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.669     |
|    n_updates            | 4530       |
|    policy_gradient_loss | -0.0325    |
|    std                  | 9          |
|    value_loss           | 0.116      |
----------------------------------------
[ADAPTIVE] Episode 231 reward: 0.033061
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1459765  |
| time/                   |            |
|    fps                  | 1308       |
|    iterations           | 227        |
|    time_elapsed         | 710        |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.01473383 |
|    clip_fraction        | 0.15       |
|    clip_range           | 0.2        |
|    entropy_loss         | -32.6      |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.62      |
|    n_updates            | 4545       |
|    policy_gradient_loss | -0.0249    |
|    std                  | 9.07       |
|    value_loss           | 0.192      |
----------------------------------------
[ADAPTIVE] Episode 232 reward: 0.076947
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1923693   |
| time/                   |             |
|    fps                  | 1308        |
|    iterations           | 228         |
|    time_elapsed         | 713         |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.014346185 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.6       |
|    explained_variance   | 0.508       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.541      |
|    n_updates            | 4560        |
|    policy_gradient_loss | -0.0276     |
|    std                  | 9.11        |
|    value_loss           | 0.24        |
-----------------------------------------
[ADAPTIVE] Episode 233 reward: 0.039497
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1422566   |
| time/                   |             |
|    fps                  | 1309        |
|    iterations           | 229         |
|    time_elapsed         | 716         |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.017525516 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.7       |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.674      |
|    n_updates            | 4575        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 9.15        |
|    value_loss           | 0.0977      |
-----------------------------------------
[ADAPTIVE] Episode 234 reward: 0.026540
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0830929   |
| time/                   |             |
|    fps                  | 1309        |
|    iterations           | 230         |
|    time_elapsed         | 719         |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.013863678 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.7       |
|    explained_variance   | 0.591       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.653      |
|    n_updates            | 4590        |
|    policy_gradient_loss | -0.0283     |
|    std                  | 9.2         |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 235 reward: -0.059297
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1923636   |
| time/                   |             |
|    fps                  | 1310        |
|    iterations           | 231         |
|    time_elapsed         | 722         |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.013192646 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.8       |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.661      |
|    n_updates            | 4605        |
|    policy_gradient_loss | -0.0261     |
|    std                  | 9.26        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 236 reward: -0.051311
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2723973   |
| time/                   |             |
|    fps                  | 1310        |
|    iterations           | 232         |
|    time_elapsed         | 725         |
|    total_timesteps      | 950272      |
| train/                  |             |
|    approx_kl            | 0.013681055 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.8       |
|    explained_variance   | 0.565       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.605      |
|    n_updates            | 4620        |
|    policy_gradient_loss | -0.0269     |
|    std                  | 9.31        |
|    value_loss           | 0.258       |
-----------------------------------------
[ADAPTIVE] Episode 237 reward: 0.037210
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1256282   |
| time/                   |             |
|    fps                  | 1310        |
|    iterations           | 233         |
|    time_elapsed         | 727         |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.011975209 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.9       |
|    explained_variance   | 0.617       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.63       |
|    n_updates            | 4635        |
|    policy_gradient_loss | -0.0238     |
|    std                  | 9.36        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 238 reward: -0.040368
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1314598   |
| time/                   |             |
|    fps                  | 1311        |
|    iterations           | 234         |
|    time_elapsed         | 730         |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.011698316 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.9       |
|    explained_variance   | 0.498       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.589      |
|    n_updates            | 4650        |
|    policy_gradient_loss | -0.023      |
|    std                  | 9.42        |
|    value_loss           | 0.274       |
-----------------------------------------
[ADAPTIVE] Episode 239 reward: -0.033811
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.032733    |
| time/                   |             |
|    fps                  | 1311        |
|    iterations           | 235         |
|    time_elapsed         | 733         |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.011734476 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33         |
|    explained_variance   | 0.408       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.512      |
|    n_updates            | 4665        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 9.48        |
|    value_loss           | 0.396       |
-----------------------------------------
[ADAPTIVE] Episode 240 reward: -0.015361
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0812671   |
| time/                   |             |
|    fps                  | 1311        |
|    iterations           | 236         |
|    time_elapsed         | 736         |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.014187993 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33         |
|    explained_variance   | 0.42        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.601      |
|    n_updates            | 4680        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 9.54        |
|    value_loss           | 0.193       |
-----------------------------------------
[ADAPTIVE] Episode 241 reward: 0.047060
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96104246  |
| time/                   |             |
|    fps                  | 1312        |
|    iterations           | 237         |
|    time_elapsed         | 739         |
|    total_timesteps      | 970752      |
| train/                  |             |
|    approx_kl            | 0.012446603 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.1       |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.626      |
|    n_updates            | 4695        |
|    policy_gradient_loss | -0.0263     |
|    std                  | 9.59        |
|    value_loss           | 0.21        |
-----------------------------------------
[ADAPTIVE] Episode 242 reward: -0.076911
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8784919   |
| time/                   |             |
|    fps                  | 1312        |
|    iterations           | 238         |
|    time_elapsed         | 742         |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.013366998 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.1       |
|    explained_variance   | 0.639       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.654      |
|    n_updates            | 4710        |
|    policy_gradient_loss | -0.0255     |
|    std                  | 9.64        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 243 reward: -0.069988
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8513277   |
| time/                   |             |
|    fps                  | 1313        |
|    iterations           | 239         |
|    time_elapsed         | 745         |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.015598083 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.2       |
|    explained_variance   | 0.496       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.586      |
|    n_updates            | 4725        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 9.68        |
|    value_loss           | 0.288       |
-----------------------------------------
[ADAPTIVE] Episode 244 reward: 0.045095
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9357324   |
| time/                   |             |
|    fps                  | 1314        |
|    iterations           | 240         |
|    time_elapsed         | 747         |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.015092977 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.2       |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.578      |
|    n_updates            | 4740        |
|    policy_gradient_loss | -0.0257     |
|    std                  | 9.73        |
|    value_loss           | 0.357       |
-----------------------------------------
[ADAPTIVE] Episode 245 reward: -0.003714
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8516048   |
| time/                   |             |
|    fps                  | 1315        |
|    iterations           | 241         |
|    time_elapsed         | 750         |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.016640203 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.3       |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.592      |
|    n_updates            | 4755        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 9.78        |
|    value_loss           | 0.245       |
-----------------------------------------
[ADAPTIVE] Episode 246 reward: -0.013325
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7414812   |
| time/                   |             |
|    fps                  | 1315        |
|    iterations           | 242         |
|    time_elapsed         | 753         |
|    total_timesteps      | 991232      |
| train/                  |             |
|    approx_kl            | 0.012938438 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.3       |
|    explained_variance   | 0.532       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.65       |
|    n_updates            | 4770        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 9.82        |
|    value_loss           | 0.21        |
-----------------------------------------
[ADAPTIVE] Episode 247 reward: -0.021407
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6054202   |
| time/                   |             |
|    fps                  | 1315        |
|    iterations           | 243         |
|    time_elapsed         | 756         |
|    total_timesteps      | 995328      |
| train/                  |             |
|    approx_kl            | 0.019210175 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.3       |
|    explained_variance   | 0.569       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.659      |
|    n_updates            | 4785        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 9.84        |
|    value_loss           | 0.176       |
-----------------------------------------
[ADAPTIVE] Episode 248 reward: 0.025513
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.66883093  |
| time/                   |             |
|    fps                  | 1316        |
|    iterations           | 244         |
|    time_elapsed         | 759         |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.014518041 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.4       |
|    explained_variance   | 0.578       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.549      |
|    n_updates            | 4800        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 9.88        |
|    value_loss           | 0.257       |
-----------------------------------------
[ADAPTIVE] Episode 249 reward: 0.016460
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.5297264  |
| time/                   |            |
|    fps                  | 1316       |
|    iterations           | 245        |
|    time_elapsed         | 762        |
|    total_timesteps      | 1003520    |
| train/                  |            |
|    approx_kl            | 0.01588194 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -33.4      |
|    explained_variance   | 0.679      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.653     |
|    n_updates            | 4815       |
|    policy_gradient_loss | -0.0259    |
|    std                  | 9.93       |
|    value_loss           | 0.167      |
----------------------------------------
[ADAPTIVE] Episode 250 reward: 0.035318
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6944406   |
| time/                   |             |
|    fps                  | 1317        |
|    iterations           | 246         |
|    time_elapsed         | 764         |
|    total_timesteps      | 1007616     |
| train/                  |             |
|    approx_kl            | 0.017788613 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.4       |
|    explained_variance   | 0.613       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.655      |
|    n_updates            | 4830        |
|    policy_gradient_loss | -0.0281     |
|    std                  | 9.99        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 251 reward: 0.000147
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6074316   |
| time/                   |             |
|    fps                  | 1318        |
|    iterations           | 247         |
|    time_elapsed         | 767         |
|    total_timesteps      | 1011712     |
| train/                  |             |
|    approx_kl            | 0.012772971 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.5       |
|    explained_variance   | 0.482       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.575      |
|    n_updates            | 4845        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 10.1        |
|    value_loss           | 0.337       |
-----------------------------------------
[ADAPTIVE] Episode 252 reward: -0.001221
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5748779   |
| time/                   |             |
|    fps                  | 1319        |
|    iterations           | 248         |
|    time_elapsed         | 770         |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.015260844 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.6       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.643      |
|    n_updates            | 4860        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 10.1        |
|    value_loss           | 0.255       |
-----------------------------------------
[ADAPTIVE] Episode 253 reward: 0.060767
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6453823   |
| time/                   |             |
|    fps                  | 1319        |
|    iterations           | 249         |
|    time_elapsed         | 772         |
|    total_timesteps      | 1019904     |
| train/                  |             |
|    approx_kl            | 0.015350978 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.6       |
|    explained_variance   | 0.602       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.675      |
|    n_updates            | 4875        |
|    policy_gradient_loss | -0.0288     |
|    std                  | 10.2        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 254 reward: -0.030809
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7765777   |
| time/                   |             |
|    fps                  | 1320        |
|    iterations           | 250         |
|    time_elapsed         | 775         |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.011578802 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.6       |
|    explained_variance   | 0.719       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.652      |
|    n_updates            | 4890        |
|    policy_gradient_loss | -0.023      |
|    std                  | 10.2        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 255 reward: -0.002248
[ADAPTIVE] Episode 256 reward: -0.079513
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.883997    |
| time/                   |             |
|    fps                  | 1321        |
|    iterations           | 251         |
|    time_elapsed         | 778         |
|    total_timesteps      | 1028096     |
| train/                  |             |
|    approx_kl            | 0.012388548 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.7       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.653      |
|    n_updates            | 4905        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 10.3        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 257 reward: 0.082601
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9473035   |
| time/                   |             |
|    fps                  | 1321        |
|    iterations           | 252         |
|    time_elapsed         | 780         |
|    total_timesteps      | 1032192     |
| train/                  |             |
|    approx_kl            | 0.013519925 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.7       |
|    explained_variance   | 0.586       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.623      |
|    n_updates            | 4920        |
|    policy_gradient_loss | -0.0268     |
|    std                  | 10.3        |
|    value_loss           | 0.176       |
-----------------------------------------
[ADAPTIVE] Episode 258 reward: 0.023243
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2395167   |
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 253         |
|    time_elapsed         | 783         |
|    total_timesteps      | 1036288     |
| train/                  |             |
|    approx_kl            | 0.014754107 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.8       |
|    explained_variance   | 0.48        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.614      |
|    n_updates            | 4935        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 10.4        |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 259 reward: -0.068351
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3296971   |
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 254         |
|    time_elapsed         | 786         |
|    total_timesteps      | 1040384     |
| train/                  |             |
|    approx_kl            | 0.015072284 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.9       |
|    explained_variance   | 0.67        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.68       |
|    n_updates            | 4950        |
|    policy_gradient_loss | -0.0253     |
|    std                  | 10.4        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 260 reward: 0.062009
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3146286   |
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 255         |
|    time_elapsed         | 789         |
|    total_timesteps      | 1044480     |
| train/                  |             |
|    approx_kl            | 0.010670798 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.9       |
|    explained_variance   | 0.555       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.595      |
|    n_updates            | 4965        |
|    policy_gradient_loss | -0.0225     |
|    std                  | 10.5        |
|    value_loss           | 0.344       |
-----------------------------------------
[ADAPTIVE] Episode 261 reward: 0.006931
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3100928    |
| time/                   |              |
|    fps                  | 1322         |
|    iterations           | 256          |
|    time_elapsed         | 792          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0144929765 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.2          |
|    entropy_loss         | -33.9        |
|    explained_variance   | 0.574        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.605       |
|    n_updates            | 4980         |
|    policy_gradient_loss | -0.0214      |
|    std                  | 10.6         |
|    value_loss           | 0.354        |
------------------------------------------
[ADAPTIVE] Episode 262 reward: 0.065259
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2489095   |
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 257         |
|    time_elapsed         | 795         |
|    total_timesteps      | 1052672     |
| train/                  |             |
|    approx_kl            | 0.010483824 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34         |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.662      |
|    n_updates            | 4995        |
|    policy_gradient_loss | -0.0211     |
|    std                  | 10.6        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 263 reward: -0.043947
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1222152   |
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 258         |
|    time_elapsed         | 799         |
|    total_timesteps      | 1056768     |
| train/                  |             |
|    approx_kl            | 0.009829557 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34         |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.615      |
|    n_updates            | 5010        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 10.6        |
|    value_loss           | 0.27        |
-----------------------------------------
[ADAPTIVE] Episode 264 reward: 0.040319
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 0.8912162 |
| time/                   |           |
|    fps                  | 1322      |
|    iterations           | 259       |
|    time_elapsed         | 801       |
|    total_timesteps      | 1060864   |
| train/                  |           |
|    approx_kl            | 0.0185627 |
|    clip_fraction        | 0.168     |
|    clip_range           | 0.2       |
|    entropy_loss         | -34       |
|    explained_variance   | 0.466     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.565    |
|    n_updates            | 5025      |
|    policy_gradient_loss | -0.0232   |
|    std                  | 10.7      |
|    value_loss           | 0.301     |
---------------------------------------
[ADAPTIVE] Episode 265 reward: 0.023587
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7466984   |
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 260         |
|    time_elapsed         | 805         |
|    total_timesteps      | 1064960     |
| train/                  |             |
|    approx_kl            | 0.013220362 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.1       |
|    explained_variance   | 0.605       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.626      |
|    n_updates            | 5040        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 10.7        |
|    value_loss           | 0.232       |
-----------------------------------------
[ADAPTIVE] Episode 266 reward: -0.051337
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6809575   |
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 261         |
|    time_elapsed         | 808         |
|    total_timesteps      | 1069056     |
| train/                  |             |
|    approx_kl            | 0.015141668 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.1       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.675      |
|    n_updates            | 5055        |
|    policy_gradient_loss | -0.0251     |
|    std                  | 10.8        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 267 reward: 0.145650
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.4835208  |
| time/                   |            |
|    fps                  | 1323       |
|    iterations           | 262        |
|    time_elapsed         | 810        |
|    total_timesteps      | 1073152    |
| train/                  |            |
|    approx_kl            | 0.01406081 |
|    clip_fraction        | 0.171      |
|    clip_range           | 0.2        |
|    entropy_loss         | -34.2      |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.603     |
|    n_updates            | 5070       |
|    policy_gradient_loss | -0.0246    |
|    std                  | 10.9       |
|    value_loss           | 0.297      |
----------------------------------------
[ADAPTIVE] Episode 268 reward: 0.018610
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.506701    |
| time/                   |             |
|    fps                  | 1324        |
|    iterations           | 263         |
|    time_elapsed         | 813         |
|    total_timesteps      | 1077248     |
| train/                  |             |
|    approx_kl            | 0.012160876 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.3       |
|    explained_variance   | 0.586       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.647      |
|    n_updates            | 5085        |
|    policy_gradient_loss | -0.0232     |
|    std                  | 10.9        |
|    value_loss           | 0.254       |
-----------------------------------------
[ADAPTIVE] Episode 269 reward: -0.017106
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7583376   |
| time/                   |             |
|    fps                  | 1324        |
|    iterations           | 264         |
|    time_elapsed         | 816         |
|    total_timesteps      | 1081344     |
| train/                  |             |
|    approx_kl            | 0.017990898 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.3       |
|    explained_variance   | 0.585       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.629      |
|    n_updates            | 5100        |
|    policy_gradient_loss | -0.018      |
|    std                  | 11          |
|    value_loss           | 0.244       |
-----------------------------------------
[ADAPTIVE] Episode 270 reward: 6.817325
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.80121064  |
| time/                   |             |
|    fps                  | 1325        |
|    iterations           | 265         |
|    time_elapsed         | 819         |
|    total_timesteps      | 1085440     |
| train/                  |             |
|    approx_kl            | 0.014397336 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.4       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.663      |
|    n_updates            | 5115        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 11.1        |
|    value_loss           | 0.148       |
-----------------------------------------
[ADAPTIVE] Episode 271 reward: 0.061444
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.8419562  |
| time/                   |            |
|    fps                  | 1325       |
|    iterations           | 266        |
|    time_elapsed         | 822        |
|    total_timesteps      | 1089536    |
| train/                  |            |
|    approx_kl            | 0.01486806 |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.2        |
|    entropy_loss         | -34.4      |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.00025    |
|    loss                 | -0.606     |
|    n_updates            | 5130       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 11.1       |
|    value_loss           | 0.351      |
----------------------------------------
[ADAPTIVE] Episode 272 reward: 0.005508
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.89504737   |
| time/                   |              |
|    fps                  | 1325         |
|    iterations           | 267          |
|    time_elapsed         | 824          |
|    total_timesteps      | 1093632      |
| train/                  |              |
|    approx_kl            | 0.0142472545 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.2          |
|    entropy_loss         | -34.5        |
|    explained_variance   | 0.592        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.593       |
|    n_updates            | 5145         |
|    policy_gradient_loss | -0.0221      |
|    std                  | 11.2         |
|    value_loss           | 0.315        |
------------------------------------------
[ADAPTIVE] Episode 273 reward: -0.039893
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0809127   |
| time/                   |             |
|    fps                  | 1326        |
|    iterations           | 268         |
|    time_elapsed         | 827         |
|    total_timesteps      | 1097728     |
| train/                  |             |
|    approx_kl            | 0.011315707 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.5       |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.553      |
|    n_updates            | 5160        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 11.2        |
|    value_loss           | 0.331       |
-----------------------------------------
[ADAPTIVE] Episode 274 reward: -0.078267
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9502103   |
| time/                   |             |
|    fps                  | 1326        |
|    iterations           | 269         |
|    time_elapsed         | 830         |
|    total_timesteps      | 1101824     |
| train/                  |             |
|    approx_kl            | 0.017406035 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.5       |
|    explained_variance   | 0.548       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.609      |
|    n_updates            | 5175        |
|    policy_gradient_loss | -0.0232     |
|    std                  | 11.3        |
|    value_loss           | 0.363       |
-----------------------------------------
[ADAPTIVE] Episode 275 reward: 0.043551
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0513277   |
| time/                   |             |
|    fps                  | 1326        |
|    iterations           | 270         |
|    time_elapsed         | 833         |
|    total_timesteps      | 1105920     |
| train/                  |             |
|    approx_kl            | 0.014218012 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.6       |
|    explained_variance   | 0.608       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.667      |
|    n_updates            | 5190        |
|    policy_gradient_loss | -0.0255     |
|    std                  | 11.3        |
|    value_loss           | 0.202       |
-----------------------------------------
[ADAPTIVE] Episode 276 reward: -0.088521
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.89103293  |
| time/                   |             |
|    fps                  | 1327        |
|    iterations           | 271         |
|    time_elapsed         | 836         |
|    total_timesteps      | 1110016     |
| train/                  |             |
|    approx_kl            | 0.015793355 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.6       |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.656      |
|    n_updates            | 5205        |
|    policy_gradient_loss | -0.0241     |
|    std                  | 11.3        |
|    value_loss           | 0.166       |
-----------------------------------------
[ADAPTIVE] Episode 277 reward: 0.026589
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0832589  |
| time/                   |            |
|    fps                  | 1328       |
|    iterations           | 272        |
|    time_elapsed         | 838        |
|    total_timesteps      | 1114112    |
| train/                  |            |
|    approx_kl            | 0.01278854 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -34.6      |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.68      |
|    n_updates            | 5220       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 11.4       |
|    value_loss           | 0.109      |
----------------------------------------
[ADAPTIVE] Episode 278 reward: 0.013956
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0167431   |
| time/                   |             |
|    fps                  | 1328        |
|    iterations           | 273         |
|    time_elapsed         | 841         |
|    total_timesteps      | 1118208     |
| train/                  |             |
|    approx_kl            | 0.011186865 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.7       |
|    explained_variance   | 0.703       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.662      |
|    n_updates            | 5235        |
|    policy_gradient_loss | -0.0244     |
|    std                  | 11.4        |
|    value_loss           | 0.134       |
-----------------------------------------
[ADAPTIVE] Episode 279 reward: -0.151031
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1323965    |
| time/                   |              |
|    fps                  | 1329         |
|    iterations           | 274          |
|    time_elapsed         | 844          |
|    total_timesteps      | 1122304      |
| train/                  |              |
|    approx_kl            | 0.0154811675 |
|    clip_fraction        | 0.183        |
|    clip_range           | 0.2          |
|    entropy_loss         | -34.7        |
|    explained_variance   | 0.646        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.65        |
|    n_updates            | 5250         |
|    policy_gradient_loss | -0.0247      |
|    std                  | 11.5         |
|    value_loss           | 0.2          |
------------------------------------------
[ADAPTIVE] Episode 280 reward: 0.081340
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1858927   |
| time/                   |             |
|    fps                  | 1329        |
|    iterations           | 275         |
|    time_elapsed         | 846         |
|    total_timesteps      | 1126400     |
| train/                  |             |
|    approx_kl            | 0.012150727 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.7       |
|    explained_variance   | 0.653       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.625      |
|    n_updates            | 5265        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 11.5        |
|    value_loss           | 0.213       |
-----------------------------------------
[ADAPTIVE] Episode 281 reward: 0.039415
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0993187   |
| time/                   |             |
|    fps                  | 1330        |
|    iterations           | 276         |
|    time_elapsed         | 849         |
|    total_timesteps      | 1130496     |
| train/                  |             |
|    approx_kl            | 0.014198033 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.8       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.679      |
|    n_updates            | 5280        |
|    policy_gradient_loss | -0.0272     |
|    std                  | 11.6        |
|    value_loss           | 0.164       |
-----------------------------------------
[ADAPTIVE] Episode 282 reward: 0.024444
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.726629    |
| time/                   |             |
|    fps                  | 1330        |
|    iterations           | 277         |
|    time_elapsed         | 852         |
|    total_timesteps      | 1134592     |
| train/                  |             |
|    approx_kl            | 0.011369145 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.8       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.65       |
|    n_updates            | 5295        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 11.7        |
|    value_loss           | 0.183       |
-----------------------------------------
[ADAPTIVE] Episode 283 reward: 0.003155
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.79983217  |
| time/                   |             |
|    fps                  | 1331        |
|    iterations           | 278         |
|    time_elapsed         | 855         |
|    total_timesteps      | 1138688     |
| train/                  |             |
|    approx_kl            | 0.010890007 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.9       |
|    explained_variance   | 0.703       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.67       |
|    n_updates            | 5310        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 11.7        |
|    value_loss           | 0.188       |
-----------------------------------------
[ADAPTIVE] Episode 284 reward: -0.041791
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.75148696 |
| time/                   |            |
|    fps                  | 1331       |
|    iterations           | 279        |
|    time_elapsed         | 858        |
|    total_timesteps      | 1142784    |
| train/                  |            |
|    approx_kl            | 0.0116661  |
|    clip_fraction        | 0.126      |
|    clip_range           | 0.2        |
|    entropy_loss         | -34.9      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.64      |
|    n_updates            | 5325       |
|    policy_gradient_loss | -0.022     |
|    std                  | 11.7       |
|    value_loss           | 0.308      |
----------------------------------------
[ADAPTIVE] Episode 285 reward: -0.019884
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67131484  |
| time/                   |             |
|    fps                  | 1331        |
|    iterations           | 280         |
|    time_elapsed         | 861         |
|    total_timesteps      | 1146880     |
| train/                  |             |
|    approx_kl            | 0.012996828 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.9       |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.681      |
|    n_updates            | 5340        |
|    policy_gradient_loss | -0.0238     |
|    std                  | 11.8        |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 286 reward: 0.005290
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6297863   |
| time/                   |             |
|    fps                  | 1332        |
|    iterations           | 281         |
|    time_elapsed         | 863         |
|    total_timesteps      | 1150976     |
| train/                  |             |
|    approx_kl            | 0.014986898 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35         |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.668      |
|    n_updates            | 5355        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 11.9        |
|    value_loss           | 0.196       |
-----------------------------------------
[ADAPTIVE] Episode 287 reward: -0.037464
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7232566   |
| time/                   |             |
|    fps                  | 1332        |
|    iterations           | 282         |
|    time_elapsed         | 866         |
|    total_timesteps      | 1155072     |
| train/                  |             |
|    approx_kl            | 0.010771716 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.1       |
|    explained_variance   | 0.657       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.616      |
|    n_updates            | 5370        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 11.9        |
|    value_loss           | 0.274       |
-----------------------------------------
[ADAPTIVE] Episode 288 reward: -0.020613
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98057055  |
| time/                   |             |
|    fps                  | 1332        |
|    iterations           | 283         |
|    time_elapsed         | 869         |
|    total_timesteps      | 1159168     |
| train/                  |             |
|    approx_kl            | 0.013069697 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.1       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.693      |
|    n_updates            | 5385        |
|    policy_gradient_loss | -0.0251     |
|    std                  | 12          |
|    value_loss           | 0.161       |
-----------------------------------------
[ADAPTIVE] Episode 289 reward: 0.083149
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.968834    |
| time/                   |             |
|    fps                  | 1332        |
|    iterations           | 284         |
|    time_elapsed         | 872         |
|    total_timesteps      | 1163264     |
| train/                  |             |
|    approx_kl            | 0.013825881 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.2       |
|    explained_variance   | 0.703       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.674      |
|    n_updates            | 5400        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 12.1        |
|    value_loss           | 0.193       |
-----------------------------------------
[ADAPTIVE] Episode 290 reward: -0.087215
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0988245   |
| time/                   |             |
|    fps                  | 1333        |
|    iterations           | 285         |
|    time_elapsed         | 875         |
|    total_timesteps      | 1167360     |
| train/                  |             |
|    approx_kl            | 0.012700768 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.2       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.686      |
|    n_updates            | 5415        |
|    policy_gradient_loss | -0.024      |
|    std                  | 12.1        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 291 reward: -0.031277
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9720423   |
| time/                   |             |
|    fps                  | 1332        |
|    iterations           | 286         |
|    time_elapsed         | 878         |
|    total_timesteps      | 1171456     |
| train/                  |             |
|    approx_kl            | 0.015710112 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.2       |
|    explained_variance   | 0.773       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.7        |
|    n_updates            | 5430        |
|    policy_gradient_loss | -0.0264     |
|    std                  | 12.2        |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 292 reward: 0.014024
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8637711   |
| time/                   |             |
|    fps                  | 1333        |
|    iterations           | 287         |
|    time_elapsed         | 881         |
|    total_timesteps      | 1175552     |
| train/                  |             |
|    approx_kl            | 0.012583593 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.3       |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.646      |
|    n_updates            | 5445        |
|    policy_gradient_loss | -0.0258     |
|    std                  | 12.3        |
|    value_loss           | 0.276       |
-----------------------------------------
[ADAPTIVE] Episode 293 reward: -0.030145
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84360313  |
| time/                   |             |
|    fps                  | 1333        |
|    iterations           | 288         |
|    time_elapsed         | 884         |
|    total_timesteps      | 1179648     |
| train/                  |             |
|    approx_kl            | 0.010960838 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.3       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.692      |
|    n_updates            | 5460        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 12.3        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 294 reward: 0.045553
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.75398755  |
| time/                   |             |
|    fps                  | 1333        |
|    iterations           | 289         |
|    time_elapsed         | 887         |
|    total_timesteps      | 1183744     |
| train/                  |             |
|    approx_kl            | 0.013260536 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.4       |
|    explained_variance   | 0.673       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.617      |
|    n_updates            | 5475        |
|    policy_gradient_loss | -0.0208     |
|    std                  | 12.4        |
|    value_loss           | 0.357       |
-----------------------------------------
[ADAPTIVE] Episode 295 reward: 0.027144
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.59366    |
| time/                   |            |
|    fps                  | 1333       |
|    iterations           | 290        |
|    time_elapsed         | 890        |
|    total_timesteps      | 1187840    |
| train/                  |            |
|    approx_kl            | 0.01362079 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -35.4      |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.646     |
|    n_updates            | 5490       |
|    policy_gradient_loss | -0.018     |
|    std                  | 12.5       |
|    value_loss           | 0.232      |
----------------------------------------
[ADAPTIVE] Episode 296 reward: -1.267507
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.49325004  |
| time/                   |             |
|    fps                  | 1334        |
|    iterations           | 291         |
|    time_elapsed         | 893         |
|    total_timesteps      | 1191936     |
| train/                  |             |
|    approx_kl            | 0.010511707 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.5       |
|    explained_variance   | 0.8         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.646      |
|    n_updates            | 5505        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 12.6        |
|    value_loss           | 0.181       |
-----------------------------------------
[ADAPTIVE] Episode 297 reward: -0.051576
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.44340593  |
| time/                   |             |
|    fps                  | 1334        |
|    iterations           | 292         |
|    time_elapsed         | 896         |
|    total_timesteps      | 1196032     |
| train/                  |             |
|    approx_kl            | 0.018726185 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.6       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.673      |
|    n_updates            | 5520        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 12.6        |
|    value_loss           | 0.122       |
-----------------------------------------
[ADAPTIVE] Episode 298 reward: -0.023713
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.55864394 |
| time/                   |            |
|    fps                  | 1334       |
|    iterations           | 293        |
|    time_elapsed         | 899        |
|    total_timesteps      | 1200128    |
| train/                  |            |
|    approx_kl            | 0.01073485 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -35.6      |
|    explained_variance   | 0.78       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.679     |
|    n_updates            | 5535       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 12.7       |
|    value_loss           | 0.157      |
----------------------------------------
[ADAPTIVE] Episode 299 reward: -0.067674
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.68077713  |
| time/                   |             |
|    fps                  | 1335        |
|    iterations           | 294         |
|    time_elapsed         | 901         |
|    total_timesteps      | 1204224     |
| train/                  |             |
|    approx_kl            | 0.013040924 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.6       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.689      |
|    n_updates            | 5550        |
|    policy_gradient_loss | -0.0229     |
|    std                  | 12.8        |
|    value_loss           | 0.199       |
-----------------------------------------
[ADAPTIVE] Episode 300 reward: 0.001889
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.54648036  |
| time/                   |             |
|    fps                  | 1335        |
|    iterations           | 295         |
|    time_elapsed         | 904         |
|    total_timesteps      | 1208320     |
| train/                  |             |
|    approx_kl            | 0.012587074 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.7       |
|    explained_variance   | 0.671       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.705      |
|    n_updates            | 5565        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 12.8        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 301 reward: -0.072548
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5140564   |
| time/                   |             |
|    fps                  | 1335        |
|    iterations           | 296         |
|    time_elapsed         | 907         |
|    total_timesteps      | 1212416     |
| train/                  |             |
|    approx_kl            | 0.024962122 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.7       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.704      |
|    n_updates            | 5580        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 12.8        |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 302 reward: -0.061165
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.72970235   |
| time/                   |              |
|    fps                  | 1335         |
|    iterations           | 297          |
|    time_elapsed         | 910          |
|    total_timesteps      | 1216512      |
| train/                  |              |
|    approx_kl            | 0.0104362145 |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.2          |
|    entropy_loss         | -35.7        |
|    explained_variance   | 0.76         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.685       |
|    n_updates            | 5595         |
|    policy_gradient_loss | -0.0238      |
|    std                  | 12.9         |
|    value_loss           | 0.163        |
------------------------------------------
[ADAPTIVE] Episode 303 reward: -0.100745
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8782711   |
| time/                   |             |
|    fps                  | 1335        |
|    iterations           | 298         |
|    time_elapsed         | 913         |
|    total_timesteps      | 1220608     |
| train/                  |             |
|    approx_kl            | 0.012269827 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.8       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.688      |
|    n_updates            | 5610        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 12.9        |
|    value_loss           | 0.193       |
-----------------------------------------
[ADAPTIVE] Episode 304 reward: -0.003368
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76699966  |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 299         |
|    time_elapsed         | 916         |
|    total_timesteps      | 1224704     |
| train/                  |             |
|    approx_kl            | 0.013762872 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.8       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.667      |
|    n_updates            | 5625        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 12.9        |
|    value_loss           | 0.243       |
-----------------------------------------
[ADAPTIVE] Episode 305 reward: 0.004574
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6848232   |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 300         |
|    time_elapsed         | 919         |
|    total_timesteps      | 1228800     |
| train/                  |             |
|    approx_kl            | 0.013653383 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.8       |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.673      |
|    n_updates            | 5640        |
|    policy_gradient_loss | -0.0236     |
|    std                  | 13          |
|    value_loss           | 0.194       |
-----------------------------------------
[ADAPTIVE] Episode 306 reward: -0.172072
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6391033   |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 301         |
|    time_elapsed         | 922         |
|    total_timesteps      | 1232896     |
| train/                  |             |
|    approx_kl            | 0.018386215 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.8       |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.696      |
|    n_updates            | 5655        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 13          |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 307 reward: -0.057353
[ADAPTIVE] Episode 308 reward: -0.041429
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67502123  |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 302         |
|    time_elapsed         | 925         |
|    total_timesteps      | 1236992     |
| train/                  |             |
|    approx_kl            | 0.015522847 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.9       |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.712      |
|    n_updates            | 5670        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 13.1        |
|    value_loss           | 0.152       |
-----------------------------------------
[ADAPTIVE] Episode 309 reward: 0.049659
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.62356937  |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 303         |
|    time_elapsed         | 928         |
|    total_timesteps      | 1241088     |
| train/                  |             |
|    approx_kl            | 0.012166366 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.9       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.722      |
|    n_updates            | 5685        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 13.2        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 310 reward: -0.045376
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.52461535  |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 304         |
|    time_elapsed         | 931         |
|    total_timesteps      | 1245184     |
| train/                  |             |
|    approx_kl            | 0.012947233 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -36         |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.666      |
|    n_updates            | 5700        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 13.3        |
|    value_loss           | 0.247       |
-----------------------------------------
[ADAPTIVE] Episode 311 reward: 0.029484
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.73438483  |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 305         |
|    time_elapsed         | 934         |
|    total_timesteps      | 1249280     |
| train/                  |             |
|    approx_kl            | 0.011387534 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.1       |
|    explained_variance   | 0.752       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.706      |
|    n_updates            | 5715        |
|    policy_gradient_loss | -0.021      |
|    std                  | 13.3        |
|    value_loss           | 0.129       |
-----------------------------------------
[ADAPTIVE] Episode 312 reward: -0.012171
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.63815206  |
| time/                   |             |
|    fps                  | 1337        |
|    iterations           | 306         |
|    time_elapsed         | 937         |
|    total_timesteps      | 1253376     |
| train/                  |             |
|    approx_kl            | 0.012958795 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.1       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.712      |
|    n_updates            | 5730        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 13.4        |
|    value_loss           | 0.0971      |
-----------------------------------------
[ADAPTIVE] Episode 313 reward: -0.004694
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.60507905  |
| time/                   |             |
|    fps                  | 1337        |
|    iterations           | 307         |
|    time_elapsed         | 940         |
|    total_timesteps      | 1257472     |
| train/                  |             |
|    approx_kl            | 0.012215519 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.1       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.674      |
|    n_updates            | 5745        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 13.5        |
|    value_loss           | 0.173       |
-----------------------------------------
[ADAPTIVE] Episode 314 reward: -0.068974
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7285931   |
| time/                   |             |
|    fps                  | 1337        |
|    iterations           | 308         |
|    time_elapsed         | 943         |
|    total_timesteps      | 1261568     |
| train/                  |             |
|    approx_kl            | 0.012276166 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.2       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.702      |
|    n_updates            | 5760        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 13.6        |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 315 reward: -0.039160
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7727261   |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 309         |
|    time_elapsed         | 946         |
|    total_timesteps      | 1265664     |
| train/                  |             |
|    approx_kl            | 0.013024045 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.2       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.717      |
|    n_updates            | 5775        |
|    policy_gradient_loss | -0.0252     |
|    std                  | 13.6        |
|    value_loss           | 0.0857      |
-----------------------------------------
[ADAPTIVE] Episode 316 reward: -0.105830
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8071494   |
| time/                   |             |
|    fps                  | 1337        |
|    iterations           | 310         |
|    time_elapsed         | 949         |
|    total_timesteps      | 1269760     |
| train/                  |             |
|    approx_kl            | 0.012625164 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.3       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.738      |
|    n_updates            | 5790        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 13.6        |
|    value_loss           | 0.0819      |
-----------------------------------------
[ADAPTIVE] Episode 317 reward: 0.022392
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7447574   |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 311         |
|    time_elapsed         | 952         |
|    total_timesteps      | 1273856     |
| train/                  |             |
|    approx_kl            | 0.011261778 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.3       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.703      |
|    n_updates            | 5805        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 13.8        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 318 reward: -0.050336
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.74414694  |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 312         |
|    time_elapsed         | 956         |
|    total_timesteps      | 1277952     |
| train/                  |             |
|    approx_kl            | 0.011496031 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.4       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.713      |
|    n_updates            | 5820        |
|    policy_gradient_loss | -0.0228     |
|    std                  | 13.8        |
|    value_loss           | 0.166       |
-----------------------------------------
[ADAPTIVE] Episode 319 reward: -0.006958
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6574285   |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 313         |
|    time_elapsed         | 959         |
|    total_timesteps      | 1282048     |
| train/                  |             |
|    approx_kl            | 0.009827934 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.4       |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.726      |
|    n_updates            | 5835        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 13.9        |
|    value_loss           | 0.0891      |
-----------------------------------------
[ADAPTIVE] Episode 320 reward: 0.045000
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.60324496   |
| time/                   |              |
|    fps                  | 1336         |
|    iterations           | 314          |
|    time_elapsed         | 962          |
|    total_timesteps      | 1286144      |
| train/                  |              |
|    approx_kl            | 0.0142269535 |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.2          |
|    entropy_loss         | -36.5        |
|    explained_variance   | 0.825        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.721       |
|    n_updates            | 5850         |
|    policy_gradient_loss | -0.0211      |
|    std                  | 14           |
|    value_loss           | 0.116        |
------------------------------------------
[ADAPTIVE] Episode 321 reward: 0.026861
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.52562165  |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 315         |
|    time_elapsed         | 965         |
|    total_timesteps      | 1290240     |
| train/                  |             |
|    approx_kl            | 0.012057938 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.5       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.681      |
|    n_updates            | 5865        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 14.1        |
|    value_loss           | 0.199       |
-----------------------------------------
[ADAPTIVE] Episode 322 reward: -0.143791
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.47359493 |
| time/                   |            |
|    fps                  | 1336       |
|    iterations           | 316        |
|    time_elapsed         | 968        |
|    total_timesteps      | 1294336    |
| train/                  |            |
|    approx_kl            | 0.01885914 |
|    clip_fraction        | 0.177      |
|    clip_range           | 0.2        |
|    entropy_loss         | -36.6      |
|    explained_variance   | 0.817      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.735     |
|    n_updates            | 5880       |
|    policy_gradient_loss | -0.0279    |
|    std                  | 14.1       |
|    value_loss           | 0.108      |
----------------------------------------
[ADAPTIVE] Episode 323 reward: -0.025478
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.43835956  |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 317         |
|    time_elapsed         | 971         |
|    total_timesteps      | 1298432     |
| train/                  |             |
|    approx_kl            | 0.011809179 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.6       |
|    explained_variance   | 0.778       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.697      |
|    n_updates            | 5895        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 14.1        |
|    value_loss           | 0.181       |
-----------------------------------------
[ADAPTIVE] Episode 324 reward: 0.145418
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.35781002  |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 318         |
|    time_elapsed         | 974         |
|    total_timesteps      | 1302528     |
| train/                  |             |
|    approx_kl            | 0.014841551 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.6       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.695      |
|    n_updates            | 5910        |
|    policy_gradient_loss | -0.0211     |
|    std                  | 14.2        |
|    value_loss           | 0.184       |
-----------------------------------------
[ADAPTIVE] Episode 325 reward: -0.042145
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.30866614   |
| time/                   |              |
|    fps                  | 1336         |
|    iterations           | 319          |
|    time_elapsed         | 977          |
|    total_timesteps      | 1306624      |
| train/                  |              |
|    approx_kl            | 0.0131430635 |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.2          |
|    entropy_loss         | -36.6        |
|    explained_variance   | 0.715        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.704       |
|    n_updates            | 5925         |
|    policy_gradient_loss | -0.0182      |
|    std                  | 14.3         |
|    value_loss           | 0.189        |
------------------------------------------
[ADAPTIVE] Episode 326 reward: 0.027323
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.38610163  |
| time/                   |             |
|    fps                  | 1336        |
|    iterations           | 320         |
|    time_elapsed         | 981         |
|    total_timesteps      | 1310720     |
| train/                  |             |
|    approx_kl            | 0.011290864 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.7       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.683      |
|    n_updates            | 5940        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 14.3        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 327 reward: -0.029077
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.34041157  |
| time/                   |             |
|    fps                  | 1335        |
|    iterations           | 321         |
|    time_elapsed         | 984         |
|    total_timesteps      | 1314816     |
| train/                  |             |
|    approx_kl            | 0.012298307 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.7       |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.672      |
|    n_updates            | 5955        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 14.4        |
|    value_loss           | 0.196       |
-----------------------------------------
[ADAPTIVE] Episode 328 reward: -0.049524
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46192655  |
| time/                   |             |
|    fps                  | 1335        |
|    iterations           | 322         |
|    time_elapsed         | 987         |
|    total_timesteps      | 1318912     |
| train/                  |             |
|    approx_kl            | 0.010879998 |
|    clip_fraction        | 0.0948      |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.8       |
|    explained_variance   | 0.795       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.689      |
|    n_updates            | 5970        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 14.4        |
|    value_loss           | 0.18        |
-----------------------------------------
[ADAPTIVE] Episode 329 reward: -0.039220
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.402441    |
| time/                   |             |
|    fps                  | 1334        |
|    iterations           | 323         |
|    time_elapsed         | 991         |
|    total_timesteps      | 1323008     |
| train/                  |             |
|    approx_kl            | 0.011796668 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.8       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.658      |
|    n_updates            | 5985        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 14.5        |
|    value_loss           | 0.184       |
-----------------------------------------
[ADAPTIVE] Episode 330 reward: -0.032578
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.49432015  |
| time/                   |             |
|    fps                  | 1334        |
|    iterations           | 324         |
|    time_elapsed         | 994         |
|    total_timesteps      | 1327104     |
| train/                  |             |
|    approx_kl            | 0.011060895 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.8       |
|    explained_variance   | 0.731       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.699      |
|    n_updates            | 6000        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 14.5        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 331 reward: -0.001879
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6612355   |
| time/                   |             |
|    fps                  | 1334        |
|    iterations           | 325         |
|    time_elapsed         | 997         |
|    total_timesteps      | 1331200     |
| train/                  |             |
|    approx_kl            | 0.017533986 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.9       |
|    explained_variance   | 0.651       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.693      |
|    n_updates            | 6015        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 14.6        |
|    value_loss           | 0.168       |
-----------------------------------------
[ADAPTIVE] Episode 332 reward: 0.065454
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6398709   |
| time/                   |             |
|    fps                  | 1334        |
|    iterations           | 326         |
|    time_elapsed         | 1000        |
|    total_timesteps      | 1335296     |
| train/                  |             |
|    approx_kl            | 0.016234025 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.9       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.736      |
|    n_updates            | 6030        |
|    policy_gradient_loss | -0.019      |
|    std                  | 14.7        |
|    value_loss           | 0.0938      |
-----------------------------------------
[ADAPTIVE] Episode 333 reward: 0.011729
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.70043695  |
| time/                   |             |
|    fps                  | 1333        |
|    iterations           | 327         |
|    time_elapsed         | 1004        |
|    total_timesteps      | 1339392     |
| train/                  |             |
|    approx_kl            | 0.011432104 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.9       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.706      |
|    n_updates            | 6045        |
|    policy_gradient_loss | -0.0229     |
|    std                  | 14.7        |
|    value_loss           | 0.147       |
-----------------------------------------
[ADAPTIVE] Episode 334 reward: 0.054243
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.6858498  |
| time/                   |            |
|    fps                  | 1334       |
|    iterations           | 328        |
|    time_elapsed         | 1006       |
|    total_timesteps      | 1343488    |
| train/                  |            |
|    approx_kl            | 0.01267655 |
|    clip_fraction        | 0.107      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37        |
|    explained_variance   | 0.739      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.673     |
|    n_updates            | 6060       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 14.8       |
|    value_loss           | 0.235      |
----------------------------------------
[ADAPTIVE] Episode 335 reward: 0.014369
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7628378   |
| time/                   |             |
|    fps                  | 1333        |
|    iterations           | 329         |
|    time_elapsed         | 1010        |
|    total_timesteps      | 1347584     |
| train/                  |             |
|    approx_kl            | 0.013871861 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37         |
|    explained_variance   | 0.638       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.694      |
|    n_updates            | 6075        |
|    policy_gradient_loss | -0.0242     |
|    std                  | 14.9        |
|    value_loss           | 0.211       |
-----------------------------------------
[ADAPTIVE] Episode 336 reward: -0.018676
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.68652457  |
| time/                   |             |
|    fps                  | 1333        |
|    iterations           | 330         |
|    time_elapsed         | 1013        |
|    total_timesteps      | 1351680     |
| train/                  |             |
|    approx_kl            | 0.010973491 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.1       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.678      |
|    n_updates            | 6090        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 14.9        |
|    value_loss           | 0.257       |
-----------------------------------------
[ADAPTIVE] Episode 337 reward: 0.040600
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8115589   |
| time/                   |             |
|    fps                  | 1333        |
|    iterations           | 331         |
|    time_elapsed         | 1016        |
|    total_timesteps      | 1355776     |
| train/                  |             |
|    approx_kl            | 0.011032409 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.1       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.709      |
|    n_updates            | 6105        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 15          |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 338 reward: 0.023493
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.78925896  |
| time/                   |             |
|    fps                  | 1333        |
|    iterations           | 332         |
|    time_elapsed         | 1020        |
|    total_timesteps      | 1359872     |
| train/                  |             |
|    approx_kl            | 0.014234094 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.1       |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.725      |
|    n_updates            | 6120        |
|    policy_gradient_loss | -0.0229     |
|    std                  | 15.1        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 339 reward: -0.081761
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7300051    |
| time/                   |              |
|    fps                  | 1333         |
|    iterations           | 333          |
|    time_elapsed         | 1023         |
|    total_timesteps      | 1363968      |
| train/                  |              |
|    approx_kl            | 0.0124875605 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.2          |
|    entropy_loss         | -37.2        |
|    explained_variance   | 0.753        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.684       |
|    n_updates            | 6135         |
|    policy_gradient_loss | -0.0192      |
|    std                  | 15.1         |
|    value_loss           | 0.26         |
------------------------------------------
[ADAPTIVE] Episode 340 reward: 0.072908
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.54560775 |
| time/                   |            |
|    fps                  | 1332       |
|    iterations           | 334        |
|    time_elapsed         | 1026       |
|    total_timesteps      | 1368064    |
| train/                  |            |
|    approx_kl            | 0.0139331  |
|    clip_fraction        | 0.0942     |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.2      |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.693     |
|    n_updates            | 6150       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 15.1       |
|    value_loss           | 0.203      |
----------------------------------------
[ADAPTIVE] Episode 341 reward: -0.075789
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.39825654  |
| time/                   |             |
|    fps                  | 1332        |
|    iterations           | 335         |
|    time_elapsed         | 1029        |
|    total_timesteps      | 1372160     |
| train/                  |             |
|    approx_kl            | 0.012334656 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.2       |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.744      |
|    n_updates            | 6165        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 15.2        |
|    value_loss           | 0.0901      |
-----------------------------------------
[ADAPTIVE] Episode 342 reward: 0.027564
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.55911434  |
| time/                   |             |
|    fps                  | 1332        |
|    iterations           | 336         |
|    time_elapsed         | 1033        |
|    total_timesteps      | 1376256     |
| train/                  |             |
|    approx_kl            | 0.011114486 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.2       |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.735      |
|    n_updates            | 6180        |
|    policy_gradient_loss | -0.0242     |
|    std                  | 15.2        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 343 reward: -0.030296
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.36204776  |
| time/                   |             |
|    fps                  | 1332        |
|    iterations           | 337         |
|    time_elapsed         | 1036        |
|    total_timesteps      | 1380352     |
| train/                  |             |
|    approx_kl            | 0.007353646 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.3       |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.694      |
|    n_updates            | 6195        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 15.3        |
|    value_loss           | 0.177       |
-----------------------------------------
[ADAPTIVE] Episode 344 reward: -0.135680
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.35482648 |
| time/                   |            |
|    fps                  | 1331       |
|    iterations           | 338        |
|    time_elapsed         | 1039       |
|    total_timesteps      | 1384448    |
| train/                  |            |
|    approx_kl            | 0.00935682 |
|    clip_fraction        | 0.115      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.3      |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.732     |
|    n_updates            | 6210       |
|    policy_gradient_loss | -0.0176    |
|    std                  | 15.3       |
|    value_loss           | 0.103      |
----------------------------------------
[ADAPTIVE] Episode 345 reward: 0.018743
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.5174766  |
| time/                   |            |
|    fps                  | 1330       |
|    iterations           | 339        |
|    time_elapsed         | 1043       |
|    total_timesteps      | 1388544    |
| train/                  |            |
|    approx_kl            | 0.01486549 |
|    clip_fraction        | 0.115      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.3      |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.651     |
|    n_updates            | 6225       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 15.4       |
|    value_loss           | 0.294      |
----------------------------------------
[ADAPTIVE] Episode 346 reward: -0.087729
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46310794  |
| time/                   |             |
|    fps                  | 1329        |
|    iterations           | 340         |
|    time_elapsed         | 1047        |
|    total_timesteps      | 1392640     |
| train/                  |             |
|    approx_kl            | 0.010007137 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.4       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.697      |
|    n_updates            | 6240        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 15.4        |
|    value_loss           | 0.134       |
-----------------------------------------
[ADAPTIVE] Episode 347 reward: -0.040842
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5528716   |
| time/                   |             |
|    fps                  | 1329        |
|    iterations           | 341         |
|    time_elapsed         | 1050        |
|    total_timesteps      | 1396736     |
| train/                  |             |
|    approx_kl            | 0.014500398 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.4       |
|    explained_variance   | 0.675       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.675      |
|    n_updates            | 6255        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 15.5        |
|    value_loss           | 0.213       |
-----------------------------------------
[ADAPTIVE] Episode 348 reward: 0.020470
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.58956647   |
| time/                   |              |
|    fps                  | 1328         |
|    iterations           | 342          |
|    time_elapsed         | 1054         |
|    total_timesteps      | 1400832      |
| train/                  |              |
|    approx_kl            | 0.0101740565 |
|    clip_fraction        | 0.127        |
|    clip_range           | 0.2          |
|    entropy_loss         | -37.4        |
|    explained_variance   | 0.809        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.747       |
|    n_updates            | 6270         |
|    policy_gradient_loss | -0.0191      |
|    std                  | 15.6         |
|    value_loss           | 0.0963       |
------------------------------------------
[ADAPTIVE] Episode 349 reward: 0.024539
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5837481   |
| time/                   |             |
|    fps                  | 1328        |
|    iterations           | 343         |
|    time_elapsed         | 1057        |
|    total_timesteps      | 1404928     |
| train/                  |             |
|    approx_kl            | 0.010466873 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.5       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.741      |
|    n_updates            | 6285        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 15.7        |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 350 reward: 0.008730
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.63302094  |
| time/                   |             |
|    fps                  | 1328        |
|    iterations           | 344         |
|    time_elapsed         | 1060        |
|    total_timesteps      | 1409024     |
| train/                  |             |
|    approx_kl            | 0.013393091 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.5       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.722      |
|    n_updates            | 6300        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 15.8        |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 351 reward: -0.025269
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.6644669  |
| time/                   |            |
|    fps                  | 1328       |
|    iterations           | 345        |
|    time_elapsed         | 1064       |
|    total_timesteps      | 1413120    |
| train/                  |            |
|    approx_kl            | 0.01182572 |
|    clip_fraction        | 0.141      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.6      |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.699     |
|    n_updates            | 6315       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 15.8       |
|    value_loss           | 0.222      |
----------------------------------------
[ADAPTIVE] Episode 352 reward: -0.026178
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8413757   |
| time/                   |             |
|    fps                  | 1327        |
|    iterations           | 346         |
|    time_elapsed         | 1067        |
|    total_timesteps      | 1417216     |
| train/                  |             |
|    approx_kl            | 0.017046873 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.6       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.722      |
|    n_updates            | 6330        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 15.9        |
|    value_loss           | 0.158       |
-----------------------------------------
[ADAPTIVE] Episode 353 reward: -0.017715
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.82943267  |
| time/                   |             |
|    fps                  | 1326        |
|    iterations           | 347         |
|    time_elapsed         | 1071        |
|    total_timesteps      | 1421312     |
| train/                  |             |
|    approx_kl            | 0.015201084 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.7       |
|    explained_variance   | 0.846       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.755      |
|    n_updates            | 6345        |
|    policy_gradient_loss | -0.0258     |
|    std                  | 16          |
|    value_loss           | 0.0888      |
-----------------------------------------
[ADAPTIVE] Episode 354 reward: 0.039925
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7356543   |
| time/                   |             |
|    fps                  | 1326        |
|    iterations           | 348         |
|    time_elapsed         | 1074        |
|    total_timesteps      | 1425408     |
| train/                  |             |
|    approx_kl            | 0.011607219 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.7       |
|    explained_variance   | 0.678       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.694      |
|    n_updates            | 6360        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 16.1        |
|    value_loss           | 0.259       |
-----------------------------------------
[ADAPTIVE] Episode 355 reward: -0.041412
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.85356283 |
| time/                   |            |
|    fps                  | 1326       |
|    iterations           | 349        |
|    time_elapsed         | 1077       |
|    total_timesteps      | 1429504    |
| train/                  |            |
|    approx_kl            | 0.01455293 |
|    clip_fraction        | 0.144      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.8      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.741     |
|    n_updates            | 6375       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 16.1       |
|    value_loss           | 0.137      |
----------------------------------------
[ADAPTIVE] Episode 356 reward: 0.000478
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8632494   |
| time/                   |             |
|    fps                  | 1325        |
|    iterations           | 350         |
|    time_elapsed         | 1081        |
|    total_timesteps      | 1433600     |
| train/                  |             |
|    approx_kl            | 0.012066615 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.8       |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.708      |
|    n_updates            | 6390        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 16.2        |
|    value_loss           | 0.201       |
-----------------------------------------
[ADAPTIVE] Episode 357 reward: 0.002484
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.80397964 |
| time/                   |            |
|    fps                  | 1325       |
|    iterations           | 351        |
|    time_elapsed         | 1084       |
|    total_timesteps      | 1437696    |
| train/                  |            |
|    approx_kl            | 0.01360031 |
|    clip_fraction        | 0.158      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.8      |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.762     |
|    n_updates            | 6405       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 16.2       |
|    value_loss           | 0.113      |
----------------------------------------
[ADAPTIVE] Episode 358 reward: 0.111074
[ADAPTIVE] Episode 359 reward: -0.062464
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.5733802  |
| time/                   |            |
|    fps                  | 1325       |
|    iterations           | 352        |
|    time_elapsed         | 1088       |
|    total_timesteps      | 1441792    |
| train/                  |            |
|    approx_kl            | 0.01109786 |
|    clip_fraction        | 0.126      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.9      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.707     |
|    n_updates            | 6420       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 16.3       |
|    value_loss           | 0.19       |
----------------------------------------
[ADAPTIVE] Episode 360 reward: -0.024882
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.52307504  |
| time/                   |             |
|    fps                  | 1324        |
|    iterations           | 353         |
|    time_elapsed         | 1091        |
|    total_timesteps      | 1445888     |
| train/                  |             |
|    approx_kl            | 0.010958552 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.9       |
|    explained_variance   | 0.831       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.727      |
|    n_updates            | 6435        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 16.4        |
|    value_loss           | 0.19        |
-----------------------------------------
[ADAPTIVE] Episode 361 reward: -0.085410
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.556273    |
| time/                   |             |
|    fps                  | 1324        |
|    iterations           | 354         |
|    time_elapsed         | 1095        |
|    total_timesteps      | 1449984     |
| train/                  |             |
|    approx_kl            | 0.011526884 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.9       |
|    explained_variance   | 0.788       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.729      |
|    n_updates            | 6450        |
|    policy_gradient_loss | -0.016      |
|    std                  | 16.5        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 362 reward: -0.009327
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.72467786  |
| time/                   |             |
|    fps                  | 1323        |
|    iterations           | 355         |
|    time_elapsed         | 1098        |
|    total_timesteps      | 1454080     |
| train/                  |             |
|    approx_kl            | 0.012986817 |
|    clip_fraction        | 0.0991      |
|    clip_range           | 0.2         |
|    entropy_loss         | -38         |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.711      |
|    n_updates            | 6465        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 16.5        |
|    value_loss           | 0.186       |
-----------------------------------------
[ADAPTIVE] Episode 363 reward: 0.044959
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6232559   |
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 356         |
|    time_elapsed         | 1102        |
|    total_timesteps      | 1458176     |
| train/                  |             |
|    approx_kl            | 0.011330214 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38         |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.763      |
|    n_updates            | 6480        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 16.6        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 364 reward: -0.028358
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.6398261  |
| time/                   |            |
|    fps                  | 1322       |
|    iterations           | 357        |
|    time_elapsed         | 1105       |
|    total_timesteps      | 1462272    |
| train/                  |            |
|    approx_kl            | 0.01115546 |
|    clip_fraction        | 0.139      |
|    clip_range           | 0.2        |
|    entropy_loss         | -38.1      |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.707     |
|    n_updates            | 6495       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 16.7       |
|    value_loss           | 0.19       |
----------------------------------------
[ADAPTIVE] Episode 365 reward: 0.037907
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.569101    |
| time/                   |             |
|    fps                  | 1322        |
|    iterations           | 358         |
|    time_elapsed         | 1108        |
|    total_timesteps      | 1466368     |
| train/                  |             |
|    approx_kl            | 0.009428414 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.1       |
|    explained_variance   | 0.776       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.742      |
|    n_updates            | 6510        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 16.8        |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 366 reward: 0.023105
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.72053385  |
| time/                   |             |
|    fps                  | 1321        |
|    iterations           | 359         |
|    time_elapsed         | 1112        |
|    total_timesteps      | 1470464     |
| train/                  |             |
|    approx_kl            | 0.009527321 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.2       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.727      |
|    n_updates            | 6525        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 16.9        |
|    value_loss           | 0.159       |
-----------------------------------------
[ADAPTIVE] Episode 367 reward: 0.034999
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8546358   |
| time/                   |             |
|    fps                  | 1321        |
|    iterations           | 360         |
|    time_elapsed         | 1116        |
|    total_timesteps      | 1474560     |
| train/                  |             |
|    approx_kl            | 0.010011703 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.2       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.714      |
|    n_updates            | 6540        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 17          |
|    value_loss           | 0.245       |
-----------------------------------------
[ADAPTIVE] Episode 368 reward: -0.033540
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.58450055  |
| time/                   |             |
|    fps                  | 1320        |
|    iterations           | 361         |
|    time_elapsed         | 1120        |
|    total_timesteps      | 1478656     |
| train/                  |             |
|    approx_kl            | 0.011111675 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.3       |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.69       |
|    n_updates            | 6555        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 17.1        |
|    value_loss           | 0.258       |
-----------------------------------------
[ADAPTIVE] Episode 369 reward: -0.018358
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5122268   |
| time/                   |             |
|    fps                  | 1319        |
|    iterations           | 362         |
|    time_elapsed         | 1123        |
|    total_timesteps      | 1482752     |
| train/                  |             |
|    approx_kl            | 0.012978593 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.3       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.722      |
|    n_updates            | 6570        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 17.2        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 370 reward: -0.005266
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.28314757  |
| time/                   |             |
|    fps                  | 1319        |
|    iterations           | 363         |
|    time_elapsed         | 1127        |
|    total_timesteps      | 1486848     |
| train/                  |             |
|    approx_kl            | 0.011502727 |
|    clip_fraction        | 0.0979      |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.4       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.76       |
|    n_updates            | 6585        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 17.3        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 371 reward: 0.026790
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.492351    |
| time/                   |             |
|    fps                  | 1318        |
|    iterations           | 364         |
|    time_elapsed         | 1131        |
|    total_timesteps      | 1490944     |
| train/                  |             |
|    approx_kl            | 0.010286311 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.4       |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.734      |
|    n_updates            | 6600        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 17.3        |
|    value_loss           | 0.12        |
-----------------------------------------
[ADAPTIVE] Episode 372 reward: 0.024395
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47596863  |
| time/                   |             |
|    fps                  | 1318        |
|    iterations           | 365         |
|    time_elapsed         | 1134        |
|    total_timesteps      | 1495040     |
| train/                  |             |
|    approx_kl            | 0.011765914 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.4       |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.731      |
|    n_updates            | 6615        |
|    policy_gradient_loss | -0.021      |
|    std                  | 17.4        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 373 reward: 0.031790
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.25364295  |
| time/                   |             |
|    fps                  | 1317        |
|    iterations           | 366         |
|    time_elapsed         | 1137        |
|    total_timesteps      | 1499136     |
| train/                  |             |
|    approx_kl            | 0.011049997 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.5       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.71       |
|    n_updates            | 6630        |
|    policy_gradient_loss | -0.0174     |
|    std                  | 17.5        |
|    value_loss           | 0.237       |
-----------------------------------------
[ADAPTIVE] Episode 374 reward: -0.021702
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.1684207   |
| time/                   |             |
|    fps                  | 1317        |
|    iterations           | 367         |
|    time_elapsed         | 1141        |
|    total_timesteps      | 1503232     |
| train/                  |             |
|    approx_kl            | 0.009817486 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.5       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.736      |
|    n_updates            | 6645        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 17.5        |
|    value_loss           | 0.19        |
-----------------------------------------
[ADAPTIVE] Episode 375 reward: -0.005143
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.30233276 |
| time/                   |            |
|    fps                  | 1317       |
|    iterations           | 368        |
|    time_elapsed         | 1144       |
|    total_timesteps      | 1507328    |
| train/                  |            |
|    approx_kl            | 0.01020213 |
|    clip_fraction        | 0.123      |
|    clip_range           | 0.2        |
|    entropy_loss         | -38.6      |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.743     |
|    n_updates            | 6660       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 17.6       |
|    value_loss           | 0.143      |
----------------------------------------
[ADAPTIVE] Episode 376 reward: 0.015964
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4787761   |
| time/                   |             |
|    fps                  | 1316        |
|    iterations           | 369         |
|    time_elapsed         | 1148        |
|    total_timesteps      | 1511424     |
| train/                  |             |
|    approx_kl            | 0.010379759 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.6       |
|    explained_variance   | 0.726       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.74       |
|    n_updates            | 6675        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 17.7        |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 377 reward: -0.045317
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.42674115  |
| time/                   |             |
|    fps                  | 1316        |
|    iterations           | 370         |
|    time_elapsed         | 1151        |
|    total_timesteps      | 1515520     |
| train/                  |             |
|    approx_kl            | 0.010436954 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.6       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.682      |
|    n_updates            | 6690        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 17.7        |
|    value_loss           | 0.199       |
-----------------------------------------
[ADAPTIVE] Episode 378 reward: -0.001426
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.17598695  |
| time/                   |             |
|    fps                  | 1315        |
|    iterations           | 371         |
|    time_elapsed         | 1154        |
|    total_timesteps      | 1519616     |
| train/                  |             |
|    approx_kl            | 0.011320643 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.7       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.756      |
|    n_updates            | 6705        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 17.8        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 379 reward: -0.007437
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5022823   |
| time/                   |             |
|    fps                  | 1315        |
|    iterations           | 372         |
|    time_elapsed         | 1157        |
|    total_timesteps      | 1523712     |
| train/                  |             |
|    approx_kl            | 0.011340469 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.7       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.764      |
|    n_updates            | 6720        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 17.9        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 380 reward: -0.010553
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5089616   |
| time/                   |             |
|    fps                  | 1315        |
|    iterations           | 373         |
|    time_elapsed         | 1161        |
|    total_timesteps      | 1527808     |
| train/                  |             |
|    approx_kl            | 0.016953252 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.8       |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.718      |
|    n_updates            | 6735        |
|    policy_gradient_loss | -0.0186     |
|    std                  | 18          |
|    value_loss           | 0.155       |
-----------------------------------------
[ADAPTIVE] Episode 381 reward: -0.120645
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.4950057  |
| time/                   |            |
|    fps                  | 1314       |
|    iterations           | 374        |
|    time_elapsed         | 1165       |
|    total_timesteps      | 1531904    |
| train/                  |            |
|    approx_kl            | 0.01044848 |
|    clip_fraction        | 0.128      |
|    clip_range           | 0.2        |
|    entropy_loss         | -38.8      |
|    explained_variance   | 0.788      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.757     |
|    n_updates            | 6750       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 18.1       |
|    value_loss           | 0.127      |
----------------------------------------
[ADAPTIVE] Episode 382 reward: -0.001926
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6328643   |
| time/                   |             |
|    fps                  | 1314        |
|    iterations           | 375         |
|    time_elapsed         | 1168        |
|    total_timesteps      | 1536000     |
| train/                  |             |
|    approx_kl            | 0.012267822 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.8       |
|    explained_variance   | 0.689       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.762      |
|    n_updates            | 6765        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 18.2        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 383 reward: 0.055793
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6573627   |
| time/                   |             |
|    fps                  | 1314        |
|    iterations           | 376         |
|    time_elapsed         | 1171        |
|    total_timesteps      | 1540096     |
| train/                  |             |
|    approx_kl            | 0.012962937 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.9       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.721      |
|    n_updates            | 6780        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 18.3        |
|    value_loss           | 0.181       |
-----------------------------------------
[ADAPTIVE] Episode 384 reward: 0.002638
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8206607   |
| time/                   |             |
|    fps                  | 1313        |
|    iterations           | 377         |
|    time_elapsed         | 1175        |
|    total_timesteps      | 1544192     |
| train/                  |             |
|    approx_kl            | 0.018812576 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.9       |
|    explained_variance   | 0.778       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.756      |
|    n_updates            | 6795        |
|    policy_gradient_loss | -0.012      |
|    std                  | 18.3        |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 385 reward: -0.007923
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.6821772  |
| time/                   |            |
|    fps                  | 1313       |
|    iterations           | 378        |
|    time_elapsed         | 1179       |
|    total_timesteps      | 1548288    |
| train/                  |            |
|    approx_kl            | 0.01225478 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -38.9      |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.782     |
|    n_updates            | 6810       |
|    policy_gradient_loss | -0.0204    |
|    std                  | 18.4       |
|    value_loss           | 0.0854     |
----------------------------------------
[ADAPTIVE] Episode 386 reward: -0.093094
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.62303233   |
| time/                   |              |
|    fps                  | 1313         |
|    iterations           | 379          |
|    time_elapsed         | 1182         |
|    total_timesteps      | 1552384      |
| train/                  |              |
|    approx_kl            | 0.0107434895 |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.2          |
|    entropy_loss         | -39          |
|    explained_variance   | 0.726        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.754       |
|    n_updates            | 6825         |
|    policy_gradient_loss | -0.015       |
|    std                  | 18.4         |
|    value_loss           | 0.138        |
------------------------------------------
[ADAPTIVE] Episode 387 reward: -0.093813
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.80594194  |
| time/                   |             |
|    fps                  | 1312        |
|    iterations           | 380         |
|    time_elapsed         | 1185        |
|    total_timesteps      | 1556480     |
| train/                  |             |
|    approx_kl            | 0.008233743 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39         |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.758      |
|    n_updates            | 6840        |
|    policy_gradient_loss | -0.0198     |
|    std                  | 18.5        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 388 reward: 0.019365
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9164793   |
| time/                   |             |
|    fps                  | 1312        |
|    iterations           | 381         |
|    time_elapsed         | 1188        |
|    total_timesteps      | 1560576     |
| train/                  |             |
|    approx_kl            | 0.014275367 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.1       |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.747      |
|    n_updates            | 6855        |
|    policy_gradient_loss | -0.0188     |
|    std                  | 18.6        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 389 reward: 0.074352
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8891942   |
| time/                   |             |
|    fps                  | 1312        |
|    iterations           | 382         |
|    time_elapsed         | 1192        |
|    total_timesteps      | 1564672     |
| train/                  |             |
|    approx_kl            | 0.010906063 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.1       |
|    explained_variance   | 0.735       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.74       |
|    n_updates            | 6870        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 18.7        |
|    value_loss           | 0.191       |
-----------------------------------------
[ADAPTIVE] Episode 390 reward: -0.023657
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.71995634  |
| time/                   |             |
|    fps                  | 1312        |
|    iterations           | 383         |
|    time_elapsed         | 1195        |
|    total_timesteps      | 1568768     |
| train/                  |             |
|    approx_kl            | 0.012637541 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.2       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.777      |
|    n_updates            | 6885        |
|    policy_gradient_loss | -0.0236     |
|    std                  | 18.9        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 391 reward: -0.007457
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7080165   |
| time/                   |             |
|    fps                  | 1311        |
|    iterations           | 384         |
|    time_elapsed         | 1199        |
|    total_timesteps      | 1572864     |
| train/                  |             |
|    approx_kl            | 0.010437487 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.2       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.727      |
|    n_updates            | 6900        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 18.9        |
|    value_loss           | 0.218       |
-----------------------------------------
[ADAPTIVE] Episode 392 reward: 0.000762
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6657772   |
| time/                   |             |
|    fps                  | 1311        |
|    iterations           | 385         |
|    time_elapsed         | 1202        |
|    total_timesteps      | 1576960     |
| train/                  |             |
|    approx_kl            | 0.011067781 |
|    clip_fraction        | 0.0798      |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.2       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.718      |
|    n_updates            | 6915        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 19          |
|    value_loss           | 0.243       |
-----------------------------------------
[ADAPTIVE] Episode 393 reward: 0.037691
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.42997062  |
| time/                   |             |
|    fps                  | 1310        |
|    iterations           | 386         |
|    time_elapsed         | 1206        |
|    total_timesteps      | 1581056     |
| train/                  |             |
|    approx_kl            | 0.009787272 |
|    clip_fraction        | 0.0965      |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.3       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.762      |
|    n_updates            | 6930        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 19          |
|    value_loss           | 0.145       |
-----------------------------------------
[ADAPTIVE] Episode 394 reward: -0.037729
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.250873   |
| time/                   |            |
|    fps                  | 1310       |
|    iterations           | 387        |
|    time_elapsed         | 1209       |
|    total_timesteps      | 1585152    |
| train/                  |            |
|    approx_kl            | 0.00939272 |
|    clip_fraction        | 0.0877     |
|    clip_range           | 0.2        |
|    entropy_loss         | -39.3      |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.745     |
|    n_updates            | 6945       |
|    policy_gradient_loss | -0.0145    |
|    std                  | 19.1       |
|    value_loss           | 0.182      |
----------------------------------------
[ADAPTIVE] Episode 395 reward: -0.010298
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.37668878  |
| time/                   |             |
|    fps                  | 1309        |
|    iterations           | 388         |
|    time_elapsed         | 1213        |
|    total_timesteps      | 1589248     |
| train/                  |             |
|    approx_kl            | 0.012132449 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.3       |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.755      |
|    n_updates            | 6960        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 19.2        |
|    value_loss           | 0.188       |
-----------------------------------------
[ADAPTIVE] Episode 396 reward: 0.166135
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.44287992  |
| time/                   |             |
|    fps                  | 1309        |
|    iterations           | 389         |
|    time_elapsed         | 1217        |
|    total_timesteps      | 1593344     |
| train/                  |             |
|    approx_kl            | 0.010634356 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.4       |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.762      |
|    n_updates            | 6975        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 19.3        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 397 reward: 0.023325
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6343596   |
| time/                   |             |
|    fps                  | 1308        |
|    iterations           | 390         |
|    time_elapsed         | 1220        |
|    total_timesteps      | 1597440     |
| train/                  |             |
|    approx_kl            | 0.016578738 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.4       |
|    explained_variance   | 0.713       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.749      |
|    n_updates            | 6990        |
|    policy_gradient_loss | -0.0188     |
|    std                  | 19.4        |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 398 reward: 0.060133
/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  UserWarning,
Eval num_timesteps=1600000, episode_reward=2.46 +/- 0.00
Episode length: 251.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 251         |
|    mean_reward          | 2.46        |
| time/                   |             |
|    total_timesteps      | 1600000     |
| train/                  |             |
|    approx_kl            | 0.009238403 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.5       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.74       |
|    n_updates            | 7005        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 19.5        |
|    value_loss           | 0.149       |
-----------------------------------------
New best mean reward!
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 251        |
|    ep_rew_mean     | 0.66883016 |
| time/              |            |
|    fps             | 1301       |
|    iterations      | 391        |
|    time_elapsed    | 1230       |
|    total_timesteps | 1601536    |
-----------------------------------
[ADAPTIVE] Episode 399 reward: 0.004577
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.843227     |
| time/                   |              |
|    fps                  | 1301         |
|    iterations           | 392          |
|    time_elapsed         | 1233         |
|    total_timesteps      | 1605632      |
| train/                  |              |
|    approx_kl            | 0.0129914535 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.2          |
|    entropy_loss         | -39.5        |
|    explained_variance   | 0.721        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.739       |
|    n_updates            | 7020         |
|    policy_gradient_loss | -0.0201      |
|    std                  | 19.6         |
|    value_loss           | 0.163        |
------------------------------------------
[ADAPTIVE] Episode 400 reward: 0.032787
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9294305   |
| time/                   |             |
|    fps                  | 1301        |
|    iterations           | 393         |
|    time_elapsed         | 1237        |
|    total_timesteps      | 1609728     |
| train/                  |             |
|    approx_kl            | 0.009292015 |
|    clip_fraction        | 0.0981      |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.5       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.742      |
|    n_updates            | 7035        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 19.6        |
|    value_loss           | 0.168       |
-----------------------------------------
[ADAPTIVE] Episode 401 reward: -0.073117
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.68364096  |
| time/                   |             |
|    fps                  | 1301        |
|    iterations           | 394         |
|    time_elapsed         | 1240        |
|    total_timesteps      | 1613824     |
| train/                  |             |
|    approx_kl            | 0.009373689 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.6       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.773      |
|    n_updates            | 7050        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 19.7        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 402 reward: 0.069357
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5034046   |
| time/                   |             |
|    fps                  | 1300        |
|    iterations           | 395         |
|    time_elapsed         | 1243        |
|    total_timesteps      | 1617920     |
| train/                  |             |
|    approx_kl            | 0.009462311 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.6       |
|    explained_variance   | 0.627       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.726      |
|    n_updates            | 7065        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 19.8        |
|    value_loss           | 0.203       |
-----------------------------------------
[ADAPTIVE] Episode 403 reward: 0.090878
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47725108  |
| time/                   |             |
|    fps                  | 1300        |
|    iterations           | 396         |
|    time_elapsed         | 1247        |
|    total_timesteps      | 1622016     |
| train/                  |             |
|    approx_kl            | 0.013089692 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.6       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.789      |
|    n_updates            | 7080        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 19.9        |
|    value_loss           | 0.119       |
-----------------------------------------
[ADAPTIVE] Episode 404 reward: 0.006355
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.44380012 |
| time/                   |            |
|    fps                  | 1300       |
|    iterations           | 397        |
|    time_elapsed         | 1250       |
|    total_timesteps      | 1626112    |
| train/                  |            |
|    approx_kl            | 0.01349001 |
|    clip_fraction        | 0.152      |
|    clip_range           | 0.2        |
|    entropy_loss         | -39.7      |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.756     |
|    n_updates            | 7095       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 20         |
|    value_loss           | 0.191      |
----------------------------------------
[ADAPTIVE] Episode 405 reward: -0.035525
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.3057156    |
| time/                   |              |
|    fps                  | 1300         |
|    iterations           | 398          |
|    time_elapsed         | 1253         |
|    total_timesteps      | 1630208      |
| train/                  |              |
|    approx_kl            | 0.0086869765 |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.2          |
|    entropy_loss         | -39.7        |
|    explained_variance   | 0.773        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.754       |
|    n_updates            | 7110         |
|    policy_gradient_loss | -0.0188      |
|    std                  | 20.1         |
|    value_loss           | 0.16         |
------------------------------------------
[ADAPTIVE] Episode 406 reward: -0.101867
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.32981873  |
| time/                   |             |
|    fps                  | 1300        |
|    iterations           | 399         |
|    time_elapsed         | 1256        |
|    total_timesteps      | 1634304     |
| train/                  |             |
|    approx_kl            | 0.010868846 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.8       |
|    explained_variance   | 0.696       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.759      |
|    n_updates            | 7125        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 20.2        |
|    value_loss           | 0.196       |
-----------------------------------------
[ADAPTIVE] Episode 407 reward: 0.076395
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.39043948  |
| time/                   |             |
|    fps                  | 1299        |
|    iterations           | 400         |
|    time_elapsed         | 1260        |
|    total_timesteps      | 1638400     |
| train/                  |             |
|    approx_kl            | 0.009790232 |
|    clip_fraction        | 0.0952      |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.8       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.743      |
|    n_updates            | 7140        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 20.3        |
|    value_loss           | 0.21        |
-----------------------------------------
[ADAPTIVE] Episode 408 reward: -0.111303
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5911678   |
| time/                   |             |
|    fps                  | 1299        |
|    iterations           | 401         |
|    time_elapsed         | 1264        |
|    total_timesteps      | 1642496     |
| train/                  |             |
|    approx_kl            | 0.010377716 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.9       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.804      |
|    n_updates            | 7155        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 20.4        |
|    value_loss           | 0.0829      |
-----------------------------------------
[ADAPTIVE] Episode 409 reward: 0.142205
[ADAPTIVE] Episode 410 reward: -0.003866
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.64161897  |
| time/                   |             |
|    fps                  | 1298        |
|    iterations           | 402         |
|    time_elapsed         | 1267        |
|    total_timesteps      | 1646592     |
| train/                  |             |
|    approx_kl            | 0.012349214 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -40         |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.78       |
|    n_updates            | 7170        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 20.6        |
|    value_loss           | 0.0781      |
-----------------------------------------
[ADAPTIVE] Episode 411 reward: -3.104537
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6814238   |
| time/                   |             |
|    fps                  | 1298        |
|    iterations           | 403         |
|    time_elapsed         | 1271        |
|    total_timesteps      | 1650688     |
| train/                  |             |
|    approx_kl            | 0.007320078 |
|    clip_fraction        | 0.0756      |
|    clip_range           | 0.2         |
|    entropy_loss         | -40         |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.737      |
|    n_updates            | 7185        |
|    policy_gradient_loss | -0.017      |
|    std                  | 20.6        |
|    value_loss           | 0.18        |
-----------------------------------------
[ADAPTIVE] Episode 412 reward: 0.094742
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46482423  |
| time/                   |             |
|    fps                  | 1298        |
|    iterations           | 404         |
|    time_elapsed         | 1274        |
|    total_timesteps      | 1654784     |
| train/                  |             |
|    approx_kl            | 0.011318171 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40         |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.777      |
|    n_updates            | 7200        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 20.8        |
|    value_loss           | 0.155       |
-----------------------------------------
[ADAPTIVE] Episode 413 reward: -0.057173
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.51971406   |
| time/                   |              |
|    fps                  | 1298         |
|    iterations           | 405          |
|    time_elapsed         | 1277         |
|    total_timesteps      | 1658880      |
| train/                  |              |
|    approx_kl            | 0.0123752225 |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.2          |
|    entropy_loss         | -40.1        |
|    explained_variance   | 0.746        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.778       |
|    n_updates            | 7215         |
|    policy_gradient_loss | -0.0167      |
|    std                  | 20.9         |
|    value_loss           | 0.131        |
------------------------------------------
[ADAPTIVE] Episode 414 reward: 0.031781
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4202795   |
| time/                   |             |
|    fps                  | 1297        |
|    iterations           | 406         |
|    time_elapsed         | 1281        |
|    total_timesteps      | 1662976     |
| train/                  |             |
|    approx_kl            | 0.010462302 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.1       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.779      |
|    n_updates            | 7230        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 21          |
|    value_loss           | 0.12        |
-----------------------------------------
[ADAPTIVE] Episode 415 reward: 0.094435
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46371347  |
| time/                   |             |
|    fps                  | 1297        |
|    iterations           | 407         |
|    time_elapsed         | 1284        |
|    total_timesteps      | 1667072     |
| train/                  |             |
|    approx_kl            | 0.008893477 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.2       |
|    explained_variance   | 0.662       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.763      |
|    n_updates            | 7245        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 21.1        |
|    value_loss           | 0.23        |
-----------------------------------------
[ADAPTIVE] Episode 416 reward: 0.026671
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.65892416   |
| time/                   |              |
|    fps                  | 1297         |
|    iterations           | 408          |
|    time_elapsed         | 1288         |
|    total_timesteps      | 1671168      |
| train/                  |              |
|    approx_kl            | 0.0071534766 |
|    clip_fraction        | 0.0669       |
|    clip_range           | 0.2          |
|    entropy_loss         | -40.2        |
|    explained_variance   | 0.663        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.771       |
|    n_updates            | 7260         |
|    policy_gradient_loss | -0.0141      |
|    std                  | 21.2         |
|    value_loss           | 0.182        |
------------------------------------------
[ADAPTIVE] Episode 417 reward: 0.093296
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6228365   |
| time/                   |             |
|    fps                  | 1297        |
|    iterations           | 409         |
|    time_elapsed         | 1291        |
|    total_timesteps      | 1675264     |
| train/                  |             |
|    approx_kl            | 0.015581954 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.3       |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.78       |
|    n_updates            | 7275        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 21.3        |
|    value_loss           | 0.157       |
-----------------------------------------
[ADAPTIVE] Episode 418 reward: 0.073247
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.69895864  |
| time/                   |             |
|    fps                  | 1297        |
|    iterations           | 410         |
|    time_elapsed         | 1294        |
|    total_timesteps      | 1679360     |
| train/                  |             |
|    approx_kl            | 0.009134233 |
|    clip_fraction        | 0.0902      |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.3       |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.776      |
|    n_updates            | 7290        |
|    policy_gradient_loss | -0.0134     |
|    std                  | 21.4        |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 419 reward: -0.029503
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5786844   |
| time/                   |             |
|    fps                  | 1296        |
|    iterations           | 411         |
|    time_elapsed         | 1298        |
|    total_timesteps      | 1683456     |
| train/                  |             |
|    approx_kl            | 0.010783156 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.4       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.793      |
|    n_updates            | 7305        |
|    policy_gradient_loss | -0.0151     |
|    std                  | 21.5        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 420 reward: -0.039101
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6572141   |
| time/                   |             |
|    fps                  | 1297        |
|    iterations           | 412         |
|    time_elapsed         | 1301        |
|    total_timesteps      | 1687552     |
| train/                  |             |
|    approx_kl            | 0.007715515 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.4       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.762      |
|    n_updates            | 7320        |
|    policy_gradient_loss | -0.0131     |
|    std                  | 21.6        |
|    value_loss           | 0.177       |
-----------------------------------------
[ADAPTIVE] Episode 421 reward: -0.110555
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.633292    |
| time/                   |             |
|    fps                  | 1296        |
|    iterations           | 413         |
|    time_elapsed         | 1304        |
|    total_timesteps      | 1691648     |
| train/                  |             |
|    approx_kl            | 0.010752247 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.4       |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.805      |
|    n_updates            | 7335        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 21.7        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 422 reward: 0.105847
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.43537453  |
| time/                   |             |
|    fps                  | 1296        |
|    iterations           | 414         |
|    time_elapsed         | 1307        |
|    total_timesteps      | 1695744     |
| train/                  |             |
|    approx_kl            | 0.007945942 |
|    clip_fraction        | 0.095       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.5       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.756      |
|    n_updates            | 7350        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 21.8        |
|    value_loss           | 0.191       |
-----------------------------------------
[ADAPTIVE] Episode 423 reward: 0.056161
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.24537724 |
| time/                   |            |
|    fps                  | 1296       |
|    iterations           | 415        |
|    time_elapsed         | 1311       |
|    total_timesteps      | 1699840    |
| train/                  |            |
|    approx_kl            | 0.01174991 |
|    clip_fraction        | 0.118      |
|    clip_range           | 0.2        |
|    entropy_loss         | -40.5      |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.817     |
|    n_updates            | 7365       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 21.9       |
|    value_loss           | 0.0986     |
----------------------------------------
[ADAPTIVE] Episode 424 reward: 0.064282
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.2598679   |
| time/                   |             |
|    fps                  | 1295        |
|    iterations           | 416         |
|    time_elapsed         | 1314        |
|    total_timesteps      | 1703936     |
| train/                  |             |
|    approx_kl            | 0.008811867 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.6       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.782      |
|    n_updates            | 7380        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 22          |
|    value_loss           | 0.138       |
-----------------------------------------
[ADAPTIVE] Episode 425 reward: 0.020636
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.3404305   |
| time/                   |             |
|    fps                  | 1295        |
|    iterations           | 417         |
|    time_elapsed         | 1317        |
|    total_timesteps      | 1708032     |
| train/                  |             |
|    approx_kl            | 0.010101628 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.6       |
|    explained_variance   | 0.752       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.803      |
|    n_updates            | 7395        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 22.2        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 426 reward: 0.018357
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.36583018   |
| time/                   |              |
|    fps                  | 1295         |
|    iterations           | 418          |
|    time_elapsed         | 1321         |
|    total_timesteps      | 1712128      |
| train/                  |              |
|    approx_kl            | 0.0121487165 |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.2          |
|    entropy_loss         | -40.7        |
|    explained_variance   | 0.856        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.82        |
|    n_updates            | 7410         |
|    policy_gradient_loss | -0.0207      |
|    std                  | 22.3         |
|    value_loss           | 0.0767       |
------------------------------------------
[ADAPTIVE] Episode 427 reward: 0.075747
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47953537  |
| time/                   |             |
|    fps                  | 1295        |
|    iterations           | 419         |
|    time_elapsed         | 1325        |
|    total_timesteps      | 1716224     |
| train/                  |             |
|    approx_kl            | 0.010206549 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.7       |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.789      |
|    n_updates            | 7425        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 22.4        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 428 reward: 0.012156
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.7642508  |
| time/                   |            |
|    fps                  | 1294       |
|    iterations           | 420        |
|    time_elapsed         | 1329       |
|    total_timesteps      | 1720320    |
| train/                  |            |
|    approx_kl            | 0.00797618 |
|    clip_fraction        | 0.145      |
|    clip_range           | 0.2        |
|    entropy_loss         | -40.8      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.75      |
|    n_updates            | 7440       |
|    policy_gradient_loss | -0.0169    |
|    std                  | 22.5       |
|    value_loss           | 0.207      |
----------------------------------------
[ADAPTIVE] Episode 429 reward: -0.002897
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.80880785  |
| time/                   |             |
|    fps                  | 1294        |
|    iterations           | 421         |
|    time_elapsed         | 1332        |
|    total_timesteps      | 1724416     |
| train/                  |             |
|    approx_kl            | 0.010355581 |
|    clip_fraction        | 0.0954      |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.8       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.808      |
|    n_updates            | 7455        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 22.6        |
|    value_loss           | 0.121       |
-----------------------------------------
[ADAPTIVE] Episode 430 reward: 0.006937
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8809018   |
| time/                   |             |
|    fps                  | 1292        |
|    iterations           | 422         |
|    time_elapsed         | 1336        |
|    total_timesteps      | 1728512     |
| train/                  |             |
|    approx_kl            | 0.012293741 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.8       |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.782      |
|    n_updates            | 7470        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 22.7        |
|    value_loss           | 0.166       |
-----------------------------------------
[ADAPTIVE] Episode 431 reward: -0.043703
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9373656   |
| time/                   |             |
|    fps                  | 1293        |
|    iterations           | 423         |
|    time_elapsed         | 1339        |
|    total_timesteps      | 1732608     |
| train/                  |             |
|    approx_kl            | 0.009575384 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.9       |
|    explained_variance   | 0.731       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.79       |
|    n_updates            | 7485        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 22.9        |
|    value_loss           | 0.186       |
-----------------------------------------
[ADAPTIVE] Episode 432 reward: 0.029686
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.79951376  |
| time/                   |             |
|    fps                  | 1292        |
|    iterations           | 424         |
|    time_elapsed         | 1343        |
|    total_timesteps      | 1736704     |
| train/                  |             |
|    approx_kl            | 0.011939103 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41         |
|    explained_variance   | 0.733       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.755      |
|    n_updates            | 7500        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 23          |
|    value_loss           | 0.217       |
-----------------------------------------
[ADAPTIVE] Episode 433 reward: -0.021867
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.59210277  |
| time/                   |             |
|    fps                  | 1292        |
|    iterations           | 425         |
|    time_elapsed         | 1346        |
|    total_timesteps      | 1740800     |
| train/                  |             |
|    approx_kl            | 0.009249005 |
|    clip_fraction        | 0.0878      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41         |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.76       |
|    n_updates            | 7515        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 23.1        |
|    value_loss           | 0.228       |
-----------------------------------------
[ADAPTIVE] Episode 434 reward: 0.035530
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.51946795  |
| time/                   |             |
|    fps                  | 1292        |
|    iterations           | 426         |
|    time_elapsed         | 1349        |
|    total_timesteps      | 1744896     |
| train/                  |             |
|    approx_kl            | 0.010358309 |
|    clip_fraction        | 0.0895      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41         |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.785      |
|    n_updates            | 7530        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 23.2        |
|    value_loss           | 0.18        |
-----------------------------------------
[ADAPTIVE] Episode 435 reward: 0.011642
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46494263  |
| time/                   |             |
|    fps                  | 1292        |
|    iterations           | 427         |
|    time_elapsed         | 1353        |
|    total_timesteps      | 1748992     |
| train/                  |             |
|    approx_kl            | 0.009394209 |
|    clip_fraction        | 0.098       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.1       |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.748      |
|    n_updates            | 7545        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 23.4        |
|    value_loss           | 0.269       |
-----------------------------------------
[ADAPTIVE] Episode 436 reward: 0.018411
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.31667608  |
| time/                   |             |
|    fps                  | 1292        |
|    iterations           | 428         |
|    time_elapsed         | 1356        |
|    total_timesteps      | 1753088     |
| train/                  |             |
|    approx_kl            | 0.011676868 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.1       |
|    explained_variance   | 0.671       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.733      |
|    n_updates            | 7560        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 23.5        |
|    value_loss           | 0.243       |
-----------------------------------------
[ADAPTIVE] Episode 437 reward: 0.055189
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.29182437  |
| time/                   |             |
|    fps                  | 1291        |
|    iterations           | 429         |
|    time_elapsed         | 1360        |
|    total_timesteps      | 1757184     |
| train/                  |             |
|    approx_kl            | 0.010550692 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.2       |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.821      |
|    n_updates            | 7575        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 23.6        |
|    value_loss           | 0.0969      |
-----------------------------------------
[ADAPTIVE] Episode 438 reward: -0.122228
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4019908    |
| time/                   |              |
|    fps                  | 1291         |
|    iterations           | 430          |
|    time_elapsed         | 1363         |
|    total_timesteps      | 1761280      |
| train/                  |              |
|    approx_kl            | 0.0077472553 |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.2          |
|    entropy_loss         | -41.2        |
|    explained_variance   | 0.717        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.806       |
|    n_updates            | 7590         |
|    policy_gradient_loss | -0.0172      |
|    std                  | 23.7         |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 439 reward: 0.063312
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.14539318  |
| time/                   |             |
|    fps                  | 1291        |
|    iterations           | 431         |
|    time_elapsed         | 1366        |
|    total_timesteps      | 1765376     |
| train/                  |             |
|    approx_kl            | 0.010681486 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.3       |
|    explained_variance   | 0.778       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.811      |
|    n_updates            | 7605        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 23.8        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 440 reward: 0.078609
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.140989    |
| time/                   |             |
|    fps                  | 1291        |
|    iterations           | 432         |
|    time_elapsed         | 1370        |
|    total_timesteps      | 1769472     |
| train/                  |             |
|    approx_kl            | 0.009603443 |
|    clip_fraction        | 0.0984      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.3       |
|    explained_variance   | 0.79        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.822      |
|    n_updates            | 7620        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 24          |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 441 reward: -0.059163
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.14121982  |
| time/                   |             |
|    fps                  | 1290        |
|    iterations           | 433         |
|    time_elapsed         | 1374        |
|    total_timesteps      | 1773568     |
| train/                  |             |
|    approx_kl            | 0.008464672 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.4       |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.761      |
|    n_updates            | 7635        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 24.1        |
|    value_loss           | 0.202       |
-----------------------------------------
[ADAPTIVE] Episode 442 reward: 0.023079
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.179792    |
| time/                   |             |
|    fps                  | 1290        |
|    iterations           | 434         |
|    time_elapsed         | 1377        |
|    total_timesteps      | 1777664     |
| train/                  |             |
|    approx_kl            | 0.011497053 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.4       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.796      |
|    n_updates            | 7650        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 24.2        |
|    value_loss           | 0.186       |
-----------------------------------------
[ADAPTIVE] Episode 443 reward: 0.095768
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.23902252   |
| time/                   |              |
|    fps                  | 1289         |
|    iterations           | 435          |
|    time_elapsed         | 1381         |
|    total_timesteps      | 1781760      |
| train/                  |              |
|    approx_kl            | 0.0094304085 |
|    clip_fraction        | 0.116        |
|    clip_range           | 0.2          |
|    entropy_loss         | -41.5        |
|    explained_variance   | 0.737        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.79        |
|    n_updates            | 7665         |
|    policy_gradient_loss | -0.0213      |
|    std                  | 24.4         |
|    value_loss           | 0.172        |
------------------------------------------
[ADAPTIVE] Episode 444 reward: -0.088776
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.23424195  |
| time/                   |             |
|    fps                  | 1289        |
|    iterations           | 436         |
|    time_elapsed         | 1385        |
|    total_timesteps      | 1785856     |
| train/                  |             |
|    approx_kl            | 0.007792388 |
|    clip_fraction        | 0.0879      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.5       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.782      |
|    n_updates            | 7680        |
|    policy_gradient_loss | -0.016      |
|    std                  | 24.5        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 445 reward: 0.008148
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.21369955  |
| time/                   |             |
|    fps                  | 1289        |
|    iterations           | 437         |
|    time_elapsed         | 1388        |
|    total_timesteps      | 1789952     |
| train/                  |             |
|    approx_kl            | 0.009583121 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.6       |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.813      |
|    n_updates            | 7695        |
|    policy_gradient_loss | -0.018      |
|    std                  | 24.7        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 446 reward: -0.087677
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.48502743  |
| time/                   |             |
|    fps                  | 1288        |
|    iterations           | 438         |
|    time_elapsed         | 1392        |
|    total_timesteps      | 1794048     |
| train/                  |             |
|    approx_kl            | 0.008770284 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.6       |
|    explained_variance   | 0.727       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.801      |
|    n_updates            | 7710        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 24.8        |
|    value_loss           | 0.186       |
-----------------------------------------
[ADAPTIVE] Episode 447 reward: -0.006857
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.41349357   |
| time/                   |              |
|    fps                  | 1288         |
|    iterations           | 439          |
|    time_elapsed         | 1395         |
|    total_timesteps      | 1798144      |
| train/                  |              |
|    approx_kl            | 0.0104247155 |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.2          |
|    entropy_loss         | -41.7        |
|    explained_variance   | 0.702        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.818       |
|    n_updates            | 7725         |
|    policy_gradient_loss | -0.0193      |
|    std                  | 24.9         |
|    value_loss           | 0.145        |
------------------------------------------
[ADAPTIVE] Episode 448 reward: 0.004947
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.3528423   |
| time/                   |             |
|    fps                  | 1287        |
|    iterations           | 440         |
|    time_elapsed         | 1399        |
|    total_timesteps      | 1802240     |
| train/                  |             |
|    approx_kl            | 0.011322649 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.7       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.768      |
|    n_updates            | 7740        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 25          |
|    value_loss           | 0.149       |
-----------------------------------------
[ADAPTIVE] Episode 449 reward: -0.043381
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.26629403  |
| time/                   |             |
|    fps                  | 1287        |
|    iterations           | 441         |
|    time_elapsed         | 1403        |
|    total_timesteps      | 1806336     |
| train/                  |             |
|    approx_kl            | 0.008682229 |
|    clip_fraction        | 0.0954      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.7       |
|    explained_variance   | 0.77        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.813      |
|    n_updates            | 7755        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 25          |
|    value_loss           | 0.179       |
-----------------------------------------
[ADAPTIVE] Episode 450 reward: -0.023266
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.178889    |
| time/                   |             |
|    fps                  | 1286        |
|    iterations           | 442         |
|    time_elapsed         | 1407        |
|    total_timesteps      | 1810432     |
| train/                  |             |
|    approx_kl            | 0.009454344 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.7       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.795      |
|    n_updates            | 7770        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 25.1        |
|    value_loss           | 0.203       |
-----------------------------------------
[ADAPTIVE] Episode 451 reward: -0.012652
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.23747084  |
| time/                   |             |
|    fps                  | 1286        |
|    iterations           | 443         |
|    time_elapsed         | 1410        |
|    total_timesteps      | 1814528     |
| train/                  |             |
|    approx_kl            | 0.009115411 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.8       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.798      |
|    n_updates            | 7785        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 25.2        |
|    value_loss           | 0.148       |
-----------------------------------------
[ADAPTIVE] Episode 452 reward: 0.055091
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.31615224  |
| time/                   |             |
|    fps                  | 1285        |
|    iterations           | 444         |
|    time_elapsed         | 1414        |
|    total_timesteps      | 1818624     |
| train/                  |             |
|    approx_kl            | 0.010008331 |
|    clip_fraction        | 0.0929      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.8       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.801      |
|    n_updates            | 7800        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 25.2        |
|    value_loss           | 0.167       |
-----------------------------------------
[ADAPTIVE] Episode 453 reward: 0.008019
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.28811803  |
| time/                   |             |
|    fps                  | 1285        |
|    iterations           | 445         |
|    time_elapsed         | 1417        |
|    total_timesteps      | 1822720     |
| train/                  |             |
|    approx_kl            | 0.008886523 |
|    clip_fraction        | 0.0967      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.8       |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.796      |
|    n_updates            | 7815        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 25.3        |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 454 reward: -0.027998
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.27383515  |
| time/                   |             |
|    fps                  | 1284        |
|    iterations           | 446         |
|    time_elapsed         | 1421        |
|    total_timesteps      | 1826816     |
| train/                  |             |
|    approx_kl            | 0.010520155 |
|    clip_fraction        | 0.0952      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.8       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.788      |
|    n_updates            | 7830        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 25.4        |
|    value_loss           | 0.176       |
-----------------------------------------
[ADAPTIVE] Episode 455 reward: -0.050453
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.2693105   |
| time/                   |             |
|    fps                  | 1284        |
|    iterations           | 447         |
|    time_elapsed         | 1425        |
|    total_timesteps      | 1830912     |
| train/                  |             |
|    approx_kl            | 0.008969052 |
|    clip_fraction        | 0.0925      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.9       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.823      |
|    n_updates            | 7845        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 25.6        |
|    value_loss           | 0.0993      |
-----------------------------------------
[ADAPTIVE] Episode 456 reward: 0.094171
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.22426844 |
| time/                   |            |
|    fps                  | 1284       |
|    iterations           | 448        |
|    time_elapsed         | 1428       |
|    total_timesteps      | 1835008    |
| train/                  |            |
|    approx_kl            | 0.00967057 |
|    clip_fraction        | 0.0937     |
|    clip_range           | 0.2        |
|    entropy_loss         | -41.9      |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.814     |
|    n_updates            | 7860       |
|    policy_gradient_loss | -0.0146    |
|    std                  | 25.7       |
|    value_loss           | 0.198      |
----------------------------------------
[ADAPTIVE] Episode 457 reward: -0.024775
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.29082304  |
| time/                   |             |
|    fps                  | 1284        |
|    iterations           | 449         |
|    time_elapsed         | 1432        |
|    total_timesteps      | 1839104     |
| train/                  |             |
|    approx_kl            | 0.009125369 |
|    clip_fraction        | 0.085       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42         |
|    explained_variance   | 0.667       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.795      |
|    n_updates            | 7875        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 25.8        |
|    value_loss           | 0.188       |
-----------------------------------------
[ADAPTIVE] Episode 458 reward: -0.097829
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.2615581   |
| time/                   |             |
|    fps                  | 1283        |
|    iterations           | 450         |
|    time_elapsed         | 1435        |
|    total_timesteps      | 1843200     |
| train/                  |             |
|    approx_kl            | 0.009123753 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42         |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.83       |
|    n_updates            | 7890        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 26          |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 459 reward: -0.120318
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.21710464  |
| time/                   |             |
|    fps                  | 1283        |
|    iterations           | 451         |
|    time_elapsed         | 1438        |
|    total_timesteps      | 1847296     |
| train/                  |             |
|    approx_kl            | 0.011181561 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.1       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.811      |
|    n_updates            | 7905        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 26.3        |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 460 reward: 0.020685
[ADAPTIVE] Episode 461 reward: -0.070768
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.110352315 |
| time/                   |             |
|    fps                  | 1283        |
|    iterations           | 452         |
|    time_elapsed         | 1442        |
|    total_timesteps      | 1851392     |
| train/                  |             |
|    approx_kl            | 0.00943833  |
|    clip_fraction        | 0.0914      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.2       |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.83       |
|    n_updates            | 7920        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 26.4        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 462 reward: -0.024354
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.089304544 |
| time/                   |             |
|    fps                  | 1283        |
|    iterations           | 453         |
|    time_elapsed         | 1445        |
|    total_timesteps      | 1855488     |
| train/                  |             |
|    approx_kl            | 0.009976378 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.2       |
|    explained_variance   | 0.83        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.833      |
|    n_updates            | 7935        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 26.4        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 463 reward: 0.100549
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.32176054 |
| time/                   |            |
|    fps                  | 1282       |
|    iterations           | 454        |
|    time_elapsed         | 1449       |
|    total_timesteps      | 1859584    |
| train/                  |            |
|    approx_kl            | 0.01046904 |
|    clip_fraction        | 0.0841     |
|    clip_range           | 0.2        |
|    entropy_loss         | -42.2      |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.762     |
|    n_updates            | 7950       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 26.6       |
|    value_loss           | 0.21       |
----------------------------------------
[ADAPTIVE] Episode 464 reward: -0.056639
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.30701497  |
| time/                   |             |
|    fps                  | 1282        |
|    iterations           | 455         |
|    time_elapsed         | 1452        |
|    total_timesteps      | 1863680     |
| train/                  |             |
|    approx_kl            | 0.008752324 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.3       |
|    explained_variance   | 0.624       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.809      |
|    n_updates            | 7965        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 26.8        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 465 reward: -0.095886
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.20749779   |
| time/                   |              |
|    fps                  | 1282         |
|    iterations           | 456          |
|    time_elapsed         | 1456         |
|    total_timesteps      | 1867776      |
| train/                  |              |
|    approx_kl            | 0.0075451136 |
|    clip_fraction        | 0.0873       |
|    clip_range           | 0.2          |
|    entropy_loss         | -42.3        |
|    explained_variance   | 0.718        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.807       |
|    n_updates            | 7980         |
|    policy_gradient_loss | -0.0171      |
|    std                  | 26.9         |
|    value_loss           | 0.131        |
------------------------------------------
[ADAPTIVE] Episode 466 reward: 0.008253
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.25034398 |
| time/                   |            |
|    fps                  | 1282       |
|    iterations           | 457        |
|    time_elapsed         | 1459       |
|    total_timesteps      | 1871872    |
| train/                  |            |
|    approx_kl            | 0.0109785  |
|    clip_fraction        | 0.09       |
|    clip_range           | 0.2        |
|    entropy_loss         | -42.4      |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.805     |
|    n_updates            | 7995       |
|    policy_gradient_loss | -0.0139    |
|    std                  | 26.9       |
|    value_loss           | 0.259      |
----------------------------------------
[ADAPTIVE] Episode 467 reward: 0.021256
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5178941   |
| time/                   |             |
|    fps                  | 1282        |
|    iterations           | 458         |
|    time_elapsed         | 1463        |
|    total_timesteps      | 1875968     |
| train/                  |             |
|    approx_kl            | 0.011465676 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.4       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.785      |
|    n_updates            | 8010        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 27.1        |
|    value_loss           | 0.214       |
-----------------------------------------
[ADAPTIVE] Episode 468 reward: -0.022745
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.49440122  |
| time/                   |             |
|    fps                  | 1281        |
|    iterations           | 459         |
|    time_elapsed         | 1467        |
|    total_timesteps      | 1880064     |
| train/                  |             |
|    approx_kl            | 0.011147325 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.4       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.805      |
|    n_updates            | 8025        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 27.1        |
|    value_loss           | 0.199       |
-----------------------------------------
[ADAPTIVE] Episode 469 reward: 0.011287
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.429065    |
| time/                   |             |
|    fps                  | 1281        |
|    iterations           | 460         |
|    time_elapsed         | 1470        |
|    total_timesteps      | 1884160     |
| train/                  |             |
|    approx_kl            | 0.008451082 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.5       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.833      |
|    n_updates            | 8040        |
|    policy_gradient_loss | -0.018      |
|    std                  | 27.3        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 470 reward: -0.091330
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47165003  |
| time/                   |             |
|    fps                  | 1280        |
|    iterations           | 461         |
|    time_elapsed         | 1474        |
|    total_timesteps      | 1888256     |
| train/                  |             |
|    approx_kl            | 0.009347986 |
|    clip_fraction        | 0.0991      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.5       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.829      |
|    n_updates            | 8055        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 27.4        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 471 reward: -0.032511
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67672265  |
| time/                   |             |
|    fps                  | 1280        |
|    iterations           | 462         |
|    time_elapsed         | 1477        |
|    total_timesteps      | 1892352     |
| train/                  |             |
|    approx_kl            | 0.010868629 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.6       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.801      |
|    n_updates            | 8070        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 27.6        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 472 reward: 0.074896
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8431965   |
| time/                   |             |
|    fps                  | 1280        |
|    iterations           | 463         |
|    time_elapsed         | 1481        |
|    total_timesteps      | 1896448     |
| train/                  |             |
|    approx_kl            | 0.008808311 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.6       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.833      |
|    n_updates            | 8085        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 27.7        |
|    value_loss           | 0.109       |
-----------------------------------------
[ADAPTIVE] Episode 473 reward: -0.029401
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6190496   |
| time/                   |             |
|    fps                  | 1279        |
|    iterations           | 464         |
|    time_elapsed         | 1485        |
|    total_timesteps      | 1900544     |
| train/                  |             |
|    approx_kl            | 0.011254089 |
|    clip_fraction        | 0.0875      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.6       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.83       |
|    n_updates            | 8100        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 27.8        |
|    value_loss           | 0.158       |
-----------------------------------------
[ADAPTIVE] Episode 474 reward: -0.017344
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5928547   |
| time/                   |             |
|    fps                  | 1279        |
|    iterations           | 465         |
|    time_elapsed         | 1488        |
|    total_timesteps      | 1904640     |
| train/                  |             |
|    approx_kl            | 0.010064777 |
|    clip_fraction        | 0.091       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.7       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.783      |
|    n_updates            | 8115        |
|    policy_gradient_loss | -0.013      |
|    std                  | 28          |
|    value_loss           | 0.168       |
-----------------------------------------
[ADAPTIVE] Episode 475 reward: -0.034414
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7428227   |
| time/                   |             |
|    fps                  | 1279        |
|    iterations           | 466         |
|    time_elapsed         | 1492        |
|    total_timesteps      | 1908736     |
| train/                  |             |
|    approx_kl            | 0.009773191 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.7       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.846      |
|    n_updates            | 8130        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 28.2        |
|    value_loss           | 0.0966      |
-----------------------------------------
[ADAPTIVE] Episode 476 reward: 0.141221
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76502955  |
| time/                   |             |
|    fps                  | 1279        |
|    iterations           | 467         |
|    time_elapsed         | 1495        |
|    total_timesteps      | 1912832     |
| train/                  |             |
|    approx_kl            | 0.012780396 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.8       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.831      |
|    n_updates            | 8145        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 28.3        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 477 reward: -0.011238
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5704421   |
| time/                   |             |
|    fps                  | 1278        |
|    iterations           | 468         |
|    time_elapsed         | 1499        |
|    total_timesteps      | 1916928     |
| train/                  |             |
|    approx_kl            | 0.010906562 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.8       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.828      |
|    n_updates            | 8160        |
|    policy_gradient_loss | -0.0132     |
|    std                  | 28.5        |
|    value_loss           | 0.145       |
-----------------------------------------
[ADAPTIVE] Episode 478 reward: -0.009163
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.35604146  |
| time/                   |             |
|    fps                  | 1278        |
|    iterations           | 469         |
|    time_elapsed         | 1502        |
|    total_timesteps      | 1921024     |
| train/                  |             |
|    approx_kl            | 0.009556485 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.9       |
|    explained_variance   | 0.813       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.828      |
|    n_updates            | 8175        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 28.6        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 479 reward: -0.068696
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.2819788   |
| time/                   |             |
|    fps                  | 1278        |
|    iterations           | 470         |
|    time_elapsed         | 1506        |
|    total_timesteps      | 1925120     |
| train/                  |             |
|    approx_kl            | 0.010224866 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.9       |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.848      |
|    n_updates            | 8190        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 28.7        |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 480 reward: -0.088578
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.33357584  |
| time/                   |             |
|    fps                  | 1278        |
|    iterations           | 471         |
|    time_elapsed         | 1509        |
|    total_timesteps      | 1929216     |
| train/                  |             |
|    approx_kl            | 0.009810781 |
|    clip_fraction        | 0.0899      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43         |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.845      |
|    n_updates            | 8205        |
|    policy_gradient_loss | -0.017      |
|    std                  | 28.8        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 481 reward: 0.018696
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.14256378  |
| time/                   |             |
|    fps                  | 1277        |
|    iterations           | 472         |
|    time_elapsed         | 1513        |
|    total_timesteps      | 1933312     |
| train/                  |             |
|    approx_kl            | 0.008477549 |
|    clip_fraction        | 0.0807      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43         |
|    explained_variance   | 0.812       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.847      |
|    n_updates            | 8220        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 29          |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 482 reward: 0.020999
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.15166694  |
| time/                   |             |
|    fps                  | 1276        |
|    iterations           | 473         |
|    time_elapsed         | 1517        |
|    total_timesteps      | 1937408     |
| train/                  |             |
|    approx_kl            | 0.010312905 |
|    clip_fraction        | 0.0932      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43         |
|    explained_variance   | 0.667       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.803      |
|    n_updates            | 8235        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 29.1        |
|    value_loss           | 0.229       |
-----------------------------------------
[ADAPTIVE] Episode 483 reward: -0.017353
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.03302945 |
| time/                   |             |
|    fps                  | 1276        |
|    iterations           | 474         |
|    time_elapsed         | 1521        |
|    total_timesteps      | 1941504     |
| train/                  |             |
|    approx_kl            | 0.009142881 |
|    clip_fraction        | 0.098       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.1       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.842      |
|    n_updates            | 8250        |
|    policy_gradient_loss | -0.016      |
|    std                  | 29.3        |
|    value_loss           | 0.0981      |
-----------------------------------------
[ADAPTIVE] Episode 484 reward: 0.037039
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.15697263  |
| time/                   |             |
|    fps                  | 1275        |
|    iterations           | 475         |
|    time_elapsed         | 1524        |
|    total_timesteps      | 1945600     |
| train/                  |             |
|    approx_kl            | 0.008535968 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.2       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.852      |
|    n_updates            | 8265        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 29.5        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 485 reward: -0.048168
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.2430592    |
| time/                   |              |
|    fps                  | 1275         |
|    iterations           | 476          |
|    time_elapsed         | 1528         |
|    total_timesteps      | 1949696      |
| train/                  |              |
|    approx_kl            | 0.0077875885 |
|    clip_fraction        | 0.0968       |
|    clip_range           | 0.2          |
|    entropy_loss         | -43.2        |
|    explained_variance   | 0.587        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.836       |
|    n_updates            | 8280         |
|    policy_gradient_loss | -0.0192      |
|    std                  | 29.6         |
|    value_loss           | 0.137        |
------------------------------------------
[ADAPTIVE] Episode 486 reward: 0.104174
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.2868462   |
| time/                   |             |
|    fps                  | 1274        |
|    iterations           | 477         |
|    time_elapsed         | 1532        |
|    total_timesteps      | 1953792     |
| train/                  |             |
|    approx_kl            | 0.010237157 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.2       |
|    explained_variance   | 0.792       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.859      |
|    n_updates            | 8295        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 29.7        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 487 reward: 0.092384
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.44909996  |
| time/                   |             |
|    fps                  | 1274        |
|    iterations           | 478         |
|    time_elapsed         | 1536        |
|    total_timesteps      | 1957888     |
| train/                  |             |
|    approx_kl            | 0.010793066 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.3       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.846      |
|    n_updates            | 8310        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 30          |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 488 reward: 0.031327
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4472333   |
| time/                   |             |
|    fps                  | 1274        |
|    iterations           | 479         |
|    time_elapsed         | 1539        |
|    total_timesteps      | 1961984     |
| train/                  |             |
|    approx_kl            | 0.009067309 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.3       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.847      |
|    n_updates            | 8325        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 30.1        |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 489 reward: -0.034268
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5809164   |
| time/                   |             |
|    fps                  | 1273        |
|    iterations           | 480         |
|    time_elapsed         | 1544        |
|    total_timesteps      | 1966080     |
| train/                  |             |
|    approx_kl            | 0.009147469 |
|    clip_fraction        | 0.0993      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.4       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.849      |
|    n_updates            | 8340        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 30.3        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 490 reward: 0.060582
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.56290954  |
| time/                   |             |
|    fps                  | 1272        |
|    iterations           | 481         |
|    time_elapsed         | 1547        |
|    total_timesteps      | 1970176     |
| train/                  |             |
|    approx_kl            | 0.008275418 |
|    clip_fraction        | 0.0917      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.4       |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.857      |
|    n_updates            | 8355        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 30.4        |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 491 reward: -0.053075
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6250737   |
| time/                   |             |
|    fps                  | 1272        |
|    iterations           | 482         |
|    time_elapsed         | 1551        |
|    total_timesteps      | 1974272     |
| train/                  |             |
|    approx_kl            | 0.008629652 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.5       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.844      |
|    n_updates            | 8370        |
|    policy_gradient_loss | -0.0153     |
|    std                  | 30.5        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 492 reward: -0.080103
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.68814707  |
| time/                   |             |
|    fps                  | 1271        |
|    iterations           | 483         |
|    time_elapsed         | 1555        |
|    total_timesteps      | 1978368     |
| train/                  |             |
|    approx_kl            | 0.010286349 |
|    clip_fraction        | 0.0776      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.5       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.839      |
|    n_updates            | 8385        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 30.7        |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 493 reward: -0.033788
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7380865   |
| time/                   |             |
|    fps                  | 1271        |
|    iterations           | 484         |
|    time_elapsed         | 1558        |
|    total_timesteps      | 1982464     |
| train/                  |             |
|    approx_kl            | 0.011977163 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.5       |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.849      |
|    n_updates            | 8400        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 30.8        |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 494 reward: 0.105246
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96269417  |
| time/                   |             |
|    fps                  | 1270        |
|    iterations           | 485         |
|    time_elapsed         | 1563        |
|    total_timesteps      | 1986560     |
| train/                  |             |
|    approx_kl            | 0.010618791 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.6       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.868      |
|    n_updates            | 8415        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 31          |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 495 reward: 0.084249
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.937633    |
| time/                   |             |
|    fps                  | 1270        |
|    iterations           | 486         |
|    time_elapsed         | 1566        |
|    total_timesteps      | 1990656     |
| train/                  |             |
|    approx_kl            | 0.008905923 |
|    clip_fraction        | 0.0873      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.6       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.857      |
|    n_updates            | 8430        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 31.1        |
|    value_loss           | 0.0848      |
-----------------------------------------
[ADAPTIVE] Episode 496 reward: -0.108868
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.89490396   |
| time/                   |              |
|    fps                  | 1270         |
|    iterations           | 487          |
|    time_elapsed         | 1570         |
|    total_timesteps      | 1994752      |
| train/                  |              |
|    approx_kl            | 0.0072351396 |
|    clip_fraction        | 0.0818       |
|    clip_range           | 0.2          |
|    entropy_loss         | -43.7        |
|    explained_variance   | 0.839        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.856       |
|    n_updates            | 8445         |
|    policy_gradient_loss | -0.0138      |
|    std                  | 31.3         |
|    value_loss           | 0.113        |
------------------------------------------
[ADAPTIVE] Episode 497 reward: 0.025016
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9316524   |
| time/                   |             |
|    fps                  | 1270        |
|    iterations           | 488         |
|    time_elapsed         | 1573        |
|    total_timesteps      | 1998848     |
| train/                  |             |
|    approx_kl            | 0.006325244 |
|    clip_fraction        | 0.072       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.7       |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.852      |
|    n_updates            | 8460        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 31.4        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 498 reward: -0.056174
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.80417925  |
| time/                   |             |
|    fps                  | 1269        |
|    iterations           | 489         |
|    time_elapsed         | 1577        |
|    total_timesteps      | 2002944     |
| train/                  |             |
|    approx_kl            | 0.008217538 |
|    clip_fraction        | 0.0776      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.7       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.83       |
|    n_updates            | 8475        |
|    policy_gradient_loss | -0.013      |
|    std                  | 31.5        |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 499 reward: 0.068972
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7056577   |
| time/                   |             |
|    fps                  | 1269        |
|    iterations           | 490         |
|    time_elapsed         | 1581        |
|    total_timesteps      | 2007040     |
| train/                  |             |
|    approx_kl            | 0.012049774 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.8       |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.862      |
|    n_updates            | 8490        |
|    policy_gradient_loss | -0.015      |
|    std                  | 31.6        |
|    value_loss           | 0.119       |
-----------------------------------------
[ADAPTIVE] Episode 500 reward: -0.101266
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8090074   |
| time/                   |             |
|    fps                  | 1268        |
|    iterations           | 491         |
|    time_elapsed         | 1584        |
|    total_timesteps      | 2011136     |
| train/                  |             |
|    approx_kl            | 0.009610781 |
|    clip_fraction        | 0.0846      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.8       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.851      |
|    n_updates            | 8505        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 31.9        |
|    value_loss           | 0.158       |
-----------------------------------------
[ADAPTIVE] Episode 501 reward: -0.016486
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.71173215  |
| time/                   |             |
|    fps                  | 1268        |
|    iterations           | 492         |
|    time_elapsed         | 1588        |
|    total_timesteps      | 2015232     |
| train/                  |             |
|    approx_kl            | 0.012926236 |
|    clip_fraction        | 0.0998      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.9       |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.834      |
|    n_updates            | 8520        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 32.1        |
|    value_loss           | 0.192       |
-----------------------------------------
[ADAPTIVE] Episode 502 reward: 0.085132
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76240295  |
| time/                   |             |
|    fps                  | 1268        |
|    iterations           | 493         |
|    time_elapsed         | 1592        |
|    total_timesteps      | 2019328     |
| train/                  |             |
|    approx_kl            | 0.009699661 |
|    clip_fraction        | 0.0759      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44         |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.826      |
|    n_updates            | 8535        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 32.3        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 503 reward: -0.103943
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7015958   |
| time/                   |             |
|    fps                  | 1267        |
|    iterations           | 494         |
|    time_elapsed         | 1596        |
|    total_timesteps      | 2023424     |
| train/                  |             |
|    approx_kl            | 0.009699842 |
|    clip_fraction        | 0.0932      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44         |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.859      |
|    n_updates            | 8550        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 32.5        |
|    value_loss           | 0.126       |
-----------------------------------------
[ADAPTIVE] Episode 504 reward: 0.005007
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.69378936  |
| time/                   |             |
|    fps                  | 1267        |
|    iterations           | 495         |
|    time_elapsed         | 1599        |
|    total_timesteps      | 2027520     |
| train/                  |             |
|    approx_kl            | 0.011153487 |
|    clip_fraction        | 0.084       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.1       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.891      |
|    n_updates            | 8565        |
|    policy_gradient_loss | -0.015      |
|    std                  | 32.7        |
|    value_loss           | 0.0979      |
-----------------------------------------
[ADAPTIVE] Episode 505 reward: 0.056167
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.72568023  |
| time/                   |             |
|    fps                  | 1267        |
|    iterations           | 496         |
|    time_elapsed         | 1603        |
|    total_timesteps      | 2031616     |
| train/                  |             |
|    approx_kl            | 0.009061144 |
|    clip_fraction        | 0.0768      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.1       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.867      |
|    n_updates            | 8580        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 32.9        |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 506 reward: -0.017966
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5751446   |
| time/                   |             |
|    fps                  | 1266        |
|    iterations           | 497         |
|    time_elapsed         | 1606        |
|    total_timesteps      | 2035712     |
| train/                  |             |
|    approx_kl            | 0.009912301 |
|    clip_fraction        | 0.0923      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.2       |
|    explained_variance   | 0.635       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.85       |
|    n_updates            | 8595        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 33.1        |
|    value_loss           | 0.251       |
-----------------------------------------
[ADAPTIVE] Episode 507 reward: 0.044826
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46405697  |
| time/                   |             |
|    fps                  | 1266        |
|    iterations           | 498         |
|    time_elapsed         | 1611        |
|    total_timesteps      | 2039808     |
| train/                  |             |
|    approx_kl            | 0.009670131 |
|    clip_fraction        | 0.0974      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.2       |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.875      |
|    n_updates            | 8610        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 33.3        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 508 reward: -0.034101
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.40900698  |
| time/                   |             |
|    fps                  | 1266        |
|    iterations           | 499         |
|    time_elapsed         | 1614        |
|    total_timesteps      | 2043904     |
| train/                  |             |
|    approx_kl            | 0.009594513 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.3       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.849      |
|    n_updates            | 8625        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 33.4        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 509 reward: 0.082563
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.37868407  |
| time/                   |             |
|    fps                  | 1265        |
|    iterations           | 500         |
|    time_elapsed         | 1617        |
|    total_timesteps      | 2048000     |
| train/                  |             |
|    approx_kl            | 0.008610786 |
|    clip_fraction        | 0.0808      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.3       |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.851      |
|    n_updates            | 8640        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 33.5        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 510 reward: -0.054315
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47868648  |
| time/                   |             |
|    fps                  | 1265        |
|    iterations           | 501         |
|    time_elapsed         | 1621        |
|    total_timesteps      | 2052096     |
| train/                  |             |
|    approx_kl            | 0.008141521 |
|    clip_fraction        | 0.0896      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.3       |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.852      |
|    n_updates            | 8655        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 33.6        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 511 reward: -0.026976
[ADAPTIVE] Episode 512 reward: 0.053057
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.40943477  |
| time/                   |             |
|    fps                  | 1264        |
|    iterations           | 502         |
|    time_elapsed         | 1625        |
|    total_timesteps      | 2056192     |
| train/                  |             |
|    approx_kl            | 0.011476645 |
|    clip_fraction        | 0.0741      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.4       |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.864      |
|    n_updates            | 8670        |
|    policy_gradient_loss | -0.0124     |
|    std                  | 33.7        |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 513 reward: -0.055920
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.36422822  |
| time/                   |             |
|    fps                  | 1264        |
|    iterations           | 503         |
|    time_elapsed         | 1628        |
|    total_timesteps      | 2060288     |
| train/                  |             |
|    approx_kl            | 0.007526016 |
|    clip_fraction        | 0.0796      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.4       |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.834      |
|    n_updates            | 8685        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 33.8        |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 514 reward: 0.094368
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.66799754  |
| time/                   |             |
|    fps                  | 1264        |
|    iterations           | 504         |
|    time_elapsed         | 1632        |
|    total_timesteps      | 2064384     |
| train/                  |             |
|    approx_kl            | 0.008433103 |
|    clip_fraction        | 0.0892      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.4       |
|    explained_variance   | 0.831       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.874      |
|    n_updates            | 8700        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 34          |
|    value_loss           | 0.0968      |
-----------------------------------------
[ADAPTIVE] Episode 515 reward: -0.067768
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5476436    |
| time/                   |              |
|    fps                  | 1264         |
|    iterations           | 505          |
|    time_elapsed         | 1636         |
|    total_timesteps      | 2068480      |
| train/                  |              |
|    approx_kl            | 0.0060755946 |
|    clip_fraction        | 0.0705       |
|    clip_range           | 0.2          |
|    entropy_loss         | -44.5        |
|    explained_variance   | 0.694        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.776       |
|    n_updates            | 8715         |
|    policy_gradient_loss | -0.01        |
|    std                  | 34.1         |
|    value_loss           | 0.253        |
------------------------------------------
[ADAPTIVE] Episode 516 reward: 0.012245
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.50738615  |
| time/                   |             |
|    fps                  | 1263        |
|    iterations           | 506         |
|    time_elapsed         | 1639        |
|    total_timesteps      | 2072576     |
| train/                  |             |
|    approx_kl            | 0.012365762 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.5       |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.862      |
|    n_updates            | 8730        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 34.3        |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 517 reward: 0.010144
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.43803543 |
| time/                   |            |
|    fps                  | 1263       |
|    iterations           | 507        |
|    time_elapsed         | 1643       |
|    total_timesteps      | 2076672    |
| train/                  |            |
|    approx_kl            | 0.00871418 |
|    clip_fraction        | 0.0784     |
|    clip_range           | 0.2        |
|    entropy_loss         | -44.6      |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.837     |
|    n_updates            | 8745       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 34.5       |
|    value_loss           | 0.169      |
----------------------------------------
[ADAPTIVE] Episode 518 reward: 0.002101
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.43208635  |
| time/                   |             |
|    fps                  | 1263        |
|    iterations           | 508         |
|    time_elapsed         | 1647        |
|    total_timesteps      | 2080768     |
| train/                  |             |
|    approx_kl            | 0.009338785 |
|    clip_fraction        | 0.0909      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.6       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.862      |
|    n_updates            | 8760        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 34.7        |
|    value_loss           | 0.205       |
-----------------------------------------
[ADAPTIVE] Episode 519 reward: -0.066564
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.57461053  |
| time/                   |             |
|    fps                  | 1263        |
|    iterations           | 509         |
|    time_elapsed         | 1650        |
|    total_timesteps      | 2084864     |
| train/                  |             |
|    approx_kl            | 0.008423874 |
|    clip_fraction        | 0.081       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.7       |
|    explained_variance   | 0.777       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.883      |
|    n_updates            | 8775        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 34.8        |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 520 reward: 0.007707
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5955277   |
| time/                   |             |
|    fps                  | 1262        |
|    iterations           | 510         |
|    time_elapsed         | 1654        |
|    total_timesteps      | 2088960     |
| train/                  |             |
|    approx_kl            | 0.008032864 |
|    clip_fraction        | 0.0771      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.7       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.869      |
|    n_updates            | 8790        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 35.1        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 521 reward: -0.003778
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4385496   |
| time/                   |             |
|    fps                  | 1262        |
|    iterations           | 511         |
|    time_elapsed         | 1658        |
|    total_timesteps      | 2093056     |
| train/                  |             |
|    approx_kl            | 0.010104433 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.8       |
|    explained_variance   | 0.788       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.855      |
|    n_updates            | 8805        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 35.4        |
|    value_loss           | 0.177       |
-----------------------------------------
[ADAPTIVE] Episode 522 reward: -0.064606
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.62355256  |
| time/                   |             |
|    fps                  | 1262        |
|    iterations           | 512         |
|    time_elapsed         | 1661        |
|    total_timesteps      | 2097152     |
| train/                  |             |
|    approx_kl            | 0.009221655 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.8       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.885      |
|    n_updates            | 8820        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 35.6        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 523 reward: -0.010698
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6922206    |
| time/                   |              |
|    fps                  | 1261         |
|    iterations           | 513          |
|    time_elapsed         | 1665         |
|    total_timesteps      | 2101248      |
| train/                  |              |
|    approx_kl            | 0.0063987556 |
|    clip_fraction        | 0.0615       |
|    clip_range           | 0.2          |
|    entropy_loss         | -44.9        |
|    explained_variance   | 0.775        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.863       |
|    n_updates            | 8835         |
|    policy_gradient_loss | -0.0121      |
|    std                  | 35.7         |
|    value_loss           | 0.134        |
------------------------------------------
[ADAPTIVE] Episode 524 reward: -0.105050
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.86477476  |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 514         |
|    time_elapsed         | 1668        |
|    total_timesteps      | 2105344     |
| train/                  |             |
|    approx_kl            | 0.010427018 |
|    clip_fraction        | 0.0985      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.9       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.889      |
|    n_updates            | 8850        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 35.9        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 525 reward: 0.112356
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6899487    |
| time/                   |              |
|    fps                  | 1261         |
|    iterations           | 515          |
|    time_elapsed         | 1671         |
|    total_timesteps      | 2109440      |
| train/                  |              |
|    approx_kl            | 0.0074061174 |
|    clip_fraction        | 0.0732       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45          |
|    explained_variance   | 0.814        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.859       |
|    n_updates            | 8865         |
|    policy_gradient_loss | -0.0122      |
|    std                  | 36.1         |
|    value_loss           | 0.155        |
------------------------------------------
[ADAPTIVE] Episode 526 reward: -0.024050
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7509239   |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 516         |
|    time_elapsed         | 1675        |
|    total_timesteps      | 2113536     |
| train/                  |             |
|    approx_kl            | 0.009783968 |
|    clip_fraction        | 0.0916      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45         |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.857      |
|    n_updates            | 8880        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 36.3        |
|    value_loss           | 0.263       |
-----------------------------------------
[ADAPTIVE] Episode 527 reward: 0.039520
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8891468   |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 517         |
|    time_elapsed         | 1679        |
|    total_timesteps      | 2117632     |
| train/                  |             |
|    approx_kl            | 0.007031687 |
|    clip_fraction        | 0.0831      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.1       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.836      |
|    n_updates            | 8895        |
|    policy_gradient_loss | -0.0115     |
|    std                  | 36.5        |
|    value_loss           | 0.237       |
-----------------------------------------
[ADAPTIVE] Episode 528 reward: 0.089418
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8749246   |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 518         |
|    time_elapsed         | 1682        |
|    total_timesteps      | 2121728     |
| train/                  |             |
|    approx_kl            | 0.007798419 |
|    clip_fraction        | 0.0831      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.1       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.883      |
|    n_updates            | 8910        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 36.7        |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 529 reward: -0.000749
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84158134  |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 519         |
|    time_elapsed         | 1685        |
|    total_timesteps      | 2125824     |
| train/                  |             |
|    approx_kl            | 0.007780249 |
|    clip_fraction        | 0.0736      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.1       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.881      |
|    n_updates            | 8925        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 36.7        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 530 reward: 0.042015
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.75273657  |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 520         |
|    time_elapsed         | 1690        |
|    total_timesteps      | 2129920     |
| train/                  |             |
|    approx_kl            | 0.008649753 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.2       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.854      |
|    n_updates            | 8940        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 36.9        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 531 reward: 0.056777
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6672714    |
| time/                   |              |
|    fps                  | 1260         |
|    iterations           | 521          |
|    time_elapsed         | 1693         |
|    total_timesteps      | 2134016      |
| train/                  |              |
|    approx_kl            | 0.0075862124 |
|    clip_fraction        | 0.0978       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45.2        |
|    explained_variance   | 0.716        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.856       |
|    n_updates            | 8955         |
|    policy_gradient_loss | -0.0119      |
|    std                  | 37.3         |
|    value_loss           | 0.207        |
------------------------------------------
[ADAPTIVE] Episode 532 reward: -0.010665
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.55613405  |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 522         |
|    time_elapsed         | 1697        |
|    total_timesteps      | 2138112     |
| train/                  |             |
|    approx_kl            | 0.008522298 |
|    clip_fraction        | 0.0684      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.3       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.886      |
|    n_updates            | 8970        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 37.5        |
|    value_loss           | 0.129       |
-----------------------------------------
[ADAPTIVE] Episode 533 reward: -0.082181
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.66520673  |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 523         |
|    time_elapsed         | 1700        |
|    total_timesteps      | 2142208     |
| train/                  |             |
|    approx_kl            | 0.009387746 |
|    clip_fraction        | 0.0921      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.3       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.882      |
|    n_updates            | 8985        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 37.6        |
|    value_loss           | 0.0909      |
-----------------------------------------
[ADAPTIVE] Episode 534 reward: 0.011766
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.79241395  |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 524         |
|    time_elapsed         | 1704        |
|    total_timesteps      | 2146304     |
| train/                  |             |
|    approx_kl            | 0.010570595 |
|    clip_fraction        | 0.0922      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.4       |
|    explained_variance   | 0.777       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.874      |
|    n_updates            | 9000        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 37.9        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 535 reward: -0.030404
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6778996   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 525         |
|    time_elapsed         | 1707        |
|    total_timesteps      | 2150400     |
| train/                  |             |
|    approx_kl            | 0.012302611 |
|    clip_fraction        | 0.0768      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.4       |
|    explained_variance   | 0.78        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.888      |
|    n_updates            | 9015        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 38          |
|    value_loss           | 0.122       |
-----------------------------------------
[ADAPTIVE] Episode 536 reward: 0.003714
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7890067   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 526         |
|    time_elapsed         | 1711        |
|    total_timesteps      | 2154496     |
| train/                  |             |
|    approx_kl            | 0.010551935 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.5       |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.855      |
|    n_updates            | 9030        |
|    policy_gradient_loss | -0.014      |
|    std                  | 38.1        |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 537 reward: 0.074166
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76648986  |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 527         |
|    time_elapsed         | 1714        |
|    total_timesteps      | 2158592     |
| train/                  |             |
|    approx_kl            | 0.009687636 |
|    clip_fraction        | 0.0851      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.5       |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.893      |
|    n_updates            | 9045        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 38.3        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 538 reward: -0.052080
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.87380254  |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 528         |
|    time_elapsed         | 1718        |
|    total_timesteps      | 2162688     |
| train/                  |             |
|    approx_kl            | 0.008963572 |
|    clip_fraction        | 0.0746      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.5       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.894      |
|    n_updates            | 9060        |
|    policy_gradient_loss | -0.017      |
|    std                  | 38.6        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 539 reward: 0.027660
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8399896   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 529         |
|    time_elapsed         | 1722        |
|    total_timesteps      | 2166784     |
| train/                  |             |
|    approx_kl            | 0.009077314 |
|    clip_fraction        | 0.0952      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.6       |
|    explained_variance   | 0.719       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.881      |
|    n_updates            | 9075        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 38.7        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 540 reward: 0.011154
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84294516  |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 530         |
|    time_elapsed         | 1726        |
|    total_timesteps      | 2170880     |
| train/                  |             |
|    approx_kl            | 0.008977994 |
|    clip_fraction        | 0.0921      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.6       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.883      |
|    n_updates            | 9090        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 38.9        |
|    value_loss           | 0.0921      |
-----------------------------------------
[ADAPTIVE] Episode 541 reward: 0.118482
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.94549096  |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 531         |
|    time_elapsed         | 1729        |
|    total_timesteps      | 2174976     |
| train/                  |             |
|    approx_kl            | 0.007822882 |
|    clip_fraction        | 0.0905      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.7       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.887      |
|    n_updates            | 9105        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 39.2        |
|    value_loss           | 0.207       |
-----------------------------------------
[ADAPTIVE] Episode 542 reward: -0.070975
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.95081884  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 532         |
|    time_elapsed         | 1733        |
|    total_timesteps      | 2179072     |
| train/                  |             |
|    approx_kl            | 0.009161271 |
|    clip_fraction        | 0.0966      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.7       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.845      |
|    n_updates            | 9120        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 39.4        |
|    value_loss           | 0.164       |
-----------------------------------------
[ADAPTIVE] Episode 543 reward: -0.025291
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.854512    |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 533         |
|    time_elapsed         | 1737        |
|    total_timesteps      | 2183168     |
| train/                  |             |
|    approx_kl            | 0.009440463 |
|    clip_fraction        | 0.0858      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.8       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.909      |
|    n_updates            | 9135        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 39.5        |
|    value_loss           | 0.1         |
-----------------------------------------
[ADAPTIVE] Episode 544 reward: -0.033997
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.941361    |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 534         |
|    time_elapsed         | 1741        |
|    total_timesteps      | 2187264     |
| train/                  |             |
|    approx_kl            | 0.008332243 |
|    clip_fraction        | 0.0795      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.8       |
|    explained_variance   | 0.697       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.866      |
|    n_updates            | 9150        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 39.7        |
|    value_loss           | 0.266       |
-----------------------------------------
[ADAPTIVE] Episode 545 reward: 0.090832
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8006649    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 535          |
|    time_elapsed         | 1744         |
|    total_timesteps      | 2191360      |
| train/                  |              |
|    approx_kl            | 0.0093584135 |
|    clip_fraction        | 0.0979       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45.8        |
|    explained_variance   | 0.722        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.901       |
|    n_updates            | 9165         |
|    policy_gradient_loss | -0.0174      |
|    std                  | 39.9         |
|    value_loss           | 0.122        |
------------------------------------------
[ADAPTIVE] Episode 546 reward: -0.006708
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.74076      |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 536          |
|    time_elapsed         | 1748         |
|    total_timesteps      | 2195456      |
| train/                  |              |
|    approx_kl            | 0.0087563135 |
|    clip_fraction        | 0.0803       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45.9        |
|    explained_variance   | 0.738        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.893       |
|    n_updates            | 9180         |
|    policy_gradient_loss | -0.0131      |
|    std                  | 40.1         |
|    value_loss           | 0.157        |
------------------------------------------
[ADAPTIVE] Episode 547 reward: -0.031503
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5902127   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 537         |
|    time_elapsed         | 1751        |
|    total_timesteps      | 2199552     |
| train/                  |             |
|    approx_kl            | 0.008971745 |
|    clip_fraction        | 0.0969      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.9       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.894      |
|    n_updates            | 9195        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 40.1        |
|    value_loss           | 0.121       |
-----------------------------------------
[ADAPTIVE] Episode 548 reward: 0.119264
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.46130145 |
| time/                   |            |
|    fps                  | 1255       |
|    iterations           | 538        |
|    time_elapsed         | 1754       |
|    total_timesteps      | 2203648    |
| train/                  |            |
|    approx_kl            | 0.00895224 |
|    clip_fraction        | 0.0746     |
|    clip_range           | 0.2        |
|    entropy_loss         | -45.9      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.877     |
|    n_updates            | 9210       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 40.3       |
|    value_loss           | 0.163      |
----------------------------------------
[ADAPTIVE] Episode 549 reward: -0.035510
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.546037    |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 539         |
|    time_elapsed         | 1758        |
|    total_timesteps      | 2207744     |
| train/                  |             |
|    approx_kl            | 0.008811594 |
|    clip_fraction        | 0.095       |
|    clip_range           | 0.2         |
|    entropy_loss         | -46         |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.909      |
|    n_updates            | 9225        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 40.5        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 550 reward: -0.029866
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.53935486   |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 540          |
|    time_elapsed         | 1761         |
|    total_timesteps      | 2211840      |
| train/                  |              |
|    approx_kl            | 0.0085300915 |
|    clip_fraction        | 0.0889       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46          |
|    explained_variance   | 0.815        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.913       |
|    n_updates            | 9240         |
|    policy_gradient_loss | -0.0171      |
|    std                  | 40.8         |
|    value_loss           | 0.102        |
------------------------------------------
[ADAPTIVE] Episode 551 reward: -0.055738
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6684269    |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 541          |
|    time_elapsed         | 1765         |
|    total_timesteps      | 2215936      |
| train/                  |              |
|    approx_kl            | 0.0068043945 |
|    clip_fraction        | 0.0816       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.1        |
|    explained_variance   | 0.772        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.885       |
|    n_updates            | 9255         |
|    policy_gradient_loss | -0.0108      |
|    std                  | 41.1         |
|    value_loss           | 0.189        |
------------------------------------------
[ADAPTIVE] Episode 552 reward: -0.001470
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.86091006  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 542         |
|    time_elapsed         | 1768        |
|    total_timesteps      | 2220032     |
| train/                  |             |
|    approx_kl            | 0.008511735 |
|    clip_fraction        | 0.0736      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.2       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.889      |
|    n_updates            | 9270        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 41.3        |
|    value_loss           | 0.137       |
-----------------------------------------
[ADAPTIVE] Episode 553 reward: 0.090127
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8562543   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 543         |
|    time_elapsed         | 1771        |
|    total_timesteps      | 2224128     |
| train/                  |             |
|    approx_kl            | 0.008288238 |
|    clip_fraction        | 0.0732      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.2       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.926      |
|    n_updates            | 9285        |
|    policy_gradient_loss | -0.017      |
|    std                  | 41.6        |
|    value_loss           | 0.098       |
-----------------------------------------
[ADAPTIVE] Episode 554 reward: 0.082028
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.85115135  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 544         |
|    time_elapsed         | 1775        |
|    total_timesteps      | 2228224     |
| train/                  |             |
|    approx_kl            | 0.007973425 |
|    clip_fraction        | 0.0621      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.2       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.904      |
|    n_updates            | 9300        |
|    policy_gradient_loss | -0.0132     |
|    std                  | 41.7        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 555 reward: -0.038380
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.92643434  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 545         |
|    time_elapsed         | 1778        |
|    total_timesteps      | 2232320     |
| train/                  |             |
|    approx_kl            | 0.008740038 |
|    clip_fraction        | 0.0876      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.3       |
|    explained_variance   | 0.632       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.892      |
|    n_updates            | 9315        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 41.9        |
|    value_loss           | 0.198       |
-----------------------------------------
[ADAPTIVE] Episode 556 reward: 0.029364
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84890664  |
| time/                   |             |
|    fps                  | 1254        |
|    iterations           | 546         |
|    time_elapsed         | 1782        |
|    total_timesteps      | 2236416     |
| train/                  |             |
|    approx_kl            | 0.008498838 |
|    clip_fraction        | 0.0967      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.3       |
|    explained_variance   | 0.803       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.915      |
|    n_updates            | 9330        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 42          |
|    value_loss           | 0.0893      |
-----------------------------------------
[ADAPTIVE] Episode 557 reward: -0.010261
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.75404     |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 547         |
|    time_elapsed         | 1784        |
|    total_timesteps      | 2240512     |
| train/                  |             |
|    approx_kl            | 0.008902415 |
|    clip_fraction        | 0.0736      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.3       |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.899      |
|    n_updates            | 9345        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 42.1        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 558 reward: -0.048906
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6072313   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 548         |
|    time_elapsed         | 1788        |
|    total_timesteps      | 2244608     |
| train/                  |             |
|    approx_kl            | 0.010346852 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.4       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.925      |
|    n_updates            | 9360        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 42.4        |
|    value_loss           | 0.0897      |
-----------------------------------------
[ADAPTIVE] Episode 559 reward: -0.113805
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6387819   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 549         |
|    time_elapsed         | 1791        |
|    total_timesteps      | 2248704     |
| train/                  |             |
|    approx_kl            | 0.008137131 |
|    clip_fraction        | 0.0947      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.4       |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.897      |
|    n_updates            | 9375        |
|    policy_gradient_loss | -0.011      |
|    std                  | 42.6        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 560 reward: 0.088227
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6828258   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 550         |
|    time_elapsed         | 1794        |
|    total_timesteps      | 2252800     |
| train/                  |             |
|    approx_kl            | 0.010960683 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.5       |
|    explained_variance   | 0.777       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.9        |
|    n_updates            | 9390        |
|    policy_gradient_loss | -0.0186     |
|    std                  | 42.8        |
|    value_loss           | 0.134       |
-----------------------------------------
[ADAPTIVE] Episode 561 reward: -0.002136
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7773674   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 551         |
|    time_elapsed         | 1797        |
|    total_timesteps      | 2256896     |
| train/                  |             |
|    approx_kl            | 0.009030434 |
|    clip_fraction        | 0.0689      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.5       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.881      |
|    n_updates            | 9405        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 43          |
|    value_loss           | 0.183       |
-----------------------------------------
[ADAPTIVE] Episode 562 reward: -0.033476
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8300319   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 552         |
|    time_elapsed         | 1800        |
|    total_timesteps      | 2260992     |
| train/                  |             |
|    approx_kl            | 0.008089545 |
|    clip_fraction        | 0.065       |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.6       |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.893      |
|    n_updates            | 9420        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 43.2        |
|    value_loss           | 0.179       |
-----------------------------------------
[ADAPTIVE] Episode 563 reward: 0.010104
[ADAPTIVE] Episode 564 reward: -0.103146
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.974312    |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 553         |
|    time_elapsed         | 1804        |
|    total_timesteps      | 2265088     |
| train/                  |             |
|    approx_kl            | 0.010423247 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.6       |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.929      |
|    n_updates            | 9435        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 43.5        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 565 reward: 0.015329
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1248723   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 554         |
|    time_elapsed         | 1807        |
|    total_timesteps      | 2269184     |
| train/                  |             |
|    approx_kl            | 0.008502324 |
|    clip_fraction        | 0.0967      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.6       |
|    explained_variance   | 0.667       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.914      |
|    n_updates            | 9450        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 43.6        |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 566 reward: -0.064342
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0953435    |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 555          |
|    time_elapsed         | 1810         |
|    total_timesteps      | 2273280      |
| train/                  |              |
|    approx_kl            | 0.0074279644 |
|    clip_fraction        | 0.0766       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.7        |
|    explained_variance   | 0.69         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.882       |
|    n_updates            | 9465         |
|    policy_gradient_loss | -0.0128      |
|    std                  | 44           |
|    value_loss           | 0.237        |
------------------------------------------
[ADAPTIVE] Episode 567 reward: -0.022466
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1208556   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 556         |
|    time_elapsed         | 1813        |
|    total_timesteps      | 2277376     |
| train/                  |             |
|    approx_kl            | 0.008786134 |
|    clip_fraction        | 0.0692      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.8       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.913      |
|    n_updates            | 9480        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 44.3        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 568 reward: -0.062660
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.186812    |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 557         |
|    time_elapsed         | 1816        |
|    total_timesteps      | 2281472     |
| train/                  |             |
|    approx_kl            | 0.008960378 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.8       |
|    explained_variance   | 0.8         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.925      |
|    n_updates            | 9495        |
|    policy_gradient_loss | -0.0151     |
|    std                  | 44.5        |
|    value_loss           | 0.0991      |
-----------------------------------------
[ADAPTIVE] Episode 569 reward: -0.074640
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9008174    |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 558          |
|    time_elapsed         | 1820         |
|    total_timesteps      | 2285568      |
| train/                  |              |
|    approx_kl            | 0.0056250067 |
|    clip_fraction        | 0.054        |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.9        |
|    explained_variance   | 0.757        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.902       |
|    n_updates            | 9510         |
|    policy_gradient_loss | -0.0118      |
|    std                  | 44.7         |
|    value_loss           | 0.171        |
------------------------------------------
[ADAPTIVE] Episode 570 reward: -0.040225
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0360541    |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 559          |
|    time_elapsed         | 1823         |
|    total_timesteps      | 2289664      |
| train/                  |              |
|    approx_kl            | 0.0074084313 |
|    clip_fraction        | 0.0674       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.9        |
|    explained_variance   | 0.651        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.905       |
|    n_updates            | 9525         |
|    policy_gradient_loss | -0.0117      |
|    std                  | 44.8         |
|    value_loss           | 0.21         |
------------------------------------------
[ADAPTIVE] Episode 571 reward: 0.131540
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.81126654   |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 560          |
|    time_elapsed         | 1827         |
|    total_timesteps      | 2293760      |
| train/                  |              |
|    approx_kl            | 0.0071010934 |
|    clip_fraction        | 0.0781       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.9        |
|    explained_variance   | 0.82         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.931       |
|    n_updates            | 9540         |
|    policy_gradient_loss | -0.0125      |
|    std                  | 44.9         |
|    value_loss           | 0.104        |
------------------------------------------
[ADAPTIVE] Episode 572 reward: -0.000503
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7971849    |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 561          |
|    time_elapsed         | 1830         |
|    total_timesteps      | 2297856      |
| train/                  |              |
|    approx_kl            | 0.0073408843 |
|    clip_fraction        | 0.0688       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.9        |
|    explained_variance   | 0.783        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.882       |
|    n_updates            | 9555         |
|    policy_gradient_loss | -0.0125      |
|    std                  | 45.2         |
|    value_loss           | 0.199        |
------------------------------------------
[ADAPTIVE] Episode 573 reward: -0.006287
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5832577   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 562         |
|    time_elapsed         | 1833        |
|    total_timesteps      | 2301952     |
| train/                  |             |
|    approx_kl            | 0.009152915 |
|    clip_fraction        | 0.0678      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47         |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.927      |
|    n_updates            | 9570        |
|    policy_gradient_loss | -0.0125     |
|    std                  | 45.3        |
|    value_loss           | 0.0885      |
-----------------------------------------
[ADAPTIVE] Episode 574 reward: 0.165965
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.43353897  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 563         |
|    time_elapsed         | 1836        |
|    total_timesteps      | 2306048     |
| train/                  |             |
|    approx_kl            | 0.006021276 |
|    clip_fraction        | 0.0632      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47         |
|    explained_variance   | 0.857       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.931      |
|    n_updates            | 9585        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 45.5        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 575 reward: 0.061612
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6473993    |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 564          |
|    time_elapsed         | 1839         |
|    total_timesteps      | 2310144      |
| train/                  |              |
|    approx_kl            | 0.0067431424 |
|    clip_fraction        | 0.0746       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47          |
|    explained_variance   | 0.86         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.933       |
|    n_updates            | 9600         |
|    policy_gradient_loss | -0.00976     |
|    std                  | 45.5         |
|    value_loss           | 0.108        |
------------------------------------------
[ADAPTIVE] Episode 576 reward: -0.121809
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6273731    |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 565          |
|    time_elapsed         | 1842         |
|    total_timesteps      | 2314240      |
| train/                  |              |
|    approx_kl            | 0.0071255057 |
|    clip_fraction        | 0.0758       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47          |
|    explained_variance   | 0.786        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.935       |
|    n_updates            | 9615         |
|    policy_gradient_loss | -0.0137      |
|    std                  | 45.6         |
|    value_loss           | 0.116        |
------------------------------------------
[ADAPTIVE] Episode 577 reward: -0.043581
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.56942326  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 566         |
|    time_elapsed         | 1845        |
|    total_timesteps      | 2318336     |
| train/                  |             |
|    approx_kl            | 0.006087699 |
|    clip_fraction        | 0.069       |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.1       |
|    explained_variance   | 0.78        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.897      |
|    n_updates            | 9630        |
|    policy_gradient_loss | -0.012      |
|    std                  | 45.8        |
|    value_loss           | 0.185       |
-----------------------------------------
[ADAPTIVE] Episode 578 reward: -0.012767
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5356238    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 567          |
|    time_elapsed         | 1848         |
|    total_timesteps      | 2322432      |
| train/                  |              |
|    approx_kl            | 0.0088891275 |
|    clip_fraction        | 0.0855       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.1        |
|    explained_variance   | 0.779        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.928       |
|    n_updates            | 9645         |
|    policy_gradient_loss | -0.0126      |
|    std                  | 45.9         |
|    value_loss           | 0.103        |
------------------------------------------
[ADAPTIVE] Episode 579 reward: 0.029550
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.63942087  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 568         |
|    time_elapsed         | 1852        |
|    total_timesteps      | 2326528     |
| train/                  |             |
|    approx_kl            | 0.008311128 |
|    clip_fraction        | 0.0994      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.1       |
|    explained_variance   | 0.733       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.907      |
|    n_updates            | 9660        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 45.9        |
|    value_loss           | 0.171       |
-----------------------------------------
[ADAPTIVE] Episode 580 reward: 0.092602
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.690118    |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 569         |
|    time_elapsed         | 1855        |
|    total_timesteps      | 2330624     |
| train/                  |             |
|    approx_kl            | 0.008112269 |
|    clip_fraction        | 0.0654      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.1       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.876      |
|    n_updates            | 9675        |
|    policy_gradient_loss | -0.013      |
|    std                  | 46.1        |
|    value_loss           | 0.225       |
-----------------------------------------
[ADAPTIVE] Episode 581 reward: -0.038140
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.63854563  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 570         |
|    time_elapsed         | 1859        |
|    total_timesteps      | 2334720     |
| train/                  |             |
|    approx_kl            | 0.009303053 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.2       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.895      |
|    n_updates            | 9690        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 46.3        |
|    value_loss           | 0.182       |
-----------------------------------------
[ADAPTIVE] Episode 582 reward: 0.030651
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.57625616  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 571         |
|    time_elapsed         | 1862        |
|    total_timesteps      | 2338816     |
| train/                  |             |
|    approx_kl            | 0.009412388 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.2       |
|    explained_variance   | 0.705       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.913      |
|    n_updates            | 9705        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 46.8        |
|    value_loss           | 0.175       |
-----------------------------------------
[ADAPTIVE] Episode 583 reward: -0.123601
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6853714   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 572         |
|    time_elapsed         | 1865        |
|    total_timesteps      | 2342912     |
| train/                  |             |
|    approx_kl            | 0.008263524 |
|    clip_fraction        | 0.0889      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.3       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.904      |
|    n_updates            | 9720        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 47          |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 584 reward: 0.055814
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9952851   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 573         |
|    time_elapsed         | 1868        |
|    total_timesteps      | 2347008     |
| train/                  |             |
|    approx_kl            | 0.007699692 |
|    clip_fraction        | 0.0861      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.3       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.899      |
|    n_updates            | 9735        |
|    policy_gradient_loss | -0.0123     |
|    std                  | 47.2        |
|    value_loss           | 0.184       |
-----------------------------------------
[ADAPTIVE] Episode 585 reward: 0.066961
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.88457793  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 574         |
|    time_elapsed         | 1871        |
|    total_timesteps      | 2351104     |
| train/                  |             |
|    approx_kl            | 0.007736751 |
|    clip_fraction        | 0.0919      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.4       |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.896      |
|    n_updates            | 9750        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 47.5        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 586 reward: -0.000839
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.81980324  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 575         |
|    time_elapsed         | 1875        |
|    total_timesteps      | 2355200     |
| train/                  |             |
|    approx_kl            | 0.008121785 |
|    clip_fraction        | 0.0619      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.4       |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.916      |
|    n_updates            | 9765        |
|    policy_gradient_loss | -0.0132     |
|    std                  | 47.4        |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 587 reward: 0.089196
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8152799   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 576         |
|    time_elapsed         | 1877        |
|    total_timesteps      | 2359296     |
| train/                  |             |
|    approx_kl            | 0.008858992 |
|    clip_fraction        | 0.0967      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.4       |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.934      |
|    n_updates            | 9780        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 47.5        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 588 reward: 0.013066
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9323944    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 577          |
|    time_elapsed         | 1881         |
|    total_timesteps      | 2363392      |
| train/                  |              |
|    approx_kl            | 0.0077118548 |
|    clip_fraction        | 0.0801       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.4        |
|    explained_variance   | 0.74         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.93        |
|    n_updates            | 9795         |
|    policy_gradient_loss | -0.0144      |
|    std                  | 47.6         |
|    value_loss           | 0.108        |
------------------------------------------
[ADAPTIVE] Episode 589 reward: 0.055412
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9063858   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 578         |
|    time_elapsed         | 1884        |
|    total_timesteps      | 2367488     |
| train/                  |             |
|    approx_kl            | 0.006913396 |
|    clip_fraction        | 0.0694      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.5       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.929      |
|    n_updates            | 9810        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 47.9        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 590 reward: -0.002616
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7486274   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 579         |
|    time_elapsed         | 1887        |
|    total_timesteps      | 2371584     |
| train/                  |             |
|    approx_kl            | 0.009089187 |
|    clip_fraction        | 0.0873      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.5       |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.916      |
|    n_updates            | 9825        |
|    policy_gradient_loss | -0.0133     |
|    std                  | 48          |
|    value_loss           | 0.194       |
-----------------------------------------
[ADAPTIVE] Episode 591 reward: -0.015440
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6681221   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 580         |
|    time_elapsed         | 1890        |
|    total_timesteps      | 2375680     |
| train/                  |             |
|    approx_kl            | 0.009205615 |
|    clip_fraction        | 0.0683      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.5       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.934      |
|    n_updates            | 9840        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 48.1        |
|    value_loss           | 0.129       |
-----------------------------------------
[ADAPTIVE] Episode 592 reward: 0.004012
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.81305593   |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 581          |
|    time_elapsed         | 1893         |
|    total_timesteps      | 2379776      |
| train/                  |              |
|    approx_kl            | 0.0071219425 |
|    clip_fraction        | 0.0795       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.6        |
|    explained_variance   | 0.718        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.918       |
|    n_updates            | 9855         |
|    policy_gradient_loss | -0.0123      |
|    std                  | 48.3         |
|    value_loss           | 0.141        |
------------------------------------------
[ADAPTIVE] Episode 593 reward: -0.021290
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7738048   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 582         |
|    time_elapsed         | 1897        |
|    total_timesteps      | 2383872     |
| train/                  |             |
|    approx_kl            | 0.009546353 |
|    clip_fraction        | 0.0891      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.6       |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.955      |
|    n_updates            | 9870        |
|    policy_gradient_loss | -0.0134     |
|    std                  | 48.6        |
|    value_loss           | 0.0865      |
-----------------------------------------
[ADAPTIVE] Episode 594 reward: 0.013915
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5013876   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 583         |
|    time_elapsed         | 1900        |
|    total_timesteps      | 2387968     |
| train/                  |             |
|    approx_kl            | 0.007986072 |
|    clip_fraction        | 0.0842      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.7       |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.934      |
|    n_updates            | 9885        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 49          |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 595 reward: 0.032015
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4400195   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 584         |
|    time_elapsed         | 1903        |
|    total_timesteps      | 2392064     |
| train/                  |             |
|    approx_kl            | 0.008185431 |
|    clip_fraction        | 0.0646      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.7       |
|    explained_variance   | 0.678       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.938      |
|    n_updates            | 9900        |
|    policy_gradient_loss | -0.011      |
|    std                  | 49.4        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 596 reward: -0.000314
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.26211902  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 585         |
|    time_elapsed         | 1906        |
|    total_timesteps      | 2396160     |
| train/                  |             |
|    approx_kl            | 0.007110766 |
|    clip_fraction        | 0.0599      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.8       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.947      |
|    n_updates            | 9915        |
|    policy_gradient_loss | -0.00975    |
|    std                  | 49.7        |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 597 reward: -0.052157
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4839272   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 586         |
|    time_elapsed         | 1910        |
|    total_timesteps      | 2400256     |
| train/                  |             |
|    approx_kl            | 0.008443909 |
|    clip_fraction        | 0.0762      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.8       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.917      |
|    n_updates            | 9930        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 50          |
|    value_loss           | 0.12        |
-----------------------------------------
[ADAPTIVE] Episode 598 reward: -0.049464
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6602558    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 587          |
|    time_elapsed         | 1913         |
|    total_timesteps      | 2404352      |
| train/                  |              |
|    approx_kl            | 0.0071865073 |
|    clip_fraction        | 0.0735       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.9        |
|    explained_variance   | 0.74         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.913       |
|    n_updates            | 9945         |
|    policy_gradient_loss | -0.0121      |
|    std                  | 50.2         |
|    value_loss           | 0.127        |
------------------------------------------
[ADAPTIVE] Episode 599 reward: 0.059584
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7902396    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 588          |
|    time_elapsed         | 1916         |
|    total_timesteps      | 2408448      |
| train/                  |              |
|    approx_kl            | 0.0076532755 |
|    clip_fraction        | 0.0671       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.9        |
|    explained_variance   | 0.744        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.887       |
|    n_updates            | 9960         |
|    policy_gradient_loss | -0.0146      |
|    std                  | 50.5         |
|    value_loss           | 0.177        |
------------------------------------------
[ADAPTIVE] Episode 600 reward: 0.028308
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7301537    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 589          |
|    time_elapsed         | 1919         |
|    total_timesteps      | 2412544      |
| train/                  |              |
|    approx_kl            | 0.0068039563 |
|    clip_fraction        | 0.0607       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48          |
|    explained_variance   | 0.64         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.913       |
|    n_updates            | 9975         |
|    policy_gradient_loss | -0.011       |
|    std                  | 50.7         |
|    value_loss           | 0.225        |
------------------------------------------
[ADAPTIVE] Episode 601 reward: 0.070186
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.79279387   |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 590          |
|    time_elapsed         | 1923         |
|    total_timesteps      | 2416640      |
| train/                  |              |
|    approx_kl            | 0.0070146853 |
|    clip_fraction        | 0.0555       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48          |
|    explained_variance   | 0.738        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.907       |
|    n_updates            | 9990         |
|    policy_gradient_loss | -0.0114      |
|    std                  | 50.9         |
|    value_loss           | 0.196        |
------------------------------------------
[ADAPTIVE] Episode 602 reward: 0.002007
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6374074   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 591         |
|    time_elapsed         | 1926        |
|    total_timesteps      | 2420736     |
| train/                  |             |
|    approx_kl            | 0.006188349 |
|    clip_fraction        | 0.08        |
|    clip_range           | 0.2         |
|    entropy_loss         | -48         |
|    explained_variance   | 0.708       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.919      |
|    n_updates            | 10005       |
|    policy_gradient_loss | -0.0103     |
|    std                  | 51          |
|    value_loss           | 0.158       |
-----------------------------------------
[ADAPTIVE] Episode 603 reward: 0.067257
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5430297   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 592         |
|    time_elapsed         | 1929        |
|    total_timesteps      | 2424832     |
| train/                  |             |
|    approx_kl            | 0.007873847 |
|    clip_fraction        | 0.0716      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.1       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.925      |
|    n_updates            | 10020       |
|    policy_gradient_loss | -0.0123     |
|    std                  | 51.2        |
|    value_loss           | 0.149       |
-----------------------------------------
[ADAPTIVE] Episode 604 reward: 0.064981
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.401094    |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 593         |
|    time_elapsed         | 1933        |
|    total_timesteps      | 2428928     |
| train/                  |             |
|    approx_kl            | 0.008064529 |
|    clip_fraction        | 0.0887      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.1       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.933      |
|    n_updates            | 10035       |
|    policy_gradient_loss | -0.013      |
|    std                  | 51.5        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 605 reward: -0.054761
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.18078595 |
| time/                   |            |
|    fps                  | 1256       |
|    iterations           | 594        |
|    time_elapsed         | 1936       |
|    total_timesteps      | 2433024    |
| train/                  |            |
|    approx_kl            | 0.00794103 |
|    clip_fraction        | 0.0602     |
|    clip_range           | 0.2        |
|    entropy_loss         | -48.2      |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.956     |
|    n_updates            | 10050      |
|    policy_gradient_loss | -0.0133    |
|    std                  | 51.9       |
|    value_loss           | 0.103      |
----------------------------------------
[ADAPTIVE] Episode 606 reward: -0.030353
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.18855663   |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 595          |
|    time_elapsed         | 1939         |
|    total_timesteps      | 2437120      |
| train/                  |              |
|    approx_kl            | 0.0073870663 |
|    clip_fraction        | 0.0669       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.2        |
|    explained_variance   | 0.792        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.933       |
|    n_updates            | 10065        |
|    policy_gradient_loss | -0.0136      |
|    std                  | 52           |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 607 reward: -0.148814
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.20590603  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 596         |
|    time_elapsed         | 1942        |
|    total_timesteps      | 2441216     |
| train/                  |             |
|    approx_kl            | 0.008214172 |
|    clip_fraction        | 0.091       |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.3       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.943      |
|    n_updates            | 10080       |
|    policy_gradient_loss | -0.0145     |
|    std                  | 52.5        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 608 reward: -0.083691
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.41159287  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 597         |
|    time_elapsed         | 1945        |
|    total_timesteps      | 2445312     |
| train/                  |             |
|    approx_kl            | 0.007774582 |
|    clip_fraction        | 0.0573      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.3       |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.884      |
|    n_updates            | 10095       |
|    policy_gradient_loss | -0.0108     |
|    std                  | 52.6        |
|    value_loss           | 0.283       |
-----------------------------------------
[ADAPTIVE] Episode 609 reward: 0.059764
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.42146462  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 598         |
|    time_elapsed         | 1949        |
|    total_timesteps      | 2449408     |
| train/                  |             |
|    approx_kl            | 0.007580213 |
|    clip_fraction        | 0.0693      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.3       |
|    explained_variance   | 0.783       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.949      |
|    n_updates            | 10110       |
|    policy_gradient_loss | -0.012      |
|    std                  | 53          |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 610 reward: 0.054058
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5827067    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 599          |
|    time_elapsed         | 1952         |
|    total_timesteps      | 2453504      |
| train/                  |              |
|    approx_kl            | 0.0073095793 |
|    clip_fraction        | 0.0874       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.4        |
|    explained_variance   | 0.783        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.935       |
|    n_updates            | 10125        |
|    policy_gradient_loss | -0.0112      |
|    std                  | 53.3         |
|    value_loss           | 0.166        |
------------------------------------------
[ADAPTIVE] Episode 611 reward: 0.100327
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.61891043  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 600         |
|    time_elapsed         | 1955        |
|    total_timesteps      | 2457600     |
| train/                  |             |
|    approx_kl            | 0.009517081 |
|    clip_fraction        | 0.0826      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.4       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.929      |
|    n_updates            | 10140       |
|    policy_gradient_loss | -0.012      |
|    std                  | 53.5        |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 612 reward: -0.089161
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.74004066  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 601         |
|    time_elapsed         | 1959        |
|    total_timesteps      | 2461696     |
| train/                  |             |
|    approx_kl            | 0.008312616 |
|    clip_fraction        | 0.0945      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.5       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.947      |
|    n_updates            | 10155       |
|    policy_gradient_loss | -0.0187     |
|    std                  | 53.9        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 613 reward: 0.075657
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.86425614  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 602         |
|    time_elapsed         | 1962        |
|    total_timesteps      | 2465792     |
| train/                  |             |
|    approx_kl            | 0.008035367 |
|    clip_fraction        | 0.0797      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.5       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.955      |
|    n_updates            | 10170       |
|    policy_gradient_loss | -0.0139     |
|    std                  | 54.2        |
|    value_loss           | 0.176       |
-----------------------------------------
[ADAPTIVE] Episode 614 reward: -0.044163
[ADAPTIVE] Episode 615 reward: 0.078230
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6616301    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 603          |
|    time_elapsed         | 1965         |
|    total_timesteps      | 2469888      |
| train/                  |              |
|    approx_kl            | 0.0071593258 |
|    clip_fraction        | 0.0546       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.6        |
|    explained_variance   | 0.772        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.938       |
|    n_updates            | 10185        |
|    policy_gradient_loss | -0.0128      |
|    std                  | 54.3         |
|    value_loss           | 0.177        |
------------------------------------------
[ADAPTIVE] Episode 616 reward: 0.026119
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6796081    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 604          |
|    time_elapsed         | 1969         |
|    total_timesteps      | 2473984      |
| train/                  |              |
|    approx_kl            | 0.0068730745 |
|    clip_fraction        | 0.0566       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.6        |
|    explained_variance   | 0.729        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.878       |
|    n_updates            | 10200        |
|    policy_gradient_loss | -0.0108      |
|    std                  | 54.7         |
|    value_loss           | 0.203        |
------------------------------------------
[ADAPTIVE] Episode 617 reward: 0.092784
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5084405   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 605         |
|    time_elapsed         | 1972        |
|    total_timesteps      | 2478080     |
| train/                  |             |
|    approx_kl            | 0.007065323 |
|    clip_fraction        | 0.092       |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.7       |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.949      |
|    n_updates            | 10215       |
|    policy_gradient_loss | -0.0133     |
|    std                  | 54.9        |
|    value_loss           | 0.0875      |
-----------------------------------------
[ADAPTIVE] Episode 618 reward: -0.046961
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6293424   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 606         |
|    time_elapsed         | 1975        |
|    total_timesteps      | 2482176     |
| train/                  |             |
|    approx_kl            | 0.007042587 |
|    clip_fraction        | 0.0659      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.7       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.938      |
|    n_updates            | 10230       |
|    policy_gradient_loss | -0.0121     |
|    std                  | 55.3        |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 619 reward: 0.029290
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.54192793   |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 607          |
|    time_elapsed         | 1979         |
|    total_timesteps      | 2486272      |
| train/                  |              |
|    approx_kl            | 0.0067296373 |
|    clip_fraction        | 0.0709       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.8        |
|    explained_variance   | 0.741        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.913       |
|    n_updates            | 10245        |
|    policy_gradient_loss | -0.0133      |
|    std                  | 55.5         |
|    value_loss           | 0.232        |
------------------------------------------
[ADAPTIVE] Episode 620 reward: -0.050132
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5440927    |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 608          |
|    time_elapsed         | 1982         |
|    total_timesteps      | 2490368      |
| train/                  |              |
|    approx_kl            | 0.0071633686 |
|    clip_fraction        | 0.0847       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.8        |
|    explained_variance   | 0.815        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.969       |
|    n_updates            | 10260        |
|    policy_gradient_loss | -0.0132      |
|    std                  | 55.6         |
|    value_loss           | 0.0807       |
------------------------------------------
[ADAPTIVE] Episode 621 reward: -0.042943
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84764916  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 609         |
|    time_elapsed         | 1986        |
|    total_timesteps      | 2494464     |
| train/                  |             |
|    approx_kl            | 0.009106513 |
|    clip_fraction        | 0.0812      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.8       |
|    explained_variance   | 0.83        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.95       |
|    n_updates            | 10275       |
|    policy_gradient_loss | -0.0134     |
|    std                  | 55.9        |
|    value_loss           | 0.0949      |
-----------------------------------------
[ADAPTIVE] Episode 622 reward: -0.171361
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.90128165  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 610         |
|    time_elapsed         | 1989        |
|    total_timesteps      | 2498560     |
| train/                  |             |
|    approx_kl            | 0.008997699 |
|    clip_fraction        | 0.0619      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.9       |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.97       |
|    n_updates            | 10290       |
|    policy_gradient_loss | -0.0137     |
|    std                  | 56.2        |
|    value_loss           | 0.0807      |
-----------------------------------------
[ADAPTIVE] Episode 623 reward: -0.047572
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.92034286  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 611         |
|    time_elapsed         | 1993        |
|    total_timesteps      | 2502656     |
| train/                  |             |
|    approx_kl            | 0.005746239 |
|    clip_fraction        | 0.0444      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.9       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.912      |
|    n_updates            | 10305       |
|    policy_gradient_loss | -0.0103     |
|    std                  | 56.5        |
|    value_loss           | 0.208       |
-----------------------------------------
[ADAPTIVE] Episode 624 reward: -0.020128
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0879798   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 612         |
|    time_elapsed         | 1996        |
|    total_timesteps      | 2506752     |
| train/                  |             |
|    approx_kl            | 0.006815112 |
|    clip_fraction        | 0.0745      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49         |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.928      |
|    n_updates            | 10320       |
|    policy_gradient_loss | -0.0116     |
|    std                  | 56.6        |
|    value_loss           | 0.193       |
-----------------------------------------
[ADAPTIVE] Episode 625 reward: 0.014210
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9050277   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 613         |
|    time_elapsed         | 1999        |
|    total_timesteps      | 2510848     |
| train/                  |             |
|    approx_kl            | 0.006680905 |
|    clip_fraction        | 0.0599      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49         |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.957      |
|    n_updates            | 10335       |
|    policy_gradient_loss | -0.0103     |
|    std                  | 56.9        |
|    value_loss           | 0.145       |
-----------------------------------------
[ADAPTIVE] Episode 626 reward: 0.024121
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.78309435   |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 614          |
|    time_elapsed         | 2002         |
|    total_timesteps      | 2514944      |
| train/                  |              |
|    approx_kl            | 0.0054708393 |
|    clip_fraction        | 0.0477       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49          |
|    explained_variance   | 0.804        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.875       |
|    n_updates            | 10350        |
|    policy_gradient_loss | -0.0105      |
|    std                  | 57.1         |
|    value_loss           | 0.234        |
------------------------------------------
[ADAPTIVE] Episode 627 reward: 0.085212
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7066297   |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 615         |
|    time_elapsed         | 2005        |
|    total_timesteps      | 2519040     |
| train/                  |             |
|    approx_kl            | 0.007803898 |
|    clip_fraction        | 0.0722      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.1       |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.942      |
|    n_updates            | 10365       |
|    policy_gradient_loss | -0.0119     |
|    std                  | 57.3        |
|    value_loss           | 0.091       |
-----------------------------------------
[ADAPTIVE] Episode 628 reward: -0.022282
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.51611865  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 616         |
|    time_elapsed         | 2009        |
|    total_timesteps      | 2523136     |
| train/                  |             |
|    approx_kl            | 0.009154705 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.1       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.952      |
|    n_updates            | 10380       |
|    policy_gradient_loss | -0.0166     |
|    std                  | 57.5        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 629 reward: -0.042317
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67553025  |
| time/                   |             |
|    fps                  | 1255        |
|    iterations           | 617         |
|    time_elapsed         | 2012        |
|    total_timesteps      | 2527232     |
| train/                  |             |
|    approx_kl            | 0.006711282 |
|    clip_fraction        | 0.0642      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.1       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.932      |
|    n_updates            | 10395       |
|    policy_gradient_loss | -0.0111     |
|    std                  | 57.9        |
|    value_loss           | 0.204       |
-----------------------------------------
[ADAPTIVE] Episode 630 reward: -0.008251
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5124367    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 618          |
|    time_elapsed         | 2015         |
|    total_timesteps      | 2531328      |
| train/                  |              |
|    approx_kl            | 0.0072784503 |
|    clip_fraction        | 0.0588       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.2        |
|    explained_variance   | 0.764        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.951       |
|    n_updates            | 10410        |
|    policy_gradient_loss | -0.0133      |
|    std                  | 58.2         |
|    value_loss           | 0.149        |
------------------------------------------
[ADAPTIVE] Episode 631 reward: 0.027426
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.74424344   |
| time/                   |              |
|    fps                  | 1255         |
|    iterations           | 619          |
|    time_elapsed         | 2018         |
|    total_timesteps      | 2535424      |
| train/                  |              |
|    approx_kl            | 0.0077539766 |
|    clip_fraction        | 0.0709       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.2        |
|    explained_variance   | 0.796        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.969       |
|    n_updates            | 10425        |
|    policy_gradient_loss | -0.0122      |
|    std                  | 58.6         |
|    value_loss           | 0.0874       |
------------------------------------------
[ADAPTIVE] Episode 632 reward: 0.154691
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.031829    |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 620         |
|    time_elapsed         | 2021        |
|    total_timesteps      | 2539520     |
| train/                  |             |
|    approx_kl            | 0.010113167 |
|    clip_fraction        | 0.0769      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.3       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.961      |
|    n_updates            | 10440       |
|    policy_gradient_loss | -0.013      |
|    std                  | 59.1        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 633 reward: 0.033851
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0317284    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 621          |
|    time_elapsed         | 2024         |
|    total_timesteps      | 2543616      |
| train/                  |              |
|    approx_kl            | 0.0071096537 |
|    clip_fraction        | 0.0722       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.4        |
|    explained_variance   | 0.776        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.938       |
|    n_updates            | 10455        |
|    policy_gradient_loss | -0.013       |
|    std                  | 59.4         |
|    value_loss           | 0.214        |
------------------------------------------
[ADAPTIVE] Episode 634 reward: 0.042969
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2231991   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 622         |
|    time_elapsed         | 2027        |
|    total_timesteps      | 2547712     |
| train/                  |             |
|    approx_kl            | 0.008213126 |
|    clip_fraction        | 0.0812      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.4       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.969      |
|    n_updates            | 10470       |
|    policy_gradient_loss | -0.0148     |
|    std                  | 59.7        |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 635 reward: -0.035804
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1234751   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 623         |
|    time_elapsed         | 2030        |
|    total_timesteps      | 2551808     |
| train/                  |             |
|    approx_kl            | 0.007834799 |
|    clip_fraction        | 0.0722      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.5       |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.942      |
|    n_updates            | 10485       |
|    policy_gradient_loss | -0.0132     |
|    std                  | 60          |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 636 reward: 0.017899
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0035881    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 624          |
|    time_elapsed         | 2034         |
|    total_timesteps      | 2555904      |
| train/                  |              |
|    approx_kl            | 0.0070611606 |
|    clip_fraction        | 0.0689       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.5        |
|    explained_variance   | 0.693        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.918       |
|    n_updates            | 10500        |
|    policy_gradient_loss | -0.0109      |
|    std                  | 60.2         |
|    value_loss           | 0.229        |
------------------------------------------
[ADAPTIVE] Episode 637 reward: 0.015742
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9687418   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 625         |
|    time_elapsed         | 2037        |
|    total_timesteps      | 2560000     |
| train/                  |             |
|    approx_kl            | 0.009524295 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.5       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.945      |
|    n_updates            | 10515       |
|    policy_gradient_loss | -0.015      |
|    std                  | 60.5        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 638 reward: -0.002690
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7175612   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 626         |
|    time_elapsed         | 2040        |
|    total_timesteps      | 2564096     |
| train/                  |             |
|    approx_kl            | 0.008561542 |
|    clip_fraction        | 0.0728      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.6       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.964      |
|    n_updates            | 10530       |
|    policy_gradient_loss | -0.0132     |
|    std                  | 60.8        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 639 reward: 0.154164
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5450888    |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 627          |
|    time_elapsed         | 2044         |
|    total_timesteps      | 2568192      |
| train/                  |              |
|    approx_kl            | 0.0077337055 |
|    clip_fraction        | 0.0707       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.6        |
|    explained_variance   | 0.721        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.958       |
|    n_updates            | 10545        |
|    policy_gradient_loss | -0.0111      |
|    std                  | 60.9         |
|    value_loss           | 0.149        |
------------------------------------------
[ADAPTIVE] Episode 640 reward: -0.040001
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.3960872   |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 628         |
|    time_elapsed         | 2046        |
|    total_timesteps      | 2572288     |
| train/                  |             |
|    approx_kl            | 0.008861512 |
|    clip_fraction        | 0.0872      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.7       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.993      |
|    n_updates            | 10560       |
|    policy_gradient_loss | -0.0151     |
|    std                  | 61.5        |
|    value_loss           | 0.0952      |
-----------------------------------------
[ADAPTIVE] Episode 641 reward: 0.071933
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.49710333   |
| time/                   |              |
|    fps                  | 1256         |
|    iterations           | 629          |
|    time_elapsed         | 2049         |
|    total_timesteps      | 2576384      |
| train/                  |              |
|    approx_kl            | 0.0076612784 |
|    clip_fraction        | 0.0651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.7        |
|    explained_variance   | 0.827        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.951       |
|    n_updates            | 10575        |
|    policy_gradient_loss | -0.0116      |
|    std                  | 61.5         |
|    value_loss           | 0.147        |
------------------------------------------
[ADAPTIVE] Episode 642 reward: 0.077938
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4438464   |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 630         |
|    time_elapsed         | 2052        |
|    total_timesteps      | 2580480     |
| train/                  |             |
|    approx_kl            | 0.008676125 |
|    clip_fraction        | 0.0806      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.7       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.981      |
|    n_updates            | 10590       |
|    policy_gradient_loss | -0.0128     |
|    std                  | 61.7        |
|    value_loss           | 0.0997      |
-----------------------------------------
[ADAPTIVE] Episode 643 reward: 0.073395
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.54831076  |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 631         |
|    time_elapsed         | 2056        |
|    total_timesteps      | 2584576     |
| train/                  |             |
|    approx_kl            | 0.010697331 |
|    clip_fraction        | 0.0792      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.8       |
|    explained_variance   | 0.803       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.973      |
|    n_updates            | 10605       |
|    policy_gradient_loss | -0.013      |
|    std                  | 62.2        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 644 reward: 0.044674
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.64717776   |
| time/                   |              |
|    fps                  | 1257         |
|    iterations           | 632          |
|    time_elapsed         | 2059         |
|    total_timesteps      | 2588672      |
| train/                  |              |
|    approx_kl            | 0.0058786087 |
|    clip_fraction        | 0.0525       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.8        |
|    explained_variance   | 0.739        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.973       |
|    n_updates            | 10620        |
|    policy_gradient_loss | -0.0117      |
|    std                  | 62.4         |
|    value_loss           | 0.126        |
------------------------------------------
[ADAPTIVE] Episode 645 reward: -0.040269
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.81689924   |
| time/                   |              |
|    fps                  | 1257         |
|    iterations           | 633          |
|    time_elapsed         | 2062         |
|    total_timesteps      | 2592768      |
| train/                  |              |
|    approx_kl            | 0.0074627902 |
|    clip_fraction        | 0.0863       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.9        |
|    explained_variance   | 0.693        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.959       |
|    n_updates            | 10635        |
|    policy_gradient_loss | -0.0105      |
|    std                  | 62.8         |
|    value_loss           | 0.164        |
------------------------------------------
[ADAPTIVE] Episode 646 reward: -0.046501
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8121052    |
| time/                   |              |
|    fps                  | 1257         |
|    iterations           | 634          |
|    time_elapsed         | 2064         |
|    total_timesteps      | 2596864      |
| train/                  |              |
|    approx_kl            | 0.0070327274 |
|    clip_fraction        | 0.0677       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.9        |
|    explained_variance   | 0.725        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.963       |
|    n_updates            | 10650        |
|    policy_gradient_loss | -0.00922     |
|    std                  | 63.3         |
|    value_loss           | 0.159        |
------------------------------------------
[ADAPTIVE] Episode 647 reward: -0.003121
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.94312644  |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 635         |
|    time_elapsed         | 2068        |
|    total_timesteps      | 2600960     |
| train/                  |             |
|    approx_kl            | 0.006415839 |
|    clip_fraction        | 0.0584      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50         |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.953      |
|    n_updates            | 10665       |
|    policy_gradient_loss | -0.0112     |
|    std                  | 63.5        |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 648 reward: 0.067908
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0579005   |
| time/                   |             |
|    fps                  | 1257        |
|    iterations           | 636         |
|    time_elapsed         | 2071        |
|    total_timesteps      | 2605056     |
| train/                  |             |
|    approx_kl            | 0.007241198 |
|    clip_fraction        | 0.0681      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50         |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.934      |
|    n_updates            | 10680       |
|    policy_gradient_loss | -0.0118     |
|    std                  | 64          |
|    value_loss           | 0.207       |
-----------------------------------------
[ADAPTIVE] Episode 649 reward: -0.049962
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0551375    |
| time/                   |              |
|    fps                  | 1257         |
|    iterations           | 637          |
|    time_elapsed         | 2074         |
|    total_timesteps      | 2609152      |
| train/                  |              |
|    approx_kl            | 0.0072611156 |
|    clip_fraction        | 0.0616       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.1        |
|    explained_variance   | 0.734        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.973       |
|    n_updates            | 10695        |
|    policy_gradient_loss | -0.0123      |
|    std                  | 64           |
|    value_loss           | 0.136        |
------------------------------------------
[ADAPTIVE] Episode 650 reward: -0.005342
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0495082    |
| time/                   |              |
|    fps                  | 1258         |
|    iterations           | 638          |
|    time_elapsed         | 2077         |
|    total_timesteps      | 2613248      |
| train/                  |              |
|    approx_kl            | 0.0063751666 |
|    clip_fraction        | 0.0554       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.1        |
|    explained_variance   | 0.74         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.989       |
|    n_updates            | 10710        |
|    policy_gradient_loss | -0.0112      |
|    std                  | 64.7         |
|    value_loss           | 0.106        |
------------------------------------------
[ADAPTIVE] Episode 651 reward: 0.113344
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.94325835  |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 639         |
|    time_elapsed         | 2079        |
|    total_timesteps      | 2617344     |
| train/                  |             |
|    approx_kl            | 0.006283449 |
|    clip_fraction        | 0.0673      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.2       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.962      |
|    n_updates            | 10725       |
|    policy_gradient_loss | -0.0106     |
|    std                  | 65          |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 652 reward: -0.073624
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9147484   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 640         |
|    time_elapsed         | 2082        |
|    total_timesteps      | 2621440     |
| train/                  |             |
|    approx_kl            | 0.008538553 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.2       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.986      |
|    n_updates            | 10740       |
|    policy_gradient_loss | -0.0126     |
|    std                  | 65.6        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 653 reward: -0.023708
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84272957  |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 641         |
|    time_elapsed         | 2085        |
|    total_timesteps      | 2625536     |
| train/                  |             |
|    approx_kl            | 0.007160752 |
|    clip_fraction        | 0.0728      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.3       |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.975      |
|    n_updates            | 10755       |
|    policy_gradient_loss | -0.0133     |
|    std                  | 65.9        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 654 reward: -0.031647
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.75941306  |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 642         |
|    time_elapsed         | 2088        |
|    total_timesteps      | 2629632     |
| train/                  |             |
|    approx_kl            | 0.006004329 |
|    clip_fraction        | 0.0647      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.3       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.972      |
|    n_updates            | 10770       |
|    policy_gradient_loss | -0.011      |
|    std                  | 66.2        |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 655 reward: 0.007196
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8735363    |
| time/                   |              |
|    fps                  | 1259         |
|    iterations           | 643          |
|    time_elapsed         | 2091         |
|    total_timesteps      | 2633728      |
| train/                  |              |
|    approx_kl            | 0.0068823337 |
|    clip_fraction        | 0.0535       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.4        |
|    explained_variance   | 0.819        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.957       |
|    n_updates            | 10785        |
|    policy_gradient_loss | -0.0101      |
|    std                  | 66.5         |
|    value_loss           | 0.194        |
------------------------------------------
[ADAPTIVE] Episode 656 reward: 0.020399
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.62864745   |
| time/                   |              |
|    fps                  | 1259         |
|    iterations           | 644          |
|    time_elapsed         | 2094         |
|    total_timesteps      | 2637824      |
| train/                  |              |
|    approx_kl            | 0.0071830107 |
|    clip_fraction        | 0.0648       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.4        |
|    explained_variance   | 0.794        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.982       |
|    n_updates            | 10800        |
|    policy_gradient_loss | -0.0127      |
|    std                  | 67.1         |
|    value_loss           | 0.143        |
------------------------------------------
[ADAPTIVE] Episode 657 reward: -0.011330
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.64968854  |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 645         |
|    time_elapsed         | 2096        |
|    total_timesteps      | 2641920     |
| train/                  |             |
|    approx_kl            | 0.008075689 |
|    clip_fraction        | 0.0771      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.5       |
|    explained_variance   | 0.612       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.975      |
|    n_updates            | 10815       |
|    policy_gradient_loss | -0.0114     |
|    std                  | 67.2        |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 658 reward: -0.072533
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.41676018  |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 646         |
|    time_elapsed         | 2099        |
|    total_timesteps      | 2646016     |
| train/                  |             |
|    approx_kl            | 0.007126488 |
|    clip_fraction        | 0.064       |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.5       |
|    explained_variance   | 0.687       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.96       |
|    n_updates            | 10830       |
|    policy_gradient_loss | -0.0104     |
|    std                  | 67.5        |
|    value_loss           | 0.173       |
-----------------------------------------
[ADAPTIVE] Episode 659 reward: -0.037016
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5442356    |
| time/                   |              |
|    fps                  | 1260         |
|    iterations           | 647          |
|    time_elapsed         | 2102         |
|    total_timesteps      | 2650112      |
| train/                  |              |
|    approx_kl            | 0.0070281564 |
|    clip_fraction        | 0.0821       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.6        |
|    explained_variance   | 0.784        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.979       |
|    n_updates            | 10845        |
|    policy_gradient_loss | -0.0121      |
|    std                  | 67.9         |
|    value_loss           | 0.161        |
------------------------------------------
[ADAPTIVE] Episode 660 reward: -0.133221
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.72311646  |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 648         |
|    time_elapsed         | 2105        |
|    total_timesteps      | 2654208     |
| train/                  |             |
|    approx_kl            | 0.007286855 |
|    clip_fraction        | 0.0588      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.6       |
|    explained_variance   | 0.72        |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 10860       |
|    policy_gradient_loss | -0.0106     |
|    std                  | 68.3        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 661 reward: -0.014973
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.68862295  |
| time/                   |             |
|    fps                  | 1260        |
|    iterations           | 649         |
|    time_elapsed         | 2108        |
|    total_timesteps      | 2658304     |
| train/                  |             |
|    approx_kl            | 0.008886782 |
|    clip_fraction        | 0.0915      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.7       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.986      |
|    n_updates            | 10875       |
|    policy_gradient_loss | -0.015      |
|    std                  | 68.5        |
|    value_loss           | 0.167       |
-----------------------------------------
[ADAPTIVE] Episode 662 reward: -0.020015
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.71351105  |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 650         |
|    time_elapsed         | 2110        |
|    total_timesteps      | 2662400     |
| train/                  |             |
|    approx_kl            | 0.007159599 |
|    clip_fraction        | 0.073       |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.7       |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.988      |
|    n_updates            | 10890       |
|    policy_gradient_loss | -0.0111     |
|    std                  | 69.3        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 663 reward: -0.017466
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7919263   |
| time/                   |             |
|    fps                  | 1261        |
|    iterations           | 651         |
|    time_elapsed         | 2113        |
|    total_timesteps      | 2666496     |
| train/                  |             |
|    approx_kl            | 0.005362666 |
|    clip_fraction        | 0.0526      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.8       |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.999      |
|    n_updates            | 10905       |
|    policy_gradient_loss | -0.0102     |
|    std                  | 69.4        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 664 reward: 0.094002
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8975239    |
| time/                   |              |
|    fps                  | 1261         |
|    iterations           | 652          |
|    time_elapsed         | 2116         |
|    total_timesteps      | 2670592      |
| train/                  |              |
|    approx_kl            | 0.0059387046 |
|    clip_fraction        | 0.0542       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.8        |
|    explained_variance   | 0.746        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.984       |
|    n_updates            | 10920        |
|    policy_gradient_loss | -0.00993     |
|    std                  | 69.5         |
|    value_loss           | 0.161        |
------------------------------------------
[ADAPTIVE] Episode 665 reward: 0.039510
[ADAPTIVE] Episode 666 reward: -0.042770
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8224229   |
| time/                   |             |
|    fps                  | 1262        |
|    iterations           | 653         |
|    time_elapsed         | 2119        |
|    total_timesteps      | 2674688     |
| train/                  |             |
|    approx_kl            | 0.008030409 |
|    clip_fraction        | 0.0713      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.8       |
|    explained_variance   | 0.802       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.983      |
|    n_updates            | 10935       |
|    policy_gradient_loss | -0.0108     |
|    std                  | 69.8        |
|    value_loss           | 0.192       |
-----------------------------------------
[ADAPTIVE] Episode 667 reward: -0.020459
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8854561   |
| time/                   |             |
|    fps                  | 1262        |
|    iterations           | 654         |
|    time_elapsed         | 2122        |
|    total_timesteps      | 2678784     |
| train/                  |             |
|    approx_kl            | 0.005609704 |
|    clip_fraction        | 0.0579      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.9       |
|    explained_variance   | 0.783       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.983      |
|    n_updates            | 10950       |
|    policy_gradient_loss | -0.0108     |
|    std                  | 70.1        |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 668 reward: 0.048097
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9539664    |
| time/                   |              |
|    fps                  | 1262         |
|    iterations           | 655          |
|    time_elapsed         | 2125         |
|    total_timesteps      | 2682880      |
| train/                  |              |
|    approx_kl            | 0.0069177737 |
|    clip_fraction        | 0.0578       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.9        |
|    explained_variance   | 0.69         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.993       |
|    n_updates            | 10965        |
|    policy_gradient_loss | -0.0123      |
|    std                  | 70.7         |
|    value_loss           | 0.171        |
------------------------------------------
[ADAPTIVE] Episode 669 reward: 0.066524
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67323524  |
| time/                   |             |
|    fps                  | 1262        |
|    iterations           | 656         |
|    time_elapsed         | 2127        |
|    total_timesteps      | 2686976     |
| train/                  |             |
|    approx_kl            | 0.006516611 |
|    clip_fraction        | 0.06        |
|    clip_range           | 0.2         |
|    entropy_loss         | -51         |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 10980       |
|    policy_gradient_loss | -0.0107     |
|    std                  | 71.1        |
|    value_loss           | 0.138       |
-----------------------------------------
[ADAPTIVE] Episode 670 reward: 0.161391
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.52067405   |
| time/                   |              |
|    fps                  | 1263         |
|    iterations           | 657          |
|    time_elapsed         | 2130         |
|    total_timesteps      | 2691072      |
| train/                  |              |
|    approx_kl            | 0.0077987914 |
|    clip_fraction        | 0.0647       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51          |
|    explained_variance   | 0.746        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.925       |
|    n_updates            | 10995        |
|    policy_gradient_loss | -0.0117      |
|    std                  | 71.5         |
|    value_loss           | 0.217        |
------------------------------------------
[ADAPTIVE] Episode 671 reward: 0.110712
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5288539   |
| time/                   |             |
|    fps                  | 1263        |
|    iterations           | 658         |
|    time_elapsed         | 2133        |
|    total_timesteps      | 2695168     |
| train/                  |             |
|    approx_kl            | 0.006225515 |
|    clip_fraction        | 0.0528      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.1       |
|    explained_variance   | 0.776       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 11010       |
|    policy_gradient_loss | -0.00959    |
|    std                  | 71.7        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 672 reward: -0.043257
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.48186016  |
| time/                   |             |
|    fps                  | 1263        |
|    iterations           | 659         |
|    time_elapsed         | 2136        |
|    total_timesteps      | 2699264     |
| train/                  |             |
|    approx_kl            | 0.006420406 |
|    clip_fraction        | 0.0665      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.1       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 11025       |
|    policy_gradient_loss | -0.012      |
|    std                  | 72.2        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 673 reward: 0.049828
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4512615    |
| time/                   |              |
|    fps                  | 1263         |
|    iterations           | 660          |
|    time_elapsed         | 2138         |
|    total_timesteps      | 2703360      |
| train/                  |              |
|    approx_kl            | 0.0070617944 |
|    clip_fraction        | 0.0717       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.2        |
|    explained_variance   | 0.766        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11040        |
|    policy_gradient_loss | -0.0114      |
|    std                  | 72.7         |
|    value_loss           | 0.11         |
------------------------------------------
[ADAPTIVE] Episode 674 reward: -0.058018
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.39039162  |
| time/                   |             |
|    fps                  | 1264        |
|    iterations           | 661         |
|    time_elapsed         | 2141        |
|    total_timesteps      | 2707456     |
| train/                  |             |
|    approx_kl            | 0.010632249 |
|    clip_fraction        | 0.0531      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.2       |
|    explained_variance   | 0.708       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.962      |
|    n_updates            | 11055       |
|    policy_gradient_loss | -0.00761    |
|    std                  | 73          |
|    value_loss           | 0.23        |
-----------------------------------------
[ADAPTIVE] Episode 675 reward: -0.002512
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.52525026   |
| time/                   |              |
|    fps                  | 1264         |
|    iterations           | 662          |
|    time_elapsed         | 2144         |
|    total_timesteps      | 2711552      |
| train/                  |              |
|    approx_kl            | 0.0065150214 |
|    clip_fraction        | 0.0592       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.2        |
|    explained_variance   | 0.783        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.992       |
|    n_updates            | 11070        |
|    policy_gradient_loss | -0.00973     |
|    std                  | 73.5         |
|    value_loss           | 0.171        |
------------------------------------------
[ADAPTIVE] Episode 676 reward: 0.030863
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.49065512   |
| time/                   |              |
|    fps                  | 1264         |
|    iterations           | 663          |
|    time_elapsed         | 2146         |
|    total_timesteps      | 2715648      |
| train/                  |              |
|    approx_kl            | 0.0077009303 |
|    clip_fraction        | 0.0738       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.3        |
|    explained_variance   | 0.781        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.937       |
|    n_updates            | 11085        |
|    policy_gradient_loss | -0.0129      |
|    std                  | 73.7         |
|    value_loss           | 0.171        |
------------------------------------------
[ADAPTIVE] Episode 677 reward: -0.132153
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5625356   |
| time/                   |             |
|    fps                  | 1265        |
|    iterations           | 664         |
|    time_elapsed         | 2149        |
|    total_timesteps      | 2719744     |
| train/                  |             |
|    approx_kl            | 0.008145856 |
|    clip_fraction        | 0.056       |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.4       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11100       |
|    policy_gradient_loss | -0.0109     |
|    std                  | 74.4        |
|    value_loss           | 0.144       |
-----------------------------------------
[ADAPTIVE] Episode 678 reward: 0.025285
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5431464   |
| time/                   |             |
|    fps                  | 1265        |
|    iterations           | 665         |
|    time_elapsed         | 2152        |
|    total_timesteps      | 2723840     |
| train/                  |             |
|    approx_kl            | 0.006149782 |
|    clip_fraction        | 0.0616      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.4       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11115       |
|    policy_gradient_loss | -0.0111     |
|    std                  | 74.9        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 679 reward: -0.000029
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4870864    |
| time/                   |              |
|    fps                  | 1265         |
|    iterations           | 666          |
|    time_elapsed         | 2154         |
|    total_timesteps      | 2727936      |
| train/                  |              |
|    approx_kl            | 0.0068163443 |
|    clip_fraction        | 0.0683       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.5        |
|    explained_variance   | 0.779        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11130        |
|    policy_gradient_loss | -0.0118      |
|    std                  | 75.5         |
|    value_loss           | 0.115        |
------------------------------------------
[ADAPTIVE] Episode 680 reward: 0.081967
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.48131865   |
| time/                   |              |
|    fps                  | 1266         |
|    iterations           | 667          |
|    time_elapsed         | 2157         |
|    total_timesteps      | 2732032      |
| train/                  |              |
|    approx_kl            | 0.0068640206 |
|    clip_fraction        | 0.0541       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.6        |
|    explained_variance   | 0.773        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11145        |
|    policy_gradient_loss | -0.0128      |
|    std                  | 76           |
|    value_loss           | 0.144        |
------------------------------------------
[ADAPTIVE] Episode 681 reward: 0.100770
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.41112033 |
| time/                   |            |
|    fps                  | 1266       |
|    iterations           | 668        |
|    time_elapsed         | 2160       |
|    total_timesteps      | 2736128    |
| train/                  |            |
|    approx_kl            | 0.00601507 |
|    clip_fraction        | 0.0503     |
|    clip_range           | 0.2        |
|    entropy_loss         | -51.6      |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.01      |
|    n_updates            | 11160      |
|    policy_gradient_loss | -0.0102    |
|    std                  | 76.5       |
|    value_loss           | 0.127      |
----------------------------------------
[ADAPTIVE] Episode 682 reward: -0.048284
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.48192418  |
| time/                   |             |
|    fps                  | 1266        |
|    iterations           | 669         |
|    time_elapsed         | 2163        |
|    total_timesteps      | 2740224     |
| train/                  |             |
|    approx_kl            | 0.006964382 |
|    clip_fraction        | 0.0501      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.7       |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11175       |
|    policy_gradient_loss | -0.00995    |
|    std                  | 76.9        |
|    value_loss           | 0.134       |
-----------------------------------------
[ADAPTIVE] Episode 683 reward: 0.004757
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.65784246  |
| time/                   |             |
|    fps                  | 1266        |
|    iterations           | 670         |
|    time_elapsed         | 2166        |
|    total_timesteps      | 2744320     |
| train/                  |             |
|    approx_kl            | 0.005802992 |
|    clip_fraction        | 0.0525      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.7       |
|    explained_variance   | 0.735       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11190       |
|    policy_gradient_loss | -0.00981    |
|    std                  | 77.3        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 684 reward: -0.051732
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7174625   |
| time/                   |             |
|    fps                  | 1266        |
|    iterations           | 671         |
|    time_elapsed         | 2169        |
|    total_timesteps      | 2748416     |
| train/                  |             |
|    approx_kl            | 0.010466511 |
|    clip_fraction        | 0.0674      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.8       |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11205       |
|    policy_gradient_loss | -0.00919    |
|    std                  | 77.7        |
|    value_loss           | 0.094       |
-----------------------------------------
[ADAPTIVE] Episode 685 reward: 0.048123
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.7422915  |
| time/                   |            |
|    fps                  | 1266       |
|    iterations           | 672        |
|    time_elapsed         | 2172       |
|    total_timesteps      | 2752512    |
| train/                  |            |
|    approx_kl            | 0.00812795 |
|    clip_fraction        | 0.0531     |
|    clip_range           | 0.2        |
|    entropy_loss         | -51.8      |
|    explained_variance   | 0.776      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.03      |
|    n_updates            | 11220      |
|    policy_gradient_loss | -0.0108    |
|    std                  | 78.3       |
|    value_loss           | 0.105      |
----------------------------------------
[ADAPTIVE] Episode 686 reward: -0.052895
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6506814    |
| time/                   |              |
|    fps                  | 1267         |
|    iterations           | 673          |
|    time_elapsed         | 2175         |
|    total_timesteps      | 2756608      |
| train/                  |              |
|    approx_kl            | 0.0063823964 |
|    clip_fraction        | 0.0552       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.9        |
|    explained_variance   | 0.708        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11235        |
|    policy_gradient_loss | -0.012       |
|    std                  | 78.8         |
|    value_loss           | 0.126        |
------------------------------------------
[ADAPTIVE] Episode 687 reward: -0.075368
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7312268    |
| time/                   |              |
|    fps                  | 1267         |
|    iterations           | 674          |
|    time_elapsed         | 2178         |
|    total_timesteps      | 2760704      |
| train/                  |              |
|    approx_kl            | 0.0075766854 |
|    clip_fraction        | 0.0802       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52          |
|    explained_variance   | 0.706        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11250        |
|    policy_gradient_loss | -0.0112      |
|    std                  | 79.6         |
|    value_loss           | 0.12         |
------------------------------------------
[ADAPTIVE] Episode 688 reward: -0.018256
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6089969    |
| time/                   |              |
|    fps                  | 1267         |
|    iterations           | 675          |
|    time_elapsed         | 2181         |
|    total_timesteps      | 2764800      |
| train/                  |              |
|    approx_kl            | 0.0066280263 |
|    clip_fraction        | 0.076        |
|    clip_range           | 0.2          |
|    entropy_loss         | -52          |
|    explained_variance   | 0.794        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11265        |
|    policy_gradient_loss | -0.0122      |
|    std                  | 80.1         |
|    value_loss           | 0.0754       |
------------------------------------------
[ADAPTIVE] Episode 689 reward: -0.007875
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7690761    |
| time/                   |              |
|    fps                  | 1267         |
|    iterations           | 676          |
|    time_elapsed         | 2183         |
|    total_timesteps      | 2768896      |
| train/                  |              |
|    approx_kl            | 0.0066315434 |
|    clip_fraction        | 0.0752       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.1        |
|    explained_variance   | 0.78         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11280        |
|    policy_gradient_loss | -0.0122      |
|    std                  | 80.5         |
|    value_loss           | 0.148        |
------------------------------------------
[ADAPTIVE] Episode 690 reward: -0.006076
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.70938385  |
| time/                   |             |
|    fps                  | 1267        |
|    iterations           | 677         |
|    time_elapsed         | 2187        |
|    total_timesteps      | 2772992     |
| train/                  |             |
|    approx_kl            | 0.008173606 |
|    clip_fraction        | 0.053       |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.1       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.994      |
|    n_updates            | 11295       |
|    policy_gradient_loss | -0.00807    |
|    std                  | 80.9        |
|    value_loss           | 0.161       |
-----------------------------------------
[ADAPTIVE] Episode 691 reward: 0.064221
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.62256765  |
| time/                   |             |
|    fps                  | 1268        |
|    iterations           | 678         |
|    time_elapsed         | 2189        |
|    total_timesteps      | 2777088     |
| train/                  |             |
|    approx_kl            | 0.008390991 |
|    clip_fraction        | 0.0763      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.2       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11310       |
|    policy_gradient_loss | -0.0114     |
|    std                  | 81          |
|    value_loss           | 0.0993      |
-----------------------------------------
[ADAPTIVE] Episode 692 reward: 0.071788
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.63537705   |
| time/                   |              |
|    fps                  | 1268         |
|    iterations           | 679          |
|    time_elapsed         | 2192         |
|    total_timesteps      | 2781184      |
| train/                  |              |
|    approx_kl            | 0.0066304635 |
|    clip_fraction        | 0.0559       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.2        |
|    explained_variance   | 0.799        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11325        |
|    policy_gradient_loss | -0.0106      |
|    std                  | 81.4         |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 693 reward: 0.066447
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7693397   |
| time/                   |             |
|    fps                  | 1268        |
|    iterations           | 680         |
|    time_elapsed         | 2195        |
|    total_timesteps      | 2785280     |
| train/                  |             |
|    approx_kl            | 0.009916604 |
|    clip_fraction        | 0.0757      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.2       |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.03       |
|    n_updates            | 11340       |
|    policy_gradient_loss | -0.012      |
|    std                  | 81.9        |
|    value_loss           | 0.119       |
-----------------------------------------
[ADAPTIVE] Episode 694 reward: -0.024619
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.816215    |
| time/                   |             |
|    fps                  | 1268        |
|    iterations           | 681         |
|    time_elapsed         | 2198        |
|    total_timesteps      | 2789376     |
| train/                  |             |
|    approx_kl            | 0.007685609 |
|    clip_fraction        | 0.0671      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.3       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.03       |
|    n_updates            | 11355       |
|    policy_gradient_loss | -0.013      |
|    std                  | 82.3        |
|    value_loss           | 0.0852      |
-----------------------------------------
[ADAPTIVE] Episode 695 reward: -0.115645
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8374994    |
| time/                   |              |
|    fps                  | 1269         |
|    iterations           | 682          |
|    time_elapsed         | 2200         |
|    total_timesteps      | 2793472      |
| train/                  |              |
|    approx_kl            | 0.0077488036 |
|    clip_fraction        | 0.0674       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.3        |
|    explained_variance   | 0.756        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 11370        |
|    policy_gradient_loss | -0.0098      |
|    std                  | 82.6         |
|    value_loss           | 0.12         |
------------------------------------------
[ADAPTIVE] Episode 696 reward: 0.033847
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9692511   |
| time/                   |             |
|    fps                  | 1269        |
|    iterations           | 683         |
|    time_elapsed         | 2203        |
|    total_timesteps      | 2797568     |
| train/                  |             |
|    approx_kl            | 0.006383393 |
|    clip_fraction        | 0.052       |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.4       |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11385       |
|    policy_gradient_loss | -0.0106     |
|    std                  | 82.9        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 697 reward: -0.028571
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0421667   |
| time/                   |             |
|    fps                  | 1269        |
|    iterations           | 684         |
|    time_elapsed         | 2206        |
|    total_timesteps      | 2801664     |
| train/                  |             |
|    approx_kl            | 0.008368533 |
|    clip_fraction        | 0.0826      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.4       |
|    explained_variance   | 0.788       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.03       |
|    n_updates            | 11400       |
|    policy_gradient_loss | -0.0132     |
|    std                  | 83.5        |
|    value_loss           | 0.147       |
-----------------------------------------
[ADAPTIVE] Episode 698 reward: 0.018948
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0247874   |
| time/                   |             |
|    fps                  | 1269        |
|    iterations           | 685         |
|    time_elapsed         | 2209        |
|    total_timesteps      | 2805760     |
| train/                  |             |
|    approx_kl            | 0.006016901 |
|    clip_fraction        | 0.0366      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.5       |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11415       |
|    policy_gradient_loss | -0.00807    |
|    std                  | 83.8        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 699 reward: 0.014232
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8930179    |
| time/                   |              |
|    fps                  | 1269         |
|    iterations           | 686          |
|    time_elapsed         | 2212         |
|    total_timesteps      | 2809856      |
| train/                  |              |
|    approx_kl            | 0.0070745535 |
|    clip_fraction        | 0.057        |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.5        |
|    explained_variance   | 0.761        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11430        |
|    policy_gradient_loss | -0.0103      |
|    std                  | 84.3         |
|    value_loss           | 0.096        |
------------------------------------------
[ADAPTIVE] Episode 700 reward: -0.115381
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6872784    |
| time/                   |              |
|    fps                  | 1270         |
|    iterations           | 687          |
|    time_elapsed         | 2215         |
|    total_timesteps      | 2813952      |
| train/                  |              |
|    approx_kl            | 0.0071354806 |
|    clip_fraction        | 0.075        |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.5        |
|    explained_variance   | 0.784        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11445        |
|    policy_gradient_loss | -0.00932     |
|    std                  | 84.7         |
|    value_loss           | 0.124        |
------------------------------------------
[ADAPTIVE] Episode 701 reward: 0.112314
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47194737  |
| time/                   |             |
|    fps                  | 1270        |
|    iterations           | 688         |
|    time_elapsed         | 2218        |
|    total_timesteps      | 2818048     |
| train/                  |             |
|    approx_kl            | 0.007157241 |
|    clip_fraction        | 0.0823      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.6       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11460       |
|    policy_gradient_loss | -0.0127     |
|    std                  | 84.9        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 702 reward: -0.064614
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.45067218   |
| time/                   |              |
|    fps                  | 1270         |
|    iterations           | 689          |
|    time_elapsed         | 2221         |
|    total_timesteps      | 2822144      |
| train/                  |              |
|    approx_kl            | 0.0048035514 |
|    clip_fraction        | 0.0378       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.6        |
|    explained_variance   | 0.686        |
|    learning_rate        | 0.00025      |
|    loss                 | -1           |
|    n_updates            | 11475        |
|    policy_gradient_loss | -0.00958     |
|    std                  | 85.3         |
|    value_loss           | 0.17         |
------------------------------------------
[ADAPTIVE] Episode 703 reward: -0.059039
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.42356324  |
| time/                   |             |
|    fps                  | 1270        |
|    iterations           | 690         |
|    time_elapsed         | 2224        |
|    total_timesteps      | 2826240     |
| train/                  |             |
|    approx_kl            | 0.007043256 |
|    clip_fraction        | 0.0679      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.6       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11490       |
|    policy_gradient_loss | -0.0113     |
|    std                  | 85.6        |
|    value_loss           | 0.154       |
-----------------------------------------
[ADAPTIVE] Episode 704 reward: -0.170971
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.40361705  |
| time/                   |             |
|    fps                  | 1271        |
|    iterations           | 691         |
|    time_elapsed         | 2226        |
|    total_timesteps      | 2830336     |
| train/                  |             |
|    approx_kl            | 0.006031233 |
|    clip_fraction        | 0.0456      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.7       |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.989      |
|    n_updates            | 11505       |
|    policy_gradient_loss | -0.00963    |
|    std                  | 85.8        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 705 reward: -0.029480
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.50068104   |
| time/                   |              |
|    fps                  | 1271         |
|    iterations           | 692          |
|    time_elapsed         | 2229         |
|    total_timesteps      | 2834432      |
| train/                  |              |
|    approx_kl            | 0.0056505157 |
|    clip_fraction        | 0.0393       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.7        |
|    explained_variance   | 0.8          |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11520        |
|    policy_gradient_loss | -0.00869     |
|    std                  | 86.2         |
|    value_loss           | 0.154        |
------------------------------------------
[ADAPTIVE] Episode 706 reward: 0.031865
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.74847376  |
| time/                   |             |
|    fps                  | 1271        |
|    iterations           | 693         |
|    time_elapsed         | 2232        |
|    total_timesteps      | 2838528     |
| train/                  |             |
|    approx_kl            | 0.006436045 |
|    clip_fraction        | 0.0295      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.7       |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11535       |
|    policy_gradient_loss | -0.00555    |
|    std                  | 86.5        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 707 reward: 0.036596
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8907236    |
| time/                   |              |
|    fps                  | 1271         |
|    iterations           | 694          |
|    time_elapsed         | 2235         |
|    total_timesteps      | 2842624      |
| train/                  |              |
|    approx_kl            | 0.0061552785 |
|    clip_fraction        | 0.0495       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.8        |
|    explained_variance   | 0.854        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11550        |
|    policy_gradient_loss | -0.00955     |
|    std                  | 86.8         |
|    value_loss           | 0.143        |
------------------------------------------
[ADAPTIVE] Episode 708 reward: 0.048580
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9376044    |
| time/                   |              |
|    fps                  | 1272         |
|    iterations           | 695          |
|    time_elapsed         | 2237         |
|    total_timesteps      | 2846720      |
| train/                  |              |
|    approx_kl            | 0.0068260636 |
|    clip_fraction        | 0.0605       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.8        |
|    explained_variance   | 0.814        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11565        |
|    policy_gradient_loss | -0.0107      |
|    std                  | 87.1         |
|    value_loss           | 0.144        |
------------------------------------------
[ADAPTIVE] Episode 709 reward: 0.051207
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.89570916 |
| time/                   |            |
|    fps                  | 1272       |
|    iterations           | 696        |
|    time_elapsed         | 2240       |
|    total_timesteps      | 2850816    |
| train/                  |            |
|    approx_kl            | 0.01032001 |
|    clip_fraction        | 0.0822     |
|    clip_range           | 0.2        |
|    entropy_loss         | -52.8      |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.04      |
|    n_updates            | 11580      |
|    policy_gradient_loss | -0.0116    |
|    std                  | 87.3       |
|    value_loss           | 0.131      |
----------------------------------------
[ADAPTIVE] Episode 710 reward: 0.025293
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9787197    |
| time/                   |              |
|    fps                  | 1272         |
|    iterations           | 697          |
|    time_elapsed         | 2243         |
|    total_timesteps      | 2854912      |
| train/                  |              |
|    approx_kl            | 0.0052475114 |
|    clip_fraction        | 0.0356       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.9        |
|    explained_variance   | 0.738        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11595        |
|    policy_gradient_loss | -0.00875     |
|    std                  | 87.6         |
|    value_loss           | 0.189        |
------------------------------------------
[ADAPTIVE] Episode 711 reward: 0.090941
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.87655675   |
| time/                   |              |
|    fps                  | 1272         |
|    iterations           | 698          |
|    time_elapsed         | 2246         |
|    total_timesteps      | 2859008      |
| train/                  |              |
|    approx_kl            | 0.0069883335 |
|    clip_fraction        | 0.0794       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.9        |
|    explained_variance   | 0.763        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 11610        |
|    policy_gradient_loss | -0.0114      |
|    std                  | 88.2         |
|    value_loss           | 0.119        |
------------------------------------------
[ADAPTIVE] Episode 712 reward: -0.039995
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8037985   |
| time/                   |             |
|    fps                  | 1273        |
|    iterations           | 699         |
|    time_elapsed         | 2248        |
|    total_timesteps      | 2863104     |
| train/                  |             |
|    approx_kl            | 0.005090615 |
|    clip_fraction        | 0.0481      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53         |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.993      |
|    n_updates            | 11625       |
|    policy_gradient_loss | -0.00886    |
|    std                  | 88.8        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 713 reward: 0.003757
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8920105   |
| time/                   |             |
|    fps                  | 1273        |
|    iterations           | 700         |
|    time_elapsed         | 2251        |
|    total_timesteps      | 2867200     |
| train/                  |             |
|    approx_kl            | 0.007109532 |
|    clip_fraction        | 0.0642      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53         |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11640       |
|    policy_gradient_loss | -0.0114     |
|    std                  | 89.1        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 714 reward: 0.000050
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.734475     |
| time/                   |              |
|    fps                  | 1273         |
|    iterations           | 701          |
|    time_elapsed         | 2254         |
|    total_timesteps      | 2871296      |
| train/                  |              |
|    approx_kl            | 0.0062216492 |
|    clip_fraction        | 0.0468       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53          |
|    explained_variance   | 0.817        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11655        |
|    policy_gradient_loss | -0.00973     |
|    std                  | 89.5         |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 715 reward: -0.021077
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6094982    |
| time/                   |              |
|    fps                  | 1273         |
|    iterations           | 702          |
|    time_elapsed         | 2257         |
|    total_timesteps      | 2875392      |
| train/                  |              |
|    approx_kl            | 0.0073359082 |
|    clip_fraction        | 0.0777       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.1        |
|    explained_variance   | 0.847        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11670        |
|    policy_gradient_loss | -0.0111      |
|    std                  | 90.1         |
|    value_loss           | 0.143        |
------------------------------------------
[ADAPTIVE] Episode 716 reward: -0.030955
[ADAPTIVE] Episode 717 reward: 0.003039
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4734504    |
| time/                   |              |
|    fps                  | 1273         |
|    iterations           | 703          |
|    time_elapsed         | 2260         |
|    total_timesteps      | 2879488      |
| train/                  |              |
|    approx_kl            | 0.0075979093 |
|    clip_fraction        | 0.0644       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.2        |
|    explained_variance   | 0.755        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11685        |
|    policy_gradient_loss | -0.00832     |
|    std                  | 90.8         |
|    value_loss           | 0.104        |
------------------------------------------
[ADAPTIVE] Episode 718 reward: -0.068518
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4632698    |
| time/                   |              |
|    fps                  | 1273         |
|    iterations           | 704          |
|    time_elapsed         | 2263         |
|    total_timesteps      | 2883584      |
| train/                  |              |
|    approx_kl            | 0.0064795064 |
|    clip_fraction        | 0.0716       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.2        |
|    explained_variance   | 0.817        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11700        |
|    policy_gradient_loss | -0.0113      |
|    std                  | 91.5         |
|    value_loss           | 0.119        |
------------------------------------------
[ADAPTIVE] Episode 719 reward: 0.032006
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.45381597  |
| time/                   |             |
|    fps                  | 1274        |
|    iterations           | 705         |
|    time_elapsed         | 2266        |
|    total_timesteps      | 2887680     |
| train/                  |             |
|    approx_kl            | 0.004030535 |
|    clip_fraction        | 0.038       |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.3       |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.04       |
|    n_updates            | 11715       |
|    policy_gradient_loss | -0.00964    |
|    std                  | 92.1        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 720 reward: -0.061471
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4967797   |
| time/                   |             |
|    fps                  | 1273        |
|    iterations           | 706         |
|    time_elapsed         | 2269        |
|    total_timesteps      | 2891776     |
| train/                  |             |
|    approx_kl            | 0.007849922 |
|    clip_fraction        | 0.0681      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.3       |
|    explained_variance   | 0.711       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.03       |
|    n_updates            | 11730       |
|    policy_gradient_loss | -0.0107     |
|    std                  | 92.7        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 721 reward: 0.018146
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.58368766  |
| time/                   |             |
|    fps                  | 1273        |
|    iterations           | 707         |
|    time_elapsed         | 2273        |
|    total_timesteps      | 2895872     |
| train/                  |             |
|    approx_kl            | 0.006113297 |
|    clip_fraction        | 0.0572      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.4       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11745       |
|    policy_gradient_loss | -0.00894    |
|    std                  | 93.3        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 722 reward: -0.023874
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7924269    |
| time/                   |              |
|    fps                  | 1274         |
|    iterations           | 708          |
|    time_elapsed         | 2275         |
|    total_timesteps      | 2899968      |
| train/                  |              |
|    approx_kl            | 0.0074118935 |
|    clip_fraction        | 0.0815       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.5        |
|    explained_variance   | 0.778        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11760        |
|    policy_gradient_loss | -0.0122      |
|    std                  | 93.9         |
|    value_loss           | 0.113        |
------------------------------------------
[ADAPTIVE] Episode 723 reward: 0.115340
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8669137   |
| time/                   |             |
|    fps                  | 1274        |
|    iterations           | 709         |
|    time_elapsed         | 2279        |
|    total_timesteps      | 2904064     |
| train/                  |             |
|    approx_kl            | 0.005689347 |
|    clip_fraction        | 0.0361      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.5       |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.04       |
|    n_updates            | 11775       |
|    policy_gradient_loss | -0.00882    |
|    std                  | 94.4        |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 724 reward: 0.053710
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.90279096   |
| time/                   |              |
|    fps                  | 1274         |
|    iterations           | 710          |
|    time_elapsed         | 2281         |
|    total_timesteps      | 2908160      |
| train/                  |              |
|    approx_kl            | 0.0053619696 |
|    clip_fraction        | 0.0466       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.6        |
|    explained_variance   | 0.831        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 11790        |
|    policy_gradient_loss | -0.00707     |
|    std                  | 95           |
|    value_loss           | 0.0942       |
------------------------------------------
[ADAPTIVE] Episode 725 reward: 0.073837
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9547941    |
| time/                   |              |
|    fps                  | 1274         |
|    iterations           | 711          |
|    time_elapsed         | 2284         |
|    total_timesteps      | 2912256      |
| train/                  |              |
|    approx_kl            | 0.0064204936 |
|    clip_fraction        | 0.0472       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.6        |
|    explained_variance   | 0.766        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.07        |
|    n_updates            | 11805        |
|    policy_gradient_loss | -0.00824     |
|    std                  | 95.4         |
|    value_loss           | 0.0827       |
------------------------------------------
[ADAPTIVE] Episode 726 reward: 0.035045
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9593923   |
| time/                   |             |
|    fps                  | 1274        |
|    iterations           | 712         |
|    time_elapsed         | 2287        |
|    total_timesteps      | 2916352     |
| train/                  |             |
|    approx_kl            | 0.006379267 |
|    clip_fraction        | 0.0584      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.7       |
|    explained_variance   | 0.702       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.956      |
|    n_updates            | 11820       |
|    policy_gradient_loss | -0.00939    |
|    std                  | 95.8        |
|    value_loss           | 0.214       |
-----------------------------------------
[ADAPTIVE] Episode 727 reward: -0.056938
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8741136    |
| time/                   |              |
|    fps                  | 1274         |
|    iterations           | 713          |
|    time_elapsed         | 2290         |
|    total_timesteps      | 2920448      |
| train/                  |              |
|    approx_kl            | 0.0068518696 |
|    clip_fraction        | 0.0692       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.7        |
|    explained_variance   | 0.724        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 11835        |
|    policy_gradient_loss | -0.0107      |
|    std                  | 96           |
|    value_loss           | 0.0955       |
------------------------------------------
[ADAPTIVE] Episode 728 reward: 0.097565
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.71550554   |
| time/                   |              |
|    fps                  | 1274         |
|    iterations           | 714          |
|    time_elapsed         | 2293         |
|    total_timesteps      | 2924544      |
| train/                  |              |
|    approx_kl            | 0.0066817137 |
|    clip_fraction        | 0.0541       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.7        |
|    explained_variance   | 0.783        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11850        |
|    policy_gradient_loss | -0.00971     |
|    std                  | 96.4         |
|    value_loss           | 0.102        |
------------------------------------------
[ADAPTIVE] Episode 729 reward: -0.022316
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.72869474   |
| time/                   |              |
|    fps                  | 1275         |
|    iterations           | 715          |
|    time_elapsed         | 2296         |
|    total_timesteps      | 2928640      |
| train/                  |              |
|    approx_kl            | 0.0066543515 |
|    clip_fraction        | 0.0623       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.8        |
|    explained_variance   | 0.827        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 11865        |
|    policy_gradient_loss | -0.0103      |
|    std                  | 96.7         |
|    value_loss           | 0.0977       |
------------------------------------------
[ADAPTIVE] Episode 730 reward: 0.006388
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7665251   |
| time/                   |             |
|    fps                  | 1275        |
|    iterations           | 716         |
|    time_elapsed         | 2299        |
|    total_timesteps      | 2932736     |
| train/                  |             |
|    approx_kl            | 0.005466519 |
|    clip_fraction        | 0.0568      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.8       |
|    explained_variance   | 0.795       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 11880       |
|    policy_gradient_loss | -0.0101     |
|    std                  | 97.2        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 731 reward: -0.062302
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7948549    |
| time/                   |              |
|    fps                  | 1275         |
|    iterations           | 717          |
|    time_elapsed         | 2302         |
|    total_timesteps      | 2936832      |
| train/                  |              |
|    approx_kl            | 0.0051271543 |
|    clip_fraction        | 0.0513       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.8        |
|    explained_variance   | 0.711        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 11895        |
|    policy_gradient_loss | -0.00935     |
|    std                  | 97.6         |
|    value_loss           | 0.116        |
------------------------------------------
[ADAPTIVE] Episode 732 reward: -0.049440
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8058378   |
| time/                   |             |
|    fps                  | 1275        |
|    iterations           | 718         |
|    time_elapsed         | 2305        |
|    total_timesteps      | 2940928     |
| train/                  |             |
|    approx_kl            | 0.006570304 |
|    clip_fraction        | 0.0584      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.9       |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 11910       |
|    policy_gradient_loss | -0.0119     |
|    std                  | 97.9        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 733 reward: -0.039164
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.62789005   |
| time/                   |              |
|    fps                  | 1275         |
|    iterations           | 719          |
|    time_elapsed         | 2308         |
|    total_timesteps      | 2945024      |
| train/                  |              |
|    approx_kl            | 0.0082424395 |
|    clip_fraction        | 0.075        |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.9        |
|    explained_variance   | 0.774        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11925        |
|    policy_gradient_loss | -0.0141      |
|    std                  | 98.4         |
|    value_loss           | 0.127        |
------------------------------------------
[ADAPTIVE] Episode 734 reward: -0.018159
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6531874    |
| time/                   |              |
|    fps                  | 1276         |
|    iterations           | 720          |
|    time_elapsed         | 2310         |
|    total_timesteps      | 2949120      |
| train/                  |              |
|    approx_kl            | 0.0046913996 |
|    clip_fraction        | 0.0291       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.9        |
|    explained_variance   | 0.7          |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11940        |
|    policy_gradient_loss | -0.00654     |
|    std                  | 98.7         |
|    value_loss           | 0.176        |
------------------------------------------
[ADAPTIVE] Episode 735 reward: 0.029978
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4611375    |
| time/                   |              |
|    fps                  | 1276         |
|    iterations           | 721          |
|    time_elapsed         | 2313         |
|    total_timesteps      | 2953216      |
| train/                  |              |
|    approx_kl            | 0.0045640226 |
|    clip_fraction        | 0.0468       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54          |
|    explained_variance   | 0.651        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 11955        |
|    policy_gradient_loss | -0.00888     |
|    std                  | 99           |
|    value_loss           | 0.185        |
------------------------------------------
[ADAPTIVE] Episode 736 reward: -0.007270
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5312611    |
| time/                   |              |
|    fps                  | 1276         |
|    iterations           | 722          |
|    time_elapsed         | 2316         |
|    total_timesteps      | 2957312      |
| train/                  |              |
|    approx_kl            | 0.0053284643 |
|    clip_fraction        | 0.0395       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54          |
|    explained_variance   | 0.784        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 11970        |
|    policy_gradient_loss | -0.0075      |
|    std                  | 99.5         |
|    value_loss           | 0.163        |
------------------------------------------
[ADAPTIVE] Episode 737 reward: 0.001642
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.52218187   |
| time/                   |              |
|    fps                  | 1277         |
|    iterations           | 723          |
|    time_elapsed         | 2318         |
|    total_timesteps      | 2961408      |
| train/                  |              |
|    approx_kl            | 0.0063163685 |
|    clip_fraction        | 0.0563       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54          |
|    explained_variance   | 0.808        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11985        |
|    policy_gradient_loss | -0.00868     |
|    std                  | 100          |
|    value_loss           | 0.17         |
------------------------------------------
[ADAPTIVE] Episode 738 reward: -0.025295
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.52792436   |
| time/                   |              |
|    fps                  | 1277         |
|    iterations           | 724          |
|    time_elapsed         | 2321         |
|    total_timesteps      | 2965504      |
| train/                  |              |
|    approx_kl            | 0.0073373085 |
|    clip_fraction        | 0.0717       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.1        |
|    explained_variance   | 0.794        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 12000        |
|    policy_gradient_loss | -0.0101      |
|    std                  | 101          |
|    value_loss           | 0.143        |
------------------------------------------
[ADAPTIVE] Episode 739 reward: -0.026495
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5807268   |
| time/                   |             |
|    fps                  | 1277        |
|    iterations           | 725         |
|    time_elapsed         | 2324        |
|    total_timesteps      | 2969600     |
| train/                  |             |
|    approx_kl            | 0.005613375 |
|    clip_fraction        | 0.0465      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54.1       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 12015       |
|    policy_gradient_loss | -0.00822    |
|    std                  | 101         |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 740 reward: -0.038476
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4951452   |
| time/                   |             |
|    fps                  | 1277        |
|    iterations           | 726         |
|    time_elapsed         | 2327        |
|    total_timesteps      | 2973696     |
| train/                  |             |
|    approx_kl            | 0.006335955 |
|    clip_fraction        | 0.0472      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54.2       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.04       |
|    n_updates            | 12030       |
|    policy_gradient_loss | -0.0098     |
|    std                  | 102         |
|    value_loss           | 0.179       |
-----------------------------------------
[ADAPTIVE] Episode 741 reward: -0.028227
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4992018   |
| time/                   |             |
|    fps                  | 1278        |
|    iterations           | 727         |
|    time_elapsed         | 2329        |
|    total_timesteps      | 2977792     |
| train/                  |             |
|    approx_kl            | 0.005730526 |
|    clip_fraction        | 0.0499      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54.2       |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 12045       |
|    policy_gradient_loss | -0.00898    |
|    std                  | 102         |
|    value_loss           | 0.154       |
-----------------------------------------
[ADAPTIVE] Episode 742 reward: 0.016928
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.64562225   |
| time/                   |              |
|    fps                  | 1278         |
|    iterations           | 728          |
|    time_elapsed         | 2333         |
|    total_timesteps      | 2981888      |
| train/                  |              |
|    approx_kl            | 0.0071110465 |
|    clip_fraction        | 0.0625       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.2        |
|    explained_variance   | 0.786        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 12060        |
|    policy_gradient_loss | -0.0121      |
|    std                  | 103          |
|    value_loss           | 0.156        |
------------------------------------------
[ADAPTIVE] Episode 743 reward: -0.161868
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4990941    |
| time/                   |              |
|    fps                  | 1278         |
|    iterations           | 729          |
|    time_elapsed         | 2336         |
|    total_timesteps      | 2985984      |
| train/                  |              |
|    approx_kl            | 0.0049101347 |
|    clip_fraction        | 0.0354       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.3        |
|    explained_variance   | 0.728        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 12075        |
|    policy_gradient_loss | -0.00805     |
|    std                  | 103          |
|    value_loss           | 0.142        |
------------------------------------------
[ADAPTIVE] Episode 744 reward: -0.074774
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.24672459   |
| time/                   |              |
|    fps                  | 1278         |
|    iterations           | 730          |
|    time_elapsed         | 2339         |
|    total_timesteps      | 2990080      |
| train/                  |              |
|    approx_kl            | 0.0091098305 |
|    clip_fraction        | 0.0499       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.4        |
|    explained_variance   | 0.811        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.07        |
|    n_updates            | 12090        |
|    policy_gradient_loss | -0.0082      |
|    std                  | 104          |
|    value_loss           | 0.141        |
------------------------------------------
[ADAPTIVE] Episode 745 reward: 0.070172
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.2707144    |
| time/                   |              |
|    fps                  | 1278         |
|    iterations           | 731          |
|    time_elapsed         | 2341         |
|    total_timesteps      | 2994176      |
| train/                  |              |
|    approx_kl            | 0.0075357785 |
|    clip_fraction        | 0.0557       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.4        |
|    explained_variance   | 0.75         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 12105        |
|    policy_gradient_loss | -0.0098      |
|    std                  | 104          |
|    value_loss           | 0.122        |
------------------------------------------
[ADAPTIVE] Episode 746 reward: 0.035091
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.26560146   |
| time/                   |              |
|    fps                  | 1278         |
|    iterations           | 732          |
|    time_elapsed         | 2344         |
|    total_timesteps      | 2998272      |
| train/                  |              |
|    approx_kl            | 0.0054886867 |
|    clip_fraction        | 0.0558       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.4        |
|    explained_variance   | 0.795        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 12120        |
|    policy_gradient_loss | -0.00928     |
|    std                  | 105          |
|    value_loss           | 0.171        |
------------------------------------------
[ADAPTIVE] Episode 747 reward: 0.062725
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.37928516   |
| time/                   |              |
|    fps                  | 1278         |
|    iterations           | 733          |
|    time_elapsed         | 2347         |
|    total_timesteps      | 3002368      |
| train/                  |              |
|    approx_kl            | 0.0076594586 |
|    clip_fraction        | 0.0709       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.5        |
|    explained_variance   | 0.753        |
|    learning_rate        | 0.00025      |
|    loss                 | -1           |
|    n_updates            | 12135        |
|    policy_gradient_loss | -0.00919     |
|    std                  | 105          |
|    value_loss           | 0.203        |
------------------------------------------
2025-07-08 19:55:13,254 2112831 INFO [TRAIN] Training complete.
2025-07-08 19:55:13,271 2112831 INFO [SAVE] Model saved to: adaptive_curriculum_on_ppo/adaptive_curriculum_on_ppo
