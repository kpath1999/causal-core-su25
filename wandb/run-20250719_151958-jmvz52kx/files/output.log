2025-07-19 15:20:00,888 4052425 INFO [PRETRAINED] Using pretrained model path: ppo_pushing_sb3/final_model.zip
2025-07-19 15:20:00,889 4052425 INFO Starting with 7 interventions
2025-07-19 15:20:00,889 4052425 INFO ===final evaluation===
2025-07-19 15:20:11,453 4052425 INFO Final performance
2025-07-19 15:20:11,454 4052425 INFO average reward: 3.394 +/- 0.000
2025-07-19 15:20:11,454 4052425 INFO success rate: 1.000
2025-07-19 15:20:11,454 4052425 INFO average episode length: 501.0
2025-07-19 15:20:11,454 4052425 INFO initial performance: {'avg_reward': 3.393721938342554, 'reward_std': 4.440892098500626e-16, 'avg_length': 501.0, 'success_rate': 1.0, 'total_episodes': 10}
2025-07-19 15:20:11,454 4052425 INFO CURRICULUM STAGE 1/7
2025-07-19 15:20:11,455 4052425 INFO Remaining interventions: ['goal', 'mass', 'friction', 'visual', 'position', 'angle', 'random']
2025-07-19 15:20:11,455 4052425 INFO
Testing intervention 1/7: goal
2025-07-19 15:20:11,455 4052425 INFO testing intervention: goal
IntervenedCausalWorld created with goal intervention
Reset #1: goal intervention applied (success: True)
2025-07-19 15:20:12,491 4052425 INFO Episode 1: reward=-1.320, length=501, success=False
Reset #2: goal intervention applied (success: True)
2025-07-19 15:20:12,595 4052425 INFO Episode 2: reward=-0.590, length=24, success=True
Reset #3: goal intervention applied (success: True)
2025-07-19 15:20:13,609 4052425 INFO Episode 3: reward=1.938, length=501, success=False
2025-07-19 15:20:18,792 4052425 INFO Results: avg_reward=1.073, success_rate=0.300, avg_length=356.8
2025-07-19 15:20:18,793 4052425 INFO
Testing intervention 2/7: mass
2025-07-19 15:20:18,793 4052425 INFO testing intervention: mass
IntervenedCausalWorld created with mass intervention
Reset #1: mass intervention applied (success: True)
2025-07-19 15:20:18,915 4052425 INFO Episode 1: reward=-1.096, length=29, success=True
Reset #2: mass intervention applied (success: True)
2025-07-19 15:20:19,024 4052425 INFO Episode 2: reward=-0.959, length=30, success=True
Reset #3: mass intervention applied (success: True)
2025-07-19 15:20:19,152 4052425 INFO Episode 3: reward=-0.881, length=41, success=True
2025-07-19 15:20:19,933 4052425 INFO Results: avg_reward=-0.686, success_rate=1.000, avg_length=32.5
2025-07-19 15:20:19,934 4052425 INFO
Testing intervention 3/7: friction
2025-07-19 15:20:19,934 4052425 INFO testing intervention: friction
IntervenedCausalWorld created with friction intervention
Reset #1: friction intervention applied (success: True)
2025-07-19 15:20:20,046 4052425 INFO Episode 1: reward=-0.772, length=27, success=True
Reset #2: friction intervention applied (success: True)
2025-07-19 15:20:20,150 4052425 INFO Episode 2: reward=-0.772, length=27, success=True
Reset #3: friction intervention applied (success: True)
2025-07-19 15:20:20,252 4052425 INFO Episode 3: reward=-0.776, length=27, success=True
2025-07-19 15:20:20,977 4052425 INFO Results: avg_reward=-0.829, success_rate=1.000, avg_length=27.4
2025-07-19 15:20:20,977 4052425 INFO
Testing intervention 4/7: visual
2025-07-19 15:20:20,978 4052425 INFO testing intervention: visual
IntervenedCausalWorld created with visual intervention
Reset #1: visual intervention applied (success: True)
2025-07-19 15:20:21,095 4052425 INFO Episode 1: reward=-0.773, length=27, success=True
Reset #2: visual intervention applied (success: True)
2025-07-19 15:20:21,200 4052425 INFO Episode 2: reward=-0.773, length=27, success=True
Reset #3: visual intervention applied (success: True)
2025-07-19 15:20:21,303 4052425 INFO Episode 3: reward=-0.773, length=27, success=True
2025-07-19 15:20:22,024 4052425 INFO Results: avg_reward=-0.773, success_rate=1.000, avg_length=27.0
2025-07-19 15:20:22,024 4052425 INFO
Testing intervention 5/7: position
2025-07-19 15:20:22,025 4052425 INFO testing intervention: position
IntervenedCausalWorld created with position intervention
Reset #1: position intervention applied (success: True)
2025-07-19 15:20:23,159 4052425 INFO Episode 1: reward=3.167, length=501, success=False
Reset #2: position intervention applied (success: True)
2025-07-19 15:20:23,259 4052425 INFO Episode 2: reward=-1.655, length=25, success=True
Reset #3: position intervention applied (success: True)
2025-07-19 15:20:24,211 4052425 INFO Episode 3: reward=0.229, length=501, success=False
2025-07-19 15:20:29,566 4052425 INFO Results: avg_reward=-0.594, success_rate=0.300, avg_length=358.8
2025-07-19 15:20:29,566 4052425 INFO
Testing intervention 6/7: angle
2025-07-19 15:20:29,567 4052425 INFO testing intervention: angle
IntervenedCausalWorld created with angle intervention
Reset #1: angle intervention applied (success: True)
2025-07-19 15:20:30,620 4052425 INFO Episode 1: reward=2.340, length=501, success=False
Reset #2: angle intervention applied (success: True)
2025-07-19 15:20:31,752 4052425 INFO Episode 2: reward=2.591, length=501, success=False
Reset #3: angle intervention applied (success: True)
2025-07-19 15:20:32,736 4052425 INFO Episode 3: reward=1.534, length=501, success=False
2025-07-19 15:20:40,061 4052425 INFO Results: avg_reward=1.232, success_rate=0.000, avg_length=501.0
2025-07-19 15:20:40,062 4052425 INFO
Testing intervention 7/7: random
2025-07-19 15:20:40,062 4052425 INFO testing intervention: random
IntervenedCausalWorld created with random intervention
Reset #1: random intervention applied (success: True)
2025-07-19 15:20:41,062 4052425 INFO Episode 1: reward=5.186, length=501, success=False
Reset #2: random intervention applied (success: True)
2025-07-19 15:20:42,001 4052425 INFO Episode 2: reward=2.216, length=501, success=False
Reset #3: random intervention applied (success: True)
2025-07-19 15:20:43,001 4052425 INFO Episode 3: reward=4.765, length=501, success=False
2025-07-19 15:20:50,054 4052425 INFO Results: avg_reward=1.528, success_rate=0.000, avg_length=501.0
2025-07-19 15:20:50,055 4052425 INFO best intervention for stage 1: random
2025-07-19 15:20:50,055 4052425 INFO average reward: 1.528
2025-07-19 15:20:50,055 4052425 INFO success rate: 0.000
2025-07-19 15:20:50,055 4052425 INFO average length: 501.0
2025-07-19 15:20:50,055 4052425 INFO === stage 1/7: training on random intervention ===
Logging to highest_reward_sequencing_logs/sb3_csv_logs_1_random
IntervenedCausalWorld created with random intervention
Reset #1: random intervention applied (success: True)
Reset #2: random intervention applied (success: True)
Reset #3: random intervention applied (success: True)
------------------------------------
| custom/              |           |
|    intervention_type | random    |
|    stage             | 1         |
| rollout/             |           |
|    ep_len_mean       | 267       |
|    ep_rew_mean       | 2.0352743 |
| time/                |           |
|    fps               | 452       |
|    iterations        | 1         |
|    time_elapsed      | 9         |
|    total_timesteps   | 5050368   |
------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 282        |
|    ep_rew_mean          | 1.8775079  |
| time/                   |            |
|    fps                  | 277        |
|    iterations           | 2          |
|    time_elapsed         | 29         |
|    total_timesteps      | 5054464    |
| train/                  |            |
|    approx_kl            | 0.03358264 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -21.6      |
|    explained_variance   | 0.336      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.479     |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.0773    |
|    std                  | 2.68       |
|    value_loss           | 0.0988     |
----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 302        |
|    ep_rew_mean          | 1.8642348  |
| time/                   |            |
|    fps                  | 246        |
|    iterations           | 3          |
|    time_elapsed         | 49         |
|    total_timesteps      | 5058560    |
| train/                  |            |
|    approx_kl            | 0.04088657 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -21.7      |
|    explained_variance   | 0.635      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.526     |
|    n_updates            | 1185       |
|    policy_gradient_loss | -0.0794    |
|    std                  | 2.72       |
|    value_loss           | 0.0415     |
----------------------------------------
-----------------------------------------
| custom/                 |             |
|    intervention_type    | random      |
|    stage                | 1           |
| rollout/                |             |
|    ep_len_mean          | 319         |
|    ep_rew_mean          | 1.8797176   |
| time/                   |             |
|    fps                  | 233         |
|    iterations           | 4           |
|    time_elapsed         | 70          |
|    total_timesteps      | 5062656     |
| train/                  |             |
|    approx_kl            | 0.040596083 |
|    clip_fraction        | 0.476       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.9       |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0914     |
|    std                  | 2.76        |
|    value_loss           | 0.0317      |
-----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 339        |
|    ep_rew_mean          | 1.7659507  |
| time/                   |            |
|    fps                  | 226        |
|    iterations           | 5          |
|    time_elapsed         | 90         |
|    total_timesteps      | 5066752    |
| train/                  |            |
|    approx_kl            | 0.04988959 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.1      |
|    explained_variance   | 0.121      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.486     |
|    n_updates            | 1215       |
|    policy_gradient_loss | -0.0589    |
|    std                  | 2.84       |
|    value_loss           | 0.117      |
----------------------------------------
---------------------------------------
| custom/                 |           |
|    intervention_type    | random    |
|    stage                | 1         |
| rollout/                |           |
|    ep_len_mean          | 359       |
|    ep_rew_mean          | 1.7642426 |
| time/                   |           |
|    fps                  | 223       |
|    iterations           | 6         |
|    time_elapsed         | 110       |
|    total_timesteps      | 5070848   |
| train/                  |           |
|    approx_kl            | 0.0411368 |
|    clip_fraction        | 0.463     |
|    clip_range           | 0.2       |
|    entropy_loss         | -22.2     |
|    explained_variance   | 0.678     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.522    |
|    n_updates            | 1230      |
|    policy_gradient_loss | -0.0901   |
|    std                  | 2.86      |
|    value_loss           | 0.0648    |
---------------------------------------
-----------------------------------------
| custom/                 |             |
|    intervention_type    | random      |
|    stage                | 1           |
| rollout/                |             |
|    ep_len_mean          | 382         |
|    ep_rew_mean          | 1.7214574   |
| time/                   |             |
|    fps                  | 220         |
|    iterations           | 7           |
|    time_elapsed         | 130         |
|    total_timesteps      | 5074944     |
| train/                  |             |
|    approx_kl            | 0.051021874 |
|    clip_fraction        | 0.531       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.3       |
|    explained_variance   | 0.437       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.52       |
|    n_updates            | 1245        |
|    policy_gradient_loss | -0.0846     |
|    std                  | 2.91        |
|    value_loss           | 0.0965      |
-----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 400        |
|    ep_rew_mean          | 1.5748848  |
| time/                   |            |
|    fps                  | 218        |
|    iterations           | 8          |
|    time_elapsed         | 149        |
|    total_timesteps      | 5079040    |
| train/                  |            |
|    approx_kl            | 0.08102546 |
|    clip_fraction        | 0.598      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.5      |
|    explained_variance   | 0.486      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.542     |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0913    |
|    std                  | 2.96       |
|    value_loss           | 0.129      |
----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 420        |
|    ep_rew_mean          | 1.4576712  |
| time/                   |            |
|    fps                  | 217        |
|    iterations           | 9          |
|    time_elapsed         | 169        |
|    total_timesteps      | 5083136    |
| train/                  |            |
|    approx_kl            | 0.03957784 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.6      |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.537     |
|    n_updates            | 1275       |
|    policy_gradient_loss | -0.0924    |
|    std                  | 2.98       |
|    value_loss           | 0.0578     |
----------------------------------------
-----------------------------------------
| custom/                 |             |
|    intervention_type    | random      |
|    stage                | 1           |
| rollout/                |             |
|    ep_len_mean          | 440         |
|    ep_rew_mean          | 1.3762034   |
| time/                   |             |
|    fps                  | 215         |
|    iterations           | 10          |
|    time_elapsed         | 189         |
|    total_timesteps      | 5087232     |
| train/                  |             |
|    approx_kl            | 0.050730415 |
|    clip_fraction        | 0.538       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.604       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.568      |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.105      |
|    std                  | 3           |
|    value_loss           | 0.039       |
-----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 458        |
|    ep_rew_mean          | 1.2981023  |
| time/                   |            |
|    fps                  | 214        |
|    iterations           | 11         |
|    time_elapsed         | 209        |
|    total_timesteps      | 5091328    |
| train/                  |            |
|    approx_kl            | 0.04173594 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.7      |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.564     |
|    n_updates            | 1305       |
|    policy_gradient_loss | -0.0951    |
|    std                  | 3.03       |
|    value_loss           | 0.0494     |
----------------------------------------
-----------------------------------------
| custom/                 |             |
|    intervention_type    | random      |
|    stage                | 1           |
| rollout/                |             |
|    ep_len_mean          | 460         |
|    ep_rew_mean          | 1.0735073   |
| time/                   |             |
|    fps                  | 213         |
|    iterations           | 12          |
|    time_elapsed         | 229         |
|    total_timesteps      | 5095424     |
| train/                  |             |
|    approx_kl            | 0.048470315 |
|    clip_fraction        | 0.539       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.8       |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.564      |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0971     |
|    std                  | 3.07        |
|    value_loss           | 0.043       |
-----------------------------------------
----------------------------------------
| custom/                 |            |
|    intervention_type    | random     |
|    stage                | 1          |
| rollout/                |            |
|    ep_len_mean          | 465        |
|    ep_rew_mean          | 1.158713   |
| time/                   |            |
|    fps                  | 213        |
|    iterations           | 13         |
|    time_elapsed         | 249        |
|    total_timesteps      | 5099520    |
| train/                  |            |
|    approx_kl            | 0.06387389 |
|    clip_fraction        | 0.575      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.9      |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.563     |
|    n_updates            | 1335       |
|    policy_gradient_loss | -0.106     |
|    std                  | 3.1        |
|    value_loss           | 0.0298     |
----------------------------------------
2025-07-19 15:25:10,862 4052425 INFO Training completed in 260.8s
2025-07-19 15:25:10,863 4052425 INFO episodes: 0
2025-07-19 15:25:10,864 4052425 INFO mean reward: 0.000 +/- 0.000
2025-07-19 15:25:10,864 4052425 INFO success rate: 0.000
2025-07-19 15:25:10,864 4052425 INFO mean episode length: 0.0
2025-07-19 15:25:10,880 4052425 INFO model saved to highest_reward_sequencing_logs/model_stage_1_random
Traceback (most recent call last):
  File "highest_reward_sequencing.py", line 924, in <module>
    main()
  File "highest_reward_sequencing.py", line 771, in main
    cumulative_timesteps
  File "highest_reward_sequencing.py", line 586, in train_on_intervention
    return stats, reward_monitor.cumulative_timesteps
AttributeError: 'RewardMonitorCallback' object has no attribute 'cumulative_timesteps'
