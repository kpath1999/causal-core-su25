2025-06-30 14:15:23,540 INFO    MainThread:3597719 [wandb_setup.py:_flush():79] Current SDK version is 0.18.7
2025-06-30 14:15:23,540 INFO    MainThread:3597719 [wandb_setup.py:_flush():79] Configure stats pid to 3597719
2025-06-30 14:15:23,540 INFO    MainThread:3597719 [wandb_setup.py:_flush():79] Loading settings from /home/kpatherya3/.config/wandb/settings
2025-06-30 14:15:23,540 INFO    MainThread:3597719 [wandb_setup.py:_flush():79] Loading settings from /home/kpatherya3/causal-core-su25/wandb/settings
2025-06-30 14:15:23,540 INFO    MainThread:3597719 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2025-06-30 14:15:23,540 INFO    MainThread:3597719 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2025-06-30 14:15:23,540 INFO    MainThread:3597719 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program_relpath': 'ppo_vanilla.py', 'program_abspath': '/home/kpatherya3/causal-core-su25/ppo_vanilla.py', 'program': 'ppo_vanilla.py'}
2025-06-30 14:15:23,540 INFO    MainThread:3597719 [wandb_setup.py:_flush():79] Applying login settings: {}
2025-06-30 14:15:23,541 INFO    MainThread:3597719 [wandb_init.py:_log_setup():533] Logging user logs to /home/kpatherya3/causal-core-su25/wandb/run-20250630_141523-fixqlbx3/logs/debug.log
2025-06-30 14:15:23,541 INFO    MainThread:3597719 [wandb_init.py:_log_setup():534] Logging internal logs to /home/kpatherya3/causal-core-su25/wandb/run-20250630_141523-fixqlbx3/logs/debug-internal.log
2025-06-30 14:15:23,541 INFO    MainThread:3597719 [wandb_init.py:init():619] calling init triggers
2025-06-30 14:15:23,541 INFO    MainThread:3597719 [wandb_init.py:init():627] wandb.init called with sweep_config: {}
config: {'task_name': 'picking', 'max_episode_length': 250, 'skip_frame': 3, 'seed': 0, 'total_timesteps': 5000000, 'gamma': 0.995, 'n_steps': 4096, 'ent_coef': 0.02, 'learning_rate': 0.00025, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'gae_lambda': 0.97, 'batch_size': 512, 'n_epochs': 15}
2025-06-30 14:15:23,541 INFO    MainThread:3597719 [wandb_init.py:init():669] starting backend
2025-06-30 14:15:23,541 INFO    MainThread:3597719 [wandb_init.py:init():673] sending inform_init request
2025-06-30 14:15:23,544 INFO    MainThread:3597719 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-06-30 14:15:23,544 INFO    MainThread:3597719 [wandb_init.py:init():686] backend started and connected
2025-06-30 14:15:23,547 INFO    MainThread:3597719 [wandb_init.py:init():781] updated telemetry
2025-06-30 14:15:23,568 INFO    MainThread:3597719 [wandb_init.py:init():814] communicating run to backend with 90.0 second timeout
2025-06-30 14:15:25,056 INFO    MainThread:3597719 [wandb_init.py:init():867] starting run threads in backend
2025-06-30 14:15:25,136 INFO    MainThread:3597719 [wandb_run.py:_console_start():2456] atexit reg
2025-06-30 14:15:25,136 INFO    MainThread:3597719 [wandb_run.py:_redirect():2305] redirect: wrap_raw
2025-06-30 14:15:25,137 INFO    MainThread:3597719 [wandb_run.py:_redirect():2370] Wrapping output streams.
2025-06-30 14:15:25,137 INFO    MainThread:3597719 [wandb_run.py:_redirect():2395] Redirects installed.
2025-06-30 14:15:25,139 INFO    MainThread:3597719 [wandb_init.py:init():911] run started, returning control to user process
2025-06-30 14:15:29,937 INFO    MainThread:3597719 [wandb_run.py:_tensorboard_callback():1544] tensorboard callback: ppo_picking_sb3/ppo_sb3_1, True
2025-06-30 14:15:29,946 INFO    MainThread:3597719 [wandb_watch.py:_watch():71] Watching
2025-06-30 14:15:29,947 INFO    MainThread:3597719 [wandb_run.py:_config_callback():1387] config_cb None None {'algo': 'PPO', 'policy_class': "<class 'stable_baselines3.common.policies.ActorCriticPolicy'>", 'device': 'cuda', 'env': '<stable_baselines3.common.vec_env.vec_monitor.VecMonitor object at 0x7fcface4f850>', '_vec_normalize_env': 'None', 'verbose': 1, 'policy_kwargs': "{'activation_fn': <class 'torch.nn.modules.activation.LeakyReLU'>, 'net_arch': [512, 256]}", 'observation_space': 'Box(56,)', 'action_space': 'Box(9,)', 'n_envs': 16, 'num_timesteps': 0, '_total_timesteps': 5000000, '_num_timesteps_at_start': 0, 'eval_env': 'None', 'action_noise': 'None', 'start_time': 1751307329.925653, 'policy': 'ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (shared_net): Sequential(\n      (0): Linear(in_features=56, out_features=512, bias=True)\n      (1): LeakyReLU(negative_slope=0.01)\n      (2): Linear(in_features=512, out_features=256, bias=True)\n      (3): LeakyReLU(negative_slope=0.01)\n    )\n    (policy_net): Sequential()\n    (value_net): Sequential()\n  )\n  (action_net): Linear(in_features=256, out_features=9, bias=True)\n  (value_net): Linear(in_features=256, out_features=1, bias=True)\n)', 'tensorboard_log': 'ppo_picking_sb3', 'lr_schedule': '<function constant_fn.<locals>.func at 0x7fcfacc8b710>', '_last_obs': '[[ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]\n [ 1.          0.22178988  0.43350048 -0.26179939  0.22178988  0.43350048\n  -0.26179939  0.22178988  0.43350048 -0.26179939  0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.1189      0.31727417 -0.77654834  0.33421749 -0.05566666\n  -0.77654834 -0.21531749 -0.26160751 -0.77654834  1.          0.\n   0.          0.          0.          0.         -0.87        0.\n   0.          0.          0.1         0.          0.          0.\n   0.          0.          0.         20.          0.          0.\n   0.          0.          0.         -0.4         0.          0.\n   0.          0.1       ]]', '_last_episode_starts': '[ True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_logger': '<stable_baselines3.common.logger.Logger object at 0x7fcf0895aad0>', '_custom_logger': 'False', 'rollout_buffer': '<stable_baselines3.common.buffers.RolloutBuffer object at 0x7fcfacc779d0>', 'clip_range': '<function constant_fn.<locals>.func at 0x7fcfac383f80>', 'clip_range_vf': 'None', 'target_kl': 'None'}
2025-06-30 15:33:08,910 INFO    MainThread:3597719 [sb3.py:save_model():153] Saving model checkpoint to ppo_picking_sb3/wandb_models/model.zip
2025-06-30 15:33:08,924 INFO    MainThread:3597719 [wandb_run.py:_finish():2155] finishing run kausarpatherya-georgia-institute-of-technology/causal-world-ppo-picking/fixqlbx3
2025-06-30 15:33:08,924 INFO    MainThread:3597719 [wandb_run.py:_atexit_cleanup():2420] got exitcode: 0
2025-06-30 15:33:08,924 INFO    MainThread:3597719 [wandb_run.py:_restore():2402] restore
2025-06-30 15:33:08,924 INFO    MainThread:3597719 [wandb_run.py:_restore():2408] restore done
2025-06-30 15:33:11,996 INFO    MainThread:3597719 [wandb_run.py:_footer_history_summary_info():3960] rendering history
2025-06-30 15:33:11,998 INFO    MainThread:3597719 [wandb_run.py:_footer_history_summary_info():3992] rendering summary
2025-06-30 15:33:12,005 INFO    MainThread:3597719 [wandb_run.py:_footer_sync_info():3921] logging synced files
