2025-07-08 15:35:41,384 2000932 INFO [WANDB] Initialized with project: adaptive-curriculum-ppo-pushing and run name: adaptive_curriculum_ppo_pushing_seed0
2025-07-08 15:35:41,384 2000932 INFO [LOGDIR] Log directory: adaptive_curriculum_on_ppo
2025-07-08 15:35:41,385 2000932 INFO [CURRICULUM] Interventions: ['GoalInterventionActorPolicy', 'PhysicalPropertiesInterventionActorPolicy', 'VisualInterventionActorPolicy', 'JointsInterventionActorPolicy', 'RigidPoseInterventionActorPolicy', 'RandomInterventionActorPolicy']
[ADAPTIVE] Initialized with 6 interventions.
2025-07-08 15:35:41,404 2000932 INFO [ENV] Creating 16 parallel training environments for task: pushing
2025-07-08 15:35:45,523 2000932 INFO [ENV] Creating evaluation environment for task: pushing
2025-07-08 15:35:45,684 2000932 INFO [MODEL] PPO model loaded from: ppo_pushing_sb3/final_model.zip
2025-07-08 15:35:48,386 2000932 INFO [CALLBACKS] Callbacks set up: ['CheckpointCallback', 'EvalCallback', 'AdaptiveCurriculumCallback', 'WandbCallback']
2025-07-08 15:35:48,387 2000932 INFO [TRAIN] Starting training for 3000000 timesteps...
Logging to adaptive_curriculum_on_ppo/adaptive_curriculum_on_ppo_3
/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/stable_baselines3/common/callbacks.py:337: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_monitor.VecMonitor object at 0x7f31a82d5090> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f31a82ee9d0>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
[ADAPTIVE] Episode 1 reward: 0.044508
[34m[1mwandb[0m: [33mWARNING[0m Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 251        |
|    ep_rew_mean     | 0.44771796 |
| time/              |            |
|    fps             | 1655       |
|    iterations      | 1          |
|    time_elapsed    | 2          |
|    total_timesteps | 4096       |
-----------------------------------
[ADAPTIVE] Episode 2 reward: -0.019474
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.54302555  |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 2           |
|    time_elapsed         | 6           |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.020774283 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.6       |
|    explained_variance   | 0.319       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.444      |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 2.67        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 3 reward: 0.058256
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.50937486  |
| time/                   |             |
|    fps                  | 1256        |
|    iterations           | 3           |
|    time_elapsed         | 9           |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.015857464 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.6       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.452      |
|    n_updates            | 1185        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 2.69        |
|    value_loss           | 0.0826      |
-----------------------------------------
[ADAPTIVE] Episode 4 reward: 0.022794
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.71154886  |
| time/                   |             |
|    fps                  | 1181        |
|    iterations           | 4           |
|    time_elapsed         | 13          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.012181164 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.7       |
|    explained_variance   | 0.65        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.416      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 2.7         |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 5 reward: 0.065724
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7426218   |
| time/                   |             |
|    fps                  | 1198        |
|    iterations           | 5           |
|    time_elapsed         | 17          |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.013972141 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.7       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.458      |
|    n_updates            | 1215        |
|    policy_gradient_loss | -0.0345     |
|    std                  | 2.71        |
|    value_loss           | 0.0794      |
-----------------------------------------
[ADAPTIVE] Episode 6 reward: 0.046310
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8336002   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 6           |
|    time_elapsed         | 20          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.020464005 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.8       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.453      |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0381     |
|    std                  | 2.73        |
|    value_loss           | 0.0914      |
-----------------------------------------
[ADAPTIVE] Episode 7 reward: 0.086479
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96656466  |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 7           |
|    time_elapsed         | 23          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.015610911 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.8       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.474      |
|    n_updates            | 1245        |
|    policy_gradient_loss | -0.0396     |
|    std                  | 2.75        |
|    value_loss           | 0.0793      |
-----------------------------------------
[ADAPTIVE] Episode 8 reward: 0.000106
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98293823  |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 8           |
|    time_elapsed         | 27          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.015538834 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.9       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.464      |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.0328     |
|    std                  | 2.76        |
|    value_loss           | 0.069       |
-----------------------------------------
[ADAPTIVE] Episode 9 reward: 0.069685
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1524526   |
| time/                   |             |
|    fps                  | 1171        |
|    iterations           | 9           |
|    time_elapsed         | 31          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.015828885 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.9       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.463      |
|    n_updates            | 1275        |
|    policy_gradient_loss | -0.0393     |
|    std                  | 2.77        |
|    value_loss           | 0.078       |
-----------------------------------------
[ADAPTIVE] Episode 10 reward: 0.007708
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0824707   |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 10          |
|    time_elapsed         | 34          |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 0.017265957 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22         |
|    explained_variance   | 0.628       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.452      |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 2.79        |
|    value_loss           | 0.0836      |
-----------------------------------------
[ADAPTIVE] Episode 11 reward: -0.014539
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1893039   |
| time/                   |             |
|    fps                  | 1169        |
|    iterations           | 11          |
|    time_elapsed         | 38          |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.021542298 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22         |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.443      |
|    n_updates            | 1305        |
|    policy_gradient_loss | -0.033      |
|    std                  | 2.81        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 12 reward: -0.070326
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1348537   |
| time/                   |             |
|    fps                  | 1176        |
|    iterations           | 12          |
|    time_elapsed         | 41          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.012048994 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.1       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.464      |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.03       |
|    std                  | 2.82        |
|    value_loss           | 0.0722      |
-----------------------------------------
[ADAPTIVE] Episode 13 reward: -0.039777
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0850974  |
| time/                   |            |
|    fps                  | 1167       |
|    iterations           | 13         |
|    time_elapsed         | 45         |
|    total_timesteps      | 53248      |
| train/                  |            |
|    approx_kl            | 0.01477824 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.1      |
|    explained_variance   | 0.575      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.442     |
|    n_updates            | 1335       |
|    policy_gradient_loss | -0.038     |
|    std                  | 2.83       |
|    value_loss           | 0.12       |
----------------------------------------
[ADAPTIVE] Episode 14 reward: -0.021250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0364498   |
| time/                   |             |
|    fps                  | 1171        |
|    iterations           | 14          |
|    time_elapsed         | 48          |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.013529695 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.1       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.453      |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.0357     |
|    std                  | 2.84        |
|    value_loss           | 0.0744      |
-----------------------------------------
[ADAPTIVE] Episode 15 reward: 0.016976
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1043496   |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 15          |
|    time_elapsed         | 52          |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.019558478 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.2       |
|    explained_variance   | 0.673       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.462      |
|    n_updates            | 1365        |
|    policy_gradient_loss | -0.0387     |
|    std                  | 2.85        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 16 reward: -0.020608
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1040657   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 16          |
|    time_elapsed         | 56          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.016971081 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.2       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.471      |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0356     |
|    std                  | 2.88        |
|    value_loss           | 0.0724      |
-----------------------------------------
[ADAPTIVE] Episode 17 reward: 0.052910
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0130414   |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 17          |
|    time_elapsed         | 59          |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.017253805 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.3       |
|    explained_variance   | 0.618       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.467      |
|    n_updates            | 1395        |
|    policy_gradient_loss | -0.039      |
|    std                  | 2.88        |
|    value_loss           | 0.0941      |
-----------------------------------------
[ADAPTIVE] Episode 18 reward: 0.012119
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1000907  |
| time/                   |            |
|    fps                  | 1166       |
|    iterations           | 18         |
|    time_elapsed         | 63         |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.01577152 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.3      |
|    explained_variance   | 0.65       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.45      |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0382    |
|    std                  | 2.91       |
|    value_loss           | 0.118      |
----------------------------------------
[ADAPTIVE] Episode 19 reward: -0.018569
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.141419    |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 19          |
|    time_elapsed         | 66          |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.022263343 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.4       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.469      |
|    n_updates            | 1425        |
|    policy_gradient_loss | -0.0403     |
|    std                  | 2.92        |
|    value_loss           | 0.0836      |
-----------------------------------------
[ADAPTIVE] Episode 20 reward: 0.062665
[ADAPTIVE] Mean reward over last 20 episodes: 0.017085
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2471058  |
| time/                   |            |
|    fps                  | 1160       |
|    iterations           | 20         |
|    time_elapsed         | 70         |
|    total_timesteps      | 81920      |
| train/                  |            |
|    approx_kl            | 0.02762944 |
|    clip_fraction        | 0.185      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.5      |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.44      |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.0364    |
|    std                  | 2.95       |
|    value_loss           | 0.121      |
----------------------------------------
[ADAPTIVE] Episode 21 reward: 0.063045
[ADAPTIVE] Mean reward over last 20 episodes: 0.018012
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0500066   |
| time/                   |             |
|    fps                  | 1161        |
|    iterations           | 21          |
|    time_elapsed         | 74          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.020719958 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.5       |
|    explained_variance   | 0.597       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.46       |
|    n_updates            | 1455        |
|    policy_gradient_loss | -0.0328     |
|    std                  | 2.96        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 22 reward: -0.026625
[ADAPTIVE] Mean reward over last 20 episodes: 0.017654
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0539143   |
| time/                   |             |
|    fps                  | 1161        |
|    iterations           | 22          |
|    time_elapsed         | 77          |
|    total_timesteps      | 90112       |
| train/                  |             |
|    approx_kl            | 0.022521704 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.662       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.477      |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0399     |
|    std                  | 2.97        |
|    value_loss           | 0.0841      |
-----------------------------------------
[ADAPTIVE] Episode 23 reward: -0.078636
[ADAPTIVE] Mean reward over last 20 episodes: 0.010810
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9087077   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 23          |
|    time_elapsed         | 80          |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.015333629 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.504       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.409      |
|    n_updates            | 1485        |
|    policy_gradient_loss | -0.028      |
|    std                  | 2.98        |
|    value_loss           | 0.19        |
-----------------------------------------
[ADAPTIVE] Episode 24 reward: -0.030189
[ADAPTIVE] Mean reward over last 20 episodes: 0.008160
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.86970985  |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 24          |
|    time_elapsed         | 84          |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.022468707 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.48       |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0388     |
|    std                  | 3           |
|    value_loss           | 0.0911      |
-----------------------------------------
[ADAPTIVE] Episode 25 reward: -0.021722
[ADAPTIVE] Mean reward over last 20 episodes: 0.003788
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96936834  |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 25          |
|    time_elapsed         | 87          |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.018136121 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.7       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.458      |
|    n_updates            | 1515        |
|    policy_gradient_loss | -0.0373     |
|    std                  | 3.02        |
|    value_loss           | 0.0974      |
-----------------------------------------
[ADAPTIVE] Episode 26 reward: -0.025693
[ADAPTIVE] Mean reward over last 20 episodes: 0.000188
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9557821   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 26          |
|    time_elapsed         | 91          |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.020904409 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.7       |
|    explained_variance   | 0.676       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.481      |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.0395     |
|    std                  | 3.04        |
|    value_loss           | 0.0787      |
-----------------------------------------
[ADAPTIVE] Episode 27 reward: 0.059015
[ADAPTIVE] Mean reward over last 20 episodes: -0.001185
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9789924   |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 27          |
|    time_elapsed         | 94          |
|    total_timesteps      | 110592      |
| train/                  |             |
|    approx_kl            | 0.014926747 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.8       |
|    explained_variance   | 0.715       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.463      |
|    n_updates            | 1545        |
|    policy_gradient_loss | -0.039      |
|    std                  | 3.06        |
|    value_loss           | 0.0832      |
-----------------------------------------
[ADAPTIVE] Episode 28 reward: 0.081077
[ADAPTIVE] Mean reward over last 20 episodes: 0.002863
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1057986   |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 28          |
|    time_elapsed         | 98          |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.019043531 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.9       |
|    explained_variance   | 0.612       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.458      |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0332     |
|    std                  | 3.08        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 29 reward: 0.015579
[ADAPTIVE] Mean reward over last 20 episodes: 0.000158
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2044342   |
| time/                   |             |
|    fps                  | 1168        |
|    iterations           | 29          |
|    time_elapsed         | 101         |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.015171533 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.9       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.483      |
|    n_updates            | 1575        |
|    policy_gradient_loss | -0.0327     |
|    std                  | 3.1         |
|    value_loss           | 0.0748      |
-----------------------------------------
[ADAPTIVE] Episode 30 reward: -0.025975
[ADAPTIVE] Mean reward over last 20 episodes: -0.001526
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 1: PhysicalPropertiesInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 1
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1818559   |
| time/                   |             |
|    fps                  | 1161        |
|    iterations           | 30          |
|    time_elapsed         | 105         |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.013834863 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23         |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.477      |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.03       |
|    std                  | 3.1         |
|    value_loss           | 0.0825      |
-----------------------------------------
[ADAPTIVE] Episode 31 reward: -0.027172
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.04637     |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 31          |
|    time_elapsed         | 108         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.018948209 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -23         |
|    explained_variance   | 0.713       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.465      |
|    n_updates            | 1605        |
|    policy_gradient_loss | -0.0324     |
|    std                  | 3.12        |
|    value_loss           | 0.0978      |
-----------------------------------------
[ADAPTIVE] Episode 32 reward: 0.006730
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1293664   |
| time/                   |             |
|    fps                  | 1161        |
|    iterations           | 32          |
|    time_elapsed         | 112         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.022299714 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23         |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.481      |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.04       |
|    std                  | 3.13        |
|    value_loss           | 0.0687      |
-----------------------------------------
[ADAPTIVE] Episode 33 reward: 0.010987
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.142485    |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 33          |
|    time_elapsed         | 116         |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.020014219 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.1       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.489      |
|    n_updates            | 1635        |
|    policy_gradient_loss | -0.0388     |
|    std                  | 3.15        |
|    value_loss           | 0.0603      |
-----------------------------------------
[ADAPTIVE] Episode 34 reward: 0.009330
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2184403  |
| time/                   |            |
|    fps                  | 1164       |
|    iterations           | 34         |
|    time_elapsed         | 119        |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.01234639 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -23.1      |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.459     |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.0308    |
|    std                  | 3.16       |
|    value_loss           | 0.115      |
----------------------------------------
[ADAPTIVE] Episode 35 reward: 0.000244
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1629131   |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 35          |
|    time_elapsed         | 123         |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.015124595 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.1       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.492      |
|    n_updates            | 1665        |
|    policy_gradient_loss | -0.0366     |
|    std                  | 3.17        |
|    value_loss           | 0.0656      |
-----------------------------------------
[ADAPTIVE] Episode 36 reward: -0.029698
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2759223   |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 36          |
|    time_elapsed         | 126         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.017738424 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.2       |
|    explained_variance   | 0.623       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.48       |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0362     |
|    std                  | 3.18        |
|    value_loss           | 0.0813      |
-----------------------------------------
[ADAPTIVE] Episode 37 reward: 0.025118
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3670114   |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 37          |
|    time_elapsed         | 130         |
|    total_timesteps      | 151552      |
| train/                  |             |
|    approx_kl            | 0.015437935 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.2       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.493      |
|    n_updates            | 1695        |
|    policy_gradient_loss | -0.0339     |
|    std                  | 3.2         |
|    value_loss           | 0.051       |
-----------------------------------------
[ADAPTIVE] Episode 38 reward: 0.080619
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3540545   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 38          |
|    time_elapsed         | 133         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.017791621 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.3       |
|    explained_variance   | 0.702       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.48       |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.0355     |
|    std                  | 3.23        |
|    value_loss           | 0.0981      |
-----------------------------------------
[ADAPTIVE] Episode 39 reward: -0.002963
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4777844   |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 39          |
|    time_elapsed         | 137         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.017675124 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.4       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.504      |
|    n_updates            | 1725        |
|    policy_gradient_loss | -0.0375     |
|    std                  | 3.25        |
|    value_loss           | 0.046       |
-----------------------------------------
[ADAPTIVE] Episode 40 reward: 0.040556
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5964024   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 40          |
|    time_elapsed         | 140         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.014996907 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.4       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.487      |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0326     |
|    std                  | 3.26        |
|    value_loss           | 0.0514      |
-----------------------------------------
[ADAPTIVE] Episode 41 reward: -0.131929
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6566216   |
| time/                   |             |
|    fps                  | 1160        |
|    iterations           | 41          |
|    time_elapsed         | 144         |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.024925523 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.4       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.479      |
|    n_updates            | 1755        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 3.28        |
|    value_loss           | 0.0571      |
-----------------------------------------
[ADAPTIVE] Episode 42 reward: 0.000997
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.7491887   |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 42          |
|    time_elapsed         | 147         |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 0.020713516 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.5       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.499      |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0353     |
|    std                  | 3.31        |
|    value_loss           | 0.0633      |
-----------------------------------------
[ADAPTIVE] Episode 43 reward: 0.025390
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9818729   |
| time/                   |             |
|    fps                  | 1159        |
|    iterations           | 43          |
|    time_elapsed         | 151         |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.019455742 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.6       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.488      |
|    n_updates            | 1785        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 3.32        |
|    value_loss           | 0.0506      |
-----------------------------------------
[ADAPTIVE] Episode 44 reward: 0.016379
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9339751   |
| time/                   |             |
|    fps                  | 1160        |
|    iterations           | 44          |
|    time_elapsed         | 155         |
|    total_timesteps      | 180224      |
| train/                  |             |
|    approx_kl            | 0.015691953 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.6       |
|    explained_variance   | 0.535       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.496      |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.0355     |
|    std                  | 3.35        |
|    value_loss           | 0.074       |
-----------------------------------------
[ADAPTIVE] Episode 45 reward: 0.019962
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9969368   |
| time/                   |             |
|    fps                  | 1159        |
|    iterations           | 45          |
|    time_elapsed         | 158         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.017251281 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.7       |
|    explained_variance   | 0.667       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.505      |
|    n_updates            | 1815        |
|    policy_gradient_loss | -0.0408     |
|    std                  | 3.36        |
|    value_loss           | 0.0589      |
-----------------------------------------
[ADAPTIVE] Episode 46 reward: -0.023597
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9612846   |
| time/                   |             |
|    fps                  | 1159        |
|    iterations           | 46          |
|    time_elapsed         | 162         |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.017033175 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.7       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.487      |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.0342     |
|    std                  | 3.38        |
|    value_loss           | 0.0833      |
-----------------------------------------
[ADAPTIVE] Episode 47 reward: 0.023995
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9437975   |
| time/                   |             |
|    fps                  | 1157        |
|    iterations           | 47          |
|    time_elapsed         | 166         |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.019540064 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.8       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.478      |
|    n_updates            | 1845        |
|    policy_gradient_loss | -0.0391     |
|    std                  | 3.4         |
|    value_loss           | 0.0709      |
-----------------------------------------
[ADAPTIVE] Episode 48 reward: -0.025910
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9119887   |
| time/                   |             |
|    fps                  | 1158        |
|    iterations           | 48          |
|    time_elapsed         | 169         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.012432542 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.8       |
|    explained_variance   | 0.598       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.449      |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.028      |
|    std                  | 3.41        |
|    value_loss           | 0.126       |
-----------------------------------------
[ADAPTIVE] Episode 49 reward: -0.006448
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8889604   |
| time/                   |             |
|    fps                  | 1156        |
|    iterations           | 49          |
|    time_elapsed         | 173         |
|    total_timesteps      | 200704      |
| train/                  |             |
|    approx_kl            | 0.018509286 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.8       |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.506      |
|    n_updates            | 1875        |
|    policy_gradient_loss | -0.036      |
|    std                  | 3.43        |
|    value_loss           | 0.0629      |
-----------------------------------------
[ADAPTIVE] Episode 50 reward: -0.057215
[ADAPTIVE] Mean reward over last 20 episodes: -0.002231
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9764335   |
| time/                   |             |
|    fps                  | 1158        |
|    iterations           | 50          |
|    time_elapsed         | 176         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.021141889 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.9       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.503      |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0351     |
|    std                  | 3.45        |
|    value_loss           | 0.0902      |
-----------------------------------------
[ADAPTIVE] Episode 51 reward: 0.015502
[ADAPTIVE] Mean reward over last 20 episodes: -0.000098
[ADAPTIVE] Plateau counter: 1/10
[ADAPTIVE] Episode 52 reward: 0.011444
[ADAPTIVE] Mean reward over last 20 episodes: 0.000138
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.140235    |
| time/                   |             |
|    fps                  | 1155        |
|    iterations           | 51          |
|    time_elapsed         | 180         |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.016060244 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.9       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.503      |
|    n_updates            | 1905        |
|    policy_gradient_loss | -0.032      |
|    std                  | 3.48        |
|    value_loss           | 0.0567      |
-----------------------------------------
[ADAPTIVE] Episode 53 reward: 0.034515
[ADAPTIVE] Mean reward over last 20 episodes: 0.001315
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.3454647   |
| time/                   |             |
|    fps                  | 1156        |
|    iterations           | 52          |
|    time_elapsed         | 184         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.019535467 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24         |
|    explained_variance   | 0.67        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.496      |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.0308     |
|    std                  | 3.49        |
|    value_loss           | 0.0964      |
-----------------------------------------
[ADAPTIVE] Episode 54 reward: 0.033488
[ADAPTIVE] Mean reward over last 20 episodes: 0.002523
[ADAPTIVE] Plateau counter: 4/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.4336567  |
| time/                   |            |
|    fps                  | 1157       |
|    iterations           | 53         |
|    time_elapsed         | 187        |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.01249425 |
|    clip_fraction        | 0.153      |
|    clip_range           | 0.2        |
|    entropy_loss         | -24        |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.512     |
|    n_updates            | 1935       |
|    policy_gradient_loss | -0.0301    |
|    std                  | 3.5        |
|    value_loss           | 0.0416     |
----------------------------------------
[ADAPTIVE] Episode 55 reward: -0.043990
[ADAPTIVE] Mean reward over last 20 episodes: 0.000311
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.3651447   |
| time/                   |             |
|    fps                  | 1158        |
|    iterations           | 54          |
|    time_elapsed         | 190         |
|    total_timesteps      | 221184      |
| train/                  |             |
|    approx_kl            | 0.021179479 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.1       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.502      |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0379     |
|    std                  | 3.52        |
|    value_loss           | 0.0619      |
-----------------------------------------
[ADAPTIVE] Episode 56 reward: 0.091596
[ADAPTIVE] Mean reward over last 20 episodes: 0.006376
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.3565423   |
| time/                   |             |
|    fps                  | 1158        |
|    iterations           | 55          |
|    time_elapsed         | 194         |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.014651973 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.1       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 1965        |
|    policy_gradient_loss | -0.036      |
|    std                  | 3.54        |
|    value_loss           | 0.055       |
-----------------------------------------
[ADAPTIVE] Episode 57 reward: -0.049349
[ADAPTIVE] Mean reward over last 20 episodes: 0.002652
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.286869    |
| time/                   |             |
|    fps                  | 1158        |
|    iterations           | 56          |
|    time_elapsed         | 197         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.018659763 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.2       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.52       |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0358     |
|    std                  | 3.55        |
|    value_loss           | 0.0508      |
-----------------------------------------
[ADAPTIVE] Episode 58 reward: -0.170047
[ADAPTIVE] Mean reward over last 20 episodes: -0.009881
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2682765   |
| time/                   |             |
|    fps                  | 1159        |
|    iterations           | 57          |
|    time_elapsed         | 201         |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.013829544 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.2       |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.503      |
|    n_updates            | 1995        |
|    policy_gradient_loss | -0.0306     |
|    std                  | 3.57        |
|    value_loss           | 0.0519      |
-----------------------------------------
[ADAPTIVE] Episode 59 reward: 0.035814
[ADAPTIVE] Mean reward over last 20 episodes: -0.007942
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2427466   |
| time/                   |             |
|    fps                  | 1158        |
|    iterations           | 58          |
|    time_elapsed         | 205         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.019396672 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.2       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.0351     |
|    std                  | 3.59        |
|    value_loss           | 0.068       |
-----------------------------------------
[ADAPTIVE] Episode 60 reward: 0.083788
[ADAPTIVE] Mean reward over last 20 episodes: -0.005781
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 2: VisualInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 2
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.0375683  |
| time/                   |            |
|    fps                  | 1159       |
|    iterations           | 59         |
|    time_elapsed         | 208        |
|    total_timesteps      | 241664     |
| train/                  |            |
|    approx_kl            | 0.01807819 |
|    clip_fraction        | 0.189      |
|    clip_range           | 0.2        |
|    entropy_loss         | -24.3      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.48      |
|    n_updates            | 2025       |
|    policy_gradient_loss | -0.0333    |
|    std                  | 3.6        |
|    value_loss           | 0.0872     |
----------------------------------------
[ADAPTIVE] Episode 61 reward: -0.013884
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1491785   |
| time/                   |             |
|    fps                  | 1157        |
|    iterations           | 60          |
|    time_elapsed         | 212         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.020539675 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.3       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.513      |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.0369     |
|    std                  | 3.62        |
|    value_loss           | 0.0687      |
-----------------------------------------
[ADAPTIVE] Episode 62 reward: 0.008602
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0605228   |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 61          |
|    time_elapsed         | 214         |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.015211884 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.4       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.511      |
|    n_updates            | 2055        |
|    policy_gradient_loss | -0.0309     |
|    std                  | 3.65        |
|    value_loss           | 0.0654      |
-----------------------------------------
[ADAPTIVE] Episode 63 reward: -0.000390
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0686016   |
| time/                   |             |
|    fps                  | 1159        |
|    iterations           | 62          |
|    time_elapsed         | 218         |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.018577468 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.4       |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.499      |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.03       |
|    std                  | 3.66        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 64 reward: 0.039358
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0566406   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 63          |
|    time_elapsed         | 221         |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.018885078 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.5       |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.512      |
|    n_updates            | 2085        |
|    policy_gradient_loss | -0.0348     |
|    std                  | 3.68        |
|    value_loss           | 0.0616      |
-----------------------------------------
[ADAPTIVE] Episode 65 reward: 0.006452
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0359018   |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 64          |
|    time_elapsed         | 225         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.017259154 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.5       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.494      |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.0267     |
|    std                  | 3.71        |
|    value_loss           | 0.0788      |
-----------------------------------------
[ADAPTIVE] Episode 66 reward: -0.054680
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0889428   |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 65          |
|    time_elapsed         | 228         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.015997278 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.6       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 2115        |
|    policy_gradient_loss | -0.0349     |
|    std                  | 3.73        |
|    value_loss           | 0.0529      |
-----------------------------------------
[ADAPTIVE] Episode 67 reward: -0.029486
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8742692   |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 66          |
|    time_elapsed         | 232         |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 0.018718526 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.6       |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.512      |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0322     |
|    std                  | 3.76        |
|    value_loss           | 0.0707      |
-----------------------------------------
[ADAPTIVE] Episode 68 reward: 0.077507
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9585935   |
| time/                   |             |
|    fps                  | 1161        |
|    iterations           | 67          |
|    time_elapsed         | 236         |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.019881234 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.7       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.499      |
|    n_updates            | 2145        |
|    policy_gradient_loss | -0.0333     |
|    std                  | 3.78        |
|    value_loss           | 0.0879      |
-----------------------------------------
[ADAPTIVE] Episode 69 reward: 0.021770
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9679551   |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 68          |
|    time_elapsed         | 239         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.013537236 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.7       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.516      |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 3.79        |
|    value_loss           | 0.0559      |
-----------------------------------------
[ADAPTIVE] Episode 70 reward: -0.054339
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.977674    |
| time/                   |             |
|    fps                  | 1160        |
|    iterations           | 69          |
|    time_elapsed         | 243         |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.019342989 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.8       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.504      |
|    n_updates            | 2175        |
|    policy_gradient_loss | -0.0284     |
|    std                  | 3.82        |
|    value_loss           | 0.0672      |
-----------------------------------------
[ADAPTIVE] Episode 71 reward: 0.030548
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9604491   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 70          |
|    time_elapsed         | 246         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.016988203 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.9       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.513      |
|    n_updates            | 2190        |
|    policy_gradient_loss | -0.034      |
|    std                  | 3.85        |
|    value_loss           | 0.0684      |
-----------------------------------------
[ADAPTIVE] Episode 72 reward: 0.014672
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0359278   |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 71          |
|    time_elapsed         | 250         |
|    total_timesteps      | 290816      |
| train/                  |             |
|    approx_kl            | 0.010960259 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.9       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.53       |
|    n_updates            | 2205        |
|    policy_gradient_loss | -0.029      |
|    std                  | 3.87        |
|    value_loss           | 0.0335      |
-----------------------------------------
[ADAPTIVE] Episode 73 reward: -0.008748
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2437792   |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 72          |
|    time_elapsed         | 253         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.016838465 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25         |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.514      |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 3.89        |
|    value_loss           | 0.0576      |
-----------------------------------------
[ADAPTIVE] Episode 74 reward: -0.000316
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.33816     |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 73          |
|    time_elapsed         | 256         |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.016019644 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25         |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.532      |
|    n_updates            | 2235        |
|    policy_gradient_loss | -0.0323     |
|    std                  | 3.92        |
|    value_loss           | 0.0415      |
-----------------------------------------
[ADAPTIVE] Episode 75 reward: -0.059783
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.289259    |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 74          |
|    time_elapsed         | 260         |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.015547612 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.1       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 3.93        |
|    value_loss           | 0.0566      |
-----------------------------------------
[ADAPTIVE] Episode 76 reward: 0.021881
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2648854   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 75          |
|    time_elapsed         | 264         |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.015987333 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.1       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.531      |
|    n_updates            | 2265        |
|    policy_gradient_loss | -0.0337     |
|    std                  | 3.96        |
|    value_loss           | 0.0541      |
-----------------------------------------
[ADAPTIVE] Episode 77 reward: 0.013682
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1401234   |
| time/                   |             |
|    fps                  | 1161        |
|    iterations           | 76          |
|    time_elapsed         | 267         |
|    total_timesteps      | 311296      |
| train/                  |             |
|    approx_kl            | 0.011982983 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.2       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.477      |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.0269     |
|    std                  | 3.97        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 78 reward: 0.058203
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 2.156193  |
| time/                   |           |
|    fps                  | 1162      |
|    iterations           | 77        |
|    time_elapsed         | 271       |
|    total_timesteps      | 315392    |
| train/                  |           |
|    approx_kl            | 0.0174316 |
|    clip_fraction        | 0.191     |
|    clip_range           | 0.2       |
|    entropy_loss         | -25.2     |
|    explained_variance   | 0.716     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.516    |
|    n_updates            | 2295      |
|    policy_gradient_loss | -0.0296   |
|    std                  | 3.99      |
|    value_loss           | 0.0781    |
---------------------------------------
[ADAPTIVE] Episode 79 reward: 0.001330
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1106293   |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 78          |
|    time_elapsed         | 274         |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.012667289 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.2       |
|    explained_variance   | 0.688       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.517      |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.0308     |
|    std                  | 4           |
|    value_loss           | 0.0688      |
-----------------------------------------
[ADAPTIVE] Episode 80 reward: -0.057436
[ADAPTIVE] Mean reward over last 20 episodes: 0.000747
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9781046   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 79          |
|    time_elapsed         | 278         |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.020065632 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.3       |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.513      |
|    n_updates            | 2325        |
|    policy_gradient_loss | -0.0296     |
|    std                  | 4.04        |
|    value_loss           | 0.0794      |
-----------------------------------------
[ADAPTIVE] Episode 81 reward: 0.003828
[ADAPTIVE] Mean reward over last 20 episodes: 0.001633
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9014658   |
| time/                   |             |
|    fps                  | 1161        |
|    iterations           | 80          |
|    time_elapsed         | 282         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.010825807 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.3       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.521      |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.0277     |
|    std                  | 4.06        |
|    value_loss           | 0.0677      |
-----------------------------------------
[ADAPTIVE] Episode 82 reward: -0.038987
[ADAPTIVE] Mean reward over last 20 episodes: -0.000747
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8696911   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 81          |
|    time_elapsed         | 285         |
|    total_timesteps      | 331776      |
| train/                  |             |
|    approx_kl            | 0.014495917 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.4       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.505      |
|    n_updates            | 2355        |
|    policy_gradient_loss | -0.0294     |
|    std                  | 4.09        |
|    value_loss           | 0.0933      |
-----------------------------------------
[ADAPTIVE] Episode 83 reward: -0.055597
[ADAPTIVE] Mean reward over last 20 episodes: -0.003507
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9310107   |
| time/                   |             |
|    fps                  | 1161        |
|    iterations           | 82          |
|    time_elapsed         | 289         |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.012116797 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.4       |
|    explained_variance   | 0.665       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.509      |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.0323     |
|    std                  | 4.1         |
|    value_loss           | 0.0896      |
-----------------------------------------
[ADAPTIVE] Episode 84 reward: -0.017365
[ADAPTIVE] Mean reward over last 20 episodes: -0.006343
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9926268   |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 83          |
|    time_elapsed         | 292         |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.017100349 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.5       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.522      |
|    n_updates            | 2385        |
|    policy_gradient_loss | -0.0254     |
|    std                  | 4.13        |
|    value_loss           | 0.0686      |
-----------------------------------------
[ADAPTIVE] Episode 85 reward: -0.019918
[ADAPTIVE] Mean reward over last 20 episodes: -0.007662
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.041513    |
| time/                   |             |
|    fps                  | 1160        |
|    iterations           | 84          |
|    time_elapsed         | 296         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.011596739 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.5       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.53       |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 4.15        |
|    value_loss           | 0.0515      |
-----------------------------------------
[ADAPTIVE] Episode 86 reward: 0.024465
[ADAPTIVE] Mean reward over last 20 episodes: -0.003705
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.105191    |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 85          |
|    time_elapsed         | 299         |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.013937154 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.6       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.541      |
|    n_updates            | 2415        |
|    policy_gradient_loss | -0.0305     |
|    std                  | 4.17        |
|    value_loss           | 0.0573      |
-----------------------------------------
[ADAPTIVE] Episode 87 reward: -0.089779
[ADAPTIVE] Mean reward over last 20 episodes: -0.006719
[ADAPTIVE] Plateau counter: 7/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.1957073  |
| time/                   |            |
|    fps                  | 1161       |
|    iterations           | 86         |
|    time_elapsed         | 303        |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.02076029 |
|    clip_fraction        | 0.209      |
|    clip_range           | 0.2        |
|    entropy_loss         | -25.7      |
|    explained_variance   | 0.618      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.534     |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.0343    |
|    std                  | 4.22       |
|    value_loss           | 0.0788     |
----------------------------------------
[ADAPTIVE] Episode 88 reward: -0.054571
[ADAPTIVE] Mean reward over last 20 episodes: -0.013323
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.215868    |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 87          |
|    time_elapsed         | 306         |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.011997826 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.7       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.533      |
|    n_updates            | 2445        |
|    policy_gradient_loss | -0.0325     |
|    std                  | 4.24        |
|    value_loss           | 0.0651      |
-----------------------------------------
[ADAPTIVE] Episode 89 reward: 0.025696
[ADAPTIVE] Mean reward over last 20 episodes: -0.013127
[ADAPTIVE] Plateau counter: 9/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.2313995  |
| time/                   |            |
|    fps                  | 1161       |
|    iterations           | 88         |
|    time_elapsed         | 310        |
|    total_timesteps      | 360448     |
| train/                  |            |
|    approx_kl            | 0.02008802 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | -25.8      |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.536     |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0335    |
|    std                  | 4.27       |
|    value_loss           | 0.0515     |
----------------------------------------
[ADAPTIVE] Episode 90 reward: 0.058291
[ADAPTIVE] Mean reward over last 20 episodes: -0.007495
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 3: JointsInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 3
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2642615   |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 89          |
|    time_elapsed         | 313         |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.011327001 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.8       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.534      |
|    n_updates            | 2475        |
|    policy_gradient_loss | -0.03       |
|    std                  | 4.28        |
|    value_loss           | 0.0492      |
-----------------------------------------
[ADAPTIVE] Episode 91 reward: 0.035196
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1400537   |
| time/                   |             |
|    fps                  | 1162        |
|    iterations           | 90          |
|    time_elapsed         | 316         |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.016546417 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.9       |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.544      |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.0332     |
|    std                  | 4.31        |
|    value_loss           | 0.0639      |
-----------------------------------------
[ADAPTIVE] Episode 92 reward: 0.009683
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0931766   |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 91          |
|    time_elapsed         | 320         |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.012317695 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -26         |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.53       |
|    n_updates            | 2505        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 4.34        |
|    value_loss           | 0.0555      |
-----------------------------------------
[ADAPTIVE] Episode 93 reward: 0.021190
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1495125   |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 92          |
|    time_elapsed         | 323         |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.010695658 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26         |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.539      |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.0293     |
|    std                  | 4.36        |
|    value_loss           | 0.0553      |
-----------------------------------------
[ADAPTIVE] Episode 94 reward: 0.000938
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 2.0985575    |
| time/                   |              |
|    fps                  | 1162         |
|    iterations           | 93           |
|    time_elapsed         | 327          |
|    total_timesteps      | 380928       |
| train/                  |              |
|    approx_kl            | 0.0153713105 |
|    clip_fraction        | 0.215        |
|    clip_range           | 0.2          |
|    entropy_loss         | -26          |
|    explained_variance   | 0.782        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.557       |
|    n_updates            | 2535         |
|    policy_gradient_loss | -0.0358      |
|    std                  | 4.39         |
|    value_loss           | 0.0397       |
------------------------------------------
[ADAPTIVE] Episode 95 reward: 0.003817
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1772313   |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 94          |
|    time_elapsed         | 330         |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.011552697 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.1       |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.543      |
|    n_updates            | 2550        |
|    policy_gradient_loss | -0.0295     |
|    std                  | 4.4         |
|    value_loss           | 0.0454      |
-----------------------------------------
[ADAPTIVE] Episode 96 reward: 0.048696
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.103196    |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 95          |
|    time_elapsed         | 334         |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.009786437 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.1       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.522      |
|    n_updates            | 2565        |
|    policy_gradient_loss | -0.0264     |
|    std                  | 4.41        |
|    value_loss           | 0.0728      |
-----------------------------------------
[ADAPTIVE] Episode 97 reward: -0.110806
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.173254    |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 96          |
|    time_elapsed         | 337         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.012944983 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.1       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.55       |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 4.42        |
|    value_loss           | 0.0484      |
-----------------------------------------
[ADAPTIVE] Episode 98 reward: -0.022164
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1050613   |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 97          |
|    time_elapsed         | 340         |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.016497536 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.2       |
|    explained_variance   | 0.643       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.509      |
|    n_updates            | 2595        |
|    policy_gradient_loss | -0.0265     |
|    std                  | 4.45        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 99 reward: -0.010072
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1458642   |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 98          |
|    time_elapsed         | 344         |
|    total_timesteps      | 401408      |
| train/                  |             |
|    approx_kl            | 0.013045518 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.2       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.538      |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.0349     |
|    std                  | 4.48        |
|    value_loss           | 0.0714      |
-----------------------------------------
[ADAPTIVE] Episode 100 reward: 0.021868
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1711786   |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 99          |
|    time_elapsed         | 347         |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.017513916 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.3       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.551      |
|    n_updates            | 2625        |
|    policy_gradient_loss | -0.0304     |
|    std                  | 4.51        |
|    value_loss           | 0.0414      |
-----------------------------------------
[ADAPTIVE] Episode 101 reward: 0.006178
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.1471288  |
| time/                   |            |
|    fps                  | 1167       |
|    iterations           | 100        |
|    time_elapsed         | 350        |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.01342684 |
|    clip_fraction        | 0.174      |
|    clip_range           | 0.2        |
|    entropy_loss         | -26.3      |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.538     |
|    n_updates            | 2640       |
|    policy_gradient_loss | -0.0329    |
|    std                  | 4.53       |
|    value_loss           | 0.0665     |
----------------------------------------
[ADAPTIVE] Episode 102 reward: 0.040206
[ADAPTIVE] Episode 103 reward: 0.081741
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1297715   |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 101         |
|    time_elapsed         | 354         |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.012694037 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.4       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 2655        |
|    policy_gradient_loss | -0.032      |
|    std                  | 4.56        |
|    value_loss           | 0.0939      |
-----------------------------------------
[ADAPTIVE] Episode 104 reward: -0.051800
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.2455726  |
| time/                   |            |
|    fps                  | 1166       |
|    iterations           | 102        |
|    time_elapsed         | 358        |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.01670741 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -26.4      |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.559     |
|    n_updates            | 2670       |
|    policy_gradient_loss | -0.0341    |
|    std                  | 4.58       |
|    value_loss           | 0.0607     |
----------------------------------------
[ADAPTIVE] Episode 105 reward: 0.028034
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 2.1112716    |
| time/                   |              |
|    fps                  | 1166         |
|    iterations           | 103          |
|    time_elapsed         | 361          |
|    total_timesteps      | 421888       |
| train/                  |              |
|    approx_kl            | 0.0131432535 |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.2          |
|    entropy_loss         | -26.5        |
|    explained_variance   | 0.712        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.551       |
|    n_updates            | 2685         |
|    policy_gradient_loss | -0.03        |
|    std                  | 4.6          |
|    value_loss           | 0.051        |
------------------------------------------
[ADAPTIVE] Episode 106 reward: 0.023947
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 2.2045789    |
| time/                   |              |
|    fps                  | 1166         |
|    iterations           | 104          |
|    time_elapsed         | 365          |
|    total_timesteps      | 425984       |
| train/                  |              |
|    approx_kl            | 0.0138251325 |
|    clip_fraction        | 0.177        |
|    clip_range           | 0.2          |
|    entropy_loss         | -26.5        |
|    explained_variance   | 0.715        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.539       |
|    n_updates            | 2700         |
|    policy_gradient_loss | -0.0313      |
|    std                  | 4.63         |
|    value_loss           | 0.0668       |
------------------------------------------
[ADAPTIVE] Episode 107 reward: 0.008644
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0992467   |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 105         |
|    time_elapsed         | 368         |
|    total_timesteps      | 430080      |
| train/                  |             |
|    approx_kl            | 0.011945583 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.6       |
|    explained_variance   | 0.705       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.547      |
|    n_updates            | 2715        |
|    policy_gradient_loss | -0.0272     |
|    std                  | 4.65        |
|    value_loss           | 0.0496      |
-----------------------------------------
[ADAPTIVE] Episode 108 reward: 0.029117
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1191812   |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 106         |
|    time_elapsed         | 371         |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.018378865 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.6       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.536      |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.0322     |
|    std                  | 4.68        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 109 reward: -0.040202
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.046071    |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 107         |
|    time_elapsed         | 375         |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.019339127 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.7       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.547      |
|    n_updates            | 2745        |
|    policy_gradient_loss | -0.0322     |
|    std                  | 4.73        |
|    value_loss           | 0.0607      |
-----------------------------------------
[ADAPTIVE] Episode 110 reward: 0.012717
[ADAPTIVE] Mean reward over last 20 episodes: 0.006847
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9865329   |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 108         |
|    time_elapsed         | 378         |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.019054737 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.7       |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.544      |
|    n_updates            | 2760        |
|    policy_gradient_loss | -0.0295     |
|    std                  | 4.74        |
|    value_loss           | 0.0944      |
-----------------------------------------
[ADAPTIVE] Episode 111 reward: 0.030798
[ADAPTIVE] Mean reward over last 20 episodes: 0.006627
[ADAPTIVE] Plateau counter: 1/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 2.139557   |
| time/                   |            |
|    fps                  | 1165       |
|    iterations           | 109        |
|    time_elapsed         | 383        |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.01653162 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -26.8      |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.556     |
|    n_updates            | 2775       |
|    policy_gradient_loss | -0.0297    |
|    std                  | 4.78       |
|    value_loss           | 0.0532     |
----------------------------------------
[ADAPTIVE] Episode 112 reward: 0.008932
[ADAPTIVE] Mean reward over last 20 episodes: 0.006589
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1740644   |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 110         |
|    time_elapsed         | 386         |
|    total_timesteps      | 450560      |
| train/                  |             |
|    approx_kl            | 0.011434214 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.9       |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.529      |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0274     |
|    std                  | 4.81        |
|    value_loss           | 0.0672      |
-----------------------------------------
[ADAPTIVE] Episode 113 reward: 0.015907
[ADAPTIVE] Mean reward over last 20 episodes: 0.006325
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.2644594   |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 111         |
|    time_elapsed         | 389         |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.015049081 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.9       |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.584      |
|    n_updates            | 2805        |
|    policy_gradient_loss | -0.0324     |
|    std                  | 4.83        |
|    value_loss           | 0.0368      |
-----------------------------------------
[ADAPTIVE] Episode 114 reward: 0.026436
[ADAPTIVE] Mean reward over last 20 episodes: 0.007600
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1577938   |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 112         |
|    time_elapsed         | 393         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.018203314 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.9       |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.545      |
|    n_updates            | 2820        |
|    policy_gradient_loss | -0.0249     |
|    std                  | 4.86        |
|    value_loss           | 0.0769      |
-----------------------------------------
[ADAPTIVE] Episode 115 reward: 0.033750
[ADAPTIVE] Mean reward over last 20 episodes: 0.009096
[ADAPTIVE] Plateau counter: 5/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 2.220383     |
| time/                   |              |
|    fps                  | 1168         |
|    iterations           | 113          |
|    time_elapsed         | 396          |
|    total_timesteps      | 462848       |
| train/                  |              |
|    approx_kl            | 0.0109349545 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.2          |
|    entropy_loss         | -27          |
|    explained_variance   | 0.74         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.54        |
|    n_updates            | 2835         |
|    policy_gradient_loss | -0.0269      |
|    std                  | 4.87         |
|    value_loss           | 0.0953       |
------------------------------------------
[ADAPTIVE] Episode 116 reward: 0.065818
[ADAPTIVE] Mean reward over last 20 episodes: 0.009953
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.1374338   |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 114         |
|    time_elapsed         | 399         |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.018378334 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -27         |
|    explained_variance   | 0.627       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.497      |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.0297     |
|    std                  | 4.89        |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 117 reward: -0.034297
[ADAPTIVE] Mean reward over last 20 episodes: 0.013778
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 2.0546565   |
| time/                   |             |
|    fps                  | 1168        |
|    iterations           | 115         |
|    time_elapsed         | 403         |
|    total_timesteps      | 471040      |
| train/                  |             |
|    approx_kl            | 0.014527628 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.1       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.558      |
|    n_updates            | 2865        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 4.92        |
|    value_loss           | 0.0813      |
-----------------------------------------
[ADAPTIVE] Episode 118 reward: -0.049605
[ADAPTIVE] Mean reward over last 20 episodes: 0.012406
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.994963    |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 116         |
|    time_elapsed         | 406         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.010646565 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.1       |
|    explained_variance   | 0.601       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.52       |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 4.93        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 119 reward: -0.016534
[ADAPTIVE] Mean reward over last 20 episodes: 0.012083
[ADAPTIVE] Plateau counter: 9/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.8326674    |
| time/                   |              |
|    fps                  | 1168         |
|    iterations           | 117          |
|    time_elapsed         | 410          |
|    total_timesteps      | 479232       |
| train/                  |              |
|    approx_kl            | 0.0111983325 |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.2          |
|    entropy_loss         | -27.1        |
|    explained_variance   | 0.609        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.558       |
|    n_updates            | 2895         |
|    policy_gradient_loss | -0.029       |
|    std                  | 4.96         |
|    value_loss           | 0.0801       |
------------------------------------------
[ADAPTIVE] Episode 120 reward: 0.028185
[ADAPTIVE] Mean reward over last 20 episodes: 0.012399
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 4: RigidPoseInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 4
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8688531   |
| time/                   |             |
|    fps                  | 1168        |
|    iterations           | 118         |
|    time_elapsed         | 413         |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.018753525 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.2       |
|    explained_variance   | 0.683       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.551      |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 5           |
|    value_loss           | 0.0891      |
-----------------------------------------
[ADAPTIVE] Episode 121 reward: -0.012398
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.904982    |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 119         |
|    time_elapsed         | 417         |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.017130017 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.3       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.559      |
|    n_updates            | 2925        |
|    policy_gradient_loss | -0.0319     |
|    std                  | 5.02        |
|    value_loss           | 0.0742      |
-----------------------------------------
[ADAPTIVE] Episode 122 reward: 0.014183
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.715021    |
| time/                   |             |
|    fps                  | 1169        |
|    iterations           | 120         |
|    time_elapsed         | 420         |
|    total_timesteps      | 491520      |
| train/                  |             |
|    approx_kl            | 0.018424323 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.3       |
|    explained_variance   | 0.615       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.548      |
|    n_updates            | 2940        |
|    policy_gradient_loss | -0.0294     |
|    std                  | 5.06        |
|    value_loss           | 0.0922      |
-----------------------------------------
[ADAPTIVE] Episode 123 reward: -0.009046
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3795706   |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 121         |
|    time_elapsed         | 424         |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.015852066 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.4       |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.522      |
|    n_updates            | 2955        |
|    policy_gradient_loss | -0.0286     |
|    std                  | 5.09        |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 124 reward: 0.066557
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.152381    |
| time/                   |             |
|    fps                  | 1169        |
|    iterations           | 122         |
|    time_elapsed         | 427         |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.015157491 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.4       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.544      |
|    n_updates            | 2970        |
|    policy_gradient_loss | -0.0328     |
|    std                  | 5.1         |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 125 reward: -0.025575
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 0.8895015 |
| time/                   |           |
|    fps                  | 1167      |
|    iterations           | 123       |
|    time_elapsed         | 431       |
|    total_timesteps      | 503808    |
| train/                  |           |
|    approx_kl            | 0.0171938 |
|    clip_fraction        | 0.194     |
|    clip_range           | 0.2       |
|    entropy_loss         | -27.4     |
|    explained_variance   | 0.591     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.537    |
|    n_updates            | 2985      |
|    policy_gradient_loss | -0.0292   |
|    std                  | 5.11      |
|    value_loss           | 0.114     |
---------------------------------------
[ADAPTIVE] Episode 126 reward: -0.029512
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.44870457  |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 124         |
|    time_elapsed         | 435         |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.012129105 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.5       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.53       |
|    n_updates            | 3000        |
|    policy_gradient_loss | -0.0301     |
|    std                  | 5.13        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 127 reward: -0.055807
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.17399196  |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 125         |
|    time_elapsed         | 438         |
|    total_timesteps      | 512000      |
| train/                  |             |
|    approx_kl            | 0.014250448 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.5       |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.549      |
|    n_updates            | 3015        |
|    policy_gradient_loss | -0.0314     |
|    std                  | 5.16        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 128 reward: 0.067839
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.112482846 |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 126         |
|    time_elapsed         | 442         |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.018848855 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.5       |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.554      |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.025      |
|    std                  | 5.18        |
|    value_loss           | 0.0997      |
-----------------------------------------
[ADAPTIVE] Episode 129 reward: -0.047334
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 251           |
|    ep_rew_mean          | -0.0054320693 |
| time/                   |               |
|    fps                  | 1165          |
|    iterations           | 127           |
|    time_elapsed         | 446           |
|    total_timesteps      | 520192        |
| train/                  |               |
|    approx_kl            | 0.014814488   |
|    clip_fraction        | 0.189         |
|    clip_range           | 0.2           |
|    entropy_loss         | -27.6         |
|    explained_variance   | 0.604         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.506        |
|    n_updates            | 3045          |
|    policy_gradient_loss | -0.0334       |
|    std                  | 5.2           |
|    value_loss           | 0.165         |
-------------------------------------------
[ADAPTIVE] Episode 130 reward: 0.046624
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 251           |
|    ep_rew_mean          | -0.0013028414 |
| time/                   |               |
|    fps                  | 1166          |
|    iterations           | 128           |
|    time_elapsed         | 449           |
|    total_timesteps      | 524288        |
| train/                  |               |
|    approx_kl            | 0.018403139   |
|    clip_fraction        | 0.195         |
|    clip_range           | 0.2           |
|    entropy_loss         | -27.6         |
|    explained_variance   | 0.555         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.542        |
|    n_updates            | 3060          |
|    policy_gradient_loss | -0.0315       |
|    std                  | 5.23          |
|    value_loss           | 0.139         |
-------------------------------------------
[ADAPTIVE] Episode 131 reward: -0.083239
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.09039588 |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 129         |
|    time_elapsed         | 453         |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.024106562 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.7       |
|    explained_variance   | 0.571       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.538      |
|    n_updates            | 3075        |
|    policy_gradient_loss | -0.0345     |
|    std                  | 5.26        |
|    value_loss           | 0.119       |
-----------------------------------------
[ADAPTIVE] Episode 132 reward: 0.029149
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.12572658  |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 130         |
|    time_elapsed         | 457         |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.012042057 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.7       |
|    explained_variance   | 0.712       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.549      |
|    n_updates            | 3090        |
|    policy_gradient_loss | -0.0265     |
|    std                  | 5.29        |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 133 reward: 0.014267
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 251           |
|    ep_rew_mean          | -0.0063703563 |
| time/                   |               |
|    fps                  | 1164          |
|    iterations           | 131           |
|    time_elapsed         | 460           |
|    total_timesteps      | 536576        |
| train/                  |               |
|    approx_kl            | 0.01778683    |
|    clip_fraction        | 0.206         |
|    clip_range           | 0.2           |
|    entropy_loss         | -27.8         |
|    explained_variance   | 0.777         |
|    learning_rate        | 0.00025       |
|    loss                 | -0.572        |
|    n_updates            | 3105          |
|    policy_gradient_loss | -0.0358       |
|    std                  | 5.33          |
|    value_loss           | 0.0866        |
-------------------------------------------
[ADAPTIVE] Episode 134 reward: 0.057124
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | -0.065179855 |
| time/                   |              |
|    fps                  | 1164         |
|    iterations           | 132          |
|    time_elapsed         | 464          |
|    total_timesteps      | 540672       |
| train/                  |              |
|    approx_kl            | 0.021603836  |
|    clip_fraction        | 0.244        |
|    clip_range           | 0.2          |
|    entropy_loss         | -27.8        |
|    explained_variance   | 0.683        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.552       |
|    n_updates            | 3120         |
|    policy_gradient_loss | -0.0331      |
|    std                  | 5.36         |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 135 reward: 0.010935
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.06357003 |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 133         |
|    time_elapsed         | 468         |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.01590585  |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.9       |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.552      |
|    n_updates            | 3135        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 5.42        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 136 reward: 0.050024
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.045901556 |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 134         |
|    time_elapsed         | 471         |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.012791481 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28         |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.567      |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.031      |
|    std                  | 5.44        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 137 reward: -0.020267
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.13107926 |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 135         |
|    time_elapsed         | 475         |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.015400309 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28         |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.543      |
|    n_updates            | 3165        |
|    policy_gradient_loss | -0.0289     |
|    std                  | 5.47        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 138 reward: -0.099652
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.26974657 |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 136         |
|    time_elapsed         | 478         |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.015650038 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.1       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.556      |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.031      |
|    std                  | 5.49        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 139 reward: 0.050556
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.38591722 |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 137         |
|    time_elapsed         | 482         |
|    total_timesteps      | 561152      |
| train/                  |             |
|    approx_kl            | 0.017017229 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.1       |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.573      |
|    n_updates            | 3195        |
|    policy_gradient_loss | -0.0288     |
|    std                  | 5.52        |
|    value_loss           | 0.0755      |
-----------------------------------------
[ADAPTIVE] Episode 140 reward: 0.057838
[ADAPTIVE] Mean reward over last 20 episodes: 0.004113
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.4549537  |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 138         |
|    time_elapsed         | 485         |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.013249424 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.2       |
|    explained_variance   | 0.621       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.558      |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.0276     |
|    std                  | 5.55        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 141 reward: 0.037370
[ADAPTIVE] Mean reward over last 20 episodes: 0.006602
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.47964036 |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 139         |
|    time_elapsed         | 489         |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.016470613 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.2       |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.534      |
|    n_updates            | 3225        |
|    policy_gradient_loss | -0.0241     |
|    std                  | 5.58        |
|    value_loss           | 0.175       |
-----------------------------------------
[ADAPTIVE] Episode 142 reward: 0.126516
[ADAPTIVE] Mean reward over last 20 episodes: 0.012218
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.5386811  |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 140         |
|    time_elapsed         | 492         |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.014755037 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.3       |
|    explained_variance   | 0.669       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.58       |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.0284     |
|    std                  | 5.63        |
|    value_loss           | 0.0997      |
-----------------------------------------
[ADAPTIVE] Episode 143 reward: 0.039301
[ADAPTIVE] Mean reward over last 20 episodes: 0.014636
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.4494196  |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 141         |
|    time_elapsed         | 496         |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.026333112 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.3       |
|    explained_variance   | 0.592       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.561      |
|    n_updates            | 3255        |
|    policy_gradient_loss | -0.0308     |
|    std                  | 5.67        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 144 reward: -0.020142
[ADAPTIVE] Mean reward over last 20 episodes: 0.010301
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.40858966 |
| time/                   |             |
|    fps                  | 1163        |
|    iterations           | 142         |
|    time_elapsed         | 499         |
|    total_timesteps      | 581632      |
| train/                  |             |
|    approx_kl            | 0.013152582 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.4       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.556      |
|    n_updates            | 3270        |
|    policy_gradient_loss | -0.0281     |
|    std                  | 5.68        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 145 reward: -0.108135
[ADAPTIVE] Mean reward over last 20 episodes: 0.006173
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.2617768  |
| time/                   |             |
|    fps                  | 1164        |
|    iterations           | 143         |
|    time_elapsed         | 503         |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.013430664 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.4       |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.563      |
|    n_updates            | 3285        |
|    policy_gradient_loss | -0.028      |
|    std                  | 5.71        |
|    value_loss           | 0.112       |
-----------------------------------------
[ADAPTIVE] Episode 146 reward: 0.136290
[ADAPTIVE] Mean reward over last 20 episodes: 0.014463
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.18347469 |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 144         |
|    time_elapsed         | 506         |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.013076326 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.5       |
|    explained_variance   | 0.59        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.529      |
|    n_updates            | 3300        |
|    policy_gradient_loss | -0.0307     |
|    std                  | 5.74        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 147 reward: -0.019104
[ADAPTIVE] Mean reward over last 20 episodes: 0.016298
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.10533465 |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 145         |
|    time_elapsed         | 509         |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.019765697 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.5       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.547      |
|    n_updates            | 3315        |
|    policy_gradient_loss | -0.0279     |
|    std                  | 5.77        |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 148 reward: -0.001697
[ADAPTIVE] Mean reward over last 20 episodes: 0.012821
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.11033194 |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 146         |
|    time_elapsed         | 512         |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.014323939 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.6       |
|    explained_variance   | 0.676       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.574      |
|    n_updates            | 3330        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 5.8         |
|    value_loss           | 0.112       |
-----------------------------------------
[ADAPTIVE] Episode 149 reward: -0.028539
[ADAPTIVE] Mean reward over last 20 episodes: 0.013761
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.27252686 |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 147         |
|    time_elapsed         | 516         |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.019662661 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.6       |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.54       |
|    n_updates            | 3345        |
|    policy_gradient_loss | -0.0286     |
|    std                  | 5.84        |
|    value_loss           | 0.129       |
-----------------------------------------
[ADAPTIVE] Episode 150 reward: 0.044162
[ADAPTIVE] Mean reward over last 20 episodes: 0.013638
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.27719793 |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 148         |
|    time_elapsed         | 519         |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.017161965 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.7       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.57       |
|    n_updates            | 3360        |
|    policy_gradient_loss | -0.0278     |
|    std                  | 5.89        |
|    value_loss           | 0.1         |
-----------------------------------------
[ADAPTIVE] Episode 151 reward: 0.036984
[ADAPTIVE] Mean reward over last 20 episodes: 0.019649
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.49250802 |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 149         |
|    time_elapsed         | 523         |
|    total_timesteps      | 610304      |
| train/                  |             |
|    approx_kl            | 0.017596569 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.7       |
|    explained_variance   | 0.546       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.535      |
|    n_updates            | 3375        |
|    policy_gradient_loss | -0.0264     |
|    std                  | 5.92        |
|    value_loss           | 0.171       |
-----------------------------------------
[ADAPTIVE] Episode 152 reward: 0.083350
[ADAPTIVE] Mean reward over last 20 episodes: 0.022359
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.50741595 |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 150         |
|    time_elapsed         | 526         |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.011654488 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.8       |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.557      |
|    n_updates            | 3390        |
|    policy_gradient_loss | -0.0256     |
|    std                  | 5.92        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 153 reward: 0.024841
[ADAPTIVE] Mean reward over last 20 episodes: 0.022888
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 5: RandomInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 154 reward: 0.115502
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.25540185 |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 151         |
|    time_elapsed         | 530         |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.011575777 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.8       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.578      |
|    n_updates            | 3405        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 5.95        |
|    value_loss           | 0.0877      |
-----------------------------------------
[ADAPTIVE] Episode 155 reward: 0.030776
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.091257475 |
| time/                   |             |
|    fps                  | 1165        |
|    iterations           | 152         |
|    time_elapsed         | 533         |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.015399637 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.8       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.561      |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.0252     |
|    std                  | 5.96        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 156 reward: -0.016838
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.33839202  |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 153         |
|    time_elapsed         | 537         |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.013680769 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.8       |
|    explained_variance   | 0.565       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.536      |
|    n_updates            | 3435        |
|    policy_gradient_loss | -0.0247     |
|    std                  | 5.99        |
|    value_loss           | 0.173       |
-----------------------------------------
[ADAPTIVE] Episode 157 reward: -0.176065
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.3687432   |
| time/                   |             |
|    fps                  | 1166        |
|    iterations           | 154         |
|    time_elapsed         | 540         |
|    total_timesteps      | 630784      |
| train/                  |             |
|    approx_kl            | 0.021073082 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.9       |
|    explained_variance   | 0.371       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.519      |
|    n_updates            | 3450        |
|    policy_gradient_loss | -0.0281     |
|    std                  | 6.02        |
|    value_loss           | 0.253       |
-----------------------------------------
[ADAPTIVE] Episode 158 reward: 0.133772
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4536893   |
| time/                   |             |
|    fps                  | 1167        |
|    iterations           | 155         |
|    time_elapsed         | 543         |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.019058956 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.9       |
|    explained_variance   | 0.345       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.439      |
|    n_updates            | 3465        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 6.06        |
|    value_loss           | 0.511       |
-----------------------------------------
[ADAPTIVE] Episode 159 reward: 0.047071
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.6736095  |
| time/                   |            |
|    fps                  | 1168       |
|    iterations           | 156        |
|    time_elapsed         | 547        |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.01611262 |
|    clip_fraction        | 0.142      |
|    clip_range           | 0.2        |
|    entropy_loss         | -29        |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.552     |
|    n_updates            | 3480       |
|    policy_gradient_loss | -0.0257    |
|    std                  | 6.05       |
|    value_loss           | 0.122      |
----------------------------------------
[ADAPTIVE] Episode 160 reward: 0.000304
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.64549726  |
| time/                   |             |
|    fps                  | 1168        |
|    iterations           | 157         |
|    time_elapsed         | 550         |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.021050975 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29         |
|    explained_variance   | -0.0941     |
|    learning_rate        | 0.00025     |
|    loss                 | -0.393      |
|    n_updates            | 3495        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 6.1         |
|    value_loss           | 0.341       |
-----------------------------------------
[ADAPTIVE] Episode 161 reward: -0.027506
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7672554   |
| time/                   |             |
|    fps                  | 1169        |
|    iterations           | 158         |
|    time_elapsed         | 553         |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.016175926 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29         |
|    explained_variance   | 0.292       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.528      |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.0252     |
|    std                  | 6.12        |
|    value_loss           | 0.298       |
-----------------------------------------
[ADAPTIVE] Episode 162 reward: -0.006721
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.80290633  |
| time/                   |             |
|    fps                  | 1170        |
|    iterations           | 159         |
|    time_elapsed         | 556         |
|    total_timesteps      | 651264      |
| train/                  |             |
|    approx_kl            | 0.011339006 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.1       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.576      |
|    n_updates            | 3525        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 6.14        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 163 reward: 0.012387
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8951719   |
| time/                   |             |
|    fps                  | 1171        |
|    iterations           | 160         |
|    time_elapsed         | 559         |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.020638209 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.1       |
|    explained_variance   | 0.374       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.558      |
|    n_updates            | 3540        |
|    policy_gradient_loss | -0.0299     |
|    std                  | 6.2         |
|    value_loss           | 0.247       |
-----------------------------------------
[ADAPTIVE] Episode 164 reward: 0.002808
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9580836   |
| time/                   |             |
|    fps                  | 1171        |
|    iterations           | 161         |
|    time_elapsed         | 563         |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.016889118 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.2       |
|    explained_variance   | 0.517       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.552      |
|    n_updates            | 3555        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 6.24        |
|    value_loss           | 0.171       |
-----------------------------------------
[ADAPTIVE] Episode 165 reward: 0.042560
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.87196374 |
| time/                   |            |
|    fps                  | 1171       |
|    iterations           | 162        |
|    time_elapsed         | 566        |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.01662957 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -29.3      |
|    explained_variance   | 0.179      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.302     |
|    n_updates            | 3570       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 6.26       |
|    value_loss           | 1.02       |
----------------------------------------
[ADAPTIVE] Episode 166 reward: 0.053020
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8106869   |
| time/                   |             |
|    fps                  | 1171        |
|    iterations           | 163         |
|    time_elapsed         | 569         |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.014630845 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.3       |
|    explained_variance   | 0.573       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.569      |
|    n_updates            | 3585        |
|    policy_gradient_loss | -0.0274     |
|    std                  | 6.28        |
|    value_loss           | 0.168       |
-----------------------------------------
[ADAPTIVE] Episode 167 reward: -0.025901
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.87774336  |
| time/                   |             |
|    fps                  | 1172        |
|    iterations           | 164         |
|    time_elapsed         | 572         |
|    total_timesteps      | 671744      |
| train/                  |             |
|    approx_kl            | 0.013212002 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.3       |
|    explained_variance   | 0.614       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.573      |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 6.32        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 168 reward: 0.016822
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.82658434  |
| time/                   |             |
|    fps                  | 1173        |
|    iterations           | 165         |
|    time_elapsed         | 576         |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.014969373 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.4       |
|    explained_variance   | 0.384       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.551      |
|    n_updates            | 3615        |
|    policy_gradient_loss | -0.0265     |
|    std                  | 6.38        |
|    value_loss           | 0.205       |
-----------------------------------------
[ADAPTIVE] Episode 169 reward: 0.053556
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0228117   |
| time/                   |             |
|    fps                  | 1174        |
|    iterations           | 166         |
|    time_elapsed         | 579         |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.018024592 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.5       |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.49       |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.028      |
|    std                  | 6.42        |
|    value_loss           | 0.336       |
-----------------------------------------
[ADAPTIVE] Episode 170 reward: 0.084515
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0256567   |
| time/                   |             |
|    fps                  | 1173        |
|    iterations           | 167         |
|    time_elapsed         | 582         |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.017785426 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.5       |
|    explained_variance   | 0.24        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.352      |
|    n_updates            | 3645        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 6.47        |
|    value_loss           | 0.55        |
-----------------------------------------
[ADAPTIVE] Episode 171 reward: 0.022448
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1524917   |
| time/                   |             |
|    fps                  | 1174        |
|    iterations           | 168         |
|    time_elapsed         | 585         |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.017073173 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.6       |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.495      |
|    n_updates            | 3660        |
|    policy_gradient_loss | -0.0316     |
|    std                  | 6.52        |
|    value_loss           | 0.362       |
-----------------------------------------
[ADAPTIVE] Episode 172 reward: -0.053940
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2747586   |
| time/                   |             |
|    fps                  | 1175        |
|    iterations           | 169         |
|    time_elapsed         | 589         |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.015030209 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.7       |
|    explained_variance   | 0.31        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.54       |
|    n_updates            | 3675        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 6.55        |
|    value_loss           | 0.205       |
-----------------------------------------
[ADAPTIVE] Episode 173 reward: 0.066534
[ADAPTIVE] Mean reward over last 20 episodes: 0.018755
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1870022   |
| time/                   |             |
|    fps                  | 1175        |
|    iterations           | 170         |
|    time_elapsed         | 592         |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.013398621 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.7       |
|    explained_variance   | 0.452       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.495      |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 6.59        |
|    value_loss           | 0.404       |
-----------------------------------------
[ADAPTIVE] Episode 174 reward: 0.028592
[ADAPTIVE] Mean reward over last 20 episodes: 0.014410
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0684236   |
| time/                   |             |
|    fps                  | 1175        |
|    iterations           | 171         |
|    time_elapsed         | 595         |
|    total_timesteps      | 700416      |
| train/                  |             |
|    approx_kl            | 0.018278476 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.8       |
|    explained_variance   | 0.283       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.482      |
|    n_updates            | 3705        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 6.65        |
|    value_loss           | 0.417       |
-----------------------------------------
[ADAPTIVE] Episode 175 reward: -0.015754
[ADAPTIVE] Mean reward over last 20 episodes: 0.012083
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.87643236  |
| time/                   |             |
|    fps                  | 1176        |
|    iterations           | 172         |
|    time_elapsed         | 598         |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.018401362 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.8       |
|    explained_variance   | 0.322       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.421      |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.025      |
|    std                  | 6.7         |
|    value_loss           | 0.609       |
-----------------------------------------
[ADAPTIVE] Episode 176 reward: -0.040017
[ADAPTIVE] Mean reward over last 20 episodes: 0.010924
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9920649   |
| time/                   |             |
|    fps                  | 1176        |
|    iterations           | 173         |
|    time_elapsed         | 602         |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.022792052 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.9       |
|    explained_variance   | 0.335       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.481      |
|    n_updates            | 3735        |
|    policy_gradient_loss | -0.0287     |
|    std                  | 6.75        |
|    value_loss           | 0.376       |
-----------------------------------------
[ADAPTIVE] Episode 177 reward: -0.041286
[ADAPTIVE] Mean reward over last 20 episodes: 0.017663
[ADAPTIVE] Plateau counter: 4/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.76399934 |
| time/                   |            |
|    fps                  | 1177       |
|    iterations           | 174        |
|    time_elapsed         | 605        |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.0180123  |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -30        |
|    explained_variance   | 0.466      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.555     |
|    n_updates            | 3750       |
|    policy_gradient_loss | -0.0265    |
|    std                  | 6.78       |
|    value_loss           | 0.224      |
----------------------------------------
[ADAPTIVE] Episode 178 reward: 0.047433
[ADAPTIVE] Mean reward over last 20 episodes: 0.013346
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67480105  |
| time/                   |             |
|    fps                  | 1177        |
|    iterations           | 175         |
|    time_elapsed         | 608         |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.015292734 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30         |
|    explained_variance   | 0.46        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.49       |
|    n_updates            | 3765        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 6.8         |
|    value_loss           | 0.305       |
-----------------------------------------
[ADAPTIVE] Episode 179 reward: -0.056359
[ADAPTIVE] Mean reward over last 20 episodes: 0.008175
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7122876   |
| time/                   |             |
|    fps                  | 1178        |
|    iterations           | 176         |
|    time_elapsed         | 611         |
|    total_timesteps      | 720896      |
| train/                  |             |
|    approx_kl            | 0.015829392 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30         |
|    explained_variance   | 0.344       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.548      |
|    n_updates            | 3780        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 6.83        |
|    value_loss           | 0.313       |
-----------------------------------------
[ADAPTIVE] Episode 180 reward: -0.041260
[ADAPTIVE] Mean reward over last 20 episodes: 0.006097
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.72593     |
| time/                   |             |
|    fps                  | 1178        |
|    iterations           | 177         |
|    time_elapsed         | 615         |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.013214672 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30         |
|    explained_variance   | 0.38        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.555      |
|    n_updates            | 3795        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 6.84        |
|    value_loss           | 0.224       |
-----------------------------------------
[ADAPTIVE] Episode 181 reward: 0.050312
[ADAPTIVE] Mean reward over last 20 episodes: 0.009987
[ADAPTIVE] Plateau counter: 8/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.8427098  |
| time/                   |            |
|    fps                  | 1177       |
|    iterations           | 178        |
|    time_elapsed         | 618        |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.01838062 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.1      |
|    explained_variance   | 0.39       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.548     |
|    n_updates            | 3810       |
|    policy_gradient_loss | -0.0268    |
|    std                  | 6.89       |
|    value_loss           | 0.283      |
----------------------------------------
[ADAPTIVE] Episode 182 reward: -0.021545
[ADAPTIVE] Mean reward over last 20 episodes: 0.009246
[ADAPTIVE] Plateau counter: 9/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.8118927  |
| time/                   |            |
|    fps                  | 1178       |
|    iterations           | 179        |
|    time_elapsed         | 622        |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.01849674 |
|    clip_fraction        | 0.18       |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.2      |
|    explained_variance   | 0.32       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.47      |
|    n_updates            | 3825       |
|    policy_gradient_loss | -0.0223    |
|    std                  | 6.94       |
|    value_loss           | 0.367      |
----------------------------------------
[ADAPTIVE] Episode 183 reward: 0.001607
[ADAPTIVE] Mean reward over last 20 episodes: 0.008707
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.59830856  |
| time/                   |             |
|    fps                  | 1177        |
|    iterations           | 180         |
|    time_elapsed         | 625         |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.020764608 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.2       |
|    explained_variance   | 0.542       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.595      |
|    n_updates            | 3840        |
|    policy_gradient_loss | -0.0273     |
|    std                  | 7           |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 184 reward: 0.021220
[ADAPTIVE] Mean reward over last 20 episodes: 0.009628
[ADAPTIVE] Plateau counter: 11/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7067291   |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 181         |
|    time_elapsed         | 628         |
|    total_timesteps      | 741376      |
| train/                  |             |
|    approx_kl            | 0.016914584 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.3       |
|    explained_variance   | 0.14        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.37       |
|    n_updates            | 3855        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 7.03        |
|    value_loss           | 0.513       |
-----------------------------------------
[ADAPTIVE] Episode 185 reward: -0.058663
[ADAPTIVE] Mean reward over last 20 episodes: 0.004567
[ADAPTIVE] Plateau counter: 12/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6242975   |
| time/                   |             |
|    fps                  | 1178        |
|    iterations           | 182         |
|    time_elapsed         | 632         |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.016308237 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.3       |
|    explained_variance   | 0.18        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.494      |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 7.08        |
|    value_loss           | 0.334       |
-----------------------------------------
[ADAPTIVE] Episode 186 reward: 0.078378
[ADAPTIVE] Mean reward over last 20 episodes: 0.005835
[ADAPTIVE] Plateau counter: 13/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67843515  |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 183         |
|    time_elapsed         | 635         |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.015935712 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.4       |
|    explained_variance   | 0.56        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.587      |
|    n_updates            | 3885        |
|    policy_gradient_loss | -0.0319     |
|    std                  | 7.1         |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 187 reward: 0.020827
[ADAPTIVE] Mean reward over last 20 episodes: 0.008171
[ADAPTIVE] Plateau counter: 14/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.51548064  |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 184         |
|    time_elapsed         | 639         |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.017824233 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.4       |
|    explained_variance   | 0.412       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.586      |
|    n_updates            | 3900        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 7.15        |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 188 reward: 0.059762
[ADAPTIVE] Mean reward over last 20 episodes: 0.010318
[ADAPTIVE] Plateau counter: 15/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.58351773  |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 185         |
|    time_elapsed         | 642         |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.016262481 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.5       |
|    explained_variance   | 0.326       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.562      |
|    n_updates            | 3915        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 7.19        |
|    value_loss           | 0.335       |
-----------------------------------------
[ADAPTIVE] Episode 189 reward: 0.008899
[ADAPTIVE] Mean reward over last 20 episodes: 0.008085
[ADAPTIVE] Plateau counter: 16/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8189724   |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 186         |
|    time_elapsed         | 645         |
|    total_timesteps      | 761856      |
| train/                  |             |
|    approx_kl            | 0.017938834 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.5       |
|    explained_variance   | 0.387       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.429      |
|    n_updates            | 3930        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 7.22        |
|    value_loss           | 0.367       |
-----------------------------------------
[ADAPTIVE] Episode 190 reward: 0.061352
[ADAPTIVE] Mean reward over last 20 episodes: 0.006927
[ADAPTIVE] Plateau counter: 17/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9035331   |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 187         |
|    time_elapsed         | 649         |
|    total_timesteps      | 765952      |
| train/                  |             |
|    approx_kl            | 0.013400197 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.6       |
|    explained_variance   | 0.472       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.576      |
|    n_updates            | 3945        |
|    policy_gradient_loss | -0.026      |
|    std                  | 7.25        |
|    value_loss           | 0.212       |
-----------------------------------------
[ADAPTIVE] Episode 191 reward: -0.056795
[ADAPTIVE] Mean reward over last 20 episodes: 0.002965
[ADAPTIVE] Plateau counter: 18/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.9064609  |
| time/                   |            |
|    fps                  | 1179       |
|    iterations           | 188        |
|    time_elapsed         | 652        |
|    total_timesteps      | 770048     |
| train/                  |            |
|    approx_kl            | 0.01636665 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.6      |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.563     |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.0265    |
|    std                  | 7.3        |
|    value_loss           | 0.236      |
----------------------------------------
[ADAPTIVE] Episode 192 reward: -0.103321
[ADAPTIVE] Mean reward over last 20 episodes: 0.000496
[ADAPTIVE] Plateau counter: 19/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9933461    |
| time/                   |              |
|    fps                  | 1179         |
|    iterations           | 189          |
|    time_elapsed         | 656          |
|    total_timesteps      | 774144       |
| train/                  |              |
|    approx_kl            | 0.0144309085 |
|    clip_fraction        | 0.163        |
|    clip_range           | 0.2          |
|    entropy_loss         | -30.7        |
|    explained_variance   | 0.572        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.623       |
|    n_updates            | 3975         |
|    policy_gradient_loss | -0.0288      |
|    std                  | 7.32         |
|    value_loss           | 0.0936       |
------------------------------------------
[ADAPTIVE] Episode 193 reward: 0.074582
[ADAPTIVE] Mean reward over last 20 episodes: 0.000898
[ADAPTIVE] Plateau counter: 20/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0571961   |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 190         |
|    time_elapsed         | 659         |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.019693678 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.7       |
|    explained_variance   | 0.324       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.477      |
|    n_updates            | 3990        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 7.36        |
|    value_loss           | 0.433       |
-----------------------------------------
[ADAPTIVE] Episode 194 reward: -0.034889
[ADAPTIVE] Mean reward over last 20 episodes: -0.002276
[ADAPTIVE] Plateau counter: 21/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0751362  |
| time/                   |            |
|    fps                  | 1179       |
|    iterations           | 191        |
|    time_elapsed         | 663        |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.01817067 |
|    clip_fraction        | 0.212      |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.7      |
|    explained_variance   | 0.411      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.554     |
|    n_updates            | 4005       |
|    policy_gradient_loss | -0.029     |
|    std                  | 7.4        |
|    value_loss           | 0.238      |
----------------------------------------
[ADAPTIVE] Episode 195 reward: -0.005917
[ADAPTIVE] Mean reward over last 20 episodes: -0.001784
[ADAPTIVE] Plateau counter: 22/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8972672   |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 192         |
|    time_elapsed         | 666         |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.018996544 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.8       |
|    explained_variance   | 0.5         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.609      |
|    n_updates            | 4020        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 7.44        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 196 reward: 0.054358
[ADAPTIVE] Mean reward over last 20 episodes: 0.002935
[ADAPTIVE] Plateau counter: 23/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.75293136  |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 193         |
|    time_elapsed         | 670         |
|    total_timesteps      | 790528      |
| train/                  |             |
|    approx_kl            | 0.015266327 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.9       |
|    explained_variance   | 0.625       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.622      |
|    n_updates            | 4035        |
|    policy_gradient_loss | -0.0295     |
|    std                  | 7.5         |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 197 reward: 0.082938
[ADAPTIVE] Mean reward over last 20 episodes: 0.009146
[ADAPTIVE] Plateau counter: 24/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.719273    |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 194         |
|    time_elapsed         | 673         |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.015902558 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.9       |
|    explained_variance   | 0.4         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.577      |
|    n_updates            | 4050        |
|    policy_gradient_loss | -0.0245     |
|    std                  | 7.56        |
|    value_loss           | 0.259       |
-----------------------------------------
[ADAPTIVE] Episode 198 reward: -0.060144
[ADAPTIVE] Mean reward over last 20 episodes: 0.003767
[ADAPTIVE] Plateau counter: 25/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4888601    |
| time/                   |              |
|    fps                  | 1179         |
|    iterations           | 195          |
|    time_elapsed         | 677          |
|    total_timesteps      | 798720       |
| train/                  |              |
|    approx_kl            | 0.0153936455 |
|    clip_fraction        | 0.177        |
|    clip_range           | 0.2          |
|    entropy_loss         | -31          |
|    explained_variance   | 0.602        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.612       |
|    n_updates            | 4065         |
|    policy_gradient_loss | -0.0301      |
|    std                  | 7.62         |
|    value_loss           | 0.135        |
------------------------------------------
[ADAPTIVE] Episode 199 reward: -0.037079
[ADAPTIVE] Mean reward over last 20 episodes: 0.004731
[ADAPTIVE] Plateau counter: 26/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.39467523  |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 196         |
|    time_elapsed         | 680         |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.012512383 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.1       |
|    explained_variance   | 0.531       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.621      |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.0263     |
|    std                  | 7.67        |
|    value_loss           | 0.156       |
-----------------------------------------
[ADAPTIVE] Episode 200 reward: 0.044294
[ADAPTIVE] Mean reward over last 20 episodes: 0.009009
[ADAPTIVE] Plateau counter: 27/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.42680076  |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 197         |
|    time_elapsed         | 684         |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.013944373 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.1       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.485      |
|    n_updates            | 4095        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 7.7         |
|    value_loss           | 0.268       |
-----------------------------------------
[ADAPTIVE] Episode 201 reward: 0.028485
[ADAPTIVE] Mean reward over last 20 episodes: 0.007918
[ADAPTIVE] Plateau counter: 28/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.64392835  |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 198         |
|    time_elapsed         | 687         |
|    total_timesteps      | 811008      |
| train/                  |             |
|    approx_kl            | 0.012892248 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.1       |
|    explained_variance   | 0.359       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.581      |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.0252     |
|    std                  | 7.74        |
|    value_loss           | 0.233       |
-----------------------------------------
[ADAPTIVE] Episode 202 reward: 0.001137
[ADAPTIVE] Mean reward over last 20 episodes: 0.009052
[ADAPTIVE] Plateau counter: 29/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.68382096 |
| time/                   |            |
|    fps                  | 1179       |
|    iterations           | 199        |
|    time_elapsed         | 690        |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.01620066 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -31.2      |
|    explained_variance   | 0.18       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.45      |
|    n_updates            | 4125       |
|    policy_gradient_loss | -0.0239    |
|    std                  | 7.75       |
|    value_loss           | 0.605      |
----------------------------------------
[ADAPTIVE] Episode 203 reward: 0.095408
[ADAPTIVE] Mean reward over last 20 episodes: 0.013742
[ADAPTIVE] Plateau counter: 30/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.51607776  |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 200         |
|    time_elapsed         | 694         |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.016881693 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.2       |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.524      |
|    n_updates            | 4140        |
|    policy_gradient_loss | -0.027      |
|    std                  | 7.8         |
|    value_loss           | 0.333       |
-----------------------------------------
[ADAPTIVE] Episode 204 reward: 0.014965
[ADAPTIVE] Mean reward over last 20 episodes: 0.013429
[ADAPTIVE] Plateau counter: 31/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 205 reward: 0.078096
[ADAPTIVE] Mean reward over last 20 episodes: 0.020267
[ADAPTIVE] Plateau counter: 32/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9210393   |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 201         |
|    time_elapsed         | 697         |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.018959284 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.3       |
|    explained_variance   | 0.364       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 4155        |
|    policy_gradient_loss | -0.0261     |
|    std                  | 7.87        |
|    value_loss           | 0.315       |
-----------------------------------------
[ADAPTIVE] Episode 206 reward: -0.036347
[ADAPTIVE] Mean reward over last 20 episodes: 0.014531
[ADAPTIVE] Plateau counter: 33/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.81471634  |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 202         |
|    time_elapsed         | 700         |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.016163126 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.4       |
|    explained_variance   | 0.44        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.597      |
|    n_updates            | 4170        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 7.92        |
|    value_loss           | 0.234       |
-----------------------------------------
[ADAPTIVE] Episode 207 reward: -0.107598
[ADAPTIVE] Mean reward over last 20 episodes: 0.008109
[ADAPTIVE] Plateau counter: 34/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.70090574  |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 203         |
|    time_elapsed         | 704         |
|    total_timesteps      | 831488      |
| train/                  |             |
|    approx_kl            | 0.015040621 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.4       |
|    explained_variance   | 0.438       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.605      |
|    n_updates            | 4185        |
|    policy_gradient_loss | -0.0254     |
|    std                  | 7.95        |
|    value_loss           | 0.215       |
-----------------------------------------
[ADAPTIVE] Episode 208 reward: -0.007045
[ADAPTIVE] Mean reward over last 20 episodes: 0.004769
[ADAPTIVE] Plateau counter: 35/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.71022385   |
| time/                   |              |
|    fps                  | 1180         |
|    iterations           | 204          |
|    time_elapsed         | 707          |
|    total_timesteps      | 835584       |
| train/                  |              |
|    approx_kl            | 0.0151782315 |
|    clip_fraction        | 0.188        |
|    clip_range           | 0.2          |
|    entropy_loss         | -31.4        |
|    explained_variance   | 0.243        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.358       |
|    n_updates            | 4200         |
|    policy_gradient_loss | -0.0244      |
|    std                  | 8            |
|    value_loss           | 0.76         |
------------------------------------------
[ADAPTIVE] Episode 209 reward: 0.017479
[ADAPTIVE] Mean reward over last 20 episodes: 0.005198
[ADAPTIVE] Plateau counter: 36/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76055425  |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 205         |
|    time_elapsed         | 711         |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.017157136 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.5       |
|    explained_variance   | 0.281       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.595      |
|    n_updates            | 4215        |
|    policy_gradient_loss | -0.0283     |
|    std                  | 8.03        |
|    value_loss           | 0.25        |
-----------------------------------------
[ADAPTIVE] Episode 210 reward: -0.089799
[ADAPTIVE] Mean reward over last 20 episodes: -0.002359
[ADAPTIVE] Plateau counter: 37/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 0.6381666 |
| time/                   |           |
|    fps                  | 1180      |
|    iterations           | 206       |
|    time_elapsed         | 714       |
|    total_timesteps      | 843776    |
| train/                  |           |
|    approx_kl            | 0.0140731 |
|    clip_fraction        | 0.152     |
|    clip_range           | 0.2       |
|    entropy_loss         | -31.5     |
|    explained_variance   | 0.394     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.501    |
|    n_updates            | 4230      |
|    policy_gradient_loss | -0.024    |
|    std                  | 8.09      |
|    value_loss           | 0.415     |
---------------------------------------
[ADAPTIVE] Episode 211 reward: 0.019261
[ADAPTIVE] Mean reward over last 20 episodes: 0.001443
[ADAPTIVE] Plateau counter: 38/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6572746   |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 207         |
|    time_elapsed         | 718         |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.013695645 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.6       |
|    explained_variance   | 0.619       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.642      |
|    n_updates            | 4245        |
|    policy_gradient_loss | -0.0315     |
|    std                  | 8.13        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 212 reward: -0.023154
[ADAPTIVE] Mean reward over last 20 episodes: 0.005452
[ADAPTIVE] Plateau counter: 39/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7910331   |
| time/                   |             |
|    fps                  | 1181        |
|    iterations           | 208         |
|    time_elapsed         | 721         |
|    total_timesteps      | 851968      |
| train/                  |             |
|    approx_kl            | 0.018957885 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.7       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.616      |
|    n_updates            | 4260        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 8.2         |
|    value_loss           | 0.157       |
-----------------------------------------
[ADAPTIVE] Episode 213 reward: -0.114913
[ADAPTIVE] Mean reward over last 20 episodes: -0.004023
[ADAPTIVE] Plateau counter: 40/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.78766173  |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 209         |
|    time_elapsed         | 725         |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.016550831 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.7       |
|    explained_variance   | 0.34        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 4275        |
|    policy_gradient_loss | -0.0257     |
|    std                  | 8.24        |
|    value_loss           | 0.327       |
-----------------------------------------
[ADAPTIVE] Episode 214 reward: -0.061983
[ADAPTIVE] Mean reward over last 20 episodes: -0.005378
[ADAPTIVE] Plateau counter: 41/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.88179535  |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 210         |
|    time_elapsed         | 728         |
|    total_timesteps      | 860160      |
| train/                  |             |
|    approx_kl            | 0.019650398 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.7       |
|    explained_variance   | 0.246       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.417      |
|    n_updates            | 4290        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 8.26        |
|    value_loss           | 0.634       |
-----------------------------------------
[ADAPTIVE] Episode 215 reward: 0.021128
[ADAPTIVE] Mean reward over last 20 episodes: -0.004026
[ADAPTIVE] Plateau counter: 42/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98404074  |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 211         |
|    time_elapsed         | 731         |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.016964609 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.8       |
|    explained_variance   | 0.289       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.48       |
|    n_updates            | 4305        |
|    policy_gradient_loss | -0.027      |
|    std                  | 8.31        |
|    value_loss           | 0.48        |
-----------------------------------------
[ADAPTIVE] Episode 216 reward: 0.034012
[ADAPTIVE] Mean reward over last 20 episodes: -0.005043
[ADAPTIVE] Plateau counter: 43/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0207912   |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 212         |
|    time_elapsed         | 735         |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.023618234 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.8       |
|    explained_variance   | 0.499       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.464      |
|    n_updates            | 4320        |
|    policy_gradient_loss | -0.0229     |
|    std                  | 8.37        |
|    value_loss           | 0.312       |
-----------------------------------------
[ADAPTIVE] Episode 217 reward: -0.061342
[ADAPTIVE] Mean reward over last 20 episodes: -0.012257
[ADAPTIVE] Plateau counter: 44/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0433385   |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 213         |
|    time_elapsed         | 739         |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.012545315 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.9       |
|    explained_variance   | 0.55        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.65       |
|    n_updates            | 4335        |
|    policy_gradient_loss | -0.032      |
|    std                  | 8.43        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 218 reward: 0.070284
[ADAPTIVE] Mean reward over last 20 episodes: -0.005736
[ADAPTIVE] Plateau counter: 45/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98528314  |
| time/                   |             |
|    fps                  | 1181        |
|    iterations           | 214         |
|    time_elapsed         | 741         |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.014920685 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32         |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.574      |
|    n_updates            | 4350        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 8.48        |
|    value_loss           | 0.255       |
-----------------------------------------
[ADAPTIVE] Episode 219 reward: 0.026514
[ADAPTIVE] Mean reward over last 20 episodes: -0.002556
[ADAPTIVE] Plateau counter: 46/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8818337   |
| time/                   |             |
|    fps                  | 1181        |
|    iterations           | 215         |
|    time_elapsed         | 745         |
|    total_timesteps      | 880640      |
| train/                  |             |
|    approx_kl            | 0.019104645 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32         |
|    explained_variance   | 0.232       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.536      |
|    n_updates            | 4365        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 8.53        |
|    value_loss           | 0.437       |
-----------------------------------------
[ADAPTIVE] Episode 220 reward: 0.058503
[ADAPTIVE] Mean reward over last 20 episodes: -0.001845
[ADAPTIVE] Plateau counter: 47/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9246867   |
| time/                   |             |
|    fps                  | 1181        |
|    iterations           | 216         |
|    time_elapsed         | 748         |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.018237637 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.1       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.621      |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.0285     |
|    std                  | 8.58        |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 221 reward: -0.057985
[ADAPTIVE] Mean reward over last 20 episodes: -0.006169
[ADAPTIVE] Plateau counter: 48/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0715117   |
| time/                   |             |
|    fps                  | 1181        |
|    iterations           | 217         |
|    time_elapsed         | 752         |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.014945636 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.1       |
|    explained_variance   | 0.546       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.647      |
|    n_updates            | 4395        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 8.62        |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 222 reward: -0.086169
[ADAPTIVE] Mean reward over last 20 episodes: -0.010534
[ADAPTIVE] Plateau counter: 49/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0731916  |
| time/                   |            |
|    fps                  | 1182       |
|    iterations           | 218        |
|    time_elapsed         | 755        |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.01202256 |
|    clip_fraction        | 0.167      |
|    clip_range           | 0.2        |
|    entropy_loss         | -32.1      |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.00025    |
|    loss                 | -0.641     |
|    n_updates            | 4410       |
|    policy_gradient_loss | -0.0235    |
|    std                  | 8.63       |
|    value_loss           | 0.122      |
----------------------------------------
[ADAPTIVE] Episode 223 reward: -0.011306
[ADAPTIVE] Mean reward over last 20 episodes: -0.015870
[ADAPTIVE] Plateau counter: 50/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0841444   |
| time/                   |             |
|    fps                  | 1183        |
|    iterations           | 219         |
|    time_elapsed         | 758         |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.016582577 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.2       |
|    explained_variance   | 0.383       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.488      |
|    n_updates            | 4425        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 8.69        |
|    value_loss           | 0.34        |
-----------------------------------------
[ADAPTIVE] Episode 224 reward: 0.019879
[ADAPTIVE] Mean reward over last 20 episodes: -0.015624
[ADAPTIVE] Plateau counter: 51/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 1.2208467 |
| time/                   |           |
|    fps                  | 1183      |
|    iterations           | 220       |
|    time_elapsed         | 761       |
|    total_timesteps      | 901120    |
| train/                  |           |
|    approx_kl            | 0.0130255 |
|    clip_fraction        | 0.166     |
|    clip_range           | 0.2       |
|    entropy_loss         | -32.2     |
|    explained_variance   | 0.567     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.63     |
|    n_updates            | 4440      |
|    policy_gradient_loss | -0.0305   |
|    std                  | 8.71      |
|    value_loss           | 0.144     |
---------------------------------------
[ADAPTIVE] Episode 225 reward: -0.041982
[ADAPTIVE] Mean reward over last 20 episodes: -0.021628
[ADAPTIVE] Plateau counter: 52/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1810395  |
| time/                   |            |
|    fps                  | 1184       |
|    iterations           | 221        |
|    time_elapsed         | 763        |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.01319484 |
|    clip_fraction        | 0.145      |
|    clip_range           | 0.2        |
|    entropy_loss         | -32.3      |
|    explained_variance   | 0.266      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.598     |
|    n_updates            | 4455       |
|    policy_gradient_loss | -0.0251    |
|    std                  | 8.75       |
|    value_loss           | 0.297      |
----------------------------------------
[ADAPTIVE] Episode 226 reward: 0.004121
[ADAPTIVE] Mean reward over last 20 episodes: -0.019605
[ADAPTIVE] Plateau counter: 53/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1855807   |
| time/                   |             |
|    fps                  | 1184        |
|    iterations           | 222         |
|    time_elapsed         | 767         |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.012065981 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.3       |
|    explained_variance   | 0.54        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.612      |
|    n_updates            | 4470        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 8.79        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 227 reward: 0.038970
[ADAPTIVE] Mean reward over last 20 episodes: -0.012276
[ADAPTIVE] Plateau counter: 54/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3170019   |
| time/                   |             |
|    fps                  | 1186        |
|    iterations           | 223         |
|    time_elapsed         | 770         |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.014053546 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.3       |
|    explained_variance   | 0.332       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 4485        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 8.84        |
|    value_loss           | 0.381       |
-----------------------------------------
[ADAPTIVE] Episode 228 reward: -0.032692
[ADAPTIVE] Mean reward over last 20 episodes: -0.013559
[ADAPTIVE] Plateau counter: 55/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.296972    |
| time/                   |             |
|    fps                  | 1185        |
|    iterations           | 224         |
|    time_elapsed         | 773         |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.013718469 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.4       |
|    explained_variance   | 0.32        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.555      |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 8.89        |
|    value_loss           | 0.365       |
-----------------------------------------
[ADAPTIVE] Episode 229 reward: 0.018359
[ADAPTIVE] Mean reward over last 20 episodes: -0.013515
[ADAPTIVE] Plateau counter: 56/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1441747   |
| time/                   |             |
|    fps                  | 1186        |
|    iterations           | 225         |
|    time_elapsed         | 776         |
|    total_timesteps      | 921600      |
| train/                  |             |
|    approx_kl            | 0.013211752 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.5       |
|    explained_variance   | 0.31        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.475      |
|    n_updates            | 4515        |
|    policy_gradient_loss | -0.0242     |
|    std                  | 8.95        |
|    value_loss           | 0.504       |
-----------------------------------------
[ADAPTIVE] Episode 230 reward: -0.063768
[ADAPTIVE] Mean reward over last 20 episodes: -0.012213
[ADAPTIVE] Plateau counter: 57/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.94529414 |
| time/                   |            |
|    fps                  | 1186       |
|    iterations           | 226        |
|    time_elapsed         | 780        |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.01859203 |
|    clip_fraction        | 0.182      |
|    clip_range           | 0.2        |
|    entropy_loss         | -32.5      |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.669     |
|    n_updates            | 4530       |
|    policy_gradient_loss | -0.0325    |
|    std                  | 9          |
|    value_loss           | 0.116      |
----------------------------------------
[ADAPTIVE] Episode 231 reward: 0.033061
[ADAPTIVE] Mean reward over last 20 episodes: -0.011523
[ADAPTIVE] Plateau counter: 58/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1459765  |
| time/                   |            |
|    fps                  | 1187       |
|    iterations           | 227        |
|    time_elapsed         | 783        |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.01473383 |
|    clip_fraction        | 0.15       |
|    clip_range           | 0.2        |
|    entropy_loss         | -32.6      |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.62      |
|    n_updates            | 4545       |
|    policy_gradient_loss | -0.0249    |
|    std                  | 9.07       |
|    value_loss           | 0.192      |
----------------------------------------
[ADAPTIVE] Episode 232 reward: 0.076947
[ADAPTIVE] Mean reward over last 20 episodes: -0.006518
[ADAPTIVE] Plateau counter: 59/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1923693   |
| time/                   |             |
|    fps                  | 1187        |
|    iterations           | 228         |
|    time_elapsed         | 786         |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.014346185 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.6       |
|    explained_variance   | 0.508       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.541      |
|    n_updates            | 4560        |
|    policy_gradient_loss | -0.0276     |
|    std                  | 9.11        |
|    value_loss           | 0.24        |
-----------------------------------------
[ADAPTIVE] Episode 233 reward: 0.039497
[ADAPTIVE] Mean reward over last 20 episodes: 0.001202
[ADAPTIVE] Plateau counter: 60/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1422566   |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 229         |
|    time_elapsed         | 789         |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.017525516 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.7       |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.674      |
|    n_updates            | 4575        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 9.15        |
|    value_loss           | 0.0977      |
-----------------------------------------
[ADAPTIVE] Episode 234 reward: 0.026540
[ADAPTIVE] Mean reward over last 20 episodes: 0.005629
[ADAPTIVE] Plateau counter: 61/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0830929   |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 230         |
|    time_elapsed         | 792         |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.013863678 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.7       |
|    explained_variance   | 0.591       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.653      |
|    n_updates            | 4590        |
|    policy_gradient_loss | -0.0283     |
|    std                  | 9.2         |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 235 reward: -0.059297
[ADAPTIVE] Mean reward over last 20 episodes: 0.001607
[ADAPTIVE] Plateau counter: 62/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1923636   |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 231         |
|    time_elapsed         | 796         |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.013192646 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.8       |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.661      |
|    n_updates            | 4605        |
|    policy_gradient_loss | -0.0261     |
|    std                  | 9.26        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 236 reward: -0.051311
[ADAPTIVE] Mean reward over last 20 episodes: -0.002659
[ADAPTIVE] Plateau counter: 63/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2723973   |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 232         |
|    time_elapsed         | 799         |
|    total_timesteps      | 950272      |
| train/                  |             |
|    approx_kl            | 0.013681055 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.8       |
|    explained_variance   | 0.565       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.605      |
|    n_updates            | 4620        |
|    policy_gradient_loss | -0.0269     |
|    std                  | 9.31        |
|    value_loss           | 0.258       |
-----------------------------------------
[ADAPTIVE] Episode 237 reward: 0.037210
[ADAPTIVE] Mean reward over last 20 episodes: 0.002269
[ADAPTIVE] Plateau counter: 64/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1256282   |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 233         |
|    time_elapsed         | 802         |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.011975209 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.9       |
|    explained_variance   | 0.617       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.63       |
|    n_updates            | 4635        |
|    policy_gradient_loss | -0.0238     |
|    std                  | 9.36        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 238 reward: -0.040368
[ADAPTIVE] Mean reward over last 20 episodes: -0.003264
[ADAPTIVE] Plateau counter: 65/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1314598   |
| time/                   |             |
|    fps                  | 1189        |
|    iterations           | 234         |
|    time_elapsed         | 805         |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.011698316 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.9       |
|    explained_variance   | 0.498       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.589      |
|    n_updates            | 4650        |
|    policy_gradient_loss | -0.023      |
|    std                  | 9.42        |
|    value_loss           | 0.274       |
-----------------------------------------
[ADAPTIVE] Episode 239 reward: -0.033811
[ADAPTIVE] Mean reward over last 20 episodes: -0.006280
[ADAPTIVE] Plateau counter: 66/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.032733    |
| time/                   |             |
|    fps                  | 1189        |
|    iterations           | 235         |
|    time_elapsed         | 809         |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.011734476 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33         |
|    explained_variance   | 0.408       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.512      |
|    n_updates            | 4665        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 9.48        |
|    value_loss           | 0.396       |
-----------------------------------------
[ADAPTIVE] Episode 240 reward: -0.015361
[ADAPTIVE] Mean reward over last 20 episodes: -0.009973
[ADAPTIVE] Plateau counter: 67/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0812671   |
| time/                   |             |
|    fps                  | 1189        |
|    iterations           | 236         |
|    time_elapsed         | 812         |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.014187993 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33         |
|    explained_variance   | 0.42        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.601      |
|    n_updates            | 4680        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 9.54        |
|    value_loss           | 0.193       |
-----------------------------------------
[ADAPTIVE] Episode 241 reward: 0.047060
[ADAPTIVE] Mean reward over last 20 episodes: -0.004721
[ADAPTIVE] Plateau counter: 68/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96104246  |
| time/                   |             |
|    fps                  | 1189        |
|    iterations           | 237         |
|    time_elapsed         | 816         |
|    total_timesteps      | 970752      |
| train/                  |             |
|    approx_kl            | 0.012446603 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.1       |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.626      |
|    n_updates            | 4695        |
|    policy_gradient_loss | -0.0263     |
|    std                  | 9.59        |
|    value_loss           | 0.21        |
-----------------------------------------
[ADAPTIVE] Episode 242 reward: -0.076911
[ADAPTIVE] Mean reward over last 20 episodes: -0.004258
[ADAPTIVE] Plateau counter: 69/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8784919   |
| time/                   |             |
|    fps                  | 1190        |
|    iterations           | 238         |
|    time_elapsed         | 819         |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.013366998 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.1       |
|    explained_variance   | 0.639       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.654      |
|    n_updates            | 4710        |
|    policy_gradient_loss | -0.0255     |
|    std                  | 9.64        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 243 reward: -0.069988
[ADAPTIVE] Mean reward over last 20 episodes: -0.007192
[ADAPTIVE] Plateau counter: 70/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8513277   |
| time/                   |             |
|    fps                  | 1189        |
|    iterations           | 239         |
|    time_elapsed         | 822         |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.015598083 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.2       |
|    explained_variance   | 0.496       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.586      |
|    n_updates            | 4725        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 9.68        |
|    value_loss           | 0.288       |
-----------------------------------------
[ADAPTIVE] Episode 244 reward: 0.045095
[ADAPTIVE] Mean reward over last 20 episodes: -0.005931
[ADAPTIVE] Plateau counter: 71/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9357324   |
| time/                   |             |
|    fps                  | 1190        |
|    iterations           | 240         |
|    time_elapsed         | 825         |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.015092977 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.2       |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.578      |
|    n_updates            | 4740        |
|    policy_gradient_loss | -0.0257     |
|    std                  | 9.73        |
|    value_loss           | 0.357       |
-----------------------------------------
[ADAPTIVE] Episode 245 reward: -0.003714
[ADAPTIVE] Mean reward over last 20 episodes: -0.004018
[ADAPTIVE] Plateau counter: 72/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8516048   |
| time/                   |             |
|    fps                  | 1190        |
|    iterations           | 241         |
|    time_elapsed         | 829         |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.016640203 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.3       |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.592      |
|    n_updates            | 4755        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 9.78        |
|    value_loss           | 0.245       |
-----------------------------------------
[ADAPTIVE] Episode 246 reward: -0.013325
[ADAPTIVE] Mean reward over last 20 episodes: -0.004890
[ADAPTIVE] Plateau counter: 73/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7414812   |
| time/                   |             |
|    fps                  | 1191        |
|    iterations           | 242         |
|    time_elapsed         | 831         |
|    total_timesteps      | 991232      |
| train/                  |             |
|    approx_kl            | 0.012938438 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.3       |
|    explained_variance   | 0.532       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.65       |
|    n_updates            | 4770        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 9.82        |
|    value_loss           | 0.21        |
-----------------------------------------
[ADAPTIVE] Episode 247 reward: -0.021407
[ADAPTIVE] Mean reward over last 20 episodes: -0.007909
[ADAPTIVE] Plateau counter: 74/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6054202   |
| time/                   |             |
|    fps                  | 1191        |
|    iterations           | 243         |
|    time_elapsed         | 835         |
|    total_timesteps      | 995328      |
| train/                  |             |
|    approx_kl            | 0.019210175 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.3       |
|    explained_variance   | 0.569       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.659      |
|    n_updates            | 4785        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 9.84        |
|    value_loss           | 0.176       |
-----------------------------------------
[ADAPTIVE] Episode 248 reward: 0.025513
[ADAPTIVE] Mean reward over last 20 episodes: -0.004999
[ADAPTIVE] Plateau counter: 75/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.66883093  |
| time/                   |             |
|    fps                  | 1192        |
|    iterations           | 244         |
|    time_elapsed         | 837         |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.014518041 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.4       |
|    explained_variance   | 0.578       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.549      |
|    n_updates            | 4800        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 9.88        |
|    value_loss           | 0.257       |
-----------------------------------------
[ADAPTIVE] Episode 249 reward: 0.016460
[ADAPTIVE] Mean reward over last 20 episodes: -0.005094
[ADAPTIVE] Plateau counter: 76/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.5297264  |
| time/                   |            |
|    fps                  | 1192       |
|    iterations           | 245        |
|    time_elapsed         | 841        |
|    total_timesteps      | 1003520    |
| train/                  |            |
|    approx_kl            | 0.01588194 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -33.4      |
|    explained_variance   | 0.679      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.653     |
|    n_updates            | 4815       |
|    policy_gradient_loss | -0.0259    |
|    std                  | 9.93       |
|    value_loss           | 0.167      |
----------------------------------------
[ADAPTIVE] Episode 250 reward: 0.035318
[ADAPTIVE] Mean reward over last 20 episodes: -0.000140
[ADAPTIVE] Plateau counter: 77/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6944406   |
| time/                   |             |
|    fps                  | 1192        |
|    iterations           | 246         |
|    time_elapsed         | 844         |
|    total_timesteps      | 1007616     |
| train/                  |             |
|    approx_kl            | 0.017788613 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.4       |
|    explained_variance   | 0.613       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.655      |
|    n_updates            | 4830        |
|    policy_gradient_loss | -0.0281     |
|    std                  | 9.99        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 251 reward: 0.000147
[ADAPTIVE] Mean reward over last 20 episodes: -0.001785
[ADAPTIVE] Plateau counter: 78/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6074316   |
| time/                   |             |
|    fps                  | 1192        |
|    iterations           | 247         |
|    time_elapsed         | 848         |
|    total_timesteps      | 1011712     |
| train/                  |             |
|    approx_kl            | 0.012772971 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.5       |
|    explained_variance   | 0.482       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.575      |
|    n_updates            | 4845        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 10.1        |
|    value_loss           | 0.337       |
-----------------------------------------
[ADAPTIVE] Episode 252 reward: -0.001221
[ADAPTIVE] Mean reward over last 20 episodes: -0.005694
[ADAPTIVE] Plateau counter: 79/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5748779   |
| time/                   |             |
|    fps                  | 1193        |
|    iterations           | 248         |
|    time_elapsed         | 851         |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.015260844 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.6       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.643      |
|    n_updates            | 4860        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 10.1        |
|    value_loss           | 0.255       |
-----------------------------------------
[ADAPTIVE] Episode 253 reward: 0.060767
[ADAPTIVE] Mean reward over last 20 episodes: -0.004630
[ADAPTIVE] Plateau counter: 80/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6453823   |
| time/                   |             |
|    fps                  | 1194        |
|    iterations           | 249         |
|    time_elapsed         | 854         |
|    total_timesteps      | 1019904     |
| train/                  |             |
|    approx_kl            | 0.015350978 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.6       |
|    explained_variance   | 0.602       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.675      |
|    n_updates            | 4875        |
|    policy_gradient_loss | -0.0288     |
|    std                  | 10.2        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 254 reward: -0.030809
[ADAPTIVE] Mean reward over last 20 episodes: -0.007498
[ADAPTIVE] Plateau counter: 81/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7765777   |
| time/                   |             |
|    fps                  | 1194        |
|    iterations           | 250         |
|    time_elapsed         | 857         |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.011578802 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.6       |
|    explained_variance   | 0.719       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.652      |
|    n_updates            | 4890        |
|    policy_gradient_loss | -0.023      |
|    std                  | 10.2        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 255 reward: -0.002248
[ADAPTIVE] Mean reward over last 20 episodes: -0.004645
[ADAPTIVE] Plateau counter: 82/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 256 reward: -0.079513
[ADAPTIVE] Mean reward over last 20 episodes: -0.006055
[ADAPTIVE] Plateau counter: 83/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.883997    |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 251         |
|    time_elapsed         | 860         |
|    total_timesteps      | 1028096     |
| train/                  |             |
|    approx_kl            | 0.012388548 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.7       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.653      |
|    n_updates            | 4905        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 10.3        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 257 reward: 0.082601
[ADAPTIVE] Mean reward over last 20 episodes: -0.003786
[ADAPTIVE] Plateau counter: 84/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9473035   |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 252         |
|    time_elapsed         | 863         |
|    total_timesteps      | 1032192     |
| train/                  |             |
|    approx_kl            | 0.013519925 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.7       |
|    explained_variance   | 0.586       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.623      |
|    n_updates            | 4920        |
|    policy_gradient_loss | -0.0268     |
|    std                  | 10.3        |
|    value_loss           | 0.176       |
-----------------------------------------
[ADAPTIVE] Episode 258 reward: 0.023243
[ADAPTIVE] Mean reward over last 20 episodes: -0.000605
[ADAPTIVE] Plateau counter: 85/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2395167   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 253         |
|    time_elapsed         | 866         |
|    total_timesteps      | 1036288     |
| train/                  |             |
|    approx_kl            | 0.014754107 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.8       |
|    explained_variance   | 0.48        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.614      |
|    n_updates            | 4935        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 10.4        |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 259 reward: -0.068351
[ADAPTIVE] Mean reward over last 20 episodes: -0.002332
[ADAPTIVE] Plateau counter: 86/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3296971   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 254         |
|    time_elapsed         | 869         |
|    total_timesteps      | 1040384     |
| train/                  |             |
|    approx_kl            | 0.015072284 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.9       |
|    explained_variance   | 0.67        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.68       |
|    n_updates            | 4950        |
|    policy_gradient_loss | -0.0253     |
|    std                  | 10.4        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 260 reward: 0.062009
[ADAPTIVE] Mean reward over last 20 episodes: 0.001536
[ADAPTIVE] Plateau counter: 87/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3146286   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 255         |
|    time_elapsed         | 872         |
|    total_timesteps      | 1044480     |
| train/                  |             |
|    approx_kl            | 0.010670798 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.9       |
|    explained_variance   | 0.555       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.595      |
|    n_updates            | 4965        |
|    policy_gradient_loss | -0.0225     |
|    std                  | 10.5        |
|    value_loss           | 0.344       |
-----------------------------------------
[ADAPTIVE] Episode 261 reward: 0.006931
[ADAPTIVE] Mean reward over last 20 episodes: -0.000470
[ADAPTIVE] Plateau counter: 88/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3100928    |
| time/                   |              |
|    fps                  | 1198         |
|    iterations           | 256          |
|    time_elapsed         | 874          |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0144929765 |
|    clip_fraction        | 0.155        |
|    clip_range           | 0.2          |
|    entropy_loss         | -33.9        |
|    explained_variance   | 0.574        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.605       |
|    n_updates            | 4980         |
|    policy_gradient_loss | -0.0214      |
|    std                  | 10.6         |
|    value_loss           | 0.354        |
------------------------------------------
[ADAPTIVE] Episode 262 reward: 0.065259
[ADAPTIVE] Mean reward over last 20 episodes: 0.006638
[ADAPTIVE] Plateau counter: 89/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2489095   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 257         |
|    time_elapsed         | 877         |
|    total_timesteps      | 1052672     |
| train/                  |             |
|    approx_kl            | 0.010483824 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34         |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.662      |
|    n_updates            | 4995        |
|    policy_gradient_loss | -0.0211     |
|    std                  | 10.6        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 263 reward: -0.043947
[ADAPTIVE] Mean reward over last 20 episodes: 0.007940
[ADAPTIVE] Plateau counter: 90/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1222152   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 258         |
|    time_elapsed         | 880         |
|    total_timesteps      | 1056768     |
| train/                  |             |
|    approx_kl            | 0.009829557 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34         |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.615      |
|    n_updates            | 5010        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 10.6        |
|    value_loss           | 0.27        |
-----------------------------------------
[ADAPTIVE] Episode 264 reward: 0.040319
[ADAPTIVE] Mean reward over last 20 episodes: 0.007702
[ADAPTIVE] Plateau counter: 91/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 0.8912162 |
| time/                   |           |
|    fps                  | 1201      |
|    iterations           | 259       |
|    time_elapsed         | 883       |
|    total_timesteps      | 1060864   |
| train/                  |           |
|    approx_kl            | 0.0185627 |
|    clip_fraction        | 0.168     |
|    clip_range           | 0.2       |
|    entropy_loss         | -34       |
|    explained_variance   | 0.466     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.565    |
|    n_updates            | 5025      |
|    policy_gradient_loss | -0.0232   |
|    std                  | 10.7      |
|    value_loss           | 0.301     |
---------------------------------------
[ADAPTIVE] Episode 265 reward: 0.023587
[ADAPTIVE] Mean reward over last 20 episodes: 0.009067
[ADAPTIVE] Plateau counter: 92/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7466984   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 260         |
|    time_elapsed         | 885         |
|    total_timesteps      | 1064960     |
| train/                  |             |
|    approx_kl            | 0.013220362 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.1       |
|    explained_variance   | 0.605       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.626      |
|    n_updates            | 5040        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 10.7        |
|    value_loss           | 0.232       |
-----------------------------------------
[ADAPTIVE] Episode 266 reward: -0.051337
[ADAPTIVE] Mean reward over last 20 episodes: 0.007166
[ADAPTIVE] Plateau counter: 93/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6809575   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 261         |
|    time_elapsed         | 888         |
|    total_timesteps      | 1069056     |
| train/                  |             |
|    approx_kl            | 0.015141668 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.1       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.675      |
|    n_updates            | 5055        |
|    policy_gradient_loss | -0.0251     |
|    std                  | 10.8        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 267 reward: 0.145650
[ADAPTIVE] Mean reward over last 20 episodes: 0.015519
[ADAPTIVE] Plateau counter: 94/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.4835208  |
| time/                   |            |
|    fps                  | 1203       |
|    iterations           | 262        |
|    time_elapsed         | 891        |
|    total_timesteps      | 1073152    |
| train/                  |            |
|    approx_kl            | 0.01406081 |
|    clip_fraction        | 0.171      |
|    clip_range           | 0.2        |
|    entropy_loss         | -34.2      |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.603     |
|    n_updates            | 5070       |
|    policy_gradient_loss | -0.0246    |
|    std                  | 10.9       |
|    value_loss           | 0.297      |
----------------------------------------
[ADAPTIVE] Episode 268 reward: 0.018610
[ADAPTIVE] Mean reward over last 20 episodes: 0.015174
[ADAPTIVE] Plateau counter: 95/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.506701    |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 263         |
|    time_elapsed         | 894         |
|    total_timesteps      | 1077248     |
| train/                  |             |
|    approx_kl            | 0.012160876 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.3       |
|    explained_variance   | 0.586       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.647      |
|    n_updates            | 5085        |
|    policy_gradient_loss | -0.0232     |
|    std                  | 10.9        |
|    value_loss           | 0.254       |
-----------------------------------------
[ADAPTIVE] Episode 269 reward: -0.017106
[ADAPTIVE] Mean reward over last 20 episodes: 0.013495
[ADAPTIVE] Plateau counter: 96/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7583376   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 264         |
|    time_elapsed         | 897         |
|    total_timesteps      | 1081344     |
| train/                  |             |
|    approx_kl            | 0.017990898 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.3       |
|    explained_variance   | 0.585       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.629      |
|    n_updates            | 5100        |
|    policy_gradient_loss | -0.018      |
|    std                  | 11          |
|    value_loss           | 0.244       |
-----------------------------------------
[ADAPTIVE] Episode 270 reward: 6.817325
[ADAPTIVE] Mean reward over last 20 episodes: 0.352596
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.80121064  |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 265         |
|    time_elapsed         | 900         |
|    total_timesteps      | 1085440     |
| train/                  |             |
|    approx_kl            | 0.014397336 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.4       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.663      |
|    n_updates            | 5115        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 11.1        |
|    value_loss           | 0.148       |
-----------------------------------------
[ADAPTIVE] Episode 271 reward: 0.061444
[ADAPTIVE] Mean reward over last 20 episodes: 0.355661
[ADAPTIVE] Plateau counter: 1/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.8419562  |
| time/                   |            |
|    fps                  | 1205       |
|    iterations           | 266        |
|    time_elapsed         | 903        |
|    total_timesteps      | 1089536    |
| train/                  |            |
|    approx_kl            | 0.01486806 |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.2        |
|    entropy_loss         | -34.4      |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.00025    |
|    loss                 | -0.606     |
|    n_updates            | 5130       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 11.1       |
|    value_loss           | 0.351      |
----------------------------------------
[ADAPTIVE] Episode 272 reward: 0.005508
[ADAPTIVE] Mean reward over last 20 episodes: 0.355997
[ADAPTIVE] Plateau counter: 2/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.89504737   |
| time/                   |              |
|    fps                  | 1206         |
|    iterations           | 267          |
|    time_elapsed         | 906          |
|    total_timesteps      | 1093632      |
| train/                  |              |
|    approx_kl            | 0.0142472545 |
|    clip_fraction        | 0.145        |
|    clip_range           | 0.2          |
|    entropy_loss         | -34.5        |
|    explained_variance   | 0.592        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.593       |
|    n_updates            | 5145         |
|    policy_gradient_loss | -0.0221      |
|    std                  | 11.2         |
|    value_loss           | 0.315        |
------------------------------------------
[ADAPTIVE] Episode 273 reward: -0.039893
[ADAPTIVE] Mean reward over last 20 episodes: 0.350964
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0809127   |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 268         |
|    time_elapsed         | 909         |
|    total_timesteps      | 1097728     |
| train/                  |             |
|    approx_kl            | 0.011315707 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.5       |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.553      |
|    n_updates            | 5160        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 11.2        |
|    value_loss           | 0.331       |
-----------------------------------------
[ADAPTIVE] Episode 274 reward: -0.078267
[ADAPTIVE] Mean reward over last 20 episodes: 0.348591
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9502103   |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 269         |
|    time_elapsed         | 912         |
|    total_timesteps      | 1101824     |
| train/                  |             |
|    approx_kl            | 0.017406035 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.5       |
|    explained_variance   | 0.548       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.609      |
|    n_updates            | 5175        |
|    policy_gradient_loss | -0.0232     |
|    std                  | 11.3        |
|    value_loss           | 0.363       |
-----------------------------------------
[ADAPTIVE] Episode 275 reward: 0.043551
[ADAPTIVE] Mean reward over last 20 episodes: 0.350881
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0513277   |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 270         |
|    time_elapsed         | 915         |
|    total_timesteps      | 1105920     |
| train/                  |             |
|    approx_kl            | 0.014218012 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.6       |
|    explained_variance   | 0.608       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.667      |
|    n_updates            | 5190        |
|    policy_gradient_loss | -0.0255     |
|    std                  | 11.3        |
|    value_loss           | 0.202       |
-----------------------------------------
[ADAPTIVE] Episode 276 reward: -0.088521
[ADAPTIVE] Mean reward over last 20 episodes: 0.350431
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.89103293  |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 271         |
|    time_elapsed         | 918         |
|    total_timesteps      | 1110016     |
| train/                  |             |
|    approx_kl            | 0.015793355 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.6       |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.656      |
|    n_updates            | 5205        |
|    policy_gradient_loss | -0.0241     |
|    std                  | 11.3        |
|    value_loss           | 0.166       |
-----------------------------------------
[ADAPTIVE] Episode 277 reward: 0.026589
[ADAPTIVE] Mean reward over last 20 episodes: 0.347630
[ADAPTIVE] Plateau counter: 7/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0832589  |
| time/                   |            |
|    fps                  | 1209       |
|    iterations           | 272        |
|    time_elapsed         | 921        |
|    total_timesteps      | 1114112    |
| train/                  |            |
|    approx_kl            | 0.01278854 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -34.6      |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.68      |
|    n_updates            | 5220       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 11.4       |
|    value_loss           | 0.109      |
----------------------------------------
[ADAPTIVE] Episode 278 reward: 0.013956
[ADAPTIVE] Mean reward over last 20 episodes: 0.347166
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0167431   |
| time/                   |             |
|    fps                  | 1209        |
|    iterations           | 273         |
|    time_elapsed         | 924         |
|    total_timesteps      | 1118208     |
| train/                  |             |
|    approx_kl            | 0.011186865 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.7       |
|    explained_variance   | 0.703       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.662      |
|    n_updates            | 5235        |
|    policy_gradient_loss | -0.0244     |
|    std                  | 11.4        |
|    value_loss           | 0.134       |
-----------------------------------------
[ADAPTIVE] Episode 279 reward: -0.151031
[ADAPTIVE] Mean reward over last 20 episodes: 0.343032
[ADAPTIVE] Plateau counter: 9/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1323965    |
| time/                   |              |
|    fps                  | 1209         |
|    iterations           | 274          |
|    time_elapsed         | 927          |
|    total_timesteps      | 1122304      |
| train/                  |              |
|    approx_kl            | 0.0154811675 |
|    clip_fraction        | 0.183        |
|    clip_range           | 0.2          |
|    entropy_loss         | -34.7        |
|    explained_variance   | 0.646        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.65        |
|    n_updates            | 5250         |
|    policy_gradient_loss | -0.0247      |
|    std                  | 11.5         |
|    value_loss           | 0.2          |
------------------------------------------
[ADAPTIVE] Episode 280 reward: 0.081340
[ADAPTIVE] Mean reward over last 20 episodes: 0.343998
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1858927   |
| time/                   |             |
|    fps                  | 1210        |
|    iterations           | 275         |
|    time_elapsed         | 930         |
|    total_timesteps      | 1126400     |
| train/                  |             |
|    approx_kl            | 0.012150727 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.7       |
|    explained_variance   | 0.653       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.625      |
|    n_updates            | 5265        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 11.5        |
|    value_loss           | 0.213       |
-----------------------------------------
[ADAPTIVE] Episode 281 reward: 0.039415
[ADAPTIVE] Mean reward over last 20 episodes: 0.345623
[ADAPTIVE] Plateau counter: 11/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0993187   |
| time/                   |             |
|    fps                  | 1210        |
|    iterations           | 276         |
|    time_elapsed         | 933         |
|    total_timesteps      | 1130496     |
| train/                  |             |
|    approx_kl            | 0.014198033 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.8       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.679      |
|    n_updates            | 5280        |
|    policy_gradient_loss | -0.0272     |
|    std                  | 11.6        |
|    value_loss           | 0.164       |
-----------------------------------------
[ADAPTIVE] Episode 282 reward: 0.024444
[ADAPTIVE] Mean reward over last 20 episodes: 0.343582
[ADAPTIVE] Plateau counter: 12/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.726629    |
| time/                   |             |
|    fps                  | 1211        |
|    iterations           | 277         |
|    time_elapsed         | 936         |
|    total_timesteps      | 1134592     |
| train/                  |             |
|    approx_kl            | 0.011369145 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.8       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.65       |
|    n_updates            | 5295        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 11.7        |
|    value_loss           | 0.183       |
-----------------------------------------
[ADAPTIVE] Episode 283 reward: 0.003155
[ADAPTIVE] Mean reward over last 20 episodes: 0.345937
[ADAPTIVE] Plateau counter: 13/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.79983217  |
| time/                   |             |
|    fps                  | 1211        |
|    iterations           | 278         |
|    time_elapsed         | 939         |
|    total_timesteps      | 1138688     |
| train/                  |             |
|    approx_kl            | 0.010890007 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.9       |
|    explained_variance   | 0.703       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.67       |
|    n_updates            | 5310        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 11.7        |
|    value_loss           | 0.188       |
-----------------------------------------
[ADAPTIVE] Episode 284 reward: -0.041791
[ADAPTIVE] Mean reward over last 20 episodes: 0.341831
[ADAPTIVE] Plateau counter: 14/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.75148696 |
| time/                   |            |
|    fps                  | 1212       |
|    iterations           | 279        |
|    time_elapsed         | 942        |
|    total_timesteps      | 1142784    |
| train/                  |            |
|    approx_kl            | 0.0116661  |
|    clip_fraction        | 0.126      |
|    clip_range           | 0.2        |
|    entropy_loss         | -34.9      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.64      |
|    n_updates            | 5325       |
|    policy_gradient_loss | -0.022     |
|    std                  | 11.7       |
|    value_loss           | 0.308      |
----------------------------------------
[ADAPTIVE] Episode 285 reward: -0.019884
[ADAPTIVE] Mean reward over last 20 episodes: 0.339658
[ADAPTIVE] Plateau counter: 15/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67131484  |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 280         |
|    time_elapsed         | 945         |
|    total_timesteps      | 1146880     |
| train/                  |             |
|    approx_kl            | 0.012996828 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.9       |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.681      |
|    n_updates            | 5340        |
|    policy_gradient_loss | -0.0238     |
|    std                  | 11.8        |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 286 reward: 0.005290
[ADAPTIVE] Mean reward over last 20 episodes: 0.342489
[ADAPTIVE] Plateau counter: 16/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6297863   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 281         |
|    time_elapsed         | 948         |
|    total_timesteps      | 1150976     |
| train/                  |             |
|    approx_kl            | 0.014986898 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35         |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.668      |
|    n_updates            | 5355        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 11.9        |
|    value_loss           | 0.196       |
-----------------------------------------
[ADAPTIVE] Episode 287 reward: -0.037464
[ADAPTIVE] Mean reward over last 20 episodes: 0.333334
[ADAPTIVE] Plateau counter: 17/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7232566   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 282         |
|    time_elapsed         | 951         |
|    total_timesteps      | 1155072     |
| train/                  |             |
|    approx_kl            | 0.010771716 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.1       |
|    explained_variance   | 0.657       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.616      |
|    n_updates            | 5370        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 11.9        |
|    value_loss           | 0.274       |
-----------------------------------------
[ADAPTIVE] Episode 288 reward: -0.020613
[ADAPTIVE] Mean reward over last 20 episodes: 0.331372
[ADAPTIVE] Plateau counter: 18/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98057055  |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 283         |
|    time_elapsed         | 954         |
|    total_timesteps      | 1159168     |
| train/                  |             |
|    approx_kl            | 0.013069697 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.1       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.693      |
|    n_updates            | 5385        |
|    policy_gradient_loss | -0.0251     |
|    std                  | 12          |
|    value_loss           | 0.161       |
-----------------------------------------
[ADAPTIVE] Episode 289 reward: 0.083149
[ADAPTIVE] Mean reward over last 20 episodes: 0.336385
[ADAPTIVE] Plateau counter: 19/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.968834    |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 284         |
|    time_elapsed         | 957         |
|    total_timesteps      | 1163264     |
| train/                  |             |
|    approx_kl            | 0.013825881 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.2       |
|    explained_variance   | 0.703       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.674      |
|    n_updates            | 5400        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 12.1        |
|    value_loss           | 0.193       |
-----------------------------------------
[ADAPTIVE] Episode 290 reward: -0.087215
[ADAPTIVE] Mean reward over last 20 episodes: -0.008842
[ADAPTIVE] Plateau counter: 20/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0988245   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 285         |
|    time_elapsed         | 961         |
|    total_timesteps      | 1167360     |
| train/                  |             |
|    approx_kl            | 0.012700768 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.2       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.686      |
|    n_updates            | 5415        |
|    policy_gradient_loss | -0.024      |
|    std                  | 12.1        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 291 reward: -0.031277
[ADAPTIVE] Mean reward over last 20 episodes: -0.013478
[ADAPTIVE] Plateau counter: 21/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9720423   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 286         |
|    time_elapsed         | 964         |
|    total_timesteps      | 1171456     |
| train/                  |             |
|    approx_kl            | 0.015710112 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.2       |
|    explained_variance   | 0.773       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.7        |
|    n_updates            | 5430        |
|    policy_gradient_loss | -0.0264     |
|    std                  | 12.2        |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 292 reward: 0.014024
[ADAPTIVE] Mean reward over last 20 episodes: -0.013052
[ADAPTIVE] Plateau counter: 22/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8637711   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 287         |
|    time_elapsed         | 967         |
|    total_timesteps      | 1175552     |
| train/                  |             |
|    approx_kl            | 0.012583593 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.3       |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.646      |
|    n_updates            | 5445        |
|    policy_gradient_loss | -0.0258     |
|    std                  | 12.3        |
|    value_loss           | 0.276       |
-----------------------------------------
[ADAPTIVE] Episode 293 reward: -0.030145
[ADAPTIVE] Mean reward over last 20 episodes: -0.012565
[ADAPTIVE] Plateau counter: 23/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84360313  |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 288         |
|    time_elapsed         | 969         |
|    total_timesteps      | 1179648     |
| train/                  |             |
|    approx_kl            | 0.010960838 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.3       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.692      |
|    n_updates            | 5460        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 12.3        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 294 reward: 0.045553
[ADAPTIVE] Mean reward over last 20 episodes: -0.006374
[ADAPTIVE] Plateau counter: 24/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.75398755  |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 289         |
|    time_elapsed         | 973         |
|    total_timesteps      | 1183744     |
| train/                  |             |
|    approx_kl            | 0.013260536 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.4       |
|    explained_variance   | 0.673       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.617      |
|    n_updates            | 5475        |
|    policy_gradient_loss | -0.0208     |
|    std                  | 12.4        |
|    value_loss           | 0.357       |
-----------------------------------------
[ADAPTIVE] Episode 295 reward: 0.027144
[ADAPTIVE] Mean reward over last 20 episodes: -0.007194
[ADAPTIVE] Plateau counter: 25/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.59366    |
| time/                   |            |
|    fps                  | 1217       |
|    iterations           | 290        |
|    time_elapsed         | 975        |
|    total_timesteps      | 1187840    |
| train/                  |            |
|    approx_kl            | 0.01362079 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -35.4      |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.646     |
|    n_updates            | 5490       |
|    policy_gradient_loss | -0.018     |
|    std                  | 12.5       |
|    value_loss           | 0.232      |
----------------------------------------
[ADAPTIVE] Episode 296 reward: -1.267507
[ADAPTIVE] Mean reward over last 20 episodes: -0.066143
[ADAPTIVE] Plateau counter: 26/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.49325004  |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 291         |
|    time_elapsed         | 979         |
|    total_timesteps      | 1191936     |
| train/                  |             |
|    approx_kl            | 0.010511707 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.5       |
|    explained_variance   | 0.8         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.646      |
|    n_updates            | 5505        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 12.6        |
|    value_loss           | 0.181       |
-----------------------------------------
[ADAPTIVE] Episode 297 reward: -0.051576
[ADAPTIVE] Mean reward over last 20 episodes: -0.070052
[ADAPTIVE] Plateau counter: 27/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.44340593  |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 292         |
|    time_elapsed         | 982         |
|    total_timesteps      | 1196032     |
| train/                  |             |
|    approx_kl            | 0.018726185 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.6       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.673      |
|    n_updates            | 5520        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 12.6        |
|    value_loss           | 0.122       |
-----------------------------------------
[ADAPTIVE] Episode 298 reward: -0.023713
[ADAPTIVE] Mean reward over last 20 episodes: -0.071935
[ADAPTIVE] Plateau counter: 28/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.55864394 |
| time/                   |            |
|    fps                  | 1217       |
|    iterations           | 293        |
|    time_elapsed         | 985        |
|    total_timesteps      | 1200128    |
| train/                  |            |
|    approx_kl            | 0.01073485 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -35.6      |
|    explained_variance   | 0.78       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.679     |
|    n_updates            | 5535       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 12.7       |
|    value_loss           | 0.157      |
----------------------------------------
[ADAPTIVE] Episode 299 reward: -0.067674
[ADAPTIVE] Mean reward over last 20 episodes: -0.067767
[ADAPTIVE] Plateau counter: 29/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.68077713  |
| time/                   |             |
|    fps                  | 1218        |
|    iterations           | 294         |
|    time_elapsed         | 988         |
|    total_timesteps      | 1204224     |
| train/                  |             |
|    approx_kl            | 0.013040924 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.6       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.689      |
|    n_updates            | 5550        |
|    policy_gradient_loss | -0.0229     |
|    std                  | 12.8        |
|    value_loss           | 0.199       |
-----------------------------------------
[ADAPTIVE] Episode 300 reward: 0.001889
[ADAPTIVE] Mean reward over last 20 episodes: -0.071740
[ADAPTIVE] Plateau counter: 30/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.54648036  |
| time/                   |             |
|    fps                  | 1218        |
|    iterations           | 295         |
|    time_elapsed         | 991         |
|    total_timesteps      | 1208320     |
| train/                  |             |
|    approx_kl            | 0.012587074 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.7       |
|    explained_variance   | 0.671       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.705      |
|    n_updates            | 5565        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 12.8        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 301 reward: -0.072548
[ADAPTIVE] Mean reward over last 20 episodes: -0.077338
[ADAPTIVE] Plateau counter: 31/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5140564   |
| time/                   |             |
|    fps                  | 1218        |
|    iterations           | 296         |
|    time_elapsed         | 994         |
|    total_timesteps      | 1212416     |
| train/                  |             |
|    approx_kl            | 0.024962122 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.7       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.704      |
|    n_updates            | 5580        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 12.8        |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 302 reward: -0.061165
[ADAPTIVE] Mean reward over last 20 episodes: -0.081618
[ADAPTIVE] Plateau counter: 32/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.72970235   |
| time/                   |              |
|    fps                  | 1219         |
|    iterations           | 297          |
|    time_elapsed         | 997          |
|    total_timesteps      | 1216512      |
| train/                  |              |
|    approx_kl            | 0.0104362145 |
|    clip_fraction        | 0.156        |
|    clip_range           | 0.2          |
|    entropy_loss         | -35.7        |
|    explained_variance   | 0.76         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.685       |
|    n_updates            | 5595         |
|    policy_gradient_loss | -0.0238      |
|    std                  | 12.9         |
|    value_loss           | 0.163        |
------------------------------------------
[ADAPTIVE] Episode 303 reward: -0.100745
[ADAPTIVE] Mean reward over last 20 episodes: -0.086813
[ADAPTIVE] Plateau counter: 33/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8782711   |
| time/                   |             |
|    fps                  | 1219        |
|    iterations           | 298         |
|    time_elapsed         | 1000        |
|    total_timesteps      | 1220608     |
| train/                  |             |
|    approx_kl            | 0.012269827 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.8       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.688      |
|    n_updates            | 5610        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 12.9        |
|    value_loss           | 0.193       |
-----------------------------------------
[ADAPTIVE] Episode 304 reward: -0.003368
[ADAPTIVE] Mean reward over last 20 episodes: -0.084892
[ADAPTIVE] Plateau counter: 34/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76699966  |
| time/                   |             |
|    fps                  | 1219        |
|    iterations           | 299         |
|    time_elapsed         | 1003        |
|    total_timesteps      | 1224704     |
| train/                  |             |
|    approx_kl            | 0.013762872 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.8       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.667      |
|    n_updates            | 5625        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 12.9        |
|    value_loss           | 0.243       |
-----------------------------------------
[ADAPTIVE] Episode 305 reward: 0.004574
[ADAPTIVE] Mean reward over last 20 episodes: -0.083669
[ADAPTIVE] Plateau counter: 35/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6848232   |
| time/                   |             |
|    fps                  | 1220        |
|    iterations           | 300         |
|    time_elapsed         | 1007        |
|    total_timesteps      | 1228800     |
| train/                  |             |
|    approx_kl            | 0.013653383 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.8       |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.673      |
|    n_updates            | 5640        |
|    policy_gradient_loss | -0.0236     |
|    std                  | 13          |
|    value_loss           | 0.194       |
-----------------------------------------
[ADAPTIVE] Episode 306 reward: -0.172072
[ADAPTIVE] Mean reward over last 20 episodes: -0.092537
[ADAPTIVE] Plateau counter: 36/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6391033   |
| time/                   |             |
|    fps                  | 1220        |
|    iterations           | 301         |
|    time_elapsed         | 1010        |
|    total_timesteps      | 1232896     |
| train/                  |             |
|    approx_kl            | 0.018386215 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.8       |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.696      |
|    n_updates            | 5655        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 13          |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 307 reward: -0.057353
[ADAPTIVE] Mean reward over last 20 episodes: -0.093532
[ADAPTIVE] Plateau counter: 37/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 308 reward: -0.041429
[ADAPTIVE] Mean reward over last 20 episodes: -0.094573
[ADAPTIVE] Plateau counter: 38/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67502123  |
| time/                   |             |
|    fps                  | 1220        |
|    iterations           | 302         |
|    time_elapsed         | 1013        |
|    total_timesteps      | 1236992     |
| train/                  |             |
|    approx_kl            | 0.015522847 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.9       |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.712      |
|    n_updates            | 5670        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 13.1        |
|    value_loss           | 0.152       |
-----------------------------------------
[ADAPTIVE] Episode 309 reward: 0.049659
[ADAPTIVE] Mean reward over last 20 episodes: -0.096247
[ADAPTIVE] Plateau counter: 39/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.62356937  |
| time/                   |             |
|    fps                  | 1220        |
|    iterations           | 303         |
|    time_elapsed         | 1016        |
|    total_timesteps      | 1241088     |
| train/                  |             |
|    approx_kl            | 0.012166366 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.9       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.722      |
|    n_updates            | 5685        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 13.2        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 310 reward: -0.045376
[ADAPTIVE] Mean reward over last 20 episodes: -0.094155
[ADAPTIVE] Plateau counter: 40/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.52461535  |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 304         |
|    time_elapsed         | 1019        |
|    total_timesteps      | 1245184     |
| train/                  |             |
|    approx_kl            | 0.012947233 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -36         |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.666      |
|    n_updates            | 5700        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 13.3        |
|    value_loss           | 0.247       |
-----------------------------------------
[ADAPTIVE] Episode 311 reward: 0.029484
[ADAPTIVE] Mean reward over last 20 episodes: -0.091117
[ADAPTIVE] Plateau counter: 41/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.73438483  |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 305         |
|    time_elapsed         | 1022        |
|    total_timesteps      | 1249280     |
| train/                  |             |
|    approx_kl            | 0.011387534 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.1       |
|    explained_variance   | 0.752       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.706      |
|    n_updates            | 5715        |
|    policy_gradient_loss | -0.021      |
|    std                  | 13.3        |
|    value_loss           | 0.129       |
-----------------------------------------
[ADAPTIVE] Episode 312 reward: -0.012171
[ADAPTIVE] Mean reward over last 20 episodes: -0.092427
[ADAPTIVE] Plateau counter: 42/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.63815206  |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 306         |
|    time_elapsed         | 1025        |
|    total_timesteps      | 1253376     |
| train/                  |             |
|    approx_kl            | 0.012958795 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.1       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.712      |
|    n_updates            | 5730        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 13.4        |
|    value_loss           | 0.0971      |
-----------------------------------------
[ADAPTIVE] Episode 313 reward: -0.004694
[ADAPTIVE] Mean reward over last 20 episodes: -0.091154
[ADAPTIVE] Plateau counter: 43/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.60507905  |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 307         |
|    time_elapsed         | 1028        |
|    total_timesteps      | 1257472     |
| train/                  |             |
|    approx_kl            | 0.012215519 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.1       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.674      |
|    n_updates            | 5745        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 13.5        |
|    value_loss           | 0.173       |
-----------------------------------------
[ADAPTIVE] Episode 314 reward: -0.068974
[ADAPTIVE] Mean reward over last 20 episodes: -0.096881
[ADAPTIVE] Plateau counter: 44/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7285931   |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 308         |
|    time_elapsed         | 1031        |
|    total_timesteps      | 1261568     |
| train/                  |             |
|    approx_kl            | 0.012276166 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.2       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.702      |
|    n_updates            | 5760        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 13.6        |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 315 reward: -0.039160
[ADAPTIVE] Mean reward over last 20 episodes: -0.100196
[ADAPTIVE] Plateau counter: 45/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7727261   |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 309         |
|    time_elapsed         | 1034        |
|    total_timesteps      | 1265664     |
| train/                  |             |
|    approx_kl            | 0.013024045 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.2       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.717      |
|    n_updates            | 5775        |
|    policy_gradient_loss | -0.0252     |
|    std                  | 13.6        |
|    value_loss           | 0.0857      |
-----------------------------------------
[ADAPTIVE] Episode 316 reward: -0.105830
[ADAPTIVE] Mean reward over last 20 episodes: -0.042112
[ADAPTIVE] Plateau counter: 46/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8071494   |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 310         |
|    time_elapsed         | 1037        |
|    total_timesteps      | 1269760     |
| train/                  |             |
|    approx_kl            | 0.012625164 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.3       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.738      |
|    n_updates            | 5790        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 13.6        |
|    value_loss           | 0.0819      |
-----------------------------------------
[ADAPTIVE] Episode 317 reward: 0.022392
[ADAPTIVE] Mean reward over last 20 episodes: -0.038414
[ADAPTIVE] Plateau counter: 47/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7447574   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 311         |
|    time_elapsed         | 1040        |
|    total_timesteps      | 1273856     |
| train/                  |             |
|    approx_kl            | 0.011261778 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.3       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.703      |
|    n_updates            | 5805        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 13.8        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 318 reward: -0.050336
[ADAPTIVE] Mean reward over last 20 episodes: -0.039745
[ADAPTIVE] Plateau counter: 48/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.74414694  |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 312         |
|    time_elapsed         | 1043        |
|    total_timesteps      | 1277952     |
| train/                  |             |
|    approx_kl            | 0.011496031 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.4       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.713      |
|    n_updates            | 5820        |
|    policy_gradient_loss | -0.0228     |
|    std                  | 13.8        |
|    value_loss           | 0.166       |
-----------------------------------------
[ADAPTIVE] Episode 319 reward: -0.006958
[ADAPTIVE] Mean reward over last 20 episodes: -0.036709
[ADAPTIVE] Plateau counter: 49/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6574285   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 313         |
|    time_elapsed         | 1046        |
|    total_timesteps      | 1282048     |
| train/                  |             |
|    approx_kl            | 0.009827934 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.4       |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.726      |
|    n_updates            | 5835        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 13.9        |
|    value_loss           | 0.0891      |
-----------------------------------------
[ADAPTIVE] Episode 320 reward: 0.045000
[ADAPTIVE] Mean reward over last 20 episodes: -0.034554
[ADAPTIVE] Plateau counter: 50/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.60324496   |
| time/                   |              |
|    fps                  | 1224         |
|    iterations           | 314          |
|    time_elapsed         | 1050         |
|    total_timesteps      | 1286144      |
| train/                  |              |
|    approx_kl            | 0.0142269535 |
|    clip_fraction        | 0.141        |
|    clip_range           | 0.2          |
|    entropy_loss         | -36.5        |
|    explained_variance   | 0.825        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.721       |
|    n_updates            | 5850         |
|    policy_gradient_loss | -0.0211      |
|    std                  | 14           |
|    value_loss           | 0.116        |
------------------------------------------
[ADAPTIVE] Episode 321 reward: 0.026861
[ADAPTIVE] Mean reward over last 20 episodes: -0.029583
[ADAPTIVE] Plateau counter: 51/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.52562165  |
| time/                   |             |
|    fps                  | 1225        |
|    iterations           | 315         |
|    time_elapsed         | 1052        |
|    total_timesteps      | 1290240     |
| train/                  |             |
|    approx_kl            | 0.012057938 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.5       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.681      |
|    n_updates            | 5865        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 14.1        |
|    value_loss           | 0.199       |
-----------------------------------------
[ADAPTIVE] Episode 322 reward: -0.143791
[ADAPTIVE] Mean reward over last 20 episodes: -0.033714
[ADAPTIVE] Plateau counter: 52/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.47359493 |
| time/                   |            |
|    fps                  | 1225       |
|    iterations           | 316        |
|    time_elapsed         | 1056       |
|    total_timesteps      | 1294336    |
| train/                  |            |
|    approx_kl            | 0.01885914 |
|    clip_fraction        | 0.177      |
|    clip_range           | 0.2        |
|    entropy_loss         | -36.6      |
|    explained_variance   | 0.817      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.735     |
|    n_updates            | 5880       |
|    policy_gradient_loss | -0.0279    |
|    std                  | 14.1       |
|    value_loss           | 0.108      |
----------------------------------------
[ADAPTIVE] Episode 323 reward: -0.025478
[ADAPTIVE] Mean reward over last 20 episodes: -0.029951
[ADAPTIVE] Plateau counter: 53/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.43835956  |
| time/                   |             |
|    fps                  | 1225        |
|    iterations           | 317         |
|    time_elapsed         | 1059        |
|    total_timesteps      | 1298432     |
| train/                  |             |
|    approx_kl            | 0.011809179 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.6       |
|    explained_variance   | 0.778       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.697      |
|    n_updates            | 5895        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 14.1        |
|    value_loss           | 0.181       |
-----------------------------------------
[ADAPTIVE] Episode 324 reward: 0.145418
[ADAPTIVE] Mean reward over last 20 episodes: -0.022512
[ADAPTIVE] Plateau counter: 54/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.35781002  |
| time/                   |             |
|    fps                  | 1225        |
|    iterations           | 318         |
|    time_elapsed         | 1062        |
|    total_timesteps      | 1302528     |
| train/                  |             |
|    approx_kl            | 0.014841551 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.6       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.695      |
|    n_updates            | 5910        |
|    policy_gradient_loss | -0.0211     |
|    std                  | 14.2        |
|    value_loss           | 0.184       |
-----------------------------------------
[ADAPTIVE] Episode 325 reward: -0.042145
[ADAPTIVE] Mean reward over last 20 episodes: -0.024848
[ADAPTIVE] Plateau counter: 55/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.30866614   |
| time/                   |              |
|    fps                  | 1225         |
|    iterations           | 319          |
|    time_elapsed         | 1066         |
|    total_timesteps      | 1306624      |
| train/                  |              |
|    approx_kl            | 0.0131430635 |
|    clip_fraction        | 0.135        |
|    clip_range           | 0.2          |
|    entropy_loss         | -36.6        |
|    explained_variance   | 0.715        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.704       |
|    n_updates            | 5925         |
|    policy_gradient_loss | -0.0182      |
|    std                  | 14.3         |
|    value_loss           | 0.189        |
------------------------------------------
[ADAPTIVE] Episode 326 reward: 0.027323
[ADAPTIVE] Mean reward over last 20 episodes: -0.014878
[ADAPTIVE] Plateau counter: 56/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.38610163  |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 320         |
|    time_elapsed         | 1069        |
|    total_timesteps      | 1310720     |
| train/                  |             |
|    approx_kl            | 0.011290864 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.7       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.683      |
|    n_updates            | 5940        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 14.3        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 327 reward: -0.029077
[ADAPTIVE] Mean reward over last 20 episodes: -0.013464
[ADAPTIVE] Plateau counter: 57/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.34041157  |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 321         |
|    time_elapsed         | 1072        |
|    total_timesteps      | 1314816     |
| train/                  |             |
|    approx_kl            | 0.012298307 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.7       |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.672      |
|    n_updates            | 5955        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 14.4        |
|    value_loss           | 0.196       |
-----------------------------------------
[ADAPTIVE] Episode 328 reward: -0.049524
[ADAPTIVE] Mean reward over last 20 episodes: -0.013869
[ADAPTIVE] Plateau counter: 58/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46192655  |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 322         |
|    time_elapsed         | 1075        |
|    total_timesteps      | 1318912     |
| train/                  |             |
|    approx_kl            | 0.010879998 |
|    clip_fraction        | 0.0948      |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.8       |
|    explained_variance   | 0.795       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.689      |
|    n_updates            | 5970        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 14.4        |
|    value_loss           | 0.18        |
-----------------------------------------
[ADAPTIVE] Episode 329 reward: -0.039220
[ADAPTIVE] Mean reward over last 20 episodes: -0.018313
[ADAPTIVE] Plateau counter: 59/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.402441    |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 323         |
|    time_elapsed         | 1078        |
|    total_timesteps      | 1323008     |
| train/                  |             |
|    approx_kl            | 0.011796668 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.8       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.658      |
|    n_updates            | 5985        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 14.5        |
|    value_loss           | 0.184       |
-----------------------------------------
[ADAPTIVE] Episode 330 reward: -0.032578
[ADAPTIVE] Mean reward over last 20 episodes: -0.017673
[ADAPTIVE] Plateau counter: 60/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.49432015  |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 324         |
|    time_elapsed         | 1081        |
|    total_timesteps      | 1327104     |
| train/                  |             |
|    approx_kl            | 0.011060895 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.8       |
|    explained_variance   | 0.731       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.699      |
|    n_updates            | 6000        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 14.5        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 331 reward: -0.001879
[ADAPTIVE] Mean reward over last 20 episodes: -0.019241
[ADAPTIVE] Plateau counter: 61/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6612355   |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 325         |
|    time_elapsed         | 1084        |
|    total_timesteps      | 1331200     |
| train/                  |             |
|    approx_kl            | 0.017533986 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.9       |
|    explained_variance   | 0.651       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.693      |
|    n_updates            | 6015        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 14.6        |
|    value_loss           | 0.168       |
-----------------------------------------
[ADAPTIVE] Episode 332 reward: 0.065454
[ADAPTIVE] Mean reward over last 20 episodes: -0.015360
[ADAPTIVE] Plateau counter: 62/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6398709   |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 326         |
|    time_elapsed         | 1087        |
|    total_timesteps      | 1335296     |
| train/                  |             |
|    approx_kl            | 0.016234025 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.9       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.736      |
|    n_updates            | 6030        |
|    policy_gradient_loss | -0.019      |
|    std                  | 14.7        |
|    value_loss           | 0.0938      |
-----------------------------------------
[ADAPTIVE] Episode 333 reward: 0.011729
[ADAPTIVE] Mean reward over last 20 episodes: -0.014539
[ADAPTIVE] Plateau counter: 63/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.70043695  |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 327         |
|    time_elapsed         | 1091        |
|    total_timesteps      | 1339392     |
| train/                  |             |
|    approx_kl            | 0.011432104 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.9       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.706      |
|    n_updates            | 6045        |
|    policy_gradient_loss | -0.0229     |
|    std                  | 14.7        |
|    value_loss           | 0.147       |
-----------------------------------------
[ADAPTIVE] Episode 334 reward: 0.054243
[ADAPTIVE] Mean reward over last 20 episodes: -0.008378
[ADAPTIVE] Plateau counter: 64/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.6858498  |
| time/                   |            |
|    fps                  | 1227       |
|    iterations           | 328        |
|    time_elapsed         | 1094       |
|    total_timesteps      | 1343488    |
| train/                  |            |
|    approx_kl            | 0.01267655 |
|    clip_fraction        | 0.107      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37        |
|    explained_variance   | 0.739      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.673     |
|    n_updates            | 6060       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 14.8       |
|    value_loss           | 0.235      |
----------------------------------------
[ADAPTIVE] Episode 335 reward: 0.014369
[ADAPTIVE] Mean reward over last 20 episodes: -0.005701
[ADAPTIVE] Plateau counter: 65/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7628378   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 329         |
|    time_elapsed         | 1097        |
|    total_timesteps      | 1347584     |
| train/                  |             |
|    approx_kl            | 0.013871861 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37         |
|    explained_variance   | 0.638       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.694      |
|    n_updates            | 6075        |
|    policy_gradient_loss | -0.0242     |
|    std                  | 14.9        |
|    value_loss           | 0.211       |
-----------------------------------------
[ADAPTIVE] Episode 336 reward: -0.018676
[ADAPTIVE] Mean reward over last 20 episodes: -0.001344
[ADAPTIVE] Plateau counter: 66/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.68652457  |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 330         |
|    time_elapsed         | 1100        |
|    total_timesteps      | 1351680     |
| train/                  |             |
|    approx_kl            | 0.010973491 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.1       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.678      |
|    n_updates            | 6090        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 14.9        |
|    value_loss           | 0.257       |
-----------------------------------------
[ADAPTIVE] Episode 337 reward: 0.040600
[ADAPTIVE] Mean reward over last 20 episodes: -0.000433
[ADAPTIVE] Plateau counter: 67/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8115589   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 331         |
|    time_elapsed         | 1103        |
|    total_timesteps      | 1355776     |
| train/                  |             |
|    approx_kl            | 0.011032409 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.1       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.709      |
|    n_updates            | 6105        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 15          |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 338 reward: 0.023493
[ADAPTIVE] Mean reward over last 20 episodes: 0.003258
[ADAPTIVE] Plateau counter: 68/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.78925896  |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 332         |
|    time_elapsed         | 1106        |
|    total_timesteps      | 1359872     |
| train/                  |             |
|    approx_kl            | 0.014234094 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.1       |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.725      |
|    n_updates            | 6120        |
|    policy_gradient_loss | -0.0229     |
|    std                  | 15.1        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 339 reward: -0.081761
[ADAPTIVE] Mean reward over last 20 episodes: -0.000482
[ADAPTIVE] Plateau counter: 69/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7300051    |
| time/                   |              |
|    fps                  | 1228         |
|    iterations           | 333          |
|    time_elapsed         | 1110         |
|    total_timesteps      | 1363968      |
| train/                  |              |
|    approx_kl            | 0.0124875605 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.2          |
|    entropy_loss         | -37.2        |
|    explained_variance   | 0.753        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.684       |
|    n_updates            | 6135         |
|    policy_gradient_loss | -0.0192      |
|    std                  | 15.1         |
|    value_loss           | 0.26         |
------------------------------------------
[ADAPTIVE] Episode 340 reward: 0.072908
[ADAPTIVE] Mean reward over last 20 episodes: 0.000913
[ADAPTIVE] Plateau counter: 70/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.54560775 |
| time/                   |            |
|    fps                  | 1229       |
|    iterations           | 334        |
|    time_elapsed         | 1112       |
|    total_timesteps      | 1368064    |
| train/                  |            |
|    approx_kl            | 0.0139331  |
|    clip_fraction        | 0.0942     |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.2      |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.693     |
|    n_updates            | 6150       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 15.1       |
|    value_loss           | 0.203      |
----------------------------------------
[ADAPTIVE] Episode 341 reward: -0.075789
[ADAPTIVE] Mean reward over last 20 episodes: -0.004219
[ADAPTIVE] Plateau counter: 71/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.39825654  |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 335         |
|    time_elapsed         | 1115        |
|    total_timesteps      | 1372160     |
| train/                  |             |
|    approx_kl            | 0.012334656 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.2       |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.744      |
|    n_updates            | 6165        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 15.2        |
|    value_loss           | 0.0901      |
-----------------------------------------
[ADAPTIVE] Episode 342 reward: 0.027564
[ADAPTIVE] Mean reward over last 20 episodes: 0.004349
[ADAPTIVE] Plateau counter: 72/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.55911434  |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 336         |
|    time_elapsed         | 1118        |
|    total_timesteps      | 1376256     |
| train/                  |             |
|    approx_kl            | 0.011114486 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.2       |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.735      |
|    n_updates            | 6180        |
|    policy_gradient_loss | -0.0242     |
|    std                  | 15.2        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 343 reward: -0.030296
[ADAPTIVE] Mean reward over last 20 episodes: 0.004108
[ADAPTIVE] Plateau counter: 73/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.36204776  |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 337         |
|    time_elapsed         | 1121        |
|    total_timesteps      | 1380352     |
| train/                  |             |
|    approx_kl            | 0.007353646 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.3       |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.694      |
|    n_updates            | 6195        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 15.3        |
|    value_loss           | 0.177       |
-----------------------------------------
[ADAPTIVE] Episode 344 reward: -0.135680
[ADAPTIVE] Mean reward over last 20 episodes: -0.009947
[ADAPTIVE] Plateau counter: 74/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.35482648 |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 338        |
|    time_elapsed         | 1124       |
|    total_timesteps      | 1384448    |
| train/                  |            |
|    approx_kl            | 0.00935682 |
|    clip_fraction        | 0.115      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.3      |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.732     |
|    n_updates            | 6210       |
|    policy_gradient_loss | -0.0176    |
|    std                  | 15.3       |
|    value_loss           | 0.103      |
----------------------------------------
[ADAPTIVE] Episode 345 reward: 0.018743
[ADAPTIVE] Mean reward over last 20 episodes: -0.006903
[ADAPTIVE] Plateau counter: 75/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.5174766  |
| time/                   |            |
|    fps                  | 1231       |
|    iterations           | 339        |
|    time_elapsed         | 1127       |
|    total_timesteps      | 1388544    |
| train/                  |            |
|    approx_kl            | 0.01486549 |
|    clip_fraction        | 0.115      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.3      |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.651     |
|    n_updates            | 6225       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 15.4       |
|    value_loss           | 0.294      |
----------------------------------------
[ADAPTIVE] Episode 346 reward: -0.087729
[ADAPTIVE] Mean reward over last 20 episodes: -0.012655
[ADAPTIVE] Plateau counter: 76/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46310794  |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 340         |
|    time_elapsed         | 1130        |
|    total_timesteps      | 1392640     |
| train/                  |             |
|    approx_kl            | 0.010007137 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.4       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.697      |
|    n_updates            | 6240        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 15.4        |
|    value_loss           | 0.134       |
-----------------------------------------
[ADAPTIVE] Episode 347 reward: -0.040842
[ADAPTIVE] Mean reward over last 20 episodes: -0.013244
[ADAPTIVE] Plateau counter: 77/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5528716   |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 341         |
|    time_elapsed         | 1134        |
|    total_timesteps      | 1396736     |
| train/                  |             |
|    approx_kl            | 0.014500398 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.4       |
|    explained_variance   | 0.675       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.675      |
|    n_updates            | 6255        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 15.5        |
|    value_loss           | 0.213       |
-----------------------------------------
[ADAPTIVE] Episode 348 reward: 0.020470
[ADAPTIVE] Mean reward over last 20 episodes: -0.009744
[ADAPTIVE] Plateau counter: 78/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.58956647   |
| time/                   |              |
|    fps                  | 1231         |
|    iterations           | 342          |
|    time_elapsed         | 1137         |
|    total_timesteps      | 1400832      |
| train/                  |              |
|    approx_kl            | 0.0101740565 |
|    clip_fraction        | 0.127        |
|    clip_range           | 0.2          |
|    entropy_loss         | -37.4        |
|    explained_variance   | 0.809        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.747       |
|    n_updates            | 6270         |
|    policy_gradient_loss | -0.0191      |
|    std                  | 15.6         |
|    value_loss           | 0.0963       |
------------------------------------------
[ADAPTIVE] Episode 349 reward: 0.024539
[ADAPTIVE] Mean reward over last 20 episodes: -0.006556
[ADAPTIVE] Plateau counter: 79/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5837481   |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 343         |
|    time_elapsed         | 1140        |
|    total_timesteps      | 1404928     |
| train/                  |             |
|    approx_kl            | 0.010466873 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.5       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.741      |
|    n_updates            | 6285        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 15.7        |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 350 reward: 0.008730
[ADAPTIVE] Mean reward over last 20 episodes: -0.004491
[ADAPTIVE] Plateau counter: 80/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.63302094  |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 344         |
|    time_elapsed         | 1143        |
|    total_timesteps      | 1409024     |
| train/                  |             |
|    approx_kl            | 0.013393091 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.5       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.722      |
|    n_updates            | 6300        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 15.8        |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 351 reward: -0.025269
[ADAPTIVE] Mean reward over last 20 episodes: -0.005660
[ADAPTIVE] Plateau counter: 81/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.6644669  |
| time/                   |            |
|    fps                  | 1232       |
|    iterations           | 345        |
|    time_elapsed         | 1146       |
|    total_timesteps      | 1413120    |
| train/                  |            |
|    approx_kl            | 0.01182572 |
|    clip_fraction        | 0.141      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.6      |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.699     |
|    n_updates            | 6315       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 15.8       |
|    value_loss           | 0.222      |
----------------------------------------
[ADAPTIVE] Episode 352 reward: -0.026178
[ADAPTIVE] Mean reward over last 20 episodes: -0.010242
[ADAPTIVE] Plateau counter: 82/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8413757   |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 346         |
|    time_elapsed         | 1149        |
|    total_timesteps      | 1417216     |
| train/                  |             |
|    approx_kl            | 0.017046873 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.6       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.722      |
|    n_updates            | 6330        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 15.9        |
|    value_loss           | 0.158       |
-----------------------------------------
[ADAPTIVE] Episode 353 reward: -0.017715
[ADAPTIVE] Mean reward over last 20 episodes: -0.011714
[ADAPTIVE] Plateau counter: 83/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.82943267  |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 347         |
|    time_elapsed         | 1152        |
|    total_timesteps      | 1421312     |
| train/                  |             |
|    approx_kl            | 0.015201084 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.7       |
|    explained_variance   | 0.846       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.755      |
|    n_updates            | 6345        |
|    policy_gradient_loss | -0.0258     |
|    std                  | 16          |
|    value_loss           | 0.0888      |
-----------------------------------------
[ADAPTIVE] Episode 354 reward: 0.039925
[ADAPTIVE] Mean reward over last 20 episodes: -0.012430
[ADAPTIVE] Plateau counter: 84/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7356543   |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 348         |
|    time_elapsed         | 1155        |
|    total_timesteps      | 1425408     |
| train/                  |             |
|    approx_kl            | 0.011607219 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.7       |
|    explained_variance   | 0.678       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.694      |
|    n_updates            | 6360        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 16.1        |
|    value_loss           | 0.259       |
-----------------------------------------
[ADAPTIVE] Episode 355 reward: -0.041412
[ADAPTIVE] Mean reward over last 20 episodes: -0.015219
[ADAPTIVE] Plateau counter: 85/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.85356283 |
| time/                   |            |
|    fps                  | 1233       |
|    iterations           | 349        |
|    time_elapsed         | 1159       |
|    total_timesteps      | 1429504    |
| train/                  |            |
|    approx_kl            | 0.01455293 |
|    clip_fraction        | 0.144      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.8      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.741     |
|    n_updates            | 6375       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 16.1       |
|    value_loss           | 0.137      |
----------------------------------------
[ADAPTIVE] Episode 356 reward: 0.000478
[ADAPTIVE] Mean reward over last 20 episodes: -0.014261
[ADAPTIVE] Plateau counter: 86/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8632494   |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 350         |
|    time_elapsed         | 1162        |
|    total_timesteps      | 1433600     |
| train/                  |             |
|    approx_kl            | 0.012066615 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.8       |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.708      |
|    n_updates            | 6390        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 16.2        |
|    value_loss           | 0.201       |
-----------------------------------------
[ADAPTIVE] Episode 357 reward: 0.002484
[ADAPTIVE] Mean reward over last 20 episodes: -0.016167
[ADAPTIVE] Plateau counter: 87/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.80397964 |
| time/                   |            |
|    fps                  | 1233       |
|    iterations           | 351        |
|    time_elapsed         | 1165       |
|    total_timesteps      | 1437696    |
| train/                  |            |
|    approx_kl            | 0.01360031 |
|    clip_fraction        | 0.158      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.8      |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.762     |
|    n_updates            | 6405       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 16.2       |
|    value_loss           | 0.113      |
----------------------------------------
[ADAPTIVE] Episode 358 reward: 0.111074
[ADAPTIVE] Mean reward over last 20 episodes: -0.011788
[ADAPTIVE] Plateau counter: 88/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 359 reward: -0.062464
[ADAPTIVE] Mean reward over last 20 episodes: -0.010823
[ADAPTIVE] Plateau counter: 89/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.5733802  |
| time/                   |            |
|    fps                  | 1233       |
|    iterations           | 352        |
|    time_elapsed         | 1168       |
|    total_timesteps      | 1441792    |
| train/                  |            |
|    approx_kl            | 0.01109786 |
|    clip_fraction        | 0.126      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.9      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.707     |
|    n_updates            | 6420       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 16.3       |
|    value_loss           | 0.19       |
----------------------------------------
[ADAPTIVE] Episode 360 reward: -0.024882
[ADAPTIVE] Mean reward over last 20 episodes: -0.015712
[ADAPTIVE] Plateau counter: 90/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.52307504  |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 353         |
|    time_elapsed         | 1172        |
|    total_timesteps      | 1445888     |
| train/                  |             |
|    approx_kl            | 0.010958552 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.9       |
|    explained_variance   | 0.831       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.727      |
|    n_updates            | 6435        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 16.4        |
|    value_loss           | 0.19        |
-----------------------------------------
[ADAPTIVE] Episode 361 reward: -0.085410
[ADAPTIVE] Mean reward over last 20 episodes: -0.016193
[ADAPTIVE] Plateau counter: 91/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.556273    |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 354         |
|    time_elapsed         | 1175        |
|    total_timesteps      | 1449984     |
| train/                  |             |
|    approx_kl            | 0.011526884 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.9       |
|    explained_variance   | 0.788       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.729      |
|    n_updates            | 6450        |
|    policy_gradient_loss | -0.016      |
|    std                  | 16.5        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 362 reward: -0.009327
[ADAPTIVE] Mean reward over last 20 episodes: -0.018038
[ADAPTIVE] Plateau counter: 92/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.72467786  |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 355         |
|    time_elapsed         | 1178        |
|    total_timesteps      | 1454080     |
| train/                  |             |
|    approx_kl            | 0.012986817 |
|    clip_fraction        | 0.0991      |
|    clip_range           | 0.2         |
|    entropy_loss         | -38         |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.711      |
|    n_updates            | 6465        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 16.5        |
|    value_loss           | 0.186       |
-----------------------------------------
[ADAPTIVE] Episode 363 reward: 0.044959
[ADAPTIVE] Mean reward over last 20 episodes: -0.014275
[ADAPTIVE] Plateau counter: 93/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6232559   |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 356         |
|    time_elapsed         | 1182        |
|    total_timesteps      | 1458176     |
| train/                  |             |
|    approx_kl            | 0.011330214 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38         |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.763      |
|    n_updates            | 6480        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 16.6        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 364 reward: -0.028358
[ADAPTIVE] Mean reward over last 20 episodes: -0.008909
[ADAPTIVE] Plateau counter: 94/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.6398261  |
| time/                   |            |
|    fps                  | 1233       |
|    iterations           | 357        |
|    time_elapsed         | 1185       |
|    total_timesteps      | 1462272    |
| train/                  |            |
|    approx_kl            | 0.01115546 |
|    clip_fraction        | 0.139      |
|    clip_range           | 0.2        |
|    entropy_loss         | -38.1      |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.707     |
|    n_updates            | 6495       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 16.7       |
|    value_loss           | 0.19       |
----------------------------------------
[ADAPTIVE] Episode 365 reward: 0.037907
[ADAPTIVE] Mean reward over last 20 episodes: -0.007951
[ADAPTIVE] Plateau counter: 95/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.569101    |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 358         |
|    time_elapsed         | 1188        |
|    total_timesteps      | 1466368     |
| train/                  |             |
|    approx_kl            | 0.009428414 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.1       |
|    explained_variance   | 0.776       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.742      |
|    n_updates            | 6510        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 16.8        |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 366 reward: 0.023105
[ADAPTIVE] Mean reward over last 20 episodes: -0.002409
[ADAPTIVE] Plateau counter: 96/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.72053385  |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 359         |
|    time_elapsed         | 1191        |
|    total_timesteps      | 1470464     |
| train/                  |             |
|    approx_kl            | 0.009527321 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.2       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.727      |
|    n_updates            | 6525        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 16.9        |
|    value_loss           | 0.159       |
-----------------------------------------
[ADAPTIVE] Episode 367 reward: 0.034999
[ADAPTIVE] Mean reward over last 20 episodes: 0.001383
[ADAPTIVE] Plateau counter: 97/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8546358   |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 360         |
|    time_elapsed         | 1194        |
|    total_timesteps      | 1474560     |
| train/                  |             |
|    approx_kl            | 0.010011703 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.2       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.714      |
|    n_updates            | 6540        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 17          |
|    value_loss           | 0.245       |
-----------------------------------------
[ADAPTIVE] Episode 368 reward: -0.033540
[ADAPTIVE] Mean reward over last 20 episodes: -0.001318
[ADAPTIVE] Plateau counter: 98/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.58450055  |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 361         |
|    time_elapsed         | 1198        |
|    total_timesteps      | 1478656     |
| train/                  |             |
|    approx_kl            | 0.011111675 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.3       |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.69       |
|    n_updates            | 6555        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 17.1        |
|    value_loss           | 0.258       |
-----------------------------------------
[ADAPTIVE] Episode 369 reward: -0.018358
[ADAPTIVE] Mean reward over last 20 episodes: -0.003463
[ADAPTIVE] Plateau counter: 99/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5122268   |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 362         |
|    time_elapsed         | 1201        |
|    total_timesteps      | 1482752     |
| train/                  |             |
|    approx_kl            | 0.012978593 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.3       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.722      |
|    n_updates            | 6570        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 17.2        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 370 reward: -0.005266
[ADAPTIVE] Mean reward over last 20 episodes: -0.004162
[ADAPTIVE] Plateau counter: 100/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.28314757  |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 363         |
|    time_elapsed         | 1204        |
|    total_timesteps      | 1486848     |
| train/                  |             |
|    approx_kl            | 0.011502727 |
|    clip_fraction        | 0.0979      |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.4       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.76       |
|    n_updates            | 6585        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 17.3        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 371 reward: 0.026790
[ADAPTIVE] Mean reward over last 20 episodes: -0.001559
[ADAPTIVE] Plateau counter: 101/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.492351    |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 364         |
|    time_elapsed         | 1208        |
|    total_timesteps      | 1490944     |
| train/                  |             |
|    approx_kl            | 0.010286311 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.4       |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.734      |
|    n_updates            | 6600        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 17.3        |
|    value_loss           | 0.12        |
-----------------------------------------
[ADAPTIVE] Episode 372 reward: 0.024395
[ADAPTIVE] Mean reward over last 20 episodes: 0.000969
[ADAPTIVE] Plateau counter: 102/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47596863  |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 365         |
|    time_elapsed         | 1211        |
|    total_timesteps      | 1495040     |
| train/                  |             |
|    approx_kl            | 0.011765914 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.4       |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.731      |
|    n_updates            | 6615        |
|    policy_gradient_loss | -0.021      |
|    std                  | 17.4        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 373 reward: 0.031790
[ADAPTIVE] Mean reward over last 20 episodes: 0.003445
[ADAPTIVE] Plateau counter: 103/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.25364295  |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 366         |
|    time_elapsed         | 1215        |
|    total_timesteps      | 1499136     |
| train/                  |             |
|    approx_kl            | 0.011049997 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.5       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.71       |
|    n_updates            | 6630        |
|    policy_gradient_loss | -0.0174     |
|    std                  | 17.5        |
|    value_loss           | 0.237       |
-----------------------------------------
[ADAPTIVE] Episode 374 reward: -0.021702
[ADAPTIVE] Mean reward over last 20 episodes: 0.000363
[ADAPTIVE] Plateau counter: 104/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.1684207   |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 367         |
|    time_elapsed         | 1218        |
|    total_timesteps      | 1503232     |
| train/                  |             |
|    approx_kl            | 0.009817486 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.5       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.736      |
|    n_updates            | 6645        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 17.5        |
|    value_loss           | 0.19        |
-----------------------------------------
[ADAPTIVE] Episode 375 reward: -0.005143
[ADAPTIVE] Mean reward over last 20 episodes: 0.002177
[ADAPTIVE] Plateau counter: 105/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.30233276 |
| time/                   |            |
|    fps                  | 1234       |
|    iterations           | 368        |
|    time_elapsed         | 1221       |
|    total_timesteps      | 1507328    |
| train/                  |            |
|    approx_kl            | 0.01020213 |
|    clip_fraction        | 0.123      |
|    clip_range           | 0.2        |
|    entropy_loss         | -38.6      |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.743     |
|    n_updates            | 6660       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 17.6       |
|    value_loss           | 0.143      |
----------------------------------------
[ADAPTIVE] Episode 376 reward: 0.015964
[ADAPTIVE] Mean reward over last 20 episodes: 0.002951
[ADAPTIVE] Plateau counter: 106/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4787761   |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 369         |
|    time_elapsed         | 1224        |
|    total_timesteps      | 1511424     |
| train/                  |             |
|    approx_kl            | 0.010379759 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.6       |
|    explained_variance   | 0.726       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.74       |
|    n_updates            | 6675        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 17.7        |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 377 reward: -0.045317
[ADAPTIVE] Mean reward over last 20 episodes: 0.000561
[ADAPTIVE] Plateau counter: 107/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.42674115  |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 370         |
|    time_elapsed         | 1227        |
|    total_timesteps      | 1515520     |
| train/                  |             |
|    approx_kl            | 0.010436954 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.6       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.682      |
|    n_updates            | 6690        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 17.7        |
|    value_loss           | 0.199       |
-----------------------------------------
[ADAPTIVE] Episode 378 reward: -0.001426
[ADAPTIVE] Mean reward over last 20 episodes: -0.005064
[ADAPTIVE] Plateau counter: 108/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.17598695  |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 371         |
|    time_elapsed         | 1231        |
|    total_timesteps      | 1519616     |
| train/                  |             |
|    approx_kl            | 0.011320643 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.7       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.756      |
|    n_updates            | 6705        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 17.8        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 379 reward: -0.007437
[ADAPTIVE] Mean reward over last 20 episodes: -0.002313
[ADAPTIVE] Plateau counter: 109/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5022823   |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 372         |
|    time_elapsed         | 1234        |
|    total_timesteps      | 1523712     |
| train/                  |             |
|    approx_kl            | 0.011340469 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.7       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.764      |
|    n_updates            | 6720        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 17.9        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 380 reward: -0.010553
[ADAPTIVE] Mean reward over last 20 episodes: -0.001596
[ADAPTIVE] Plateau counter: 110/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5089616   |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 373         |
|    time_elapsed         | 1238        |
|    total_timesteps      | 1527808     |
| train/                  |             |
|    approx_kl            | 0.016953252 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.8       |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.718      |
|    n_updates            | 6735        |
|    policy_gradient_loss | -0.0186     |
|    std                  | 18          |
|    value_loss           | 0.155       |
-----------------------------------------
[ADAPTIVE] Episode 381 reward: -0.120645
[ADAPTIVE] Mean reward over last 20 episodes: -0.003358
[ADAPTIVE] Plateau counter: 111/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.4950057  |
| time/                   |            |
|    fps                  | 1233       |
|    iterations           | 374        |
|    time_elapsed         | 1241       |
|    total_timesteps      | 1531904    |
| train/                  |            |
|    approx_kl            | 0.01044848 |
|    clip_fraction        | 0.128      |
|    clip_range           | 0.2        |
|    entropy_loss         | -38.8      |
|    explained_variance   | 0.788      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.757     |
|    n_updates            | 6750       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 18.1       |
|    value_loss           | 0.127      |
----------------------------------------
[ADAPTIVE] Episode 382 reward: -0.001926
[ADAPTIVE] Mean reward over last 20 episodes: -0.002988
[ADAPTIVE] Plateau counter: 112/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6328643   |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 375         |
|    time_elapsed         | 1244        |
|    total_timesteps      | 1536000     |
| train/                  |             |
|    approx_kl            | 0.012267822 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.8       |
|    explained_variance   | 0.689       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.762      |
|    n_updates            | 6765        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 18.2        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 383 reward: 0.055793
[ADAPTIVE] Mean reward over last 20 episodes: -0.002446
[ADAPTIVE] Plateau counter: 113/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6573627   |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 376         |
|    time_elapsed         | 1248        |
|    total_timesteps      | 1540096     |
| train/                  |             |
|    approx_kl            | 0.012962937 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.9       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.721      |
|    n_updates            | 6780        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 18.3        |
|    value_loss           | 0.181       |
-----------------------------------------
[ADAPTIVE] Episode 384 reward: 0.002638
[ADAPTIVE] Mean reward over last 20 episodes: -0.000897
[ADAPTIVE] Plateau counter: 114/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8206607   |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 377         |
|    time_elapsed         | 1252        |
|    total_timesteps      | 1544192     |
| train/                  |             |
|    approx_kl            | 0.018812576 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.9       |
|    explained_variance   | 0.778       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.756      |
|    n_updates            | 6795        |
|    policy_gradient_loss | -0.012      |
|    std                  | 18.3        |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 385 reward: -0.007923
[ADAPTIVE] Mean reward over last 20 episodes: -0.003188
[ADAPTIVE] Plateau counter: 115/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.6821772  |
| time/                   |            |
|    fps                  | 1233       |
|    iterations           | 378        |
|    time_elapsed         | 1255       |
|    total_timesteps      | 1548288    |
| train/                  |            |
|    approx_kl            | 0.01225478 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -38.9      |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.782     |
|    n_updates            | 6810       |
|    policy_gradient_loss | -0.0204    |
|    std                  | 18.4       |
|    value_loss           | 0.0854     |
----------------------------------------
[ADAPTIVE] Episode 386 reward: -0.093094
[ADAPTIVE] Mean reward over last 20 episodes: -0.008998
[ADAPTIVE] Plateau counter: 116/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.62303233   |
| time/                   |              |
|    fps                  | 1232         |
|    iterations           | 379          |
|    time_elapsed         | 1259         |
|    total_timesteps      | 1552384      |
| train/                  |              |
|    approx_kl            | 0.0107434895 |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.2          |
|    entropy_loss         | -39          |
|    explained_variance   | 0.726        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.754       |
|    n_updates            | 6825         |
|    policy_gradient_loss | -0.015       |
|    std                  | 18.4         |
|    value_loss           | 0.138        |
------------------------------------------
[ADAPTIVE] Episode 387 reward: -0.093813
[ADAPTIVE] Mean reward over last 20 episodes: -0.015439
[ADAPTIVE] Plateau counter: 117/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.80594194  |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 380         |
|    time_elapsed         | 1262        |
|    total_timesteps      | 1556480     |
| train/                  |             |
|    approx_kl            | 0.008233743 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39         |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.758      |
|    n_updates            | 6840        |
|    policy_gradient_loss | -0.0198     |
|    std                  | 18.5        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 388 reward: 0.019365
[ADAPTIVE] Mean reward over last 20 episodes: -0.012793
[ADAPTIVE] Plateau counter: 118/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9164793   |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 381         |
|    time_elapsed         | 1266        |
|    total_timesteps      | 1560576     |
| train/                  |             |
|    approx_kl            | 0.014275367 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.1       |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.747      |
|    n_updates            | 6855        |
|    policy_gradient_loss | -0.0188     |
|    std                  | 18.6        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 389 reward: 0.074352
[ADAPTIVE] Mean reward over last 20 episodes: -0.008158
[ADAPTIVE] Plateau counter: 119/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8891942   |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 382         |
|    time_elapsed         | 1269        |
|    total_timesteps      | 1564672     |
| train/                  |             |
|    approx_kl            | 0.010906063 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.1       |
|    explained_variance   | 0.735       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.74       |
|    n_updates            | 6870        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 18.7        |
|    value_loss           | 0.191       |
-----------------------------------------
[ADAPTIVE] Episode 390 reward: -0.023657
[ADAPTIVE] Mean reward over last 20 episodes: -0.009078
[ADAPTIVE] Plateau counter: 120/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.71995634  |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 383         |
|    time_elapsed         | 1272        |
|    total_timesteps      | 1568768     |
| train/                  |             |
|    approx_kl            | 0.012637541 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.2       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.777      |
|    n_updates            | 6885        |
|    policy_gradient_loss | -0.0236     |
|    std                  | 18.9        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 391 reward: -0.007457
[ADAPTIVE] Mean reward over last 20 episodes: -0.010790
[ADAPTIVE] Plateau counter: 121/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7080165   |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 384         |
|    time_elapsed         | 1275        |
|    total_timesteps      | 1572864     |
| train/                  |             |
|    approx_kl            | 0.010437487 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.2       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.727      |
|    n_updates            | 6900        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 18.9        |
|    value_loss           | 0.218       |
-----------------------------------------
[ADAPTIVE] Episode 392 reward: 0.000762
[ADAPTIVE] Mean reward over last 20 episodes: -0.011971
[ADAPTIVE] Plateau counter: 122/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6657772   |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 385         |
|    time_elapsed         | 1279        |
|    total_timesteps      | 1576960     |
| train/                  |             |
|    approx_kl            | 0.011067781 |
|    clip_fraction        | 0.0798      |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.2       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.718      |
|    n_updates            | 6915        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 19          |
|    value_loss           | 0.243       |
-----------------------------------------
[ADAPTIVE] Episode 393 reward: 0.037691
[ADAPTIVE] Mean reward over last 20 episodes: -0.011676
[ADAPTIVE] Plateau counter: 123/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.42997062  |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 386         |
|    time_elapsed         | 1282        |
|    total_timesteps      | 1581056     |
| train/                  |             |
|    approx_kl            | 0.009787272 |
|    clip_fraction        | 0.0965      |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.3       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.762      |
|    n_updates            | 6930        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 19          |
|    value_loss           | 0.145       |
-----------------------------------------
[ADAPTIVE] Episode 394 reward: -0.037729
[ADAPTIVE] Mean reward over last 20 episodes: -0.012478
[ADAPTIVE] Plateau counter: 124/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.250873   |
| time/                   |            |
|    fps                  | 1232       |
|    iterations           | 387        |
|    time_elapsed         | 1285       |
|    total_timesteps      | 1585152    |
| train/                  |            |
|    approx_kl            | 0.00939272 |
|    clip_fraction        | 0.0877     |
|    clip_range           | 0.2        |
|    entropy_loss         | -39.3      |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.745     |
|    n_updates            | 6945       |
|    policy_gradient_loss | -0.0145    |
|    std                  | 19.1       |
|    value_loss           | 0.182      |
----------------------------------------
[ADAPTIVE] Episode 395 reward: -0.010298
[ADAPTIVE] Mean reward over last 20 episodes: -0.012736
[ADAPTIVE] Plateau counter: 125/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.37668878  |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 388         |
|    time_elapsed         | 1289        |
|    total_timesteps      | 1589248     |
| train/                  |             |
|    approx_kl            | 0.012132449 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.3       |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.755      |
|    n_updates            | 6960        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 19.2        |
|    value_loss           | 0.188       |
-----------------------------------------
[ADAPTIVE] Episode 396 reward: 0.166135
[ADAPTIVE] Mean reward over last 20 episodes: -0.005227
[ADAPTIVE] Plateau counter: 126/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.44287992  |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 389         |
|    time_elapsed         | 1292        |
|    total_timesteps      | 1593344     |
| train/                  |             |
|    approx_kl            | 0.010634356 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.4       |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.762      |
|    n_updates            | 6975        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 19.3        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 397 reward: 0.023325
[ADAPTIVE] Mean reward over last 20 episodes: -0.001795
[ADAPTIVE] Plateau counter: 127/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6343596   |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 390         |
|    time_elapsed         | 1295        |
|    total_timesteps      | 1597440     |
| train/                  |             |
|    approx_kl            | 0.016578738 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.4       |
|    explained_variance   | 0.713       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.749      |
|    n_updates            | 6990        |
|    policy_gradient_loss | -0.0188     |
|    std                  | 19.4        |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 398 reward: 0.060133
[ADAPTIVE] Mean reward over last 20 episodes: 0.001283
[ADAPTIVE] Plateau counter: 128/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  UserWarning,
Eval num_timesteps=1600000, episode_reward=2.46 +/- 0.00
Episode length: 251.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 251         |
|    mean_reward          | 2.46        |
| time/                   |             |
|    total_timesteps      | 1600000     |
| train/                  |             |
|    approx_kl            | 0.009238403 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.5       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.74       |
|    n_updates            | 7005        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 19.5        |
|    value_loss           | 0.149       |
-----------------------------------------
New best mean reward!
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 251        |
|    ep_rew_mean     | 0.66883016 |
| time/              |            |
|    fps             | 1228       |
|    iterations      | 391        |
|    time_elapsed    | 1303       |
|    total_timesteps | 1601536    |
-----------------------------------
[ADAPTIVE] Episode 399 reward: 0.004577
[ADAPTIVE] Mean reward over last 20 episodes: 0.001884
[ADAPTIVE] Plateau counter: 129/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.843227     |
| time/                   |              |
|    fps                  | 1228         |
|    iterations           | 392          |
|    time_elapsed         | 1307         |
|    total_timesteps      | 1605632      |
| train/                  |              |
|    approx_kl            | 0.0129914535 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.2          |
|    entropy_loss         | -39.5        |
|    explained_variance   | 0.721        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.739       |
|    n_updates            | 7020         |
|    policy_gradient_loss | -0.0201      |
|    std                  | 19.6         |
|    value_loss           | 0.163        |
------------------------------------------
[ADAPTIVE] Episode 400 reward: 0.032787
[ADAPTIVE] Mean reward over last 20 episodes: 0.004051
[ADAPTIVE] Plateau counter: 130/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9294305   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 393         |
|    time_elapsed         | 1310        |
|    total_timesteps      | 1609728     |
| train/                  |             |
|    approx_kl            | 0.009292015 |
|    clip_fraction        | 0.0981      |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.5       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.742      |
|    n_updates            | 7035        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 19.6        |
|    value_loss           | 0.168       |
-----------------------------------------
[ADAPTIVE] Episode 401 reward: -0.073117
[ADAPTIVE] Mean reward over last 20 episodes: 0.006427
[ADAPTIVE] Plateau counter: 131/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.68364096  |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 394         |
|    time_elapsed         | 1313        |
|    total_timesteps      | 1613824     |
| train/                  |             |
|    approx_kl            | 0.009373689 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.6       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.773      |
|    n_updates            | 7050        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 19.7        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 402 reward: 0.069357
[ADAPTIVE] Mean reward over last 20 episodes: 0.009991
[ADAPTIVE] Plateau counter: 132/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5034046   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 395         |
|    time_elapsed         | 1316        |
|    total_timesteps      | 1617920     |
| train/                  |             |
|    approx_kl            | 0.009462311 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.6       |
|    explained_variance   | 0.627       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.726      |
|    n_updates            | 7065        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 19.8        |
|    value_loss           | 0.203       |
-----------------------------------------
[ADAPTIVE] Episode 403 reward: 0.090878
[ADAPTIVE] Mean reward over last 20 episodes: 0.011746
[ADAPTIVE] Plateau counter: 133/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47725108  |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 396         |
|    time_elapsed         | 1320        |
|    total_timesteps      | 1622016     |
| train/                  |             |
|    approx_kl            | 0.013089692 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.6       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.789      |
|    n_updates            | 7080        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 19.9        |
|    value_loss           | 0.119       |
-----------------------------------------
[ADAPTIVE] Episode 404 reward: 0.006355
[ADAPTIVE] Mean reward over last 20 episodes: 0.011931
[ADAPTIVE] Plateau counter: 134/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.44380012 |
| time/                   |            |
|    fps                  | 1228       |
|    iterations           | 397        |
|    time_elapsed         | 1323       |
|    total_timesteps      | 1626112    |
| train/                  |            |
|    approx_kl            | 0.01349001 |
|    clip_fraction        | 0.152      |
|    clip_range           | 0.2        |
|    entropy_loss         | -39.7      |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.756     |
|    n_updates            | 7095       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 20         |
|    value_loss           | 0.191      |
----------------------------------------
[ADAPTIVE] Episode 405 reward: -0.035525
[ADAPTIVE] Mean reward over last 20 episodes: 0.010551
[ADAPTIVE] Plateau counter: 135/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.3057156    |
| time/                   |              |
|    fps                  | 1229         |
|    iterations           | 398          |
|    time_elapsed         | 1326         |
|    total_timesteps      | 1630208      |
| train/                  |              |
|    approx_kl            | 0.0086869765 |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.2          |
|    entropy_loss         | -39.7        |
|    explained_variance   | 0.773        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.754       |
|    n_updates            | 7110         |
|    policy_gradient_loss | -0.0188      |
|    std                  | 20.1         |
|    value_loss           | 0.16         |
------------------------------------------
[ADAPTIVE] Episode 406 reward: -0.101867
[ADAPTIVE] Mean reward over last 20 episodes: 0.010113
[ADAPTIVE] Plateau counter: 136/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.32981873  |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 399         |
|    time_elapsed         | 1329        |
|    total_timesteps      | 1634304     |
| train/                  |             |
|    approx_kl            | 0.010868846 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.8       |
|    explained_variance   | 0.696       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.759      |
|    n_updates            | 7125        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 20.2        |
|    value_loss           | 0.196       |
-----------------------------------------
[ADAPTIVE] Episode 407 reward: 0.076395
[ADAPTIVE] Mean reward over last 20 episodes: 0.018623
[ADAPTIVE] Plateau counter: 137/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.39043948  |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 400         |
|    time_elapsed         | 1332        |
|    total_timesteps      | 1638400     |
| train/                  |             |
|    approx_kl            | 0.009790232 |
|    clip_fraction        | 0.0952      |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.8       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.743      |
|    n_updates            | 7140        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 20.3        |
|    value_loss           | 0.21        |
-----------------------------------------
[ADAPTIVE] Episode 408 reward: -0.111303
[ADAPTIVE] Mean reward over last 20 episodes: 0.012090
[ADAPTIVE] Plateau counter: 138/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5911678   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 401         |
|    time_elapsed         | 1336        |
|    total_timesteps      | 1642496     |
| train/                  |             |
|    approx_kl            | 0.010377716 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.9       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.804      |
|    n_updates            | 7155        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 20.4        |
|    value_loss           | 0.0829      |
-----------------------------------------
[ADAPTIVE] Episode 409 reward: 0.142205
[ADAPTIVE] Mean reward over last 20 episodes: 0.015482
[ADAPTIVE] Plateau counter: 139/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 410 reward: -0.003866
[ADAPTIVE] Mean reward over last 20 episodes: 0.016472
[ADAPTIVE] Plateau counter: 140/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.64161897  |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 402         |
|    time_elapsed         | 1339        |
|    total_timesteps      | 1646592     |
| train/                  |             |
|    approx_kl            | 0.012349214 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -40         |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.78       |
|    n_updates            | 7170        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 20.6        |
|    value_loss           | 0.0781      |
-----------------------------------------
[ADAPTIVE] Episode 411 reward: -3.104537
[ADAPTIVE] Mean reward over last 20 episodes: -0.138382
[ADAPTIVE] Plateau counter: 141/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6814238   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 403         |
|    time_elapsed         | 1342        |
|    total_timesteps      | 1650688     |
| train/                  |             |
|    approx_kl            | 0.007320078 |
|    clip_fraction        | 0.0756      |
|    clip_range           | 0.2         |
|    entropy_loss         | -40         |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.737      |
|    n_updates            | 7185        |
|    policy_gradient_loss | -0.017      |
|    std                  | 20.6        |
|    value_loss           | 0.18        |
-----------------------------------------
[ADAPTIVE] Episode 412 reward: 0.094742
[ADAPTIVE] Mean reward over last 20 episodes: -0.133683
[ADAPTIVE] Plateau counter: 142/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46482423  |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 404         |
|    time_elapsed         | 1346        |
|    total_timesteps      | 1654784     |
| train/                  |             |
|    approx_kl            | 0.011318171 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40         |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.777      |
|    n_updates            | 7200        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 20.8        |
|    value_loss           | 0.155       |
-----------------------------------------
[ADAPTIVE] Episode 413 reward: -0.057173
[ADAPTIVE] Mean reward over last 20 episodes: -0.138426
[ADAPTIVE] Plateau counter: 143/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.51971406   |
| time/                   |              |
|    fps                  | 1229         |
|    iterations           | 405          |
|    time_elapsed         | 1349         |
|    total_timesteps      | 1658880      |
| train/                  |              |
|    approx_kl            | 0.0123752225 |
|    clip_fraction        | 0.103        |
|    clip_range           | 0.2          |
|    entropy_loss         | -40.1        |
|    explained_variance   | 0.746        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.778       |
|    n_updates            | 7215         |
|    policy_gradient_loss | -0.0167      |
|    std                  | 20.9         |
|    value_loss           | 0.131        |
------------------------------------------
[ADAPTIVE] Episode 414 reward: 0.031781
[ADAPTIVE] Mean reward over last 20 episodes: -0.134951
[ADAPTIVE] Plateau counter: 144/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4202795   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 406         |
|    time_elapsed         | 1352        |
|    total_timesteps      | 1662976     |
| train/                  |             |
|    approx_kl            | 0.010462302 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.1       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.779      |
|    n_updates            | 7230        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 21          |
|    value_loss           | 0.12        |
-----------------------------------------
[ADAPTIVE] Episode 415 reward: 0.094435
[ADAPTIVE] Mean reward over last 20 episodes: -0.129714
[ADAPTIVE] Plateau counter: 145/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46371347  |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 407         |
|    time_elapsed         | 1356        |
|    total_timesteps      | 1667072     |
| train/                  |             |
|    approx_kl            | 0.008893477 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.2       |
|    explained_variance   | 0.662       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.763      |
|    n_updates            | 7245        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 21.1        |
|    value_loss           | 0.23        |
-----------------------------------------
[ADAPTIVE] Episode 416 reward: 0.026671
[ADAPTIVE] Mean reward over last 20 episodes: -0.136687
[ADAPTIVE] Plateau counter: 146/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.65892416   |
| time/                   |              |
|    fps                  | 1229         |
|    iterations           | 408          |
|    time_elapsed         | 1359         |
|    total_timesteps      | 1671168      |
| train/                  |              |
|    approx_kl            | 0.0071534766 |
|    clip_fraction        | 0.0669       |
|    clip_range           | 0.2          |
|    entropy_loss         | -40.2        |
|    explained_variance   | 0.663        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.771       |
|    n_updates            | 7260         |
|    policy_gradient_loss | -0.0141      |
|    std                  | 21.2         |
|    value_loss           | 0.182        |
------------------------------------------
[ADAPTIVE] Episode 417 reward: 0.093296
[ADAPTIVE] Mean reward over last 20 episodes: -0.133189
[ADAPTIVE] Plateau counter: 147/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6228365   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 409         |
|    time_elapsed         | 1363        |
|    total_timesteps      | 1675264     |
| train/                  |             |
|    approx_kl            | 0.015581954 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.3       |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.78       |
|    n_updates            | 7275        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 21.3        |
|    value_loss           | 0.157       |
-----------------------------------------
[ADAPTIVE] Episode 418 reward: 0.073247
[ADAPTIVE] Mean reward over last 20 episodes: -0.132533
[ADAPTIVE] Plateau counter: 148/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.69895864  |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 410         |
|    time_elapsed         | 1366        |
|    total_timesteps      | 1679360     |
| train/                  |             |
|    approx_kl            | 0.009134233 |
|    clip_fraction        | 0.0902      |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.3       |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.776      |
|    n_updates            | 7290        |
|    policy_gradient_loss | -0.0134     |
|    std                  | 21.4        |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 419 reward: -0.029503
[ADAPTIVE] Mean reward over last 20 episodes: -0.134237
[ADAPTIVE] Plateau counter: 149/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5786844   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 411         |
|    time_elapsed         | 1369        |
|    total_timesteps      | 1683456     |
| train/                  |             |
|    approx_kl            | 0.010783156 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.4       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.793      |
|    n_updates            | 7305        |
|    policy_gradient_loss | -0.0151     |
|    std                  | 21.5        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 420 reward: -0.039101
[ADAPTIVE] Mean reward over last 20 episodes: -0.137832
[ADAPTIVE] Plateau counter: 150/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6572141   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 412         |
|    time_elapsed         | 1372        |
|    total_timesteps      | 1687552     |
| train/                  |             |
|    approx_kl            | 0.007715515 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.4       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.762      |
|    n_updates            | 7320        |
|    policy_gradient_loss | -0.0131     |
|    std                  | 21.6        |
|    value_loss           | 0.177       |
-----------------------------------------
[ADAPTIVE] Episode 421 reward: -0.110555
[ADAPTIVE] Mean reward over last 20 episodes: -0.139703
[ADAPTIVE] Plateau counter: 151/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.633292    |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 413         |
|    time_elapsed         | 1375        |
|    total_timesteps      | 1691648     |
| train/                  |             |
|    approx_kl            | 0.010752247 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.4       |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.805      |
|    n_updates            | 7335        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 21.7        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 422 reward: 0.105847
[ADAPTIVE] Mean reward over last 20 episodes: -0.137879
[ADAPTIVE] Plateau counter: 152/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.43537453  |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 414         |
|    time_elapsed         | 1379        |
|    total_timesteps      | 1695744     |
| train/                  |             |
|    approx_kl            | 0.007945942 |
|    clip_fraction        | 0.095       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.5       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.756      |
|    n_updates            | 7350        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 21.8        |
|    value_loss           | 0.191       |
-----------------------------------------
[ADAPTIVE] Episode 423 reward: 0.056161
[ADAPTIVE] Mean reward over last 20 episodes: -0.139615
[ADAPTIVE] Plateau counter: 153/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.24537724 |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 415        |
|    time_elapsed         | 1381       |
|    total_timesteps      | 1699840    |
| train/                  |            |
|    approx_kl            | 0.01174991 |
|    clip_fraction        | 0.118      |
|    clip_range           | 0.2        |
|    entropy_loss         | -40.5      |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.817     |
|    n_updates            | 7365       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 21.9       |
|    value_loss           | 0.0986     |
----------------------------------------
[ADAPTIVE] Episode 424 reward: 0.064282
[ADAPTIVE] Mean reward over last 20 episodes: -0.136718
[ADAPTIVE] Plateau counter: 154/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.2598679   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 416         |
|    time_elapsed         | 1385        |
|    total_timesteps      | 1703936     |
| train/                  |             |
|    approx_kl            | 0.008811867 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.6       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.782      |
|    n_updates            | 7380        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 22          |
|    value_loss           | 0.138       |
-----------------------------------------
[ADAPTIVE] Episode 425 reward: 0.020636
[ADAPTIVE] Mean reward over last 20 episodes: -0.133910
[ADAPTIVE] Plateau counter: 155/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.3404305   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 417         |
|    time_elapsed         | 1388        |
|    total_timesteps      | 1708032     |
| train/                  |             |
|    approx_kl            | 0.010101628 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.6       |
|    explained_variance   | 0.752       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.803      |
|    n_updates            | 7395        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 22.2        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 426 reward: 0.018357
[ADAPTIVE] Mean reward over last 20 episodes: -0.127899
[ADAPTIVE] Plateau counter: 156/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.36583018   |
| time/                   |              |
|    fps                  | 1230         |
|    iterations           | 418          |
|    time_elapsed         | 1391         |
|    total_timesteps      | 1712128      |
| train/                  |              |
|    approx_kl            | 0.0121487165 |
|    clip_fraction        | 0.131        |
|    clip_range           | 0.2          |
|    entropy_loss         | -40.7        |
|    explained_variance   | 0.856        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.82        |
|    n_updates            | 7410         |
|    policy_gradient_loss | -0.0207      |
|    std                  | 22.3         |
|    value_loss           | 0.0767       |
------------------------------------------
[ADAPTIVE] Episode 427 reward: 0.075747
[ADAPTIVE] Mean reward over last 20 episodes: -0.127932
[ADAPTIVE] Plateau counter: 157/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47953537  |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 419         |
|    time_elapsed         | 1395        |
|    total_timesteps      | 1716224     |
| train/                  |             |
|    approx_kl            | 0.010206549 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.7       |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.789      |
|    n_updates            | 7425        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 22.4        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 428 reward: 0.012156
[ADAPTIVE] Mean reward over last 20 episodes: -0.121759
[ADAPTIVE] Plateau counter: 158/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.7642508  |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 420        |
|    time_elapsed         | 1398       |
|    total_timesteps      | 1720320    |
| train/                  |            |
|    approx_kl            | 0.00797618 |
|    clip_fraction        | 0.145      |
|    clip_range           | 0.2        |
|    entropy_loss         | -40.8      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.75      |
|    n_updates            | 7440       |
|    policy_gradient_loss | -0.0169    |
|    std                  | 22.5       |
|    value_loss           | 0.207      |
----------------------------------------
[ADAPTIVE] Episode 429 reward: -0.002897
[ADAPTIVE] Mean reward over last 20 episodes: -0.129014
[ADAPTIVE] Plateau counter: 159/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.80880785  |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 421         |
|    time_elapsed         | 1401        |
|    total_timesteps      | 1724416     |
| train/                  |             |
|    approx_kl            | 0.010355581 |
|    clip_fraction        | 0.0954      |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.8       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.808      |
|    n_updates            | 7455        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 22.6        |
|    value_loss           | 0.121       |
-----------------------------------------
[ADAPTIVE] Episode 430 reward: 0.006937
[ADAPTIVE] Mean reward over last 20 episodes: -0.128474
[ADAPTIVE] Plateau counter: 160/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8809018   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 422         |
|    time_elapsed         | 1404        |
|    total_timesteps      | 1728512     |
| train/                  |             |
|    approx_kl            | 0.012293741 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.8       |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.782      |
|    n_updates            | 7470        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 22.7        |
|    value_loss           | 0.166       |
-----------------------------------------
[ADAPTIVE] Episode 431 reward: -0.043703
[ADAPTIVE] Mean reward over last 20 episodes: 0.024568
[ADAPTIVE] Plateau counter: 161/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9373656   |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 423         |
|    time_elapsed         | 1406        |
|    total_timesteps      | 1732608     |
| train/                  |             |
|    approx_kl            | 0.009575384 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.9       |
|    explained_variance   | 0.731       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.79       |
|    n_updates            | 7485        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 22.9        |
|    value_loss           | 0.186       |
-----------------------------------------
[ADAPTIVE] Episode 432 reward: 0.029686
[ADAPTIVE] Mean reward over last 20 episodes: 0.021315
[ADAPTIVE] Plateau counter: 162/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.79951376  |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 424         |
|    time_elapsed         | 1410        |
|    total_timesteps      | 1736704     |
| train/                  |             |
|    approx_kl            | 0.011939103 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41         |
|    explained_variance   | 0.733       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.755      |
|    n_updates            | 7500        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 23          |
|    value_loss           | 0.217       |
-----------------------------------------
[ADAPTIVE] Episode 433 reward: -0.021867
[ADAPTIVE] Mean reward over last 20 episodes: 0.023081
[ADAPTIVE] Plateau counter: 163/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.59210277  |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 425         |
|    time_elapsed         | 1413        |
|    total_timesteps      | 1740800     |
| train/                  |             |
|    approx_kl            | 0.009249005 |
|    clip_fraction        | 0.0878      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41         |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.76       |
|    n_updates            | 7515        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 23.1        |
|    value_loss           | 0.228       |
-----------------------------------------
[ADAPTIVE] Episode 434 reward: 0.035530
[ADAPTIVE] Mean reward over last 20 episodes: 0.023268
[ADAPTIVE] Plateau counter: 164/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.51946795  |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 426         |
|    time_elapsed         | 1416        |
|    total_timesteps      | 1744896     |
| train/                  |             |
|    approx_kl            | 0.010358309 |
|    clip_fraction        | 0.0895      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41         |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.785      |
|    n_updates            | 7530        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 23.2        |
|    value_loss           | 0.18        |
-----------------------------------------
[ADAPTIVE] Episode 435 reward: 0.011642
[ADAPTIVE] Mean reward over last 20 episodes: 0.019128
[ADAPTIVE] Plateau counter: 165/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46494263  |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 427         |
|    time_elapsed         | 1419        |
|    total_timesteps      | 1748992     |
| train/                  |             |
|    approx_kl            | 0.009394209 |
|    clip_fraction        | 0.098       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.1       |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.748      |
|    n_updates            | 7545        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 23.4        |
|    value_loss           | 0.269       |
-----------------------------------------
[ADAPTIVE] Episode 436 reward: 0.018411
[ADAPTIVE] Mean reward over last 20 episodes: 0.018715
[ADAPTIVE] Plateau counter: 166/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.31667608  |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 428         |
|    time_elapsed         | 1422        |
|    total_timesteps      | 1753088     |
| train/                  |             |
|    approx_kl            | 0.011676868 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.1       |
|    explained_variance   | 0.671       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.733      |
|    n_updates            | 7560        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 23.5        |
|    value_loss           | 0.243       |
-----------------------------------------
[ADAPTIVE] Episode 437 reward: 0.055189
[ADAPTIVE] Mean reward over last 20 episodes: 0.016810
[ADAPTIVE] Plateau counter: 167/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.29182437  |
| time/                   |             |
|    fps                  | 1232        |
|    iterations           | 429         |
|    time_elapsed         | 1425        |
|    total_timesteps      | 1757184     |
| train/                  |             |
|    approx_kl            | 0.010550692 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.2       |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.821      |
|    n_updates            | 7575        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 23.6        |
|    value_loss           | 0.0969      |
-----------------------------------------
[ADAPTIVE] Episode 438 reward: -0.122228
[ADAPTIVE] Mean reward over last 20 episodes: 0.007036
[ADAPTIVE] Plateau counter: 168/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4019908    |
| time/                   |              |
|    fps                  | 1232         |
|    iterations           | 430          |
|    time_elapsed         | 1428         |
|    total_timesteps      | 1761280      |
| train/                  |              |
|    approx_kl            | 0.0077472553 |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.2          |
|    entropy_loss         | -41.2        |
|    explained_variance   | 0.717        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.806       |
|    n_updates            | 7590         |
|    policy_gradient_loss | -0.0172      |
|    std                  | 23.7         |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 439 reward: 0.063312
[ADAPTIVE] Mean reward over last 20 episodes: 0.011677
[ADAPTIVE] Plateau counter: 169/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.14539318  |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 431         |
|    time_elapsed         | 1431        |
|    total_timesteps      | 1765376     |
| train/                  |             |
|    approx_kl            | 0.010681486 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.3       |
|    explained_variance   | 0.778       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.811      |
|    n_updates            | 7605        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 23.8        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 440 reward: 0.078609
[ADAPTIVE] Mean reward over last 20 episodes: 0.017563
[ADAPTIVE] Plateau counter: 170/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.140989    |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 432         |
|    time_elapsed         | 1434        |
|    total_timesteps      | 1769472     |
| train/                  |             |
|    approx_kl            | 0.009603443 |
|    clip_fraction        | 0.0984      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.3       |
|    explained_variance   | 0.79        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.822      |
|    n_updates            | 7620        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 24          |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 441 reward: -0.059163
[ADAPTIVE] Mean reward over last 20 episodes: 0.020132
[ADAPTIVE] Plateau counter: 171/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.14121982  |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 433         |
|    time_elapsed         | 1437        |
|    total_timesteps      | 1773568     |
| train/                  |             |
|    approx_kl            | 0.008464672 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.4       |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.761      |
|    n_updates            | 7635        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 24.1        |
|    value_loss           | 0.202       |
-----------------------------------------
[ADAPTIVE] Episode 442 reward: 0.023079
[ADAPTIVE] Mean reward over last 20 episodes: 0.015994
[ADAPTIVE] Plateau counter: 172/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.179792    |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 434         |
|    time_elapsed         | 1440        |
|    total_timesteps      | 1777664     |
| train/                  |             |
|    approx_kl            | 0.011497053 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.4       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.796      |
|    n_updates            | 7650        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 24.2        |
|    value_loss           | 0.186       |
-----------------------------------------
[ADAPTIVE] Episode 443 reward: 0.095768
[ADAPTIVE] Mean reward over last 20 episodes: 0.017974
[ADAPTIVE] Plateau counter: 173/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.23902252   |
| time/                   |              |
|    fps                  | 1234         |
|    iterations           | 435          |
|    time_elapsed         | 1443         |
|    total_timesteps      | 1781760      |
| train/                  |              |
|    approx_kl            | 0.0094304085 |
|    clip_fraction        | 0.116        |
|    clip_range           | 0.2          |
|    entropy_loss         | -41.5        |
|    explained_variance   | 0.737        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.79        |
|    n_updates            | 7665         |
|    policy_gradient_loss | -0.0213      |
|    std                  | 24.4         |
|    value_loss           | 0.172        |
------------------------------------------
[ADAPTIVE] Episode 444 reward: -0.088776
[ADAPTIVE] Mean reward over last 20 episodes: 0.010321
[ADAPTIVE] Plateau counter: 174/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.23424195  |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 436         |
|    time_elapsed         | 1446        |
|    total_timesteps      | 1785856     |
| train/                  |             |
|    approx_kl            | 0.007792388 |
|    clip_fraction        | 0.0879      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.5       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.782      |
|    n_updates            | 7680        |
|    policy_gradient_loss | -0.016      |
|    std                  | 24.5        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 445 reward: 0.008148
[ADAPTIVE] Mean reward over last 20 episodes: 0.009697
[ADAPTIVE] Plateau counter: 175/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.21369955  |
| time/                   |             |
|    fps                  | 1235        |
|    iterations           | 437         |
|    time_elapsed         | 1449        |
|    total_timesteps      | 1789952     |
| train/                  |             |
|    approx_kl            | 0.009583121 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.6       |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.813      |
|    n_updates            | 7695        |
|    policy_gradient_loss | -0.018      |
|    std                  | 24.7        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 446 reward: -0.087677
[ADAPTIVE] Mean reward over last 20 episodes: 0.004395
[ADAPTIVE] Plateau counter: 176/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.48502743  |
| time/                   |             |
|    fps                  | 1235        |
|    iterations           | 438         |
|    time_elapsed         | 1452        |
|    total_timesteps      | 1794048     |
| train/                  |             |
|    approx_kl            | 0.008770284 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.6       |
|    explained_variance   | 0.727       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.801      |
|    n_updates            | 7710        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 24.8        |
|    value_loss           | 0.186       |
-----------------------------------------
[ADAPTIVE] Episode 447 reward: -0.006857
[ADAPTIVE] Mean reward over last 20 episodes: 0.000265
[ADAPTIVE] Plateau counter: 177/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.41349357   |
| time/                   |              |
|    fps                  | 1235         |
|    iterations           | 439          |
|    time_elapsed         | 1454         |
|    total_timesteps      | 1798144      |
| train/                  |              |
|    approx_kl            | 0.0104247155 |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.2          |
|    entropy_loss         | -41.7        |
|    explained_variance   | 0.702        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.818       |
|    n_updates            | 7725         |
|    policy_gradient_loss | -0.0193      |
|    std                  | 24.9         |
|    value_loss           | 0.145        |
------------------------------------------
[ADAPTIVE] Episode 448 reward: 0.004947
[ADAPTIVE] Mean reward over last 20 episodes: -0.000095
[ADAPTIVE] Plateau counter: 178/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.3528423   |
| time/                   |             |
|    fps                  | 1236        |
|    iterations           | 440         |
|    time_elapsed         | 1458        |
|    total_timesteps      | 1802240     |
| train/                  |             |
|    approx_kl            | 0.011322649 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.7       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.768      |
|    n_updates            | 7740        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 25          |
|    value_loss           | 0.149       |
-----------------------------------------
[ADAPTIVE] Episode 449 reward: -0.043381
[ADAPTIVE] Mean reward over last 20 episodes: -0.002120
[ADAPTIVE] Plateau counter: 179/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.26629403  |
| time/                   |             |
|    fps                  | 1235        |
|    iterations           | 441         |
|    time_elapsed         | 1461        |
|    total_timesteps      | 1806336     |
| train/                  |             |
|    approx_kl            | 0.008682229 |
|    clip_fraction        | 0.0954      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.7       |
|    explained_variance   | 0.77        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.813      |
|    n_updates            | 7755        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 25          |
|    value_loss           | 0.179       |
-----------------------------------------
[ADAPTIVE] Episode 450 reward: -0.023266
[ADAPTIVE] Mean reward over last 20 episodes: -0.003630
[ADAPTIVE] Plateau counter: 180/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.178889    |
| time/                   |             |
|    fps                  | 1236        |
|    iterations           | 442         |
|    time_elapsed         | 1464        |
|    total_timesteps      | 1810432     |
| train/                  |             |
|    approx_kl            | 0.009454344 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.7       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.795      |
|    n_updates            | 7770        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 25.1        |
|    value_loss           | 0.203       |
-----------------------------------------
[ADAPTIVE] Episode 451 reward: -0.012652
[ADAPTIVE] Mean reward over last 20 episodes: -0.002077
[ADAPTIVE] Plateau counter: 181/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.23747084  |
| time/                   |             |
|    fps                  | 1236        |
|    iterations           | 443         |
|    time_elapsed         | 1467        |
|    total_timesteps      | 1814528     |
| train/                  |             |
|    approx_kl            | 0.009115411 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.8       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.798      |
|    n_updates            | 7785        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 25.2        |
|    value_loss           | 0.148       |
-----------------------------------------
[ADAPTIVE] Episode 452 reward: 0.055091
[ADAPTIVE] Mean reward over last 20 episodes: -0.000807
[ADAPTIVE] Plateau counter: 182/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.31615224  |
| time/                   |             |
|    fps                  | 1236        |
|    iterations           | 444         |
|    time_elapsed         | 1470        |
|    total_timesteps      | 1818624     |
| train/                  |             |
|    approx_kl            | 0.010008331 |
|    clip_fraction        | 0.0929      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.8       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.801      |
|    n_updates            | 7800        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 25.2        |
|    value_loss           | 0.167       |
-----------------------------------------
[ADAPTIVE] Episode 453 reward: 0.008019
[ADAPTIVE] Mean reward over last 20 episodes: 0.000687
[ADAPTIVE] Plateau counter: 183/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.28811803  |
| time/                   |             |
|    fps                  | 1237        |
|    iterations           | 445         |
|    time_elapsed         | 1473        |
|    total_timesteps      | 1822720     |
| train/                  |             |
|    approx_kl            | 0.008886523 |
|    clip_fraction        | 0.0967      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.8       |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.796      |
|    n_updates            | 7815        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 25.3        |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 454 reward: -0.027998
[ADAPTIVE] Mean reward over last 20 episodes: -0.002489
[ADAPTIVE] Plateau counter: 184/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.27383515  |
| time/                   |             |
|    fps                  | 1237        |
|    iterations           | 446         |
|    time_elapsed         | 1476        |
|    total_timesteps      | 1826816     |
| train/                  |             |
|    approx_kl            | 0.010520155 |
|    clip_fraction        | 0.0952      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.8       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.788      |
|    n_updates            | 7830        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 25.4        |
|    value_loss           | 0.176       |
-----------------------------------------
[ADAPTIVE] Episode 455 reward: -0.050453
[ADAPTIVE] Mean reward over last 20 episodes: -0.005594
[ADAPTIVE] Plateau counter: 185/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.2693105   |
| time/                   |             |
|    fps                  | 1237        |
|    iterations           | 447         |
|    time_elapsed         | 1478        |
|    total_timesteps      | 1830912     |
| train/                  |             |
|    approx_kl            | 0.008969052 |
|    clip_fraction        | 0.0925      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.9       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.823      |
|    n_updates            | 7845        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 25.6        |
|    value_loss           | 0.0993      |
-----------------------------------------
[ADAPTIVE] Episode 456 reward: 0.094171
[ADAPTIVE] Mean reward over last 20 episodes: -0.001806
[ADAPTIVE] Plateau counter: 186/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.22426844 |
| time/                   |            |
|    fps                  | 1238       |
|    iterations           | 448        |
|    time_elapsed         | 1482       |
|    total_timesteps      | 1835008    |
| train/                  |            |
|    approx_kl            | 0.00967057 |
|    clip_fraction        | 0.0937     |
|    clip_range           | 0.2        |
|    entropy_loss         | -41.9      |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.814     |
|    n_updates            | 7860       |
|    policy_gradient_loss | -0.0146    |
|    std                  | 25.7       |
|    value_loss           | 0.198      |
----------------------------------------
[ADAPTIVE] Episode 457 reward: -0.024775
[ADAPTIVE] Mean reward over last 20 episodes: -0.005804
[ADAPTIVE] Plateau counter: 187/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.29082304  |
| time/                   |             |
|    fps                  | 1238        |
|    iterations           | 449         |
|    time_elapsed         | 1484        |
|    total_timesteps      | 1839104     |
| train/                  |             |
|    approx_kl            | 0.009125369 |
|    clip_fraction        | 0.085       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42         |
|    explained_variance   | 0.667       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.795      |
|    n_updates            | 7875        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 25.8        |
|    value_loss           | 0.188       |
-----------------------------------------
[ADAPTIVE] Episode 458 reward: -0.097829
[ADAPTIVE] Mean reward over last 20 episodes: -0.004584
[ADAPTIVE] Plateau counter: 188/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.2615581   |
| time/                   |             |
|    fps                  | 1239        |
|    iterations           | 450         |
|    time_elapsed         | 1487        |
|    total_timesteps      | 1843200     |
| train/                  |             |
|    approx_kl            | 0.009123753 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42         |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.83       |
|    n_updates            | 7890        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 26          |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 459 reward: -0.120318
[ADAPTIVE] Mean reward over last 20 episodes: -0.013766
[ADAPTIVE] Plateau counter: 189/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.21710464  |
| time/                   |             |
|    fps                  | 1239        |
|    iterations           | 451         |
|    time_elapsed         | 1490        |
|    total_timesteps      | 1847296     |
| train/                  |             |
|    approx_kl            | 0.011181561 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.1       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.811      |
|    n_updates            | 7905        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 26.3        |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 460 reward: 0.020685
[ADAPTIVE] Mean reward over last 20 episodes: -0.016662
[ADAPTIVE] Plateau counter: 190/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 461 reward: -0.070768
[ADAPTIVE] Mean reward over last 20 episodes: -0.017242
[ADAPTIVE] Plateau counter: 191/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.110352315 |
| time/                   |             |
|    fps                  | 1239        |
|    iterations           | 452         |
|    time_elapsed         | 1493        |
|    total_timesteps      | 1851392     |
| train/                  |             |
|    approx_kl            | 0.00943833  |
|    clip_fraction        | 0.0914      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.2       |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.83       |
|    n_updates            | 7920        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 26.4        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 462 reward: -0.024354
[ADAPTIVE] Mean reward over last 20 episodes: -0.019614
[ADAPTIVE] Plateau counter: 192/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.089304544 |
| time/                   |             |
|    fps                  | 1239        |
|    iterations           | 453         |
|    time_elapsed         | 1496        |
|    total_timesteps      | 1855488     |
| train/                  |             |
|    approx_kl            | 0.009976378 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.2       |
|    explained_variance   | 0.83        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.833      |
|    n_updates            | 7935        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 26.4        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 463 reward: 0.100549
[ADAPTIVE] Mean reward over last 20 episodes: -0.019375
[ADAPTIVE] Plateau counter: 193/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.32176054 |
| time/                   |            |
|    fps                  | 1239       |
|    iterations           | 454        |
|    time_elapsed         | 1499       |
|    total_timesteps      | 1859584    |
| train/                  |            |
|    approx_kl            | 0.01046904 |
|    clip_fraction        | 0.0841     |
|    clip_range           | 0.2        |
|    entropy_loss         | -42.2      |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.762     |
|    n_updates            | 7950       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 26.6       |
|    value_loss           | 0.21       |
----------------------------------------
[ADAPTIVE] Episode 464 reward: -0.056639
[ADAPTIVE] Mean reward over last 20 episodes: -0.017768
[ADAPTIVE] Plateau counter: 194/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.30701497  |
| time/                   |             |
|    fps                  | 1240        |
|    iterations           | 455         |
|    time_elapsed         | 1502        |
|    total_timesteps      | 1863680     |
| train/                  |             |
|    approx_kl            | 0.008752324 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.3       |
|    explained_variance   | 0.624       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.809      |
|    n_updates            | 7965        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 26.8        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 465 reward: -0.095886
[ADAPTIVE] Mean reward over last 20 episodes: -0.022970
[ADAPTIVE] Plateau counter: 195/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.20749779   |
| time/                   |              |
|    fps                  | 1240         |
|    iterations           | 456          |
|    time_elapsed         | 1505         |
|    total_timesteps      | 1867776      |
| train/                  |              |
|    approx_kl            | 0.0075451136 |
|    clip_fraction        | 0.0873       |
|    clip_range           | 0.2          |
|    entropy_loss         | -42.3        |
|    explained_variance   | 0.718        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.807       |
|    n_updates            | 7980         |
|    policy_gradient_loss | -0.0171      |
|    std                  | 26.9         |
|    value_loss           | 0.131        |
------------------------------------------
[ADAPTIVE] Episode 466 reward: 0.008253
[ADAPTIVE] Mean reward over last 20 episodes: -0.018173
[ADAPTIVE] Plateau counter: 196/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.25034398 |
| time/                   |            |
|    fps                  | 1240       |
|    iterations           | 457        |
|    time_elapsed         | 1508       |
|    total_timesteps      | 1871872    |
| train/                  |            |
|    approx_kl            | 0.0109785  |
|    clip_fraction        | 0.09       |
|    clip_range           | 0.2        |
|    entropy_loss         | -42.4      |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.805     |
|    n_updates            | 7995       |
|    policy_gradient_loss | -0.0139    |
|    std                  | 26.9       |
|    value_loss           | 0.259      |
----------------------------------------
[ADAPTIVE] Episode 467 reward: 0.021256
[ADAPTIVE] Mean reward over last 20 episodes: -0.016767
[ADAPTIVE] Plateau counter: 197/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5178941   |
| time/                   |             |
|    fps                  | 1241        |
|    iterations           | 458         |
|    time_elapsed         | 1511        |
|    total_timesteps      | 1875968     |
| train/                  |             |
|    approx_kl            | 0.011465676 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.4       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.785      |
|    n_updates            | 8010        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 27.1        |
|    value_loss           | 0.214       |
-----------------------------------------
[ADAPTIVE] Episode 468 reward: -0.022745
[ADAPTIVE] Mean reward over last 20 episodes: -0.018152
[ADAPTIVE] Plateau counter: 198/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.49440122  |
| time/                   |             |
|    fps                  | 1241        |
|    iterations           | 459         |
|    time_elapsed         | 1514        |
|    total_timesteps      | 1880064     |
| train/                  |             |
|    approx_kl            | 0.011147325 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.4       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.805      |
|    n_updates            | 8025        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 27.1        |
|    value_loss           | 0.199       |
-----------------------------------------
[ADAPTIVE] Episode 469 reward: 0.011287
[ADAPTIVE] Mean reward over last 20 episodes: -0.015419
[ADAPTIVE] Plateau counter: 199/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.429065    |
| time/                   |             |
|    fps                  | 1241        |
|    iterations           | 460         |
|    time_elapsed         | 1517        |
|    total_timesteps      | 1884160     |
| train/                  |             |
|    approx_kl            | 0.008451082 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.5       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.833      |
|    n_updates            | 8040        |
|    policy_gradient_loss | -0.018      |
|    std                  | 27.3        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 470 reward: -0.091330
[ADAPTIVE] Mean reward over last 20 episodes: -0.018822
[ADAPTIVE] Plateau counter: 200/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47165003  |
| time/                   |             |
|    fps                  | 1241        |
|    iterations           | 461         |
|    time_elapsed         | 1520        |
|    total_timesteps      | 1888256     |
| train/                  |             |
|    approx_kl            | 0.009347986 |
|    clip_fraction        | 0.0991      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.5       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.829      |
|    n_updates            | 8055        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 27.4        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 471 reward: -0.032511
[ADAPTIVE] Mean reward over last 20 episodes: -0.019815
[ADAPTIVE] Plateau counter: 201/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67672265  |
| time/                   |             |
|    fps                  | 1241        |
|    iterations           | 462         |
|    time_elapsed         | 1523        |
|    total_timesteps      | 1892352     |
| train/                  |             |
|    approx_kl            | 0.010868629 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.6       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.801      |
|    n_updates            | 8070        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 27.6        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 472 reward: 0.074896
[ADAPTIVE] Mean reward over last 20 episodes: -0.018824
[ADAPTIVE] Plateau counter: 202/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8431965   |
| time/                   |             |
|    fps                  | 1242        |
|    iterations           | 463         |
|    time_elapsed         | 1526        |
|    total_timesteps      | 1896448     |
| train/                  |             |
|    approx_kl            | 0.008808311 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.6       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.833      |
|    n_updates            | 8085        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 27.7        |
|    value_loss           | 0.109       |
-----------------------------------------
[ADAPTIVE] Episode 473 reward: -0.029401
[ADAPTIVE] Mean reward over last 20 episodes: -0.020695
[ADAPTIVE] Plateau counter: 203/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6190496   |
| time/                   |             |
|    fps                  | 1242        |
|    iterations           | 464         |
|    time_elapsed         | 1530        |
|    total_timesteps      | 1900544     |
| train/                  |             |
|    approx_kl            | 0.011254089 |
|    clip_fraction        | 0.0875      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.6       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.83       |
|    n_updates            | 8100        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 27.8        |
|    value_loss           | 0.158       |
-----------------------------------------
[ADAPTIVE] Episode 474 reward: -0.017344
[ADAPTIVE] Mean reward over last 20 episodes: -0.020163
[ADAPTIVE] Plateau counter: 204/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5928547   |
| time/                   |             |
|    fps                  | 1242        |
|    iterations           | 465         |
|    time_elapsed         | 1532        |
|    total_timesteps      | 1904640     |
| train/                  |             |
|    approx_kl            | 0.010064777 |
|    clip_fraction        | 0.091       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.7       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.783      |
|    n_updates            | 8115        |
|    policy_gradient_loss | -0.013      |
|    std                  | 28          |
|    value_loss           | 0.168       |
-----------------------------------------
[ADAPTIVE] Episode 475 reward: -0.034414
[ADAPTIVE] Mean reward over last 20 episodes: -0.019361
[ADAPTIVE] Plateau counter: 205/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7428227   |
| time/                   |             |
|    fps                  | 1242        |
|    iterations           | 466         |
|    time_elapsed         | 1536        |
|    total_timesteps      | 1908736     |
| train/                  |             |
|    approx_kl            | 0.009773191 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.7       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.846      |
|    n_updates            | 8130        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 28.2        |
|    value_loss           | 0.0966      |
-----------------------------------------
[ADAPTIVE] Episode 476 reward: 0.141221
[ADAPTIVE] Mean reward over last 20 episodes: -0.017008
[ADAPTIVE] Plateau counter: 206/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76502955  |
| time/                   |             |
|    fps                  | 1242        |
|    iterations           | 467         |
|    time_elapsed         | 1538        |
|    total_timesteps      | 1912832     |
| train/                  |             |
|    approx_kl            | 0.012780396 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.8       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.831      |
|    n_updates            | 8145        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 28.3        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 477 reward: -0.011238
[ADAPTIVE] Mean reward over last 20 episodes: -0.016332
[ADAPTIVE] Plateau counter: 207/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5704421   |
| time/                   |             |
|    fps                  | 1243        |
|    iterations           | 468         |
|    time_elapsed         | 1542        |
|    total_timesteps      | 1916928     |
| train/                  |             |
|    approx_kl            | 0.010906562 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.8       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.828      |
|    n_updates            | 8160        |
|    policy_gradient_loss | -0.0132     |
|    std                  | 28.5        |
|    value_loss           | 0.145       |
-----------------------------------------
[ADAPTIVE] Episode 478 reward: -0.009163
[ADAPTIVE] Mean reward over last 20 episodes: -0.011898
[ADAPTIVE] Plateau counter: 208/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.35604146  |
| time/                   |             |
|    fps                  | 1243        |
|    iterations           | 469         |
|    time_elapsed         | 1545        |
|    total_timesteps      | 1921024     |
| train/                  |             |
|    approx_kl            | 0.009556485 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.9       |
|    explained_variance   | 0.813       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.828      |
|    n_updates            | 8175        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 28.6        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 479 reward: -0.068696
[ADAPTIVE] Mean reward over last 20 episodes: -0.009317
[ADAPTIVE] Plateau counter: 209/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.2819788   |
| time/                   |             |
|    fps                  | 1243        |
|    iterations           | 470         |
|    time_elapsed         | 1548        |
|    total_timesteps      | 1925120     |
| train/                  |             |
|    approx_kl            | 0.010224866 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.9       |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.848      |
|    n_updates            | 8190        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 28.7        |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 480 reward: -0.088578
[ADAPTIVE] Mean reward over last 20 episodes: -0.014780
[ADAPTIVE] Plateau counter: 210/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.33357584  |
| time/                   |             |
|    fps                  | 1243        |
|    iterations           | 471         |
|    time_elapsed         | 1551        |
|    total_timesteps      | 1929216     |
| train/                  |             |
|    approx_kl            | 0.009810781 |
|    clip_fraction        | 0.0899      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43         |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.845      |
|    n_updates            | 8205        |
|    policy_gradient_loss | -0.017      |
|    std                  | 28.8        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 481 reward: 0.018696
[ADAPTIVE] Mean reward over last 20 episodes: -0.010307
[ADAPTIVE] Plateau counter: 211/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.14256378  |
| time/                   |             |
|    fps                  | 1243        |
|    iterations           | 472         |
|    time_elapsed         | 1554        |
|    total_timesteps      | 1933312     |
| train/                  |             |
|    approx_kl            | 0.008477549 |
|    clip_fraction        | 0.0807      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43         |
|    explained_variance   | 0.812       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.847      |
|    n_updates            | 8220        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 29          |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 482 reward: 0.020999
[ADAPTIVE] Mean reward over last 20 episodes: -0.008039
[ADAPTIVE] Plateau counter: 212/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.15166694  |
| time/                   |             |
|    fps                  | 1243        |
|    iterations           | 473         |
|    time_elapsed         | 1558        |
|    total_timesteps      | 1937408     |
| train/                  |             |
|    approx_kl            | 0.010312905 |
|    clip_fraction        | 0.0932      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43         |
|    explained_variance   | 0.667       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.803      |
|    n_updates            | 8235        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 29.1        |
|    value_loss           | 0.229       |
-----------------------------------------
[ADAPTIVE] Episode 483 reward: -0.017353
[ADAPTIVE] Mean reward over last 20 episodes: -0.013935
[ADAPTIVE] Plateau counter: 213/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | -0.03302945 |
| time/                   |             |
|    fps                  | 1243        |
|    iterations           | 474         |
|    time_elapsed         | 1560        |
|    total_timesteps      | 1941504     |
| train/                  |             |
|    approx_kl            | 0.009142881 |
|    clip_fraction        | 0.098       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.1       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.842      |
|    n_updates            | 8250        |
|    policy_gradient_loss | -0.016      |
|    std                  | 29.3        |
|    value_loss           | 0.0981      |
-----------------------------------------
[ADAPTIVE] Episode 484 reward: 0.037039
[ADAPTIVE] Mean reward over last 20 episodes: -0.009251
[ADAPTIVE] Plateau counter: 214/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.15697263  |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 475         |
|    time_elapsed         | 1563        |
|    total_timesteps      | 1945600     |
| train/                  |             |
|    approx_kl            | 0.008535968 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.2       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.852      |
|    n_updates            | 8265        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 29.5        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 485 reward: -0.048168
[ADAPTIVE] Mean reward over last 20 episodes: -0.006865
[ADAPTIVE] Plateau counter: 215/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.2430592    |
| time/                   |              |
|    fps                  | 1244         |
|    iterations           | 476          |
|    time_elapsed         | 1567         |
|    total_timesteps      | 1949696      |
| train/                  |              |
|    approx_kl            | 0.0077875885 |
|    clip_fraction        | 0.0968       |
|    clip_range           | 0.2          |
|    entropy_loss         | -43.2        |
|    explained_variance   | 0.587        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.836       |
|    n_updates            | 8280         |
|    policy_gradient_loss | -0.0192      |
|    std                  | 29.6         |
|    value_loss           | 0.137        |
------------------------------------------
[ADAPTIVE] Episode 486 reward: 0.104174
[ADAPTIVE] Mean reward over last 20 episodes: -0.002069
[ADAPTIVE] Plateau counter: 216/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.2868462   |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 477         |
|    time_elapsed         | 1570        |
|    total_timesteps      | 1953792     |
| train/                  |             |
|    approx_kl            | 0.010237157 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.2       |
|    explained_variance   | 0.792       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.859      |
|    n_updates            | 8295        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 29.7        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 487 reward: 0.092384
[ADAPTIVE] Mean reward over last 20 episodes: 0.001488
[ADAPTIVE] Plateau counter: 217/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.44909996  |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 478         |
|    time_elapsed         | 1573        |
|    total_timesteps      | 1957888     |
| train/                  |             |
|    approx_kl            | 0.010793066 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.3       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.846      |
|    n_updates            | 8310        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 30          |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 488 reward: 0.031327
[ADAPTIVE] Mean reward over last 20 episodes: 0.004191
[ADAPTIVE] Plateau counter: 218/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4472333   |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 479         |
|    time_elapsed         | 1576        |
|    total_timesteps      | 1961984     |
| train/                  |             |
|    approx_kl            | 0.009067309 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.3       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.847      |
|    n_updates            | 8325        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 30.1        |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 489 reward: -0.034268
[ADAPTIVE] Mean reward over last 20 episodes: 0.001914
[ADAPTIVE] Plateau counter: 219/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5809164   |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 480         |
|    time_elapsed         | 1580        |
|    total_timesteps      | 1966080     |
| train/                  |             |
|    approx_kl            | 0.009147469 |
|    clip_fraction        | 0.0993      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.4       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.849      |
|    n_updates            | 8340        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 30.3        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 490 reward: 0.060582
[ADAPTIVE] Mean reward over last 20 episodes: 0.009509
[ADAPTIVE] Plateau counter: 220/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.56290954  |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 481         |
|    time_elapsed         | 1583        |
|    total_timesteps      | 1970176     |
| train/                  |             |
|    approx_kl            | 0.008275418 |
|    clip_fraction        | 0.0917      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.4       |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.857      |
|    n_updates            | 8355        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 30.4        |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 491 reward: -0.053075
[ADAPTIVE] Mean reward over last 20 episodes: 0.008481
[ADAPTIVE] Plateau counter: 221/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6250737   |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 482         |
|    time_elapsed         | 1586        |
|    total_timesteps      | 1974272     |
| train/                  |             |
|    approx_kl            | 0.008629652 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.5       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.844      |
|    n_updates            | 8370        |
|    policy_gradient_loss | -0.0153     |
|    std                  | 30.5        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 492 reward: -0.080103
[ADAPTIVE] Mean reward over last 20 episodes: 0.000731
[ADAPTIVE] Plateau counter: 222/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.68814707  |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 483         |
|    time_elapsed         | 1589        |
|    total_timesteps      | 1978368     |
| train/                  |             |
|    approx_kl            | 0.010286349 |
|    clip_fraction        | 0.0776      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.5       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.839      |
|    n_updates            | 8385        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 30.7        |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 493 reward: -0.033788
[ADAPTIVE] Mean reward over last 20 episodes: 0.000512
[ADAPTIVE] Plateau counter: 223/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7380865   |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 484         |
|    time_elapsed         | 1592        |
|    total_timesteps      | 1982464     |
| train/                  |             |
|    approx_kl            | 0.011977163 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.5       |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.849      |
|    n_updates            | 8400        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 30.8        |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 494 reward: 0.105246
[ADAPTIVE] Mean reward over last 20 episodes: 0.006641
[ADAPTIVE] Plateau counter: 224/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96269417  |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 485         |
|    time_elapsed         | 1596        |
|    total_timesteps      | 1986560     |
| train/                  |             |
|    approx_kl            | 0.010618791 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.6       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.868      |
|    n_updates            | 8415        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 31          |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 495 reward: 0.084249
[ADAPTIVE] Mean reward over last 20 episodes: 0.012574
[ADAPTIVE] Plateau counter: 225/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.937633    |
| time/                   |             |
|    fps                  | 1244        |
|    iterations           | 486         |
|    time_elapsed         | 1598        |
|    total_timesteps      | 1990656     |
| train/                  |             |
|    approx_kl            | 0.008905923 |
|    clip_fraction        | 0.0873      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.6       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.857      |
|    n_updates            | 8430        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 31.1        |
|    value_loss           | 0.0848      |
-----------------------------------------
[ADAPTIVE] Episode 496 reward: -0.108868
[ADAPTIVE] Mean reward over last 20 episodes: 0.000070
[ADAPTIVE] Plateau counter: 226/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.89490396   |
| time/                   |              |
|    fps                  | 1244         |
|    iterations           | 487          |
|    time_elapsed         | 1602         |
|    total_timesteps      | 1994752      |
| train/                  |              |
|    approx_kl            | 0.0072351396 |
|    clip_fraction        | 0.0818       |
|    clip_range           | 0.2          |
|    entropy_loss         | -43.7        |
|    explained_variance   | 0.839        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.856       |
|    n_updates            | 8445         |
|    policy_gradient_loss | -0.0138      |
|    std                  | 31.3         |
|    value_loss           | 0.113        |
------------------------------------------
[ADAPTIVE] Episode 497 reward: 0.025016
[ADAPTIVE] Mean reward over last 20 episodes: 0.001883
[ADAPTIVE] Plateau counter: 227/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9316524   |
| time/                   |             |
|    fps                  | 1245        |
|    iterations           | 488         |
|    time_elapsed         | 1605        |
|    total_timesteps      | 1998848     |
| train/                  |             |
|    approx_kl            | 0.006325244 |
|    clip_fraction        | 0.072       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.7       |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.852      |
|    n_updates            | 8460        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 31.4        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 498 reward: -0.056174
[ADAPTIVE] Mean reward over last 20 episodes: -0.000468
[ADAPTIVE] Plateau counter: 228/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.80417925  |
| time/                   |             |
|    fps                  | 1245        |
|    iterations           | 489         |
|    time_elapsed         | 1608        |
|    total_timesteps      | 2002944     |
| train/                  |             |
|    approx_kl            | 0.008217538 |
|    clip_fraction        | 0.0776      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.7       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.83       |
|    n_updates            | 8475        |
|    policy_gradient_loss | -0.013      |
|    std                  | 31.5        |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 499 reward: 0.068972
[ADAPTIVE] Mean reward over last 20 episodes: 0.006415
[ADAPTIVE] Plateau counter: 229/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7056577   |
| time/                   |             |
|    fps                  | 1245        |
|    iterations           | 490         |
|    time_elapsed         | 1611        |
|    total_timesteps      | 2007040     |
| train/                  |             |
|    approx_kl            | 0.012049774 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.8       |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.862      |
|    n_updates            | 8490        |
|    policy_gradient_loss | -0.015      |
|    std                  | 31.6        |
|    value_loss           | 0.119       |
-----------------------------------------
[ADAPTIVE] Episode 500 reward: -0.101266
[ADAPTIVE] Mean reward over last 20 episodes: 0.005781
[ADAPTIVE] Plateau counter: 230/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8090074   |
| time/                   |             |
|    fps                  | 1245        |
|    iterations           | 491         |
|    time_elapsed         | 1614        |
|    total_timesteps      | 2011136     |
| train/                  |             |
|    approx_kl            | 0.009610781 |
|    clip_fraction        | 0.0846      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.8       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.851      |
|    n_updates            | 8505        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 31.9        |
|    value_loss           | 0.158       |
-----------------------------------------
[ADAPTIVE] Episode 501 reward: -0.016486
[ADAPTIVE] Mean reward over last 20 episodes: 0.004022
[ADAPTIVE] Plateau counter: 231/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.71173215  |
| time/                   |             |
|    fps                  | 1245        |
|    iterations           | 492         |
|    time_elapsed         | 1617        |
|    total_timesteps      | 2015232     |
| train/                  |             |
|    approx_kl            | 0.012926236 |
|    clip_fraction        | 0.0998      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.9       |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.834      |
|    n_updates            | 8520        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 32.1        |
|    value_loss           | 0.192       |
-----------------------------------------
[ADAPTIVE] Episode 502 reward: 0.085132
[ADAPTIVE] Mean reward over last 20 episodes: 0.007229
[ADAPTIVE] Plateau counter: 232/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76240295  |
| time/                   |             |
|    fps                  | 1246        |
|    iterations           | 493         |
|    time_elapsed         | 1620        |
|    total_timesteps      | 2019328     |
| train/                  |             |
|    approx_kl            | 0.009699661 |
|    clip_fraction        | 0.0759      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44         |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.826      |
|    n_updates            | 8535        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 32.3        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 503 reward: -0.103943
[ADAPTIVE] Mean reward over last 20 episodes: 0.002899
[ADAPTIVE] Plateau counter: 233/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7015958   |
| time/                   |             |
|    fps                  | 1246        |
|    iterations           | 494         |
|    time_elapsed         | 1623        |
|    total_timesteps      | 2023424     |
| train/                  |             |
|    approx_kl            | 0.009699842 |
|    clip_fraction        | 0.0932      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44         |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.859      |
|    n_updates            | 8550        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 32.5        |
|    value_loss           | 0.126       |
-----------------------------------------
[ADAPTIVE] Episode 504 reward: 0.005007
[ADAPTIVE] Mean reward over last 20 episodes: 0.001297
[ADAPTIVE] Plateau counter: 234/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.69378936  |
| time/                   |             |
|    fps                  | 1246        |
|    iterations           | 495         |
|    time_elapsed         | 1626        |
|    total_timesteps      | 2027520     |
| train/                  |             |
|    approx_kl            | 0.011153487 |
|    clip_fraction        | 0.084       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.1       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.891      |
|    n_updates            | 8565        |
|    policy_gradient_loss | -0.015      |
|    std                  | 32.7        |
|    value_loss           | 0.0979      |
-----------------------------------------
[ADAPTIVE] Episode 505 reward: 0.056167
[ADAPTIVE] Mean reward over last 20 episodes: 0.006514
[ADAPTIVE] Plateau counter: 235/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.72568023  |
| time/                   |             |
|    fps                  | 1246        |
|    iterations           | 496         |
|    time_elapsed         | 1629        |
|    total_timesteps      | 2031616     |
| train/                  |             |
|    approx_kl            | 0.009061144 |
|    clip_fraction        | 0.0768      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.1       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.867      |
|    n_updates            | 8580        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 32.9        |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 506 reward: -0.017966
[ADAPTIVE] Mean reward over last 20 episodes: 0.000407
[ADAPTIVE] Plateau counter: 236/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5751446   |
| time/                   |             |
|    fps                  | 1246        |
|    iterations           | 497         |
|    time_elapsed         | 1633        |
|    total_timesteps      | 2035712     |
| train/                  |             |
|    approx_kl            | 0.009912301 |
|    clip_fraction        | 0.0923      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.2       |
|    explained_variance   | 0.635       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.85       |
|    n_updates            | 8595        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 33.1        |
|    value_loss           | 0.251       |
-----------------------------------------
[ADAPTIVE] Episode 507 reward: 0.044826
[ADAPTIVE] Mean reward over last 20 episodes: -0.001971
[ADAPTIVE] Plateau counter: 237/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.46405697  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 498         |
|    time_elapsed         | 1635        |
|    total_timesteps      | 2039808     |
| train/                  |             |
|    approx_kl            | 0.009670131 |
|    clip_fraction        | 0.0974      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.2       |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.875      |
|    n_updates            | 8610        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 33.3        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 508 reward: -0.034101
[ADAPTIVE] Mean reward over last 20 episodes: -0.005242
[ADAPTIVE] Plateau counter: 238/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.40900698  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 499         |
|    time_elapsed         | 1638        |
|    total_timesteps      | 2043904     |
| train/                  |             |
|    approx_kl            | 0.009594513 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.3       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.849      |
|    n_updates            | 8625        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 33.4        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 509 reward: 0.082563
[ADAPTIVE] Mean reward over last 20 episodes: 0.000599
[ADAPTIVE] Plateau counter: 239/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.37868407  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 500         |
|    time_elapsed         | 1642        |
|    total_timesteps      | 2048000     |
| train/                  |             |
|    approx_kl            | 0.008610786 |
|    clip_fraction        | 0.0808      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.3       |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.851      |
|    n_updates            | 8640        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 33.5        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 510 reward: -0.054315
[ADAPTIVE] Mean reward over last 20 episodes: -0.005145
[ADAPTIVE] Plateau counter: 240/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47868648  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 501         |
|    time_elapsed         | 1645        |
|    total_timesteps      | 2052096     |
| train/                  |             |
|    approx_kl            | 0.008141521 |
|    clip_fraction        | 0.0896      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.3       |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.852      |
|    n_updates            | 8655        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 33.6        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 511 reward: -0.026976
[ADAPTIVE] Mean reward over last 20 episodes: -0.003840
[ADAPTIVE] Plateau counter: 241/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 512 reward: 0.053057
[ADAPTIVE] Mean reward over last 20 episodes: 0.002818
[ADAPTIVE] Plateau counter: 242/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.40943477  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 502         |
|    time_elapsed         | 1648        |
|    total_timesteps      | 2056192     |
| train/                  |             |
|    approx_kl            | 0.011476645 |
|    clip_fraction        | 0.0741      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.4       |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.864      |
|    n_updates            | 8670        |
|    policy_gradient_loss | -0.0124     |
|    std                  | 33.7        |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 513 reward: -0.055920
[ADAPTIVE] Mean reward over last 20 episodes: 0.001711
[ADAPTIVE] Plateau counter: 243/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.36422822  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 503         |
|    time_elapsed         | 1651        |
|    total_timesteps      | 2060288     |
| train/                  |             |
|    approx_kl            | 0.007526016 |
|    clip_fraction        | 0.0796      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.4       |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.834      |
|    n_updates            | 8685        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 33.8        |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 514 reward: 0.094368
[ADAPTIVE] Mean reward over last 20 episodes: 0.001167
[ADAPTIVE] Plateau counter: 244/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.66799754  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 504         |
|    time_elapsed         | 1655        |
|    total_timesteps      | 2064384     |
| train/                  |             |
|    approx_kl            | 0.008433103 |
|    clip_fraction        | 0.0892      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.4       |
|    explained_variance   | 0.831       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.874      |
|    n_updates            | 8700        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 34          |
|    value_loss           | 0.0968      |
-----------------------------------------
[ADAPTIVE] Episode 515 reward: -0.067768
[ADAPTIVE] Mean reward over last 20 episodes: -0.006434
[ADAPTIVE] Plateau counter: 245/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5476436    |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 505          |
|    time_elapsed         | 1658         |
|    total_timesteps      | 2068480      |
| train/                  |              |
|    approx_kl            | 0.0060755946 |
|    clip_fraction        | 0.0705       |
|    clip_range           | 0.2          |
|    entropy_loss         | -44.5        |
|    explained_variance   | 0.694        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.776       |
|    n_updates            | 8715         |
|    policy_gradient_loss | -0.01        |
|    std                  | 34.1         |
|    value_loss           | 0.253        |
------------------------------------------
[ADAPTIVE] Episode 516 reward: 0.012245
[ADAPTIVE] Mean reward over last 20 episodes: -0.000378
[ADAPTIVE] Plateau counter: 246/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.50738615  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 506         |
|    time_elapsed         | 1661        |
|    total_timesteps      | 2072576     |
| train/                  |             |
|    approx_kl            | 0.012365762 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.5       |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.862      |
|    n_updates            | 8730        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 34.3        |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 517 reward: 0.010144
[ADAPTIVE] Mean reward over last 20 episodes: -0.001122
[ADAPTIVE] Plateau counter: 247/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.43803543 |
| time/                   |            |
|    fps                  | 1247       |
|    iterations           | 507        |
|    time_elapsed         | 1664       |
|    total_timesteps      | 2076672    |
| train/                  |            |
|    approx_kl            | 0.00871418 |
|    clip_fraction        | 0.0784     |
|    clip_range           | 0.2        |
|    entropy_loss         | -44.6      |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.837     |
|    n_updates            | 8745       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 34.5       |
|    value_loss           | 0.169      |
----------------------------------------
[ADAPTIVE] Episode 518 reward: 0.002101
[ADAPTIVE] Mean reward over last 20 episodes: 0.001792
[ADAPTIVE] Plateau counter: 248/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.43208635  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 508         |
|    time_elapsed         | 1667        |
|    total_timesteps      | 2080768     |
| train/                  |             |
|    approx_kl            | 0.009338785 |
|    clip_fraction        | 0.0909      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.6       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.862      |
|    n_updates            | 8760        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 34.7        |
|    value_loss           | 0.205       |
-----------------------------------------
[ADAPTIVE] Episode 519 reward: -0.066564
[ADAPTIVE] Mean reward over last 20 episodes: -0.004985
[ADAPTIVE] Plateau counter: 249/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.57461053  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 509         |
|    time_elapsed         | 1670        |
|    total_timesteps      | 2084864     |
| train/                  |             |
|    approx_kl            | 0.008423874 |
|    clip_fraction        | 0.081       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.7       |
|    explained_variance   | 0.777       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.883      |
|    n_updates            | 8775        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 34.8        |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 520 reward: 0.007707
[ADAPTIVE] Mean reward over last 20 episodes: 0.000464
[ADAPTIVE] Plateau counter: 250/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5955277   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 510         |
|    time_elapsed         | 1673        |
|    total_timesteps      | 2088960     |
| train/                  |             |
|    approx_kl            | 0.008032864 |
|    clip_fraction        | 0.0771      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.7       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.869      |
|    n_updates            | 8790        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 35.1        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 521 reward: -0.003778
[ADAPTIVE] Mean reward over last 20 episodes: 0.001099
[ADAPTIVE] Plateau counter: 251/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4385496   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 511         |
|    time_elapsed         | 1676        |
|    total_timesteps      | 2093056     |
| train/                  |             |
|    approx_kl            | 0.010104433 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.8       |
|    explained_variance   | 0.788       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.855      |
|    n_updates            | 8805        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 35.4        |
|    value_loss           | 0.177       |
-----------------------------------------
[ADAPTIVE] Episode 522 reward: -0.064606
[ADAPTIVE] Mean reward over last 20 episodes: -0.006387
[ADAPTIVE] Plateau counter: 252/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.62355256  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 512         |
|    time_elapsed         | 1680        |
|    total_timesteps      | 2097152     |
| train/                  |             |
|    approx_kl            | 0.009221655 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.8       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.885      |
|    n_updates            | 8820        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 35.6        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 523 reward: -0.010698
[ADAPTIVE] Mean reward over last 20 episodes: -0.001725
[ADAPTIVE] Plateau counter: 253/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6922206    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 513          |
|    time_elapsed         | 1683         |
|    total_timesteps      | 2101248      |
| train/                  |              |
|    approx_kl            | 0.0063987556 |
|    clip_fraction        | 0.0615       |
|    clip_range           | 0.2          |
|    entropy_loss         | -44.9        |
|    explained_variance   | 0.775        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.863       |
|    n_updates            | 8835         |
|    policy_gradient_loss | -0.0121      |
|    std                  | 35.7         |
|    value_loss           | 0.134        |
------------------------------------------
[ADAPTIVE] Episode 524 reward: -0.105050
[ADAPTIVE] Mean reward over last 20 episodes: -0.007228
[ADAPTIVE] Plateau counter: 254/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.86477476  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 514         |
|    time_elapsed         | 1686        |
|    total_timesteps      | 2105344     |
| train/                  |             |
|    approx_kl            | 0.010427018 |
|    clip_fraction        | 0.0985      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.9       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.889      |
|    n_updates            | 8850        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 35.9        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 525 reward: 0.112356
[ADAPTIVE] Mean reward over last 20 episodes: -0.004419
[ADAPTIVE] Plateau counter: 255/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6899487    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 515          |
|    time_elapsed         | 1690         |
|    total_timesteps      | 2109440      |
| train/                  |              |
|    approx_kl            | 0.0074061174 |
|    clip_fraction        | 0.0732       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45          |
|    explained_variance   | 0.814        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.859       |
|    n_updates            | 8865         |
|    policy_gradient_loss | -0.0122      |
|    std                  | 36.1         |
|    value_loss           | 0.155        |
------------------------------------------
[ADAPTIVE] Episode 526 reward: -0.024050
[ADAPTIVE] Mean reward over last 20 episodes: -0.004723
[ADAPTIVE] Plateau counter: 256/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7509239   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 516         |
|    time_elapsed         | 1692        |
|    total_timesteps      | 2113536     |
| train/                  |             |
|    approx_kl            | 0.009783968 |
|    clip_fraction        | 0.0916      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45         |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.857      |
|    n_updates            | 8880        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 36.3        |
|    value_loss           | 0.263       |
-----------------------------------------
[ADAPTIVE] Episode 527 reward: 0.039520
[ADAPTIVE] Mean reward over last 20 episodes: -0.004988
[ADAPTIVE] Plateau counter: 257/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8891468   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 517         |
|    time_elapsed         | 1696        |
|    total_timesteps      | 2117632     |
| train/                  |             |
|    approx_kl            | 0.007031687 |
|    clip_fraction        | 0.0831      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.1       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.836      |
|    n_updates            | 8895        |
|    policy_gradient_loss | -0.0115     |
|    std                  | 36.5        |
|    value_loss           | 0.237       |
-----------------------------------------
[ADAPTIVE] Episode 528 reward: 0.089418
[ADAPTIVE] Mean reward over last 20 episodes: 0.001188
[ADAPTIVE] Plateau counter: 258/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8749246   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 518         |
|    time_elapsed         | 1699        |
|    total_timesteps      | 2121728     |
| train/                  |             |
|    approx_kl            | 0.007798419 |
|    clip_fraction        | 0.0831      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.1       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.883      |
|    n_updates            | 8910        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 36.7        |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 529 reward: -0.000749
[ADAPTIVE] Mean reward over last 20 episodes: -0.002978
[ADAPTIVE] Plateau counter: 259/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84158134  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 519         |
|    time_elapsed         | 1702        |
|    total_timesteps      | 2125824     |
| train/                  |             |
|    approx_kl            | 0.007780249 |
|    clip_fraction        | 0.0736      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.1       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.881      |
|    n_updates            | 8925        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 36.7        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 530 reward: 0.042015
[ADAPTIVE] Mean reward over last 20 episodes: 0.001839
[ADAPTIVE] Plateau counter: 260/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.75273657  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 520         |
|    time_elapsed         | 1705        |
|    total_timesteps      | 2129920     |
| train/                  |             |
|    approx_kl            | 0.008649753 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.2       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.854      |
|    n_updates            | 8940        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 36.9        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 531 reward: 0.056777
[ADAPTIVE] Mean reward over last 20 episodes: 0.006026
[ADAPTIVE] Plateau counter: 261/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6672714    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 521          |
|    time_elapsed         | 1708         |
|    total_timesteps      | 2134016      |
| train/                  |              |
|    approx_kl            | 0.0075862124 |
|    clip_fraction        | 0.0978       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45.2        |
|    explained_variance   | 0.716        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.856       |
|    n_updates            | 8955         |
|    policy_gradient_loss | -0.0119      |
|    std                  | 37.3         |
|    value_loss           | 0.207        |
------------------------------------------
[ADAPTIVE] Episode 532 reward: -0.010665
[ADAPTIVE] Mean reward over last 20 episodes: 0.002840
[ADAPTIVE] Plateau counter: 262/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.55613405  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 522         |
|    time_elapsed         | 1712        |
|    total_timesteps      | 2138112     |
| train/                  |             |
|    approx_kl            | 0.008522298 |
|    clip_fraction        | 0.0684      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.3       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.886      |
|    n_updates            | 8970        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 37.5        |
|    value_loss           | 0.129       |
-----------------------------------------
[ADAPTIVE] Episode 533 reward: -0.082181
[ADAPTIVE] Mean reward over last 20 episodes: 0.001527
[ADAPTIVE] Plateau counter: 263/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.66520673  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 523         |
|    time_elapsed         | 1715        |
|    total_timesteps      | 2142208     |
| train/                  |             |
|    approx_kl            | 0.009387746 |
|    clip_fraction        | 0.0921      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.3       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.882      |
|    n_updates            | 8985        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 37.6        |
|    value_loss           | 0.0909      |
-----------------------------------------
[ADAPTIVE] Episode 534 reward: 0.011766
[ADAPTIVE] Mean reward over last 20 episodes: -0.002603
[ADAPTIVE] Plateau counter: 264/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.79241395  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 524         |
|    time_elapsed         | 1719        |
|    total_timesteps      | 2146304     |
| train/                  |             |
|    approx_kl            | 0.010570595 |
|    clip_fraction        | 0.0922      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.4       |
|    explained_variance   | 0.777       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.874      |
|    n_updates            | 9000        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 37.9        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 535 reward: -0.030404
[ADAPTIVE] Mean reward over last 20 episodes: -0.000735
[ADAPTIVE] Plateau counter: 265/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6778996   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 525         |
|    time_elapsed         | 1721        |
|    total_timesteps      | 2150400     |
| train/                  |             |
|    approx_kl            | 0.012302611 |
|    clip_fraction        | 0.0768      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.4       |
|    explained_variance   | 0.78        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.888      |
|    n_updates            | 9015        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 38          |
|    value_loss           | 0.122       |
-----------------------------------------
[ADAPTIVE] Episode 536 reward: 0.003714
[ADAPTIVE] Mean reward over last 20 episodes: -0.001161
[ADAPTIVE] Plateau counter: 266/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7890067   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 526         |
|    time_elapsed         | 1725        |
|    total_timesteps      | 2154496     |
| train/                  |             |
|    approx_kl            | 0.010551935 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.5       |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.855      |
|    n_updates            | 9030        |
|    policy_gradient_loss | -0.014      |
|    std                  | 38.1        |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 537 reward: 0.074166
[ADAPTIVE] Mean reward over last 20 episodes: 0.002040
[ADAPTIVE] Plateau counter: 267/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76648986  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 527         |
|    time_elapsed         | 1728        |
|    total_timesteps      | 2158592     |
| train/                  |             |
|    approx_kl            | 0.009687636 |
|    clip_fraction        | 0.0851      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.5       |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.893      |
|    n_updates            | 9045        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 38.3        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 538 reward: -0.052080
[ADAPTIVE] Mean reward over last 20 episodes: -0.000669
[ADAPTIVE] Plateau counter: 268/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.87380254  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 528         |
|    time_elapsed         | 1731        |
|    total_timesteps      | 2162688     |
| train/                  |             |
|    approx_kl            | 0.008963572 |
|    clip_fraction        | 0.0746      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.5       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.894      |
|    n_updates            | 9060        |
|    policy_gradient_loss | -0.017      |
|    std                  | 38.6        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 539 reward: 0.027660
[ADAPTIVE] Mean reward over last 20 episodes: 0.004042
[ADAPTIVE] Plateau counter: 269/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8399896   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 529         |
|    time_elapsed         | 1735        |
|    total_timesteps      | 2166784     |
| train/                  |             |
|    approx_kl            | 0.009077314 |
|    clip_fraction        | 0.0952      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.6       |
|    explained_variance   | 0.719       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.881      |
|    n_updates            | 9075        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 38.7        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 540 reward: 0.011154
[ADAPTIVE] Mean reward over last 20 episodes: 0.004214
[ADAPTIVE] Plateau counter: 270/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84294516  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 530         |
|    time_elapsed         | 1738        |
|    total_timesteps      | 2170880     |
| train/                  |             |
|    approx_kl            | 0.008977994 |
|    clip_fraction        | 0.0921      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.6       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.883      |
|    n_updates            | 9090        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 38.9        |
|    value_loss           | 0.0921      |
-----------------------------------------
[ADAPTIVE] Episode 541 reward: 0.118482
[ADAPTIVE] Mean reward over last 20 episodes: 0.010327
[ADAPTIVE] Plateau counter: 271/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.94549096  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 531         |
|    time_elapsed         | 1742        |
|    total_timesteps      | 2174976     |
| train/                  |             |
|    approx_kl            | 0.007822882 |
|    clip_fraction        | 0.0905      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.7       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.887      |
|    n_updates            | 9105        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 39.2        |
|    value_loss           | 0.207       |
-----------------------------------------
[ADAPTIVE] Episode 542 reward: -0.070975
[ADAPTIVE] Mean reward over last 20 episodes: 0.010009
[ADAPTIVE] Plateau counter: 272/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.95081884  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 532         |
|    time_elapsed         | 1744        |
|    total_timesteps      | 2179072     |
| train/                  |             |
|    approx_kl            | 0.009161271 |
|    clip_fraction        | 0.0966      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.7       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.845      |
|    n_updates            | 9120        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 39.4        |
|    value_loss           | 0.164       |
-----------------------------------------
[ADAPTIVE] Episode 543 reward: -0.025291
[ADAPTIVE] Mean reward over last 20 episodes: 0.009279
[ADAPTIVE] Plateau counter: 273/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.854512    |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 533         |
|    time_elapsed         | 1748        |
|    total_timesteps      | 2183168     |
| train/                  |             |
|    approx_kl            | 0.009440463 |
|    clip_fraction        | 0.0858      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.8       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.909      |
|    n_updates            | 9135        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 39.5        |
|    value_loss           | 0.1         |
-----------------------------------------
[ADAPTIVE] Episode 544 reward: -0.033997
[ADAPTIVE] Mean reward over last 20 episodes: 0.012832
[ADAPTIVE] Plateau counter: 274/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.941361    |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 534         |
|    time_elapsed         | 1751        |
|    total_timesteps      | 2187264     |
| train/                  |             |
|    approx_kl            | 0.008332243 |
|    clip_fraction        | 0.0795      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.8       |
|    explained_variance   | 0.697       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.866      |
|    n_updates            | 9150        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 39.7        |
|    value_loss           | 0.266       |
-----------------------------------------
[ADAPTIVE] Episode 545 reward: 0.090832
[ADAPTIVE] Mean reward over last 20 episodes: 0.011756
[ADAPTIVE] Plateau counter: 275/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8006649    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 535          |
|    time_elapsed         | 1755         |
|    total_timesteps      | 2191360      |
| train/                  |              |
|    approx_kl            | 0.0093584135 |
|    clip_fraction        | 0.0979       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45.8        |
|    explained_variance   | 0.722        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.901       |
|    n_updates            | 9165         |
|    policy_gradient_loss | -0.0174      |
|    std                  | 39.9         |
|    value_loss           | 0.122        |
------------------------------------------
[ADAPTIVE] Episode 546 reward: -0.006708
[ADAPTIVE] Mean reward over last 20 episodes: 0.012623
[ADAPTIVE] Plateau counter: 276/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.74076      |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 536          |
|    time_elapsed         | 1758         |
|    total_timesteps      | 2195456      |
| train/                  |              |
|    approx_kl            | 0.0087563135 |
|    clip_fraction        | 0.0803       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45.9        |
|    explained_variance   | 0.738        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.893       |
|    n_updates            | 9180         |
|    policy_gradient_loss | -0.0131      |
|    std                  | 40.1         |
|    value_loss           | 0.157        |
------------------------------------------
[ADAPTIVE] Episode 547 reward: -0.031503
[ADAPTIVE] Mean reward over last 20 episodes: 0.009072
[ADAPTIVE] Plateau counter: 277/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5902127   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 537         |
|    time_elapsed         | 1761        |
|    total_timesteps      | 2199552     |
| train/                  |             |
|    approx_kl            | 0.008971745 |
|    clip_fraction        | 0.0969      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.9       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.894      |
|    n_updates            | 9195        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 40.1        |
|    value_loss           | 0.121       |
-----------------------------------------
[ADAPTIVE] Episode 548 reward: 0.119264
[ADAPTIVE] Mean reward over last 20 episodes: 0.010564
[ADAPTIVE] Plateau counter: 278/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.46130145 |
| time/                   |            |
|    fps                  | 1248       |
|    iterations           | 538        |
|    time_elapsed         | 1764       |
|    total_timesteps      | 2203648    |
| train/                  |            |
|    approx_kl            | 0.00895224 |
|    clip_fraction        | 0.0746     |
|    clip_range           | 0.2        |
|    entropy_loss         | -45.9      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.877     |
|    n_updates            | 9210       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 40.3       |
|    value_loss           | 0.163      |
----------------------------------------
[ADAPTIVE] Episode 549 reward: -0.035510
[ADAPTIVE] Mean reward over last 20 episodes: 0.008826
[ADAPTIVE] Plateau counter: 279/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.546037    |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 539         |
|    time_elapsed         | 1768        |
|    total_timesteps      | 2207744     |
| train/                  |             |
|    approx_kl            | 0.008811594 |
|    clip_fraction        | 0.095       |
|    clip_range           | 0.2         |
|    entropy_loss         | -46         |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.909      |
|    n_updates            | 9225        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 40.5        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 550 reward: -0.029866
[ADAPTIVE] Mean reward over last 20 episodes: 0.005232
[ADAPTIVE] Plateau counter: 280/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.53935486   |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 540          |
|    time_elapsed         | 1771         |
|    total_timesteps      | 2211840      |
| train/                  |              |
|    approx_kl            | 0.0085300915 |
|    clip_fraction        | 0.0889       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46          |
|    explained_variance   | 0.815        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.913       |
|    n_updates            | 9240         |
|    policy_gradient_loss | -0.0171      |
|    std                  | 40.8         |
|    value_loss           | 0.102        |
------------------------------------------
[ADAPTIVE] Episode 551 reward: -0.055738
[ADAPTIVE] Mean reward over last 20 episodes: -0.000394
[ADAPTIVE] Plateau counter: 281/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6684269    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 541          |
|    time_elapsed         | 1775         |
|    total_timesteps      | 2215936      |
| train/                  |              |
|    approx_kl            | 0.0068043945 |
|    clip_fraction        | 0.0816       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.1        |
|    explained_variance   | 0.772        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.885       |
|    n_updates            | 9255         |
|    policy_gradient_loss | -0.0108      |
|    std                  | 41.1         |
|    value_loss           | 0.189        |
------------------------------------------
[ADAPTIVE] Episode 552 reward: -0.001470
[ADAPTIVE] Mean reward over last 20 episodes: 0.000066
[ADAPTIVE] Plateau counter: 282/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.86091006  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 542         |
|    time_elapsed         | 1778        |
|    total_timesteps      | 2220032     |
| train/                  |             |
|    approx_kl            | 0.008511735 |
|    clip_fraction        | 0.0736      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.2       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.889      |
|    n_updates            | 9270        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 41.3        |
|    value_loss           | 0.137       |
-----------------------------------------
[ADAPTIVE] Episode 553 reward: 0.090127
[ADAPTIVE] Mean reward over last 20 episodes: 0.008681
[ADAPTIVE] Plateau counter: 283/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8562543   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 543         |
|    time_elapsed         | 1781        |
|    total_timesteps      | 2224128     |
| train/                  |             |
|    approx_kl            | 0.008288238 |
|    clip_fraction        | 0.0732      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.2       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.926      |
|    n_updates            | 9285        |
|    policy_gradient_loss | -0.017      |
|    std                  | 41.6        |
|    value_loss           | 0.098       |
-----------------------------------------
[ADAPTIVE] Episode 554 reward: 0.082028
[ADAPTIVE] Mean reward over last 20 episodes: 0.012194
[ADAPTIVE] Plateau counter: 284/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.85115135  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 544         |
|    time_elapsed         | 1784        |
|    total_timesteps      | 2228224     |
| train/                  |             |
|    approx_kl            | 0.007973425 |
|    clip_fraction        | 0.0621      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.2       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.904      |
|    n_updates            | 9300        |
|    policy_gradient_loss | -0.0132     |
|    std                  | 41.7        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 555 reward: -0.038380
[ADAPTIVE] Mean reward over last 20 episodes: 0.011795
[ADAPTIVE] Plateau counter: 285/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.92643434  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 545         |
|    time_elapsed         | 1787        |
|    total_timesteps      | 2232320     |
| train/                  |             |
|    approx_kl            | 0.008740038 |
|    clip_fraction        | 0.0876      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.3       |
|    explained_variance   | 0.632       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.892      |
|    n_updates            | 9315        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 41.9        |
|    value_loss           | 0.198       |
-----------------------------------------
[ADAPTIVE] Episode 556 reward: 0.029364
[ADAPTIVE] Mean reward over last 20 episodes: 0.013078
[ADAPTIVE] Plateau counter: 286/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84890664  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 546         |
|    time_elapsed         | 1791        |
|    total_timesteps      | 2236416     |
| train/                  |             |
|    approx_kl            | 0.008498838 |
|    clip_fraction        | 0.0967      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.3       |
|    explained_variance   | 0.803       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.915      |
|    n_updates            | 9330        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 42          |
|    value_loss           | 0.0893      |
-----------------------------------------
[ADAPTIVE] Episode 557 reward: -0.010261
[ADAPTIVE] Mean reward over last 20 episodes: 0.008857
[ADAPTIVE] Plateau counter: 287/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.75404     |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 547         |
|    time_elapsed         | 1794        |
|    total_timesteps      | 2240512     |
| train/                  |             |
|    approx_kl            | 0.008902415 |
|    clip_fraction        | 0.0736      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.3       |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.899      |
|    n_updates            | 9345        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 42.1        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 558 reward: -0.048906
[ADAPTIVE] Mean reward over last 20 episodes: 0.009015
[ADAPTIVE] Plateau counter: 288/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6072313   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 548         |
|    time_elapsed         | 1798        |
|    total_timesteps      | 2244608     |
| train/                  |             |
|    approx_kl            | 0.010346852 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.4       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.925      |
|    n_updates            | 9360        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 42.4        |
|    value_loss           | 0.0897      |
-----------------------------------------
[ADAPTIVE] Episode 559 reward: -0.113805
[ADAPTIVE] Mean reward over last 20 episodes: 0.001942
[ADAPTIVE] Plateau counter: 289/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6387819   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 549         |
|    time_elapsed         | 1801        |
|    total_timesteps      | 2248704     |
| train/                  |             |
|    approx_kl            | 0.008137131 |
|    clip_fraction        | 0.0947      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.4       |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.897      |
|    n_updates            | 9375        |
|    policy_gradient_loss | -0.011      |
|    std                  | 42.6        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 560 reward: 0.088227
[ADAPTIVE] Mean reward over last 20 episodes: 0.005796
[ADAPTIVE] Plateau counter: 290/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6828258   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 550         |
|    time_elapsed         | 1804        |
|    total_timesteps      | 2252800     |
| train/                  |             |
|    approx_kl            | 0.010960683 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.5       |
|    explained_variance   | 0.777       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.9        |
|    n_updates            | 9390        |
|    policy_gradient_loss | -0.0186     |
|    std                  | 42.8        |
|    value_loss           | 0.134       |
-----------------------------------------
[ADAPTIVE] Episode 561 reward: -0.002136
[ADAPTIVE] Mean reward over last 20 episodes: -0.000235
[ADAPTIVE] Plateau counter: 291/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7773674   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 551         |
|    time_elapsed         | 1807        |
|    total_timesteps      | 2256896     |
| train/                  |             |
|    approx_kl            | 0.009030434 |
|    clip_fraction        | 0.0689      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.5       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.881      |
|    n_updates            | 9405        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 43          |
|    value_loss           | 0.183       |
-----------------------------------------
[ADAPTIVE] Episode 562 reward: -0.033476
[ADAPTIVE] Mean reward over last 20 episodes: 0.001640
[ADAPTIVE] Plateau counter: 292/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8300319   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 552         |
|    time_elapsed         | 1811        |
|    total_timesteps      | 2260992     |
| train/                  |             |
|    approx_kl            | 0.008089545 |
|    clip_fraction        | 0.065       |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.6       |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.893      |
|    n_updates            | 9420        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 43.2        |
|    value_loss           | 0.179       |
-----------------------------------------
[ADAPTIVE] Episode 563 reward: 0.010104
[ADAPTIVE] Mean reward over last 20 episodes: 0.003410
[ADAPTIVE] Plateau counter: 293/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 564 reward: -0.103146
[ADAPTIVE] Mean reward over last 20 episodes: -0.000048
[ADAPTIVE] Plateau counter: 294/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.974312    |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 553         |
|    time_elapsed         | 1814        |
|    total_timesteps      | 2265088     |
| train/                  |             |
|    approx_kl            | 0.010423247 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.6       |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.929      |
|    n_updates            | 9435        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 43.5        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 565 reward: 0.015329
[ADAPTIVE] Mean reward over last 20 episodes: -0.003823
[ADAPTIVE] Plateau counter: 295/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1248723   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 554         |
|    time_elapsed         | 1818        |
|    total_timesteps      | 2269184     |
| train/                  |             |
|    approx_kl            | 0.008502324 |
|    clip_fraction        | 0.0967      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.6       |
|    explained_variance   | 0.667       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.914      |
|    n_updates            | 9450        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 43.6        |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 566 reward: -0.064342
[ADAPTIVE] Mean reward over last 20 episodes: -0.006705
[ADAPTIVE] Plateau counter: 296/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0953435    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 555          |
|    time_elapsed         | 1821         |
|    total_timesteps      | 2273280      |
| train/                  |              |
|    approx_kl            | 0.0074279644 |
|    clip_fraction        | 0.0766       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.7        |
|    explained_variance   | 0.69         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.882       |
|    n_updates            | 9465         |
|    policy_gradient_loss | -0.0128      |
|    std                  | 44           |
|    value_loss           | 0.237        |
------------------------------------------
[ADAPTIVE] Episode 567 reward: -0.022466
[ADAPTIVE] Mean reward over last 20 episodes: -0.006253
[ADAPTIVE] Plateau counter: 297/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1208556   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 556         |
|    time_elapsed         | 1824        |
|    total_timesteps      | 2277376     |
| train/                  |             |
|    approx_kl            | 0.008786134 |
|    clip_fraction        | 0.0692      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.8       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.913      |
|    n_updates            | 9480        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 44.3        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 568 reward: -0.062660
[ADAPTIVE] Mean reward over last 20 episodes: -0.015349
[ADAPTIVE] Plateau counter: 298/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.186812    |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 557         |
|    time_elapsed         | 1827        |
|    total_timesteps      | 2281472     |
| train/                  |             |
|    approx_kl            | 0.008960378 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.8       |
|    explained_variance   | 0.8         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.925      |
|    n_updates            | 9495        |
|    policy_gradient_loss | -0.0151     |
|    std                  | 44.5        |
|    value_loss           | 0.0991      |
-----------------------------------------
[ADAPTIVE] Episode 569 reward: -0.074640
[ADAPTIVE] Mean reward over last 20 episodes: -0.017306
[ADAPTIVE] Plateau counter: 299/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9008174    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 558          |
|    time_elapsed         | 1831         |
|    total_timesteps      | 2285568      |
| train/                  |              |
|    approx_kl            | 0.0056250067 |
|    clip_fraction        | 0.054        |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.9        |
|    explained_variance   | 0.757        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.902       |
|    n_updates            | 9510         |
|    policy_gradient_loss | -0.0118      |
|    std                  | 44.7         |
|    value_loss           | 0.171        |
------------------------------------------
[ADAPTIVE] Episode 570 reward: -0.040225
[ADAPTIVE] Mean reward over last 20 episodes: -0.017824
[ADAPTIVE] Plateau counter: 300/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0360541    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 559          |
|    time_elapsed         | 1834         |
|    total_timesteps      | 2289664      |
| train/                  |              |
|    approx_kl            | 0.0074084313 |
|    clip_fraction        | 0.0674       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.9        |
|    explained_variance   | 0.651        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.905       |
|    n_updates            | 9525         |
|    policy_gradient_loss | -0.0117      |
|    std                  | 44.8         |
|    value_loss           | 0.21         |
------------------------------------------
[ADAPTIVE] Episode 571 reward: 0.131540
[ADAPTIVE] Mean reward over last 20 episodes: -0.008460
[ADAPTIVE] Plateau counter: 301/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.81126654   |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 560          |
|    time_elapsed         | 1837         |
|    total_timesteps      | 2293760      |
| train/                  |              |
|    approx_kl            | 0.0071010934 |
|    clip_fraction        | 0.0781       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.9        |
|    explained_variance   | 0.82         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.931       |
|    n_updates            | 9540         |
|    policy_gradient_loss | -0.0125      |
|    std                  | 44.9         |
|    value_loss           | 0.104        |
------------------------------------------
[ADAPTIVE] Episode 572 reward: -0.000503
[ADAPTIVE] Mean reward over last 20 episodes: -0.008411
[ADAPTIVE] Plateau counter: 302/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7971849    |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 561          |
|    time_elapsed         | 1841         |
|    total_timesteps      | 2297856      |
| train/                  |              |
|    approx_kl            | 0.0073408843 |
|    clip_fraction        | 0.0688       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.9        |
|    explained_variance   | 0.783        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.882       |
|    n_updates            | 9555         |
|    policy_gradient_loss | -0.0125      |
|    std                  | 45.2         |
|    value_loss           | 0.199        |
------------------------------------------
[ADAPTIVE] Episode 573 reward: -0.006287
[ADAPTIVE] Mean reward over last 20 episodes: -0.013232
[ADAPTIVE] Plateau counter: 303/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5832577   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 562         |
|    time_elapsed         | 1844        |
|    total_timesteps      | 2301952     |
| train/                  |             |
|    approx_kl            | 0.009152915 |
|    clip_fraction        | 0.0678      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47         |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.927      |
|    n_updates            | 9570        |
|    policy_gradient_loss | -0.0125     |
|    std                  | 45.3        |
|    value_loss           | 0.0885      |
-----------------------------------------
[ADAPTIVE] Episode 574 reward: 0.165965
[ADAPTIVE] Mean reward over last 20 episodes: -0.009035
[ADAPTIVE] Plateau counter: 304/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.43353897  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 563         |
|    time_elapsed         | 1848        |
|    total_timesteps      | 2306048     |
| train/                  |             |
|    approx_kl            | 0.006021276 |
|    clip_fraction        | 0.0632      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47         |
|    explained_variance   | 0.857       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.931      |
|    n_updates            | 9585        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 45.5        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 575 reward: 0.061612
[ADAPTIVE] Mean reward over last 20 episodes: -0.004036
[ADAPTIVE] Plateau counter: 305/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6473993    |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 564          |
|    time_elapsed         | 1851         |
|    total_timesteps      | 2310144      |
| train/                  |              |
|    approx_kl            | 0.0067431424 |
|    clip_fraction        | 0.0746       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47          |
|    explained_variance   | 0.86         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.933       |
|    n_updates            | 9600         |
|    policy_gradient_loss | -0.00976     |
|    std                  | 45.5         |
|    value_loss           | 0.108        |
------------------------------------------
[ADAPTIVE] Episode 576 reward: -0.121809
[ADAPTIVE] Mean reward over last 20 episodes: -0.011594
[ADAPTIVE] Plateau counter: 306/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6273731    |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 565          |
|    time_elapsed         | 1854         |
|    total_timesteps      | 2314240      |
| train/                  |              |
|    approx_kl            | 0.0071255057 |
|    clip_fraction        | 0.0758       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47          |
|    explained_variance   | 0.786        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.935       |
|    n_updates            | 9615         |
|    policy_gradient_loss | -0.0137      |
|    std                  | 45.6         |
|    value_loss           | 0.116        |
------------------------------------------
[ADAPTIVE] Episode 577 reward: -0.043581
[ADAPTIVE] Mean reward over last 20 episodes: -0.013260
[ADAPTIVE] Plateau counter: 307/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.56942326  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 566         |
|    time_elapsed         | 1858        |
|    total_timesteps      | 2318336     |
| train/                  |             |
|    approx_kl            | 0.006087699 |
|    clip_fraction        | 0.069       |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.1       |
|    explained_variance   | 0.78        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.897      |
|    n_updates            | 9630        |
|    policy_gradient_loss | -0.012      |
|    std                  | 45.8        |
|    value_loss           | 0.185       |
-----------------------------------------
[ADAPTIVE] Episode 578 reward: -0.012767
[ADAPTIVE] Mean reward over last 20 episodes: -0.011453
[ADAPTIVE] Plateau counter: 308/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5356238    |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 567          |
|    time_elapsed         | 1861         |
|    total_timesteps      | 2322432      |
| train/                  |              |
|    approx_kl            | 0.0088891275 |
|    clip_fraction        | 0.0855       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.1        |
|    explained_variance   | 0.779        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.928       |
|    n_updates            | 9645         |
|    policy_gradient_loss | -0.0126      |
|    std                  | 45.9         |
|    value_loss           | 0.103        |
------------------------------------------
[ADAPTIVE] Episode 579 reward: 0.029550
[ADAPTIVE] Mean reward over last 20 episodes: -0.004285
[ADAPTIVE] Plateau counter: 309/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.63942087  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 568         |
|    time_elapsed         | 1864        |
|    total_timesteps      | 2326528     |
| train/                  |             |
|    approx_kl            | 0.008311128 |
|    clip_fraction        | 0.0994      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.1       |
|    explained_variance   | 0.733       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.907      |
|    n_updates            | 9660        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 45.9        |
|    value_loss           | 0.171       |
-----------------------------------------
[ADAPTIVE] Episode 580 reward: 0.092602
[ADAPTIVE] Mean reward over last 20 episodes: -0.004067
[ADAPTIVE] Plateau counter: 310/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.690118    |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 569         |
|    time_elapsed         | 1867        |
|    total_timesteps      | 2330624     |
| train/                  |             |
|    approx_kl            | 0.008112269 |
|    clip_fraction        | 0.0654      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.1       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.876      |
|    n_updates            | 9675        |
|    policy_gradient_loss | -0.013      |
|    std                  | 46.1        |
|    value_loss           | 0.225       |
-----------------------------------------
[ADAPTIVE] Episode 581 reward: -0.038140
[ADAPTIVE] Mean reward over last 20 episodes: -0.005867
[ADAPTIVE] Plateau counter: 311/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.63854563  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 570         |
|    time_elapsed         | 1871        |
|    total_timesteps      | 2334720     |
| train/                  |             |
|    approx_kl            | 0.009303053 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.2       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.895      |
|    n_updates            | 9690        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 46.3        |
|    value_loss           | 0.182       |
-----------------------------------------
[ADAPTIVE] Episode 582 reward: 0.030651
[ADAPTIVE] Mean reward over last 20 episodes: -0.002661
[ADAPTIVE] Plateau counter: 312/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.57625616  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 571         |
|    time_elapsed         | 1874        |
|    total_timesteps      | 2338816     |
| train/                  |             |
|    approx_kl            | 0.009412388 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.2       |
|    explained_variance   | 0.705       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.913      |
|    n_updates            | 9705        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 46.8        |
|    value_loss           | 0.175       |
-----------------------------------------
[ADAPTIVE] Episode 583 reward: -0.123601
[ADAPTIVE] Mean reward over last 20 episodes: -0.009346
[ADAPTIVE] Plateau counter: 313/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6853714   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 572         |
|    time_elapsed         | 1878        |
|    total_timesteps      | 2342912     |
| train/                  |             |
|    approx_kl            | 0.008263524 |
|    clip_fraction        | 0.0889      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.3       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.904      |
|    n_updates            | 9720        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 47          |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 584 reward: 0.055814
[ADAPTIVE] Mean reward over last 20 episodes: -0.001398
[ADAPTIVE] Plateau counter: 314/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9952851   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 573         |
|    time_elapsed         | 1881        |
|    total_timesteps      | 2347008     |
| train/                  |             |
|    approx_kl            | 0.007699692 |
|    clip_fraction        | 0.0861      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.3       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.899      |
|    n_updates            | 9735        |
|    policy_gradient_loss | -0.0123     |
|    std                  | 47.2        |
|    value_loss           | 0.184       |
-----------------------------------------
[ADAPTIVE] Episode 585 reward: 0.066961
[ADAPTIVE] Mean reward over last 20 episodes: 0.001184
[ADAPTIVE] Plateau counter: 315/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.88457793  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 574         |
|    time_elapsed         | 1884        |
|    total_timesteps      | 2351104     |
| train/                  |             |
|    approx_kl            | 0.007736751 |
|    clip_fraction        | 0.0919      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.4       |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.896      |
|    n_updates            | 9750        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 47.5        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 586 reward: -0.000839
[ADAPTIVE] Mean reward over last 20 episodes: 0.004359
[ADAPTIVE] Plateau counter: 316/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.81980324  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 575         |
|    time_elapsed         | 1888        |
|    total_timesteps      | 2355200     |
| train/                  |             |
|    approx_kl            | 0.008121785 |
|    clip_fraction        | 0.0619      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.4       |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.916      |
|    n_updates            | 9765        |
|    policy_gradient_loss | -0.0132     |
|    std                  | 47.4        |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 587 reward: 0.089196
[ADAPTIVE] Mean reward over last 20 episodes: 0.009942
[ADAPTIVE] Plateau counter: 317/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8152799   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 576         |
|    time_elapsed         | 1891        |
|    total_timesteps      | 2359296     |
| train/                  |             |
|    approx_kl            | 0.008858992 |
|    clip_fraction        | 0.0967      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.4       |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.934      |
|    n_updates            | 9780        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 47.5        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 588 reward: 0.013066
[ADAPTIVE] Mean reward over last 20 episodes: 0.013728
[ADAPTIVE] Plateau counter: 318/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9323944    |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 577          |
|    time_elapsed         | 1894         |
|    total_timesteps      | 2363392      |
| train/                  |              |
|    approx_kl            | 0.0077118548 |
|    clip_fraction        | 0.0801       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.4        |
|    explained_variance   | 0.74         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.93        |
|    n_updates            | 9795         |
|    policy_gradient_loss | -0.0144      |
|    std                  | 47.6         |
|    value_loss           | 0.108        |
------------------------------------------
[ADAPTIVE] Episode 589 reward: 0.055412
[ADAPTIVE] Mean reward over last 20 episodes: 0.020231
[ADAPTIVE] Plateau counter: 319/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9063858   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 578         |
|    time_elapsed         | 1898        |
|    total_timesteps      | 2367488     |
| train/                  |             |
|    approx_kl            | 0.006913396 |
|    clip_fraction        | 0.0694      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.5       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.929      |
|    n_updates            | 9810        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 47.9        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 590 reward: -0.002616
[ADAPTIVE] Mean reward over last 20 episodes: 0.022111
[ADAPTIVE] Plateau counter: 320/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7486274   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 579         |
|    time_elapsed         | 1901        |
|    total_timesteps      | 2371584     |
| train/                  |             |
|    approx_kl            | 0.009089187 |
|    clip_fraction        | 0.0873      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.5       |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.916      |
|    n_updates            | 9825        |
|    policy_gradient_loss | -0.0133     |
|    std                  | 48          |
|    value_loss           | 0.194       |
-----------------------------------------
[ADAPTIVE] Episode 591 reward: -0.015440
[ADAPTIVE] Mean reward over last 20 episodes: 0.014762
[ADAPTIVE] Plateau counter: 321/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6681221   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 580         |
|    time_elapsed         | 1904        |
|    total_timesteps      | 2375680     |
| train/                  |             |
|    approx_kl            | 0.009205615 |
|    clip_fraction        | 0.0683      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.5       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.934      |
|    n_updates            | 9840        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 48.1        |
|    value_loss           | 0.129       |
-----------------------------------------
[ADAPTIVE] Episode 592 reward: 0.004012
[ADAPTIVE] Mean reward over last 20 episodes: 0.014988
[ADAPTIVE] Plateau counter: 322/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.81305593   |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 581          |
|    time_elapsed         | 1908         |
|    total_timesteps      | 2379776      |
| train/                  |              |
|    approx_kl            | 0.0071219425 |
|    clip_fraction        | 0.0795       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.6        |
|    explained_variance   | 0.718        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.918       |
|    n_updates            | 9855         |
|    policy_gradient_loss | -0.0123      |
|    std                  | 48.3         |
|    value_loss           | 0.141        |
------------------------------------------
[ADAPTIVE] Episode 593 reward: -0.021290
[ADAPTIVE] Mean reward over last 20 episodes: 0.014238
[ADAPTIVE] Plateau counter: 323/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7738048   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 582         |
|    time_elapsed         | 1910        |
|    total_timesteps      | 2383872     |
| train/                  |             |
|    approx_kl            | 0.009546353 |
|    clip_fraction        | 0.0891      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.6       |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.955      |
|    n_updates            | 9870        |
|    policy_gradient_loss | -0.0134     |
|    std                  | 48.6        |
|    value_loss           | 0.0865      |
-----------------------------------------
[ADAPTIVE] Episode 594 reward: 0.013915
[ADAPTIVE] Mean reward over last 20 episodes: 0.006635
[ADAPTIVE] Plateau counter: 324/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5013876   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 583         |
|    time_elapsed         | 1914        |
|    total_timesteps      | 2387968     |
| train/                  |             |
|    approx_kl            | 0.007986072 |
|    clip_fraction        | 0.0842      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.7       |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.934      |
|    n_updates            | 9885        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 49          |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 595 reward: 0.032015
[ADAPTIVE] Mean reward over last 20 episodes: 0.005156
[ADAPTIVE] Plateau counter: 325/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4400195   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 584         |
|    time_elapsed         | 1917        |
|    total_timesteps      | 2392064     |
| train/                  |             |
|    approx_kl            | 0.008185431 |
|    clip_fraction        | 0.0646      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.7       |
|    explained_variance   | 0.678       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.938      |
|    n_updates            | 9900        |
|    policy_gradient_loss | -0.011      |
|    std                  | 49.4        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 596 reward: -0.000314
[ADAPTIVE] Mean reward over last 20 episodes: 0.011230
[ADAPTIVE] Plateau counter: 326/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.26211902  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 585         |
|    time_elapsed         | 1921        |
|    total_timesteps      | 2396160     |
| train/                  |             |
|    approx_kl            | 0.007110766 |
|    clip_fraction        | 0.0599      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.8       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.947      |
|    n_updates            | 9915        |
|    policy_gradient_loss | -0.00975    |
|    std                  | 49.7        |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 597 reward: -0.052157
[ADAPTIVE] Mean reward over last 20 episodes: 0.010802
[ADAPTIVE] Plateau counter: 327/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4839272   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 586         |
|    time_elapsed         | 1924        |
|    total_timesteps      | 2400256     |
| train/                  |             |
|    approx_kl            | 0.008443909 |
|    clip_fraction        | 0.0762      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.8       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.917      |
|    n_updates            | 9930        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 50          |
|    value_loss           | 0.12        |
-----------------------------------------
[ADAPTIVE] Episode 598 reward: -0.049464
[ADAPTIVE] Mean reward over last 20 episodes: 0.008967
[ADAPTIVE] Plateau counter: 328/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6602558    |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 587          |
|    time_elapsed         | 1927         |
|    total_timesteps      | 2404352      |
| train/                  |              |
|    approx_kl            | 0.0071865073 |
|    clip_fraction        | 0.0735       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.9        |
|    explained_variance   | 0.74         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.913       |
|    n_updates            | 9945         |
|    policy_gradient_loss | -0.0121      |
|    std                  | 50.2         |
|    value_loss           | 0.127        |
------------------------------------------
[ADAPTIVE] Episode 599 reward: 0.059584
[ADAPTIVE] Mean reward over last 20 episodes: 0.010468
[ADAPTIVE] Plateau counter: 329/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7902396    |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 588          |
|    time_elapsed         | 1931         |
|    total_timesteps      | 2408448      |
| train/                  |              |
|    approx_kl            | 0.0076532755 |
|    clip_fraction        | 0.0671       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.9        |
|    explained_variance   | 0.744        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.887       |
|    n_updates            | 9960         |
|    policy_gradient_loss | -0.0146      |
|    std                  | 50.5         |
|    value_loss           | 0.177        |
------------------------------------------
[ADAPTIVE] Episode 600 reward: 0.028308
[ADAPTIVE] Mean reward over last 20 episodes: 0.007254
[ADAPTIVE] Plateau counter: 330/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7301537    |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 589          |
|    time_elapsed         | 1934         |
|    total_timesteps      | 2412544      |
| train/                  |              |
|    approx_kl            | 0.0068039563 |
|    clip_fraction        | 0.0607       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48          |
|    explained_variance   | 0.64         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.913       |
|    n_updates            | 9975         |
|    policy_gradient_loss | -0.011       |
|    std                  | 50.7         |
|    value_loss           | 0.225        |
------------------------------------------
[ADAPTIVE] Episode 601 reward: 0.070186
[ADAPTIVE] Mean reward over last 20 episodes: 0.012670
[ADAPTIVE] Plateau counter: 331/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.79279387   |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 590          |
|    time_elapsed         | 1937         |
|    total_timesteps      | 2416640      |
| train/                  |              |
|    approx_kl            | 0.0070146853 |
|    clip_fraction        | 0.0555       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48          |
|    explained_variance   | 0.738        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.907       |
|    n_updates            | 9990         |
|    policy_gradient_loss | -0.0114      |
|    std                  | 50.9         |
|    value_loss           | 0.196        |
------------------------------------------
[ADAPTIVE] Episode 602 reward: 0.002007
[ADAPTIVE] Mean reward over last 20 episodes: 0.011238
[ADAPTIVE] Plateau counter: 332/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6374074   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 591         |
|    time_elapsed         | 1940        |
|    total_timesteps      | 2420736     |
| train/                  |             |
|    approx_kl            | 0.006188349 |
|    clip_fraction        | 0.08        |
|    clip_range           | 0.2         |
|    entropy_loss         | -48         |
|    explained_variance   | 0.708       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.919      |
|    n_updates            | 10005       |
|    policy_gradient_loss | -0.0103     |
|    std                  | 51          |
|    value_loss           | 0.158       |
-----------------------------------------
[ADAPTIVE] Episode 603 reward: 0.067257
[ADAPTIVE] Mean reward over last 20 episodes: 0.020781
[ADAPTIVE] Plateau counter: 333/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5430297   |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 592         |
|    time_elapsed         | 1944        |
|    total_timesteps      | 2424832     |
| train/                  |             |
|    approx_kl            | 0.007873847 |
|    clip_fraction        | 0.0716      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.1       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.925      |
|    n_updates            | 10020       |
|    policy_gradient_loss | -0.0123     |
|    std                  | 51.2        |
|    value_loss           | 0.149       |
-----------------------------------------
[ADAPTIVE] Episode 604 reward: 0.064981
[ADAPTIVE] Mean reward over last 20 episodes: 0.021239
[ADAPTIVE] Plateau counter: 334/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.401094    |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 593         |
|    time_elapsed         | 1946        |
|    total_timesteps      | 2428928     |
| train/                  |             |
|    approx_kl            | 0.008064529 |
|    clip_fraction        | 0.0887      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.1       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.933      |
|    n_updates            | 10035       |
|    policy_gradient_loss | -0.013      |
|    std                  | 51.5        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 605 reward: -0.054761
[ADAPTIVE] Mean reward over last 20 episodes: 0.015153
[ADAPTIVE] Plateau counter: 335/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.18078595 |
| time/                   |            |
|    fps                  | 1247       |
|    iterations           | 594        |
|    time_elapsed         | 1949       |
|    total_timesteps      | 2433024    |
| train/                  |            |
|    approx_kl            | 0.00794103 |
|    clip_fraction        | 0.0602     |
|    clip_range           | 0.2        |
|    entropy_loss         | -48.2      |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.956     |
|    n_updates            | 10050      |
|    policy_gradient_loss | -0.0133    |
|    std                  | 51.9       |
|    value_loss           | 0.103      |
----------------------------------------
[ADAPTIVE] Episode 606 reward: -0.030353
[ADAPTIVE] Mean reward over last 20 episodes: 0.013677
[ADAPTIVE] Plateau counter: 336/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.18855663   |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 595          |
|    time_elapsed         | 1953         |
|    total_timesteps      | 2437120      |
| train/                  |              |
|    approx_kl            | 0.0073870663 |
|    clip_fraction        | 0.0669       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.2        |
|    explained_variance   | 0.792        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.933       |
|    n_updates            | 10065        |
|    policy_gradient_loss | -0.0136      |
|    std                  | 52           |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 607 reward: -0.148814
[ADAPTIVE] Mean reward over last 20 episodes: 0.001777
[ADAPTIVE] Plateau counter: 337/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.20590603  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 596         |
|    time_elapsed         | 1956        |
|    total_timesteps      | 2441216     |
| train/                  |             |
|    approx_kl            | 0.008214172 |
|    clip_fraction        | 0.091       |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.3       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.943      |
|    n_updates            | 10080       |
|    policy_gradient_loss | -0.0145     |
|    std                  | 52.5        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 608 reward: -0.083691
[ADAPTIVE] Mean reward over last 20 episodes: -0.003061
[ADAPTIVE] Plateau counter: 338/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.41159287  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 597         |
|    time_elapsed         | 1959        |
|    total_timesteps      | 2445312     |
| train/                  |             |
|    approx_kl            | 0.007774582 |
|    clip_fraction        | 0.0573      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.3       |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.884      |
|    n_updates            | 10095       |
|    policy_gradient_loss | -0.0108     |
|    std                  | 52.6        |
|    value_loss           | 0.283       |
-----------------------------------------
[ADAPTIVE] Episode 609 reward: 0.059764
[ADAPTIVE] Mean reward over last 20 episodes: -0.002844
[ADAPTIVE] Plateau counter: 339/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.42146462  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 598         |
|    time_elapsed         | 1963        |
|    total_timesteps      | 2449408     |
| train/                  |             |
|    approx_kl            | 0.007580213 |
|    clip_fraction        | 0.0693      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.3       |
|    explained_variance   | 0.783       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.949      |
|    n_updates            | 10110       |
|    policy_gradient_loss | -0.012      |
|    std                  | 53          |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 610 reward: 0.054058
[ADAPTIVE] Mean reward over last 20 episodes: -0.000010
[ADAPTIVE] Plateau counter: 340/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5827067    |
| time/                   |              |
|    fps                  | 1247         |
|    iterations           | 599          |
|    time_elapsed         | 1966         |
|    total_timesteps      | 2453504      |
| train/                  |              |
|    approx_kl            | 0.0073095793 |
|    clip_fraction        | 0.0874       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.4        |
|    explained_variance   | 0.783        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.935       |
|    n_updates            | 10125        |
|    policy_gradient_loss | -0.0112      |
|    std                  | 53.3         |
|    value_loss           | 0.166        |
------------------------------------------
[ADAPTIVE] Episode 611 reward: 0.100327
[ADAPTIVE] Mean reward over last 20 episodes: 0.005778
[ADAPTIVE] Plateau counter: 341/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.61891043  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 600         |
|    time_elapsed         | 1969        |
|    total_timesteps      | 2457600     |
| train/                  |             |
|    approx_kl            | 0.009517081 |
|    clip_fraction        | 0.0826      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.4       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.929      |
|    n_updates            | 10140       |
|    policy_gradient_loss | -0.012      |
|    std                  | 53.5        |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 612 reward: -0.089161
[ADAPTIVE] Mean reward over last 20 episodes: 0.001120
[ADAPTIVE] Plateau counter: 342/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.74004066  |
| time/                   |             |
|    fps                  | 1247        |
|    iterations           | 601         |
|    time_elapsed         | 1972        |
|    total_timesteps      | 2461696     |
| train/                  |             |
|    approx_kl            | 0.008312616 |
|    clip_fraction        | 0.0945      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.5       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.947      |
|    n_updates            | 10155       |
|    policy_gradient_loss | -0.0187     |
|    std                  | 53.9        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 613 reward: 0.075657
[ADAPTIVE] Mean reward over last 20 episodes: 0.005967
[ADAPTIVE] Plateau counter: 343/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.86425614  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 602         |
|    time_elapsed         | 1975        |
|    total_timesteps      | 2465792     |
| train/                  |             |
|    approx_kl            | 0.008035367 |
|    clip_fraction        | 0.0797      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.5       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.955      |
|    n_updates            | 10170       |
|    policy_gradient_loss | -0.0139     |
|    std                  | 54.2        |
|    value_loss           | 0.176       |
-----------------------------------------
[ADAPTIVE] Episode 614 reward: -0.044163
[ADAPTIVE] Mean reward over last 20 episodes: 0.003063
[ADAPTIVE] Plateau counter: 344/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 615 reward: 0.078230
[ADAPTIVE] Mean reward over last 20 episodes: 0.005374
[ADAPTIVE] Plateau counter: 345/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6616301    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 603          |
|    time_elapsed         | 1978         |
|    total_timesteps      | 2469888      |
| train/                  |              |
|    approx_kl            | 0.0071593258 |
|    clip_fraction        | 0.0546       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.6        |
|    explained_variance   | 0.772        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.938       |
|    n_updates            | 10185        |
|    policy_gradient_loss | -0.0128      |
|    std                  | 54.3         |
|    value_loss           | 0.177        |
------------------------------------------
[ADAPTIVE] Episode 616 reward: 0.026119
[ADAPTIVE] Mean reward over last 20 episodes: 0.006696
[ADAPTIVE] Plateau counter: 346/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6796081    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 604          |
|    time_elapsed         | 1981         |
|    total_timesteps      | 2473984      |
| train/                  |              |
|    approx_kl            | 0.0068730745 |
|    clip_fraction        | 0.0566       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.6        |
|    explained_variance   | 0.729        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.878       |
|    n_updates            | 10200        |
|    policy_gradient_loss | -0.0108      |
|    std                  | 54.7         |
|    value_loss           | 0.203        |
------------------------------------------
[ADAPTIVE] Episode 617 reward: 0.092784
[ADAPTIVE] Mean reward over last 20 episodes: 0.013943
[ADAPTIVE] Plateau counter: 347/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5084405   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 605         |
|    time_elapsed         | 1985        |
|    total_timesteps      | 2478080     |
| train/                  |             |
|    approx_kl            | 0.007065323 |
|    clip_fraction        | 0.092       |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.7       |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.949      |
|    n_updates            | 10215       |
|    policy_gradient_loss | -0.0133     |
|    std                  | 54.9        |
|    value_loss           | 0.0875      |
-----------------------------------------
[ADAPTIVE] Episode 618 reward: -0.046961
[ADAPTIVE] Mean reward over last 20 episodes: 0.014068
[ADAPTIVE] Plateau counter: 348/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.6293424   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 606         |
|    time_elapsed         | 1988        |
|    total_timesteps      | 2482176     |
| train/                  |             |
|    approx_kl            | 0.007042587 |
|    clip_fraction        | 0.0659      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.7       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.938      |
|    n_updates            | 10230       |
|    policy_gradient_loss | -0.0121     |
|    std                  | 55.3        |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 619 reward: 0.029290
[ADAPTIVE] Mean reward over last 20 episodes: 0.012553
[ADAPTIVE] Plateau counter: 349/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.54192793   |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 607          |
|    time_elapsed         | 1992         |
|    total_timesteps      | 2486272      |
| train/                  |              |
|    approx_kl            | 0.0067296373 |
|    clip_fraction        | 0.0709       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.8        |
|    explained_variance   | 0.741        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.913       |
|    n_updates            | 10245        |
|    policy_gradient_loss | -0.0133      |
|    std                  | 55.5         |
|    value_loss           | 0.232        |
------------------------------------------
[ADAPTIVE] Episode 620 reward: -0.050132
[ADAPTIVE] Mean reward over last 20 episodes: 0.008631
[ADAPTIVE] Plateau counter: 350/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5440927    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 608          |
|    time_elapsed         | 1995         |
|    total_timesteps      | 2490368      |
| train/                  |              |
|    approx_kl            | 0.0071633686 |
|    clip_fraction        | 0.0847       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.8        |
|    explained_variance   | 0.815        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.969       |
|    n_updates            | 10260        |
|    policy_gradient_loss | -0.0132      |
|    std                  | 55.6         |
|    value_loss           | 0.0807       |
------------------------------------------
[ADAPTIVE] Episode 621 reward: -0.042943
[ADAPTIVE] Mean reward over last 20 episodes: 0.002975
[ADAPTIVE] Plateau counter: 351/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84764916  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 609         |
|    time_elapsed         | 1998        |
|    total_timesteps      | 2494464     |
| train/                  |             |
|    approx_kl            | 0.009106513 |
|    clip_fraction        | 0.0812      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.8       |
|    explained_variance   | 0.83        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.95       |
|    n_updates            | 10275       |
|    policy_gradient_loss | -0.0134     |
|    std                  | 55.9        |
|    value_loss           | 0.0949      |
-----------------------------------------
[ADAPTIVE] Episode 622 reward: -0.171361
[ADAPTIVE] Mean reward over last 20 episodes: -0.005694
[ADAPTIVE] Plateau counter: 352/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.90128165  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 610         |
|    time_elapsed         | 2001        |
|    total_timesteps      | 2498560     |
| train/                  |             |
|    approx_kl            | 0.008997699 |
|    clip_fraction        | 0.0619      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.9       |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.97       |
|    n_updates            | 10290       |
|    policy_gradient_loss | -0.0137     |
|    std                  | 56.2        |
|    value_loss           | 0.0807      |
-----------------------------------------
[ADAPTIVE] Episode 623 reward: -0.047572
[ADAPTIVE] Mean reward over last 20 episodes: -0.011435
[ADAPTIVE] Plateau counter: 353/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.92034286  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 611         |
|    time_elapsed         | 2005        |
|    total_timesteps      | 2502656     |
| train/                  |             |
|    approx_kl            | 0.005746239 |
|    clip_fraction        | 0.0444      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.9       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.912      |
|    n_updates            | 10305       |
|    policy_gradient_loss | -0.0103     |
|    std                  | 56.5        |
|    value_loss           | 0.208       |
-----------------------------------------
[ADAPTIVE] Episode 624 reward: -0.020128
[ADAPTIVE] Mean reward over last 20 episodes: -0.015691
[ADAPTIVE] Plateau counter: 354/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0879798   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 612         |
|    time_elapsed         | 2008        |
|    total_timesteps      | 2506752     |
| train/                  |             |
|    approx_kl            | 0.006815112 |
|    clip_fraction        | 0.0745      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49         |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.928      |
|    n_updates            | 10320       |
|    policy_gradient_loss | -0.0116     |
|    std                  | 56.6        |
|    value_loss           | 0.193       |
-----------------------------------------
[ADAPTIVE] Episode 625 reward: 0.014210
[ADAPTIVE] Mean reward over last 20 episodes: -0.012242
[ADAPTIVE] Plateau counter: 355/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9050277   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 613         |
|    time_elapsed         | 2011        |
|    total_timesteps      | 2510848     |
| train/                  |             |
|    approx_kl            | 0.006680905 |
|    clip_fraction        | 0.0599      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49         |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.957      |
|    n_updates            | 10335       |
|    policy_gradient_loss | -0.0103     |
|    std                  | 56.9        |
|    value_loss           | 0.145       |
-----------------------------------------
[ADAPTIVE] Episode 626 reward: 0.024121
[ADAPTIVE] Mean reward over last 20 episodes: -0.009518
[ADAPTIVE] Plateau counter: 356/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.78309435   |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 614          |
|    time_elapsed         | 2014         |
|    total_timesteps      | 2514944      |
| train/                  |              |
|    approx_kl            | 0.0054708393 |
|    clip_fraction        | 0.0477       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49          |
|    explained_variance   | 0.804        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.875       |
|    n_updates            | 10350        |
|    policy_gradient_loss | -0.0105      |
|    std                  | 57.1         |
|    value_loss           | 0.234        |
------------------------------------------
[ADAPTIVE] Episode 627 reward: 0.085212
[ADAPTIVE] Mean reward over last 20 episodes: 0.002183
[ADAPTIVE] Plateau counter: 357/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7066297   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 615         |
|    time_elapsed         | 2018        |
|    total_timesteps      | 2519040     |
| train/                  |             |
|    approx_kl            | 0.007803898 |
|    clip_fraction        | 0.0722      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.1       |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.942      |
|    n_updates            | 10365       |
|    policy_gradient_loss | -0.0119     |
|    std                  | 57.3        |
|    value_loss           | 0.091       |
-----------------------------------------
[ADAPTIVE] Episode 628 reward: -0.022282
[ADAPTIVE] Mean reward over last 20 episodes: 0.005253
[ADAPTIVE] Plateau counter: 358/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.51611865  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 616         |
|    time_elapsed         | 2021        |
|    total_timesteps      | 2523136     |
| train/                  |             |
|    approx_kl            | 0.009154705 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.1       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.952      |
|    n_updates            | 10380       |
|    policy_gradient_loss | -0.0166     |
|    std                  | 57.5        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 629 reward: -0.042317
[ADAPTIVE] Mean reward over last 20 episodes: 0.000149
[ADAPTIVE] Plateau counter: 359/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67553025  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 617         |
|    time_elapsed         | 2024        |
|    total_timesteps      | 2527232     |
| train/                  |             |
|    approx_kl            | 0.006711282 |
|    clip_fraction        | 0.0642      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.1       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.932      |
|    n_updates            | 10395       |
|    policy_gradient_loss | -0.0111     |
|    std                  | 57.9        |
|    value_loss           | 0.204       |
-----------------------------------------
[ADAPTIVE] Episode 630 reward: -0.008251
[ADAPTIVE] Mean reward over last 20 episodes: -0.002966
[ADAPTIVE] Plateau counter: 360/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5124367    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 618          |
|    time_elapsed         | 2027         |
|    total_timesteps      | 2531328      |
| train/                  |              |
|    approx_kl            | 0.0072784503 |
|    clip_fraction        | 0.0588       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.2        |
|    explained_variance   | 0.764        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.951       |
|    n_updates            | 10410        |
|    policy_gradient_loss | -0.0133      |
|    std                  | 58.2         |
|    value_loss           | 0.149        |
------------------------------------------
[ADAPTIVE] Episode 631 reward: 0.027426
[ADAPTIVE] Mean reward over last 20 episodes: -0.006611
[ADAPTIVE] Plateau counter: 361/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.74424344   |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 619          |
|    time_elapsed         | 2030         |
|    total_timesteps      | 2535424      |
| train/                  |              |
|    approx_kl            | 0.0077539766 |
|    clip_fraction        | 0.0709       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.2        |
|    explained_variance   | 0.796        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.969       |
|    n_updates            | 10425        |
|    policy_gradient_loss | -0.0122      |
|    std                  | 58.6         |
|    value_loss           | 0.0874       |
------------------------------------------
[ADAPTIVE] Episode 632 reward: 0.154691
[ADAPTIVE] Mean reward over last 20 episodes: 0.005581
[ADAPTIVE] Plateau counter: 362/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.031829    |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 620         |
|    time_elapsed         | 2033        |
|    total_timesteps      | 2539520     |
| train/                  |             |
|    approx_kl            | 0.010113167 |
|    clip_fraction        | 0.0769      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.3       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.961      |
|    n_updates            | 10440       |
|    policy_gradient_loss | -0.013      |
|    std                  | 59.1        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 633 reward: 0.033851
[ADAPTIVE] Mean reward over last 20 episodes: 0.003491
[ADAPTIVE] Plateau counter: 363/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0317284    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 621          |
|    time_elapsed         | 2036         |
|    total_timesteps      | 2543616      |
| train/                  |              |
|    approx_kl            | 0.0071096537 |
|    clip_fraction        | 0.0722       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.4        |
|    explained_variance   | 0.776        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.938       |
|    n_updates            | 10455        |
|    policy_gradient_loss | -0.013       |
|    std                  | 59.4         |
|    value_loss           | 0.214        |
------------------------------------------
[ADAPTIVE] Episode 634 reward: 0.042969
[ADAPTIVE] Mean reward over last 20 episodes: 0.007848
[ADAPTIVE] Plateau counter: 364/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2231991   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 622         |
|    time_elapsed         | 2040        |
|    total_timesteps      | 2547712     |
| train/                  |             |
|    approx_kl            | 0.008213126 |
|    clip_fraction        | 0.0812      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.4       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.969      |
|    n_updates            | 10470       |
|    policy_gradient_loss | -0.0148     |
|    std                  | 59.7        |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 635 reward: -0.035804
[ADAPTIVE] Mean reward over last 20 episodes: 0.002146
[ADAPTIVE] Plateau counter: 365/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1234751   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 623         |
|    time_elapsed         | 2043        |
|    total_timesteps      | 2551808     |
| train/                  |             |
|    approx_kl            | 0.007834799 |
|    clip_fraction        | 0.0722      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.5       |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.942      |
|    n_updates            | 10485       |
|    policy_gradient_loss | -0.0132     |
|    std                  | 60          |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 636 reward: 0.017899
[ADAPTIVE] Mean reward over last 20 episodes: 0.001735
[ADAPTIVE] Plateau counter: 366/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0035881    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 624          |
|    time_elapsed         | 2047         |
|    total_timesteps      | 2555904      |
| train/                  |              |
|    approx_kl            | 0.0070611606 |
|    clip_fraction        | 0.0689       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.5        |
|    explained_variance   | 0.693        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.918       |
|    n_updates            | 10500        |
|    policy_gradient_loss | -0.0109      |
|    std                  | 60.2         |
|    value_loss           | 0.229        |
------------------------------------------
[ADAPTIVE] Episode 637 reward: 0.015742
[ADAPTIVE] Mean reward over last 20 episodes: -0.002117
[ADAPTIVE] Plateau counter: 367/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9687418   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 625         |
|    time_elapsed         | 2049        |
|    total_timesteps      | 2560000     |
| train/                  |             |
|    approx_kl            | 0.009524295 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.5       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.945      |
|    n_updates            | 10515       |
|    policy_gradient_loss | -0.015      |
|    std                  | 60.5        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 638 reward: -0.002690
[ADAPTIVE] Mean reward over last 20 episodes: 0.000097
[ADAPTIVE] Plateau counter: 368/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7175612   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 626         |
|    time_elapsed         | 2053        |
|    total_timesteps      | 2564096     |
| train/                  |             |
|    approx_kl            | 0.008561542 |
|    clip_fraction        | 0.0728      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.6       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.964      |
|    n_updates            | 10530       |
|    policy_gradient_loss | -0.0132     |
|    std                  | 60.8        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 639 reward: 0.154164
[ADAPTIVE] Mean reward over last 20 episodes: 0.006340
[ADAPTIVE] Plateau counter: 369/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5450888    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 627          |
|    time_elapsed         | 2056         |
|    total_timesteps      | 2568192      |
| train/                  |              |
|    approx_kl            | 0.0077337055 |
|    clip_fraction        | 0.0707       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.6        |
|    explained_variance   | 0.721        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.958       |
|    n_updates            | 10545        |
|    policy_gradient_loss | -0.0111      |
|    std                  | 60.9         |
|    value_loss           | 0.149        |
------------------------------------------
[ADAPTIVE] Episode 640 reward: -0.040001
[ADAPTIVE] Mean reward over last 20 episodes: 0.006847
[ADAPTIVE] Plateau counter: 370/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.3960872   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 628         |
|    time_elapsed         | 2060        |
|    total_timesteps      | 2572288     |
| train/                  |             |
|    approx_kl            | 0.008861512 |
|    clip_fraction        | 0.0872      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.7       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.993      |
|    n_updates            | 10560       |
|    policy_gradient_loss | -0.0151     |
|    std                  | 61.5        |
|    value_loss           | 0.0952      |
-----------------------------------------
[ADAPTIVE] Episode 641 reward: 0.071933
[ADAPTIVE] Mean reward over last 20 episodes: 0.012591
[ADAPTIVE] Plateau counter: 371/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.49710333   |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 629          |
|    time_elapsed         | 2063         |
|    total_timesteps      | 2576384      |
| train/                  |              |
|    approx_kl            | 0.0076612784 |
|    clip_fraction        | 0.0651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.7        |
|    explained_variance   | 0.827        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.951       |
|    n_updates            | 10575        |
|    policy_gradient_loss | -0.0116      |
|    std                  | 61.5         |
|    value_loss           | 0.147        |
------------------------------------------
[ADAPTIVE] Episode 642 reward: 0.077938
[ADAPTIVE] Mean reward over last 20 episodes: 0.025056
[ADAPTIVE] Plateau counter: 372/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4438464   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 630         |
|    time_elapsed         | 2066        |
|    total_timesteps      | 2580480     |
| train/                  |             |
|    approx_kl            | 0.008676125 |
|    clip_fraction        | 0.0806      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.7       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.981      |
|    n_updates            | 10590       |
|    policy_gradient_loss | -0.0128     |
|    std                  | 61.7        |
|    value_loss           | 0.0997      |
-----------------------------------------
[ADAPTIVE] Episode 643 reward: 0.073395
[ADAPTIVE] Mean reward over last 20 episodes: 0.031104
[ADAPTIVE] Plateau counter: 373/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.54831076  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 631         |
|    time_elapsed         | 2069        |
|    total_timesteps      | 2584576     |
| train/                  |             |
|    approx_kl            | 0.010697331 |
|    clip_fraction        | 0.0792      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.8       |
|    explained_variance   | 0.803       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.973      |
|    n_updates            | 10605       |
|    policy_gradient_loss | -0.013      |
|    std                  | 62.2        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 644 reward: 0.044674
[ADAPTIVE] Mean reward over last 20 episodes: 0.034344
[ADAPTIVE] Plateau counter: 374/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.64717776   |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 632          |
|    time_elapsed         | 2073         |
|    total_timesteps      | 2588672      |
| train/                  |              |
|    approx_kl            | 0.0058786087 |
|    clip_fraction        | 0.0525       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.8        |
|    explained_variance   | 0.739        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.973       |
|    n_updates            | 10620        |
|    policy_gradient_loss | -0.0117      |
|    std                  | 62.4         |
|    value_loss           | 0.126        |
------------------------------------------
[ADAPTIVE] Episode 645 reward: -0.040269
[ADAPTIVE] Mean reward over last 20 episodes: 0.031620
[ADAPTIVE] Plateau counter: 375/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.81689924   |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 633          |
|    time_elapsed         | 2076         |
|    total_timesteps      | 2592768      |
| train/                  |              |
|    approx_kl            | 0.0074627902 |
|    clip_fraction        | 0.0863       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.9        |
|    explained_variance   | 0.693        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.959       |
|    n_updates            | 10635        |
|    policy_gradient_loss | -0.0105      |
|    std                  | 62.8         |
|    value_loss           | 0.164        |
------------------------------------------
[ADAPTIVE] Episode 646 reward: -0.046501
[ADAPTIVE] Mean reward over last 20 episodes: 0.028089
[ADAPTIVE] Plateau counter: 376/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8121052    |
| time/                   |              |
|    fps                  | 1248         |
|    iterations           | 634          |
|    time_elapsed         | 2079         |
|    total_timesteps      | 2596864      |
| train/                  |              |
|    approx_kl            | 0.0070327274 |
|    clip_fraction        | 0.0677       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.9        |
|    explained_variance   | 0.725        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.963       |
|    n_updates            | 10650        |
|    policy_gradient_loss | -0.00922     |
|    std                  | 63.3         |
|    value_loss           | 0.159        |
------------------------------------------
[ADAPTIVE] Episode 647 reward: -0.003121
[ADAPTIVE] Mean reward over last 20 episodes: 0.023672
[ADAPTIVE] Plateau counter: 377/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.94312644  |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 635         |
|    time_elapsed         | 2082        |
|    total_timesteps      | 2600960     |
| train/                  |             |
|    approx_kl            | 0.006415839 |
|    clip_fraction        | 0.0584      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50         |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.953      |
|    n_updates            | 10665       |
|    policy_gradient_loss | -0.0112     |
|    std                  | 63.5        |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 648 reward: 0.067908
[ADAPTIVE] Mean reward over last 20 episodes: 0.028182
[ADAPTIVE] Plateau counter: 378/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0579005   |
| time/                   |             |
|    fps                  | 1248        |
|    iterations           | 636         |
|    time_elapsed         | 2085        |
|    total_timesteps      | 2605056     |
| train/                  |             |
|    approx_kl            | 0.007241198 |
|    clip_fraction        | 0.0681      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50         |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.934      |
|    n_updates            | 10680       |
|    policy_gradient_loss | -0.0118     |
|    std                  | 64          |
|    value_loss           | 0.207       |
-----------------------------------------
[ADAPTIVE] Episode 649 reward: -0.049962
[ADAPTIVE] Mean reward over last 20 episodes: 0.027800
[ADAPTIVE] Plateau counter: 379/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0551375    |
| time/                   |              |
|    fps                  | 1249         |
|    iterations           | 637          |
|    time_elapsed         | 2088         |
|    total_timesteps      | 2609152      |
| train/                  |              |
|    approx_kl            | 0.0072611156 |
|    clip_fraction        | 0.0616       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.1        |
|    explained_variance   | 0.734        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.973       |
|    n_updates            | 10695        |
|    policy_gradient_loss | -0.0123      |
|    std                  | 64           |
|    value_loss           | 0.136        |
------------------------------------------
[ADAPTIVE] Episode 650 reward: -0.005342
[ADAPTIVE] Mean reward over last 20 episodes: 0.027945
[ADAPTIVE] Plateau counter: 380/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0495082    |
| time/                   |              |
|    fps                  | 1249         |
|    iterations           | 638          |
|    time_elapsed         | 2092         |
|    total_timesteps      | 2613248      |
| train/                  |              |
|    approx_kl            | 0.0063751666 |
|    clip_fraction        | 0.0554       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.1        |
|    explained_variance   | 0.74         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.989       |
|    n_updates            | 10710        |
|    policy_gradient_loss | -0.0112      |
|    std                  | 64.7         |
|    value_loss           | 0.106        |
------------------------------------------
[ADAPTIVE] Episode 651 reward: 0.113344
[ADAPTIVE] Mean reward over last 20 episodes: 0.032241
[ADAPTIVE] Plateau counter: 381/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.94325835  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 639         |
|    time_elapsed         | 2095        |
|    total_timesteps      | 2617344     |
| train/                  |             |
|    approx_kl            | 0.006283449 |
|    clip_fraction        | 0.0673      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.2       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.962      |
|    n_updates            | 10725       |
|    policy_gradient_loss | -0.0106     |
|    std                  | 65          |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 652 reward: -0.073624
[ADAPTIVE] Mean reward over last 20 episodes: 0.020825
[ADAPTIVE] Plateau counter: 382/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9147484   |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 640         |
|    time_elapsed         | 2098        |
|    total_timesteps      | 2621440     |
| train/                  |             |
|    approx_kl            | 0.008538553 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.2       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.986      |
|    n_updates            | 10740       |
|    policy_gradient_loss | -0.0126     |
|    std                  | 65.6        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 653 reward: -0.023708
[ADAPTIVE] Mean reward over last 20 episodes: 0.017947
[ADAPTIVE] Plateau counter: 383/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84272957  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 641         |
|    time_elapsed         | 2101        |
|    total_timesteps      | 2625536     |
| train/                  |             |
|    approx_kl            | 0.007160752 |
|    clip_fraction        | 0.0728      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.3       |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.975      |
|    n_updates            | 10755       |
|    policy_gradient_loss | -0.0133     |
|    std                  | 65.9        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 654 reward: -0.031647
[ADAPTIVE] Mean reward over last 20 episodes: 0.014216
[ADAPTIVE] Plateau counter: 384/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.75941306  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 642         |
|    time_elapsed         | 2105        |
|    total_timesteps      | 2629632     |
| train/                  |             |
|    approx_kl            | 0.006004329 |
|    clip_fraction        | 0.0647      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.3       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.972      |
|    n_updates            | 10770       |
|    policy_gradient_loss | -0.011      |
|    std                  | 66.2        |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 655 reward: 0.007196
[ADAPTIVE] Mean reward over last 20 episodes: 0.016366
[ADAPTIVE] Plateau counter: 385/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8735363    |
| time/                   |              |
|    fps                  | 1249         |
|    iterations           | 643          |
|    time_elapsed         | 2108         |
|    total_timesteps      | 2633728      |
| train/                  |              |
|    approx_kl            | 0.0068823337 |
|    clip_fraction        | 0.0535       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.4        |
|    explained_variance   | 0.819        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.957       |
|    n_updates            | 10785        |
|    policy_gradient_loss | -0.0101      |
|    std                  | 66.5         |
|    value_loss           | 0.194        |
------------------------------------------
[ADAPTIVE] Episode 656 reward: 0.020399
[ADAPTIVE] Mean reward over last 20 episodes: 0.016492
[ADAPTIVE] Plateau counter: 386/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.62864745   |
| time/                   |              |
|    fps                  | 1249         |
|    iterations           | 644          |
|    time_elapsed         | 2111         |
|    total_timesteps      | 2637824      |
| train/                  |              |
|    approx_kl            | 0.0071830107 |
|    clip_fraction        | 0.0648       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.4        |
|    explained_variance   | 0.794        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.982       |
|    n_updates            | 10800        |
|    policy_gradient_loss | -0.0127      |
|    std                  | 67.1         |
|    value_loss           | 0.143        |
------------------------------------------
[ADAPTIVE] Episode 657 reward: -0.011330
[ADAPTIVE] Mean reward over last 20 episodes: 0.015138
[ADAPTIVE] Plateau counter: 387/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.64968854  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 645         |
|    time_elapsed         | 2114        |
|    total_timesteps      | 2641920     |
| train/                  |             |
|    approx_kl            | 0.008075689 |
|    clip_fraction        | 0.0771      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.5       |
|    explained_variance   | 0.612       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.975      |
|    n_updates            | 10815       |
|    policy_gradient_loss | -0.0114     |
|    std                  | 67.2        |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 658 reward: -0.072533
[ADAPTIVE] Mean reward over last 20 episodes: 0.011646
[ADAPTIVE] Plateau counter: 388/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.41676018  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 646         |
|    time_elapsed         | 2117        |
|    total_timesteps      | 2646016     |
| train/                  |             |
|    approx_kl            | 0.007126488 |
|    clip_fraction        | 0.064       |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.5       |
|    explained_variance   | 0.687       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.96       |
|    n_updates            | 10830       |
|    policy_gradient_loss | -0.0104     |
|    std                  | 67.5        |
|    value_loss           | 0.173       |
-----------------------------------------
[ADAPTIVE] Episode 659 reward: -0.037016
[ADAPTIVE] Mean reward over last 20 episodes: 0.002087
[ADAPTIVE] Plateau counter: 389/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5442356    |
| time/                   |              |
|    fps                  | 1249         |
|    iterations           | 647          |
|    time_elapsed         | 2121         |
|    total_timesteps      | 2650112      |
| train/                  |              |
|    approx_kl            | 0.0070281564 |
|    clip_fraction        | 0.0821       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.6        |
|    explained_variance   | 0.784        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.979       |
|    n_updates            | 10845        |
|    policy_gradient_loss | -0.0121      |
|    std                  | 67.9         |
|    value_loss           | 0.161        |
------------------------------------------
[ADAPTIVE] Episode 660 reward: -0.133221
[ADAPTIVE] Mean reward over last 20 episodes: -0.002574
[ADAPTIVE] Plateau counter: 390/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.72311646  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 648         |
|    time_elapsed         | 2124        |
|    total_timesteps      | 2654208     |
| train/                  |             |
|    approx_kl            | 0.007286855 |
|    clip_fraction        | 0.0588      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.6       |
|    explained_variance   | 0.72        |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 10860       |
|    policy_gradient_loss | -0.0106     |
|    std                  | 68.3        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 661 reward: -0.014973
[ADAPTIVE] Mean reward over last 20 episodes: -0.006920
[ADAPTIVE] Plateau counter: 391/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.68862295  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 649         |
|    time_elapsed         | 2127        |
|    total_timesteps      | 2658304     |
| train/                  |             |
|    approx_kl            | 0.008886782 |
|    clip_fraction        | 0.0915      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.7       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.986      |
|    n_updates            | 10875       |
|    policy_gradient_loss | -0.015      |
|    std                  | 68.5        |
|    value_loss           | 0.167       |
-----------------------------------------
[ADAPTIVE] Episode 662 reward: -0.020015
[ADAPTIVE] Mean reward over last 20 episodes: -0.011817
[ADAPTIVE] Plateau counter: 392/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.71351105  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 650         |
|    time_elapsed         | 2130        |
|    total_timesteps      | 2662400     |
| train/                  |             |
|    approx_kl            | 0.007159599 |
|    clip_fraction        | 0.073       |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.7       |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.988      |
|    n_updates            | 10890       |
|    policy_gradient_loss | -0.0111     |
|    std                  | 69.3        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 663 reward: -0.017466
[ADAPTIVE] Mean reward over last 20 episodes: -0.016360
[ADAPTIVE] Plateau counter: 393/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7919263   |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 651         |
|    time_elapsed         | 2134        |
|    total_timesteps      | 2666496     |
| train/                  |             |
|    approx_kl            | 0.005362666 |
|    clip_fraction        | 0.0526      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.8       |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.999      |
|    n_updates            | 10905       |
|    policy_gradient_loss | -0.0102     |
|    std                  | 69.4        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 664 reward: 0.094002
[ADAPTIVE] Mean reward over last 20 episodes: -0.013894
[ADAPTIVE] Plateau counter: 394/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8975239    |
| time/                   |              |
|    fps                  | 1249         |
|    iterations           | 652          |
|    time_elapsed         | 2137         |
|    total_timesteps      | 2670592      |
| train/                  |              |
|    approx_kl            | 0.0059387046 |
|    clip_fraction        | 0.0542       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.8        |
|    explained_variance   | 0.746        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.984       |
|    n_updates            | 10920        |
|    policy_gradient_loss | -0.00993     |
|    std                  | 69.5         |
|    value_loss           | 0.161        |
------------------------------------------
[ADAPTIVE] Episode 665 reward: 0.039510
[ADAPTIVE] Mean reward over last 20 episodes: -0.009905
[ADAPTIVE] Plateau counter: 395/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 666 reward: -0.042770
[ADAPTIVE] Mean reward over last 20 episodes: -0.009718
[ADAPTIVE] Plateau counter: 396/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8224229   |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 653         |
|    time_elapsed         | 2140        |
|    total_timesteps      | 2674688     |
| train/                  |             |
|    approx_kl            | 0.008030409 |
|    clip_fraction        | 0.0713      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.8       |
|    explained_variance   | 0.802       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.983      |
|    n_updates            | 10935       |
|    policy_gradient_loss | -0.0108     |
|    std                  | 69.8        |
|    value_loss           | 0.192       |
-----------------------------------------
[ADAPTIVE] Episode 667 reward: -0.020459
[ADAPTIVE] Mean reward over last 20 episodes: -0.010585
[ADAPTIVE] Plateau counter: 397/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8854561   |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 654         |
|    time_elapsed         | 2143        |
|    total_timesteps      | 2678784     |
| train/                  |             |
|    approx_kl            | 0.005609704 |
|    clip_fraction        | 0.0579      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.9       |
|    explained_variance   | 0.783       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.983      |
|    n_updates            | 10950       |
|    policy_gradient_loss | -0.0108     |
|    std                  | 70.1        |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 668 reward: 0.048097
[ADAPTIVE] Mean reward over last 20 episodes: -0.011576
[ADAPTIVE] Plateau counter: 398/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9539664    |
| time/                   |              |
|    fps                  | 1249         |
|    iterations           | 655          |
|    time_elapsed         | 2146         |
|    total_timesteps      | 2682880      |
| train/                  |              |
|    approx_kl            | 0.0069177737 |
|    clip_fraction        | 0.0578       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.9        |
|    explained_variance   | 0.69         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.993       |
|    n_updates            | 10965        |
|    policy_gradient_loss | -0.0123      |
|    std                  | 70.7         |
|    value_loss           | 0.171        |
------------------------------------------
[ADAPTIVE] Episode 669 reward: 0.066524
[ADAPTIVE] Mean reward over last 20 episodes: -0.005752
[ADAPTIVE] Plateau counter: 399/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.67323524  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 656         |
|    time_elapsed         | 2150        |
|    total_timesteps      | 2686976     |
| train/                  |             |
|    approx_kl            | 0.006516611 |
|    clip_fraction        | 0.06        |
|    clip_range           | 0.2         |
|    entropy_loss         | -51         |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 10980       |
|    policy_gradient_loss | -0.0107     |
|    std                  | 71.1        |
|    value_loss           | 0.138       |
-----------------------------------------
[ADAPTIVE] Episode 670 reward: 0.161391
[ADAPTIVE] Mean reward over last 20 episodes: 0.002585
[ADAPTIVE] Plateau counter: 400/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.52067405   |
| time/                   |              |
|    fps                  | 1249         |
|    iterations           | 657          |
|    time_elapsed         | 2153         |
|    total_timesteps      | 2691072      |
| train/                  |              |
|    approx_kl            | 0.0077987914 |
|    clip_fraction        | 0.0647       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51          |
|    explained_variance   | 0.746        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.925       |
|    n_updates            | 10995        |
|    policy_gradient_loss | -0.0117      |
|    std                  | 71.5         |
|    value_loss           | 0.217        |
------------------------------------------
[ADAPTIVE] Episode 671 reward: 0.110712
[ADAPTIVE] Mean reward over last 20 episodes: 0.002453
[ADAPTIVE] Plateau counter: 401/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5288539   |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 658         |
|    time_elapsed         | 2156        |
|    total_timesteps      | 2695168     |
| train/                  |             |
|    approx_kl            | 0.006225515 |
|    clip_fraction        | 0.0528      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.1       |
|    explained_variance   | 0.776       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 11010       |
|    policy_gradient_loss | -0.00959    |
|    std                  | 71.7        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 672 reward: -0.043257
[ADAPTIVE] Mean reward over last 20 episodes: 0.003972
[ADAPTIVE] Plateau counter: 402/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.48186016  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 659         |
|    time_elapsed         | 2159        |
|    total_timesteps      | 2699264     |
| train/                  |             |
|    approx_kl            | 0.006420406 |
|    clip_fraction        | 0.0665      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.1       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 11025       |
|    policy_gradient_loss | -0.012      |
|    std                  | 72.2        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 673 reward: 0.049828
[ADAPTIVE] Mean reward over last 20 episodes: 0.007649
[ADAPTIVE] Plateau counter: 403/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4512615    |
| time/                   |              |
|    fps                  | 1249         |
|    iterations           | 660          |
|    time_elapsed         | 2162         |
|    total_timesteps      | 2703360      |
| train/                  |              |
|    approx_kl            | 0.0070617944 |
|    clip_fraction        | 0.0717       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.2        |
|    explained_variance   | 0.766        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11040        |
|    policy_gradient_loss | -0.0114      |
|    std                  | 72.7         |
|    value_loss           | 0.11         |
------------------------------------------
[ADAPTIVE] Episode 674 reward: -0.058018
[ADAPTIVE] Mean reward over last 20 episodes: 0.006330
[ADAPTIVE] Plateau counter: 404/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.39039162  |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 661         |
|    time_elapsed         | 2165        |
|    total_timesteps      | 2707456     |
| train/                  |             |
|    approx_kl            | 0.010632249 |
|    clip_fraction        | 0.0531      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.2       |
|    explained_variance   | 0.708       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.962      |
|    n_updates            | 11055       |
|    policy_gradient_loss | -0.00761    |
|    std                  | 73          |
|    value_loss           | 0.23        |
-----------------------------------------
[ADAPTIVE] Episode 675 reward: -0.002512
[ADAPTIVE] Mean reward over last 20 episodes: 0.005845
[ADAPTIVE] Plateau counter: 405/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.52525026   |
| time/                   |              |
|    fps                  | 1249         |
|    iterations           | 662          |
|    time_elapsed         | 2169         |
|    total_timesteps      | 2711552      |
| train/                  |              |
|    approx_kl            | 0.0065150214 |
|    clip_fraction        | 0.0592       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.2        |
|    explained_variance   | 0.783        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.992       |
|    n_updates            | 11070        |
|    policy_gradient_loss | -0.00973     |
|    std                  | 73.5         |
|    value_loss           | 0.171        |
------------------------------------------
[ADAPTIVE] Episode 676 reward: 0.030863
[ADAPTIVE] Mean reward over last 20 episodes: 0.006368
[ADAPTIVE] Plateau counter: 406/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.49065512   |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 663          |
|    time_elapsed         | 2172         |
|    total_timesteps      | 2715648      |
| train/                  |              |
|    approx_kl            | 0.0077009303 |
|    clip_fraction        | 0.0738       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.3        |
|    explained_variance   | 0.781        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.937       |
|    n_updates            | 11085        |
|    policy_gradient_loss | -0.0129      |
|    std                  | 73.7         |
|    value_loss           | 0.171        |
------------------------------------------
[ADAPTIVE] Episode 677 reward: -0.132153
[ADAPTIVE] Mean reward over last 20 episodes: 0.000327
[ADAPTIVE] Plateau counter: 407/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5625356   |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 664         |
|    time_elapsed         | 2176        |
|    total_timesteps      | 2719744     |
| train/                  |             |
|    approx_kl            | 0.008145856 |
|    clip_fraction        | 0.056       |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.4       |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11100       |
|    policy_gradient_loss | -0.0109     |
|    std                  | 74.4        |
|    value_loss           | 0.144       |
-----------------------------------------
[ADAPTIVE] Episode 678 reward: 0.025285
[ADAPTIVE] Mean reward over last 20 episodes: 0.005218
[ADAPTIVE] Plateau counter: 408/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5431464   |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 665         |
|    time_elapsed         | 2178        |
|    total_timesteps      | 2723840     |
| train/                  |             |
|    approx_kl            | 0.006149782 |
|    clip_fraction        | 0.0616      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.4       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11115       |
|    policy_gradient_loss | -0.0111     |
|    std                  | 74.9        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 679 reward: -0.000029
[ADAPTIVE] Mean reward over last 20 episodes: 0.007067
[ADAPTIVE] Plateau counter: 409/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4870864    |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 666          |
|    time_elapsed         | 2182         |
|    total_timesteps      | 2727936      |
| train/                  |              |
|    approx_kl            | 0.0068163443 |
|    clip_fraction        | 0.0683       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.5        |
|    explained_variance   | 0.779        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11130        |
|    policy_gradient_loss | -0.0118      |
|    std                  | 75.5         |
|    value_loss           | 0.115        |
------------------------------------------
[ADAPTIVE] Episode 680 reward: 0.081967
[ADAPTIVE] Mean reward over last 20 episodes: 0.017826
[ADAPTIVE] Plateau counter: 410/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.48131865   |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 667          |
|    time_elapsed         | 2185         |
|    total_timesteps      | 2732032      |
| train/                  |              |
|    approx_kl            | 0.0068640206 |
|    clip_fraction        | 0.0541       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.6        |
|    explained_variance   | 0.773        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11145        |
|    policy_gradient_loss | -0.0128      |
|    std                  | 76           |
|    value_loss           | 0.144        |
------------------------------------------
[ADAPTIVE] Episode 681 reward: 0.100770
[ADAPTIVE] Mean reward over last 20 episodes: 0.023613
[ADAPTIVE] Plateau counter: 411/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.41112033 |
| time/                   |            |
|    fps                  | 1250       |
|    iterations           | 668        |
|    time_elapsed         | 2188       |
|    total_timesteps      | 2736128    |
| train/                  |            |
|    approx_kl            | 0.00601507 |
|    clip_fraction        | 0.0503     |
|    clip_range           | 0.2        |
|    entropy_loss         | -51.6      |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.01      |
|    n_updates            | 11160      |
|    policy_gradient_loss | -0.0102    |
|    std                  | 76.5       |
|    value_loss           | 0.127      |
----------------------------------------
[ADAPTIVE] Episode 682 reward: -0.048284
[ADAPTIVE] Mean reward over last 20 episodes: 0.022200
[ADAPTIVE] Plateau counter: 412/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.48192418  |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 669         |
|    time_elapsed         | 2191        |
|    total_timesteps      | 2740224     |
| train/                  |             |
|    approx_kl            | 0.006964382 |
|    clip_fraction        | 0.0501      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.7       |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11175       |
|    policy_gradient_loss | -0.00995    |
|    std                  | 76.9        |
|    value_loss           | 0.134       |
-----------------------------------------
[ADAPTIVE] Episode 683 reward: 0.004757
[ADAPTIVE] Mean reward over last 20 episodes: 0.023311
[ADAPTIVE] Plateau counter: 413/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.65784246  |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 670         |
|    time_elapsed         | 2195        |
|    total_timesteps      | 2744320     |
| train/                  |             |
|    approx_kl            | 0.005802992 |
|    clip_fraction        | 0.0525      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.7       |
|    explained_variance   | 0.735       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11190       |
|    policy_gradient_loss | -0.00981    |
|    std                  | 77.3        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 684 reward: -0.051732
[ADAPTIVE] Mean reward over last 20 episodes: 0.016024
[ADAPTIVE] Plateau counter: 414/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7174625   |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 671         |
|    time_elapsed         | 2198        |
|    total_timesteps      | 2748416     |
| train/                  |             |
|    approx_kl            | 0.010466511 |
|    clip_fraction        | 0.0674      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.8       |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11205       |
|    policy_gradient_loss | -0.00919    |
|    std                  | 77.7        |
|    value_loss           | 0.094       |
-----------------------------------------
[ADAPTIVE] Episode 685 reward: 0.048123
[ADAPTIVE] Mean reward over last 20 episodes: 0.016455
[ADAPTIVE] Plateau counter: 415/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.7422915  |
| time/                   |            |
|    fps                  | 1250       |
|    iterations           | 672        |
|    time_elapsed         | 2201       |
|    total_timesteps      | 2752512    |
| train/                  |            |
|    approx_kl            | 0.00812795 |
|    clip_fraction        | 0.0531     |
|    clip_range           | 0.2        |
|    entropy_loss         | -51.8      |
|    explained_variance   | 0.776      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.03      |
|    n_updates            | 11220      |
|    policy_gradient_loss | -0.0108    |
|    std                  | 78.3       |
|    value_loss           | 0.105      |
----------------------------------------
[ADAPTIVE] Episode 686 reward: -0.052895
[ADAPTIVE] Mean reward over last 20 episodes: 0.015949
[ADAPTIVE] Plateau counter: 416/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6506814    |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 673          |
|    time_elapsed         | 2204         |
|    total_timesteps      | 2756608      |
| train/                  |              |
|    approx_kl            | 0.0063823964 |
|    clip_fraction        | 0.0552       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.9        |
|    explained_variance   | 0.708        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11235        |
|    policy_gradient_loss | -0.012       |
|    std                  | 78.8         |
|    value_loss           | 0.126        |
------------------------------------------
[ADAPTIVE] Episode 687 reward: -0.075368
[ADAPTIVE] Mean reward over last 20 episodes: 0.013203
[ADAPTIVE] Plateau counter: 417/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7312268    |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 674          |
|    time_elapsed         | 2207         |
|    total_timesteps      | 2760704      |
| train/                  |              |
|    approx_kl            | 0.0075766854 |
|    clip_fraction        | 0.0802       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52          |
|    explained_variance   | 0.706        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11250        |
|    policy_gradient_loss | -0.0112      |
|    std                  | 79.6         |
|    value_loss           | 0.12         |
------------------------------------------
[ADAPTIVE] Episode 688 reward: -0.018256
[ADAPTIVE] Mean reward over last 20 episodes: 0.009886
[ADAPTIVE] Plateau counter: 418/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6089969    |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 675          |
|    time_elapsed         | 2211         |
|    total_timesteps      | 2764800      |
| train/                  |              |
|    approx_kl            | 0.0066280263 |
|    clip_fraction        | 0.076        |
|    clip_range           | 0.2          |
|    entropy_loss         | -52          |
|    explained_variance   | 0.794        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11265        |
|    policy_gradient_loss | -0.0122      |
|    std                  | 80.1         |
|    value_loss           | 0.0754       |
------------------------------------------
[ADAPTIVE] Episode 689 reward: -0.007875
[ADAPTIVE] Mean reward over last 20 episodes: 0.006166
[ADAPTIVE] Plateau counter: 419/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7690761    |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 676          |
|    time_elapsed         | 2214         |
|    total_timesteps      | 2768896      |
| train/                  |              |
|    approx_kl            | 0.0066315434 |
|    clip_fraction        | 0.0752       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.1        |
|    explained_variance   | 0.78         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11280        |
|    policy_gradient_loss | -0.0122      |
|    std                  | 80.5         |
|    value_loss           | 0.148        |
------------------------------------------
[ADAPTIVE] Episode 690 reward: -0.006076
[ADAPTIVE] Mean reward over last 20 episodes: -0.002208
[ADAPTIVE] Plateau counter: 420/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.70938385  |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 677         |
|    time_elapsed         | 2217        |
|    total_timesteps      | 2772992     |
| train/                  |             |
|    approx_kl            | 0.008173606 |
|    clip_fraction        | 0.053       |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.1       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.994      |
|    n_updates            | 11295       |
|    policy_gradient_loss | -0.00807    |
|    std                  | 80.9        |
|    value_loss           | 0.161       |
-----------------------------------------
[ADAPTIVE] Episode 691 reward: 0.064221
[ADAPTIVE] Mean reward over last 20 episodes: -0.004532
[ADAPTIVE] Plateau counter: 421/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.62256765  |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 678         |
|    time_elapsed         | 2220        |
|    total_timesteps      | 2777088     |
| train/                  |             |
|    approx_kl            | 0.008390991 |
|    clip_fraction        | 0.0763      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.2       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11310       |
|    policy_gradient_loss | -0.0114     |
|    std                  | 81          |
|    value_loss           | 0.0993      |
-----------------------------------------
[ADAPTIVE] Episode 692 reward: 0.071788
[ADAPTIVE] Mean reward over last 20 episodes: 0.001220
[ADAPTIVE] Plateau counter: 422/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.63537705   |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 679          |
|    time_elapsed         | 2224         |
|    total_timesteps      | 2781184      |
| train/                  |              |
|    approx_kl            | 0.0066304635 |
|    clip_fraction        | 0.0559       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.2        |
|    explained_variance   | 0.799        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11325        |
|    policy_gradient_loss | -0.0106      |
|    std                  | 81.4         |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 693 reward: 0.066447
[ADAPTIVE] Mean reward over last 20 episodes: 0.002051
[ADAPTIVE] Plateau counter: 423/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7693397   |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 680         |
|    time_elapsed         | 2226        |
|    total_timesteps      | 2785280     |
| train/                  |             |
|    approx_kl            | 0.009916604 |
|    clip_fraction        | 0.0757      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.2       |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.03       |
|    n_updates            | 11340       |
|    policy_gradient_loss | -0.012      |
|    std                  | 81.9        |
|    value_loss           | 0.119       |
-----------------------------------------
[ADAPTIVE] Episode 694 reward: -0.024619
[ADAPTIVE] Mean reward over last 20 episodes: 0.003721
[ADAPTIVE] Plateau counter: 424/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.816215    |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 681         |
|    time_elapsed         | 2230        |
|    total_timesteps      | 2789376     |
| train/                  |             |
|    approx_kl            | 0.007685609 |
|    clip_fraction        | 0.0671      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.3       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.03       |
|    n_updates            | 11355       |
|    policy_gradient_loss | -0.013      |
|    std                  | 82.3        |
|    value_loss           | 0.0852      |
-----------------------------------------
[ADAPTIVE] Episode 695 reward: -0.115645
[ADAPTIVE] Mean reward over last 20 episodes: -0.001936
[ADAPTIVE] Plateau counter: 425/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8374994    |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 682          |
|    time_elapsed         | 2233         |
|    total_timesteps      | 2793472      |
| train/                  |              |
|    approx_kl            | 0.0077488036 |
|    clip_fraction        | 0.0674       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.3        |
|    explained_variance   | 0.756        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 11370        |
|    policy_gradient_loss | -0.0098      |
|    std                  | 82.6         |
|    value_loss           | 0.12         |
------------------------------------------
[ADAPTIVE] Episode 696 reward: 0.033847
[ADAPTIVE] Mean reward over last 20 episodes: -0.001786
[ADAPTIVE] Plateau counter: 426/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9692511   |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 683         |
|    time_elapsed         | 2236        |
|    total_timesteps      | 2797568     |
| train/                  |             |
|    approx_kl            | 0.006383393 |
|    clip_fraction        | 0.052       |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.4       |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11385       |
|    policy_gradient_loss | -0.0106     |
|    std                  | 82.9        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 697 reward: -0.028571
[ADAPTIVE] Mean reward over last 20 episodes: 0.003393
[ADAPTIVE] Plateau counter: 427/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0421667   |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 684         |
|    time_elapsed         | 2240        |
|    total_timesteps      | 2801664     |
| train/                  |             |
|    approx_kl            | 0.008368533 |
|    clip_fraction        | 0.0826      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.4       |
|    explained_variance   | 0.788       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.03       |
|    n_updates            | 11400       |
|    policy_gradient_loss | -0.0132     |
|    std                  | 83.5        |
|    value_loss           | 0.147       |
-----------------------------------------
[ADAPTIVE] Episode 698 reward: 0.018948
[ADAPTIVE] Mean reward over last 20 episodes: 0.003076
[ADAPTIVE] Plateau counter: 428/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0247874   |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 685         |
|    time_elapsed         | 2243        |
|    total_timesteps      | 2805760     |
| train/                  |             |
|    approx_kl            | 0.006016901 |
|    clip_fraction        | 0.0366      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.5       |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11415       |
|    policy_gradient_loss | -0.00807    |
|    std                  | 83.8        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 699 reward: 0.014232
[ADAPTIVE] Mean reward over last 20 episodes: 0.003789
[ADAPTIVE] Plateau counter: 429/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8930179    |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 686          |
|    time_elapsed         | 2246         |
|    total_timesteps      | 2809856      |
| train/                  |              |
|    approx_kl            | 0.0070745535 |
|    clip_fraction        | 0.057        |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.5        |
|    explained_variance   | 0.761        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11430        |
|    policy_gradient_loss | -0.0103      |
|    std                  | 84.3         |
|    value_loss           | 0.096        |
------------------------------------------
[ADAPTIVE] Episode 700 reward: -0.115381
[ADAPTIVE] Mean reward over last 20 episodes: -0.006078
[ADAPTIVE] Plateau counter: 430/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6872784    |
| time/                   |              |
|    fps                  | 1250         |
|    iterations           | 687          |
|    time_elapsed         | 2249         |
|    total_timesteps      | 2813952      |
| train/                  |              |
|    approx_kl            | 0.0071354806 |
|    clip_fraction        | 0.075        |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.5        |
|    explained_variance   | 0.784        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11445        |
|    policy_gradient_loss | -0.00932     |
|    std                  | 84.7         |
|    value_loss           | 0.124        |
------------------------------------------
[ADAPTIVE] Episode 701 reward: 0.112314
[ADAPTIVE] Mean reward over last 20 episodes: -0.005501
[ADAPTIVE] Plateau counter: 431/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.47194737  |
| time/                   |             |
|    fps                  | 1250        |
|    iterations           | 688         |
|    time_elapsed         | 2252        |
|    total_timesteps      | 2818048     |
| train/                  |             |
|    approx_kl            | 0.007157241 |
|    clip_fraction        | 0.0823      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.6       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11460       |
|    policy_gradient_loss | -0.0127     |
|    std                  | 84.9        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 702 reward: -0.064614
[ADAPTIVE] Mean reward over last 20 episodes: -0.006318
[ADAPTIVE] Plateau counter: 432/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.45067218   |
| time/                   |              |
|    fps                  | 1251         |
|    iterations           | 689          |
|    time_elapsed         | 2255         |
|    total_timesteps      | 2822144      |
| train/                  |              |
|    approx_kl            | 0.0048035514 |
|    clip_fraction        | 0.0378       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.6        |
|    explained_variance   | 0.686        |
|    learning_rate        | 0.00025      |
|    loss                 | -1           |
|    n_updates            | 11475        |
|    policy_gradient_loss | -0.00958     |
|    std                  | 85.3         |
|    value_loss           | 0.17         |
------------------------------------------
[ADAPTIVE] Episode 703 reward: -0.059039
[ADAPTIVE] Mean reward over last 20 episodes: -0.009508
[ADAPTIVE] Plateau counter: 433/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.42356324  |
| time/                   |             |
|    fps                  | 1251        |
|    iterations           | 690         |
|    time_elapsed         | 2258        |
|    total_timesteps      | 2826240     |
| train/                  |             |
|    approx_kl            | 0.007043256 |
|    clip_fraction        | 0.0679      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.6       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11490       |
|    policy_gradient_loss | -0.0113     |
|    std                  | 85.6        |
|    value_loss           | 0.154       |
-----------------------------------------
[ADAPTIVE] Episode 704 reward: -0.170971
[ADAPTIVE] Mean reward over last 20 episodes: -0.015469
[ADAPTIVE] Plateau counter: 434/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.40361705  |
| time/                   |             |
|    fps                  | 1251        |
|    iterations           | 691         |
|    time_elapsed         | 2262        |
|    total_timesteps      | 2830336     |
| train/                  |             |
|    approx_kl            | 0.006031233 |
|    clip_fraction        | 0.0456      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.7       |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.989      |
|    n_updates            | 11505       |
|    policy_gradient_loss | -0.00963    |
|    std                  | 85.8        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 705 reward: -0.029480
[ADAPTIVE] Mean reward over last 20 episodes: -0.019350
[ADAPTIVE] Plateau counter: 435/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.50068104   |
| time/                   |              |
|    fps                  | 1251         |
|    iterations           | 692          |
|    time_elapsed         | 2265         |
|    total_timesteps      | 2834432      |
| train/                  |              |
|    approx_kl            | 0.0056505157 |
|    clip_fraction        | 0.0393       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.7        |
|    explained_variance   | 0.8          |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11520        |
|    policy_gradient_loss | -0.00869     |
|    std                  | 86.2         |
|    value_loss           | 0.154        |
------------------------------------------
[ADAPTIVE] Episode 706 reward: 0.031865
[ADAPTIVE] Mean reward over last 20 episodes: -0.015112
[ADAPTIVE] Plateau counter: 436/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.74847376  |
| time/                   |             |
|    fps                  | 1251        |
|    iterations           | 693         |
|    time_elapsed         | 2268        |
|    total_timesteps      | 2838528     |
| train/                  |             |
|    approx_kl            | 0.006436045 |
|    clip_fraction        | 0.0295      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.7       |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11535       |
|    policy_gradient_loss | -0.00555    |
|    std                  | 86.5        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 707 reward: 0.036596
[ADAPTIVE] Mean reward over last 20 episodes: -0.009513
[ADAPTIVE] Plateau counter: 437/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8907236    |
| time/                   |              |
|    fps                  | 1251         |
|    iterations           | 694          |
|    time_elapsed         | 2271         |
|    total_timesteps      | 2842624      |
| train/                  |              |
|    approx_kl            | 0.0061552785 |
|    clip_fraction        | 0.0495       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.8        |
|    explained_variance   | 0.854        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11550        |
|    policy_gradient_loss | -0.00955     |
|    std                  | 86.8         |
|    value_loss           | 0.143        |
------------------------------------------
[ADAPTIVE] Episode 708 reward: 0.048580
[ADAPTIVE] Mean reward over last 20 episodes: -0.006172
[ADAPTIVE] Plateau counter: 438/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9376044    |
| time/                   |              |
|    fps                  | 1251         |
|    iterations           | 695          |
|    time_elapsed         | 2274         |
|    total_timesteps      | 2846720      |
| train/                  |              |
|    approx_kl            | 0.0068260636 |
|    clip_fraction        | 0.0605       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.8        |
|    explained_variance   | 0.814        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11565        |
|    policy_gradient_loss | -0.0107      |
|    std                  | 87.1         |
|    value_loss           | 0.144        |
------------------------------------------
[ADAPTIVE] Episode 709 reward: 0.051207
[ADAPTIVE] Mean reward over last 20 episodes: -0.003217
[ADAPTIVE] Plateau counter: 439/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.89570916 |
| time/                   |            |
|    fps                  | 1251       |
|    iterations           | 696        |
|    time_elapsed         | 2277       |
|    total_timesteps      | 2850816    |
| train/                  |            |
|    approx_kl            | 0.01032001 |
|    clip_fraction        | 0.0822     |
|    clip_range           | 0.2        |
|    entropy_loss         | -52.8      |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.04      |
|    n_updates            | 11580      |
|    policy_gradient_loss | -0.0116    |
|    std                  | 87.3       |
|    value_loss           | 0.131      |
----------------------------------------
[ADAPTIVE] Episode 710 reward: 0.025293
[ADAPTIVE] Mean reward over last 20 episodes: -0.001649
[ADAPTIVE] Plateau counter: 440/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9787197    |
| time/                   |              |
|    fps                  | 1251         |
|    iterations           | 697          |
|    time_elapsed         | 2280         |
|    total_timesteps      | 2854912      |
| train/                  |              |
|    approx_kl            | 0.0052475114 |
|    clip_fraction        | 0.0356       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.9        |
|    explained_variance   | 0.738        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11595        |
|    policy_gradient_loss | -0.00875     |
|    std                  | 87.6         |
|    value_loss           | 0.189        |
------------------------------------------
[ADAPTIVE] Episode 711 reward: 0.090941
[ADAPTIVE] Mean reward over last 20 episodes: -0.000313
[ADAPTIVE] Plateau counter: 441/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.87655675   |
| time/                   |              |
|    fps                  | 1251         |
|    iterations           | 698          |
|    time_elapsed         | 2283         |
|    total_timesteps      | 2859008      |
| train/                  |              |
|    approx_kl            | 0.0069883335 |
|    clip_fraction        | 0.0794       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.9        |
|    explained_variance   | 0.763        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 11610        |
|    policy_gradient_loss | -0.0114      |
|    std                  | 88.2         |
|    value_loss           | 0.119        |
------------------------------------------
[ADAPTIVE] Episode 712 reward: -0.039995
[ADAPTIVE] Mean reward over last 20 episodes: -0.005902
[ADAPTIVE] Plateau counter: 442/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8037985   |
| time/                   |             |
|    fps                  | 1251        |
|    iterations           | 699         |
|    time_elapsed         | 2287        |
|    total_timesteps      | 2863104     |
| train/                  |             |
|    approx_kl            | 0.005090615 |
|    clip_fraction        | 0.0481      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53         |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.993      |
|    n_updates            | 11625       |
|    policy_gradient_loss | -0.00886    |
|    std                  | 88.8        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 713 reward: 0.003757
[ADAPTIVE] Mean reward over last 20 episodes: -0.009037
[ADAPTIVE] Plateau counter: 443/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8920105   |
| time/                   |             |
|    fps                  | 1251        |
|    iterations           | 700         |
|    time_elapsed         | 2290        |
|    total_timesteps      | 2867200     |
| train/                  |             |
|    approx_kl            | 0.007109532 |
|    clip_fraction        | 0.0642      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53         |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11640       |
|    policy_gradient_loss | -0.0114     |
|    std                  | 89.1        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 714 reward: 0.000050
[ADAPTIVE] Mean reward over last 20 episodes: -0.007803
[ADAPTIVE] Plateau counter: 444/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.734475     |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 701          |
|    time_elapsed         | 2293         |
|    total_timesteps      | 2871296      |
| train/                  |              |
|    approx_kl            | 0.0062216492 |
|    clip_fraction        | 0.0468       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53          |
|    explained_variance   | 0.817        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11655        |
|    policy_gradient_loss | -0.00973     |
|    std                  | 89.5         |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 715 reward: -0.021077
[ADAPTIVE] Mean reward over last 20 episodes: -0.003075
[ADAPTIVE] Plateau counter: 445/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6094982    |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 702          |
|    time_elapsed         | 2296         |
|    total_timesteps      | 2875392      |
| train/                  |              |
|    approx_kl            | 0.0073359082 |
|    clip_fraction        | 0.0777       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.1        |
|    explained_variance   | 0.847        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11670        |
|    policy_gradient_loss | -0.0111      |
|    std                  | 90.1         |
|    value_loss           | 0.143        |
------------------------------------------
[ADAPTIVE] Episode 716 reward: -0.030955
[ADAPTIVE] Mean reward over last 20 episodes: -0.006315
[ADAPTIVE] Plateau counter: 446/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 717 reward: 0.003039
[ADAPTIVE] Mean reward over last 20 episodes: -0.004734
[ADAPTIVE] Plateau counter: 447/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4734504    |
| time/                   |              |
|    fps                  | 1251         |
|    iterations           | 703          |
|    time_elapsed         | 2299         |
|    total_timesteps      | 2879488      |
| train/                  |              |
|    approx_kl            | 0.0075979093 |
|    clip_fraction        | 0.0644       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.2        |
|    explained_variance   | 0.755        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11685        |
|    policy_gradient_loss | -0.00832     |
|    std                  | 90.8         |
|    value_loss           | 0.104        |
------------------------------------------
[ADAPTIVE] Episode 718 reward: -0.068518
[ADAPTIVE] Mean reward over last 20 episodes: -0.009108
[ADAPTIVE] Plateau counter: 448/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4632698    |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 704          |
|    time_elapsed         | 2302         |
|    total_timesteps      | 2883584      |
| train/                  |              |
|    approx_kl            | 0.0064795064 |
|    clip_fraction        | 0.0716       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.2        |
|    explained_variance   | 0.817        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11700        |
|    policy_gradient_loss | -0.0113      |
|    std                  | 91.5         |
|    value_loss           | 0.119        |
------------------------------------------
[ADAPTIVE] Episode 719 reward: 0.032006
[ADAPTIVE] Mean reward over last 20 episodes: -0.008219
[ADAPTIVE] Plateau counter: 449/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.45381597  |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 705         |
|    time_elapsed         | 2306        |
|    total_timesteps      | 2887680     |
| train/                  |             |
|    approx_kl            | 0.004030535 |
|    clip_fraction        | 0.038       |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.3       |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.04       |
|    n_updates            | 11715       |
|    policy_gradient_loss | -0.00964    |
|    std                  | 92.1        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 720 reward: -0.061471
[ADAPTIVE] Mean reward over last 20 episodes: -0.005524
[ADAPTIVE] Plateau counter: 450/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4967797   |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 706         |
|    time_elapsed         | 2309        |
|    total_timesteps      | 2891776     |
| train/                  |             |
|    approx_kl            | 0.007849922 |
|    clip_fraction        | 0.0681      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.3       |
|    explained_variance   | 0.711       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.03       |
|    n_updates            | 11730       |
|    policy_gradient_loss | -0.0107     |
|    std                  | 92.7        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 721 reward: 0.018146
[ADAPTIVE] Mean reward over last 20 episodes: -0.010232
[ADAPTIVE] Plateau counter: 451/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.58368766  |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 707         |
|    time_elapsed         | 2312        |
|    total_timesteps      | 2895872     |
| train/                  |             |
|    approx_kl            | 0.006113297 |
|    clip_fraction        | 0.0572      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.4       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11745       |
|    policy_gradient_loss | -0.00894    |
|    std                  | 93.3        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 722 reward: -0.023874
[ADAPTIVE] Mean reward over last 20 episodes: -0.008195
[ADAPTIVE] Plateau counter: 452/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7924269    |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 708          |
|    time_elapsed         | 2315         |
|    total_timesteps      | 2899968      |
| train/                  |              |
|    approx_kl            | 0.0074118935 |
|    clip_fraction        | 0.0815       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.5        |
|    explained_variance   | 0.778        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11760        |
|    policy_gradient_loss | -0.0122      |
|    std                  | 93.9         |
|    value_loss           | 0.113        |
------------------------------------------
[ADAPTIVE] Episode 723 reward: 0.115340
[ADAPTIVE] Mean reward over last 20 episodes: 0.000524
[ADAPTIVE] Plateau counter: 453/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8669137   |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 709         |
|    time_elapsed         | 2318        |
|    total_timesteps      | 2904064     |
| train/                  |             |
|    approx_kl            | 0.005689347 |
|    clip_fraction        | 0.0361      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.5       |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.04       |
|    n_updates            | 11775       |
|    policy_gradient_loss | -0.00882    |
|    std                  | 94.4        |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 724 reward: 0.053710
[ADAPTIVE] Mean reward over last 20 episodes: 0.011758
[ADAPTIVE] Plateau counter: 454/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.90279096   |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 710          |
|    time_elapsed         | 2321         |
|    total_timesteps      | 2908160      |
| train/                  |              |
|    approx_kl            | 0.0053619696 |
|    clip_fraction        | 0.0466       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.6        |
|    explained_variance   | 0.831        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 11790        |
|    policy_gradient_loss | -0.00707     |
|    std                  | 95           |
|    value_loss           | 0.0942       |
------------------------------------------
[ADAPTIVE] Episode 725 reward: 0.073837
[ADAPTIVE] Mean reward over last 20 episodes: 0.016924
[ADAPTIVE] Plateau counter: 455/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9547941    |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 711          |
|    time_elapsed         | 2324         |
|    total_timesteps      | 2912256      |
| train/                  |              |
|    approx_kl            | 0.0064204936 |
|    clip_fraction        | 0.0472       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.6        |
|    explained_variance   | 0.766        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.07        |
|    n_updates            | 11805        |
|    policy_gradient_loss | -0.00824     |
|    std                  | 95.4         |
|    value_loss           | 0.0827       |
------------------------------------------
[ADAPTIVE] Episode 726 reward: 0.035045
[ADAPTIVE] Mean reward over last 20 episodes: 0.017083
[ADAPTIVE] Plateau counter: 456/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9593923   |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 712         |
|    time_elapsed         | 2328        |
|    total_timesteps      | 2916352     |
| train/                  |             |
|    approx_kl            | 0.006379267 |
|    clip_fraction        | 0.0584      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.7       |
|    explained_variance   | 0.702       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.956      |
|    n_updates            | 11820       |
|    policy_gradient_loss | -0.00939    |
|    std                  | 95.8        |
|    value_loss           | 0.214       |
-----------------------------------------
[ADAPTIVE] Episode 727 reward: -0.056938
[ADAPTIVE] Mean reward over last 20 episodes: 0.012406
[ADAPTIVE] Plateau counter: 457/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8741136    |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 713          |
|    time_elapsed         | 2331         |
|    total_timesteps      | 2920448      |
| train/                  |              |
|    approx_kl            | 0.0068518696 |
|    clip_fraction        | 0.0692       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.7        |
|    explained_variance   | 0.724        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 11835        |
|    policy_gradient_loss | -0.0107      |
|    std                  | 96           |
|    value_loss           | 0.0955       |
------------------------------------------
[ADAPTIVE] Episode 728 reward: 0.097565
[ADAPTIVE] Mean reward over last 20 episodes: 0.014855
[ADAPTIVE] Plateau counter: 458/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.71550554   |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 714          |
|    time_elapsed         | 2334         |
|    total_timesteps      | 2924544      |
| train/                  |              |
|    approx_kl            | 0.0066817137 |
|    clip_fraction        | 0.0541       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.7        |
|    explained_variance   | 0.783        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11850        |
|    policy_gradient_loss | -0.00971     |
|    std                  | 96.4         |
|    value_loss           | 0.102        |
------------------------------------------
[ADAPTIVE] Episode 729 reward: -0.022316
[ADAPTIVE] Mean reward over last 20 episodes: 0.011179
[ADAPTIVE] Plateau counter: 459/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.72869474   |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 715          |
|    time_elapsed         | 2337         |
|    total_timesteps      | 2928640      |
| train/                  |              |
|    approx_kl            | 0.0066543515 |
|    clip_fraction        | 0.0623       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.8        |
|    explained_variance   | 0.827        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 11865        |
|    policy_gradient_loss | -0.0103      |
|    std                  | 96.7         |
|    value_loss           | 0.0977       |
------------------------------------------
[ADAPTIVE] Episode 730 reward: 0.006388
[ADAPTIVE] Mean reward over last 20 episodes: 0.010234
[ADAPTIVE] Plateau counter: 460/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7665251   |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 716         |
|    time_elapsed         | 2340        |
|    total_timesteps      | 2932736     |
| train/                  |             |
|    approx_kl            | 0.005466519 |
|    clip_fraction        | 0.0568      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.8       |
|    explained_variance   | 0.795       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 11880       |
|    policy_gradient_loss | -0.0101     |
|    std                  | 97.2        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 731 reward: -0.062302
[ADAPTIVE] Mean reward over last 20 episodes: 0.002572
[ADAPTIVE] Plateau counter: 461/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7948549    |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 717          |
|    time_elapsed         | 2344         |
|    total_timesteps      | 2936832      |
| train/                  |              |
|    approx_kl            | 0.0051271543 |
|    clip_fraction        | 0.0513       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.8        |
|    explained_variance   | 0.711        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 11895        |
|    policy_gradient_loss | -0.00935     |
|    std                  | 97.6         |
|    value_loss           | 0.116        |
------------------------------------------
[ADAPTIVE] Episode 732 reward: -0.049440
[ADAPTIVE] Mean reward over last 20 episodes: 0.002100
[ADAPTIVE] Plateau counter: 462/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8058378   |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 718         |
|    time_elapsed         | 2347        |
|    total_timesteps      | 2940928     |
| train/                  |             |
|    approx_kl            | 0.006570304 |
|    clip_fraction        | 0.0584      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.9       |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 11910       |
|    policy_gradient_loss | -0.0119     |
|    std                  | 97.9        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 733 reward: -0.039164
[ADAPTIVE] Mean reward over last 20 episodes: -0.000046
[ADAPTIVE] Plateau counter: 463/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.62789005   |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 719          |
|    time_elapsed         | 2351         |
|    total_timesteps      | 2945024      |
| train/                  |              |
|    approx_kl            | 0.0082424395 |
|    clip_fraction        | 0.075        |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.9        |
|    explained_variance   | 0.774        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11925        |
|    policy_gradient_loss | -0.0141      |
|    std                  | 98.4         |
|    value_loss           | 0.127        |
------------------------------------------
[ADAPTIVE] Episode 734 reward: -0.018159
[ADAPTIVE] Mean reward over last 20 episodes: -0.000957
[ADAPTIVE] Plateau counter: 464/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.6531874    |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 720          |
|    time_elapsed         | 2354         |
|    total_timesteps      | 2949120      |
| train/                  |              |
|    approx_kl            | 0.0046913996 |
|    clip_fraction        | 0.0291       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.9        |
|    explained_variance   | 0.7          |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11940        |
|    policy_gradient_loss | -0.00654     |
|    std                  | 98.7         |
|    value_loss           | 0.176        |
------------------------------------------
[ADAPTIVE] Episode 735 reward: 0.029978
[ADAPTIVE] Mean reward over last 20 episodes: 0.001596
[ADAPTIVE] Plateau counter: 465/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4611375    |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 721          |
|    time_elapsed         | 2357         |
|    total_timesteps      | 2953216      |
| train/                  |              |
|    approx_kl            | 0.0045640226 |
|    clip_fraction        | 0.0468       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54          |
|    explained_variance   | 0.651        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 11955        |
|    policy_gradient_loss | -0.00888     |
|    std                  | 99           |
|    value_loss           | 0.185        |
------------------------------------------
[ADAPTIVE] Episode 736 reward: -0.007270
[ADAPTIVE] Mean reward over last 20 episodes: 0.002780
[ADAPTIVE] Plateau counter: 466/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.5312611    |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 722          |
|    time_elapsed         | 2360         |
|    total_timesteps      | 2957312      |
| train/                  |              |
|    approx_kl            | 0.0053284643 |
|    clip_fraction        | 0.0395       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54          |
|    explained_variance   | 0.784        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 11970        |
|    policy_gradient_loss | -0.0075      |
|    std                  | 99.5         |
|    value_loss           | 0.163        |
------------------------------------------
[ADAPTIVE] Episode 737 reward: 0.001642
[ADAPTIVE] Mean reward over last 20 episodes: 0.002710
[ADAPTIVE] Plateau counter: 467/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.52218187   |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 723          |
|    time_elapsed         | 2364         |
|    total_timesteps      | 2961408      |
| train/                  |              |
|    approx_kl            | 0.0063163685 |
|    clip_fraction        | 0.0563       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54          |
|    explained_variance   | 0.808        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11985        |
|    policy_gradient_loss | -0.00868     |
|    std                  | 100          |
|    value_loss           | 0.17         |
------------------------------------------
[ADAPTIVE] Episode 738 reward: -0.025295
[ADAPTIVE] Mean reward over last 20 episodes: 0.004871
[ADAPTIVE] Plateau counter: 468/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.52792436   |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 724          |
|    time_elapsed         | 2367         |
|    total_timesteps      | 2965504      |
| train/                  |              |
|    approx_kl            | 0.0073373085 |
|    clip_fraction        | 0.0717       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.1        |
|    explained_variance   | 0.794        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 12000        |
|    policy_gradient_loss | -0.0101      |
|    std                  | 101          |
|    value_loss           | 0.143        |
------------------------------------------
[ADAPTIVE] Episode 739 reward: -0.026495
[ADAPTIVE] Mean reward over last 20 episodes: 0.001946
[ADAPTIVE] Plateau counter: 469/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.5807268   |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 725         |
|    time_elapsed         | 2370        |
|    total_timesteps      | 2969600     |
| train/                  |             |
|    approx_kl            | 0.005613375 |
|    clip_fraction        | 0.0465      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54.1       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 12015       |
|    policy_gradient_loss | -0.00822    |
|    std                  | 101         |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 740 reward: -0.038476
[ADAPTIVE] Mean reward over last 20 episodes: 0.003096
[ADAPTIVE] Plateau counter: 470/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4951452   |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 726         |
|    time_elapsed         | 2373        |
|    total_timesteps      | 2973696     |
| train/                  |             |
|    approx_kl            | 0.006335955 |
|    clip_fraction        | 0.0472      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54.2       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.04       |
|    n_updates            | 12030       |
|    policy_gradient_loss | -0.0098     |
|    std                  | 102         |
|    value_loss           | 0.179       |
-----------------------------------------
[ADAPTIVE] Episode 741 reward: -0.028227
[ADAPTIVE] Mean reward over last 20 episodes: 0.000777
[ADAPTIVE] Plateau counter: 471/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.4992018   |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 727         |
|    time_elapsed         | 2376        |
|    total_timesteps      | 2977792     |
| train/                  |             |
|    approx_kl            | 0.005730526 |
|    clip_fraction        | 0.0499      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54.2       |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 12045       |
|    policy_gradient_loss | -0.00898    |
|    std                  | 102         |
|    value_loss           | 0.154       |
-----------------------------------------
[ADAPTIVE] Episode 742 reward: 0.016928
[ADAPTIVE] Mean reward over last 20 episodes: 0.002817
[ADAPTIVE] Plateau counter: 472/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.64562225   |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 728          |
|    time_elapsed         | 2380         |
|    total_timesteps      | 2981888      |
| train/                  |              |
|    approx_kl            | 0.0071110465 |
|    clip_fraction        | 0.0625       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.2        |
|    explained_variance   | 0.786        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 12060        |
|    policy_gradient_loss | -0.0121      |
|    std                  | 103          |
|    value_loss           | 0.156        |
------------------------------------------
[ADAPTIVE] Episode 743 reward: -0.161868
[ADAPTIVE] Mean reward over last 20 episodes: -0.011043
[ADAPTIVE] Plateau counter: 473/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.4990941    |
| time/                   |              |
|    fps                  | 1253         |
|    iterations           | 729          |
|    time_elapsed         | 2383         |
|    total_timesteps      | 2985984      |
| train/                  |              |
|    approx_kl            | 0.0049101347 |
|    clip_fraction        | 0.0354       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.3        |
|    explained_variance   | 0.728        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 12075        |
|    policy_gradient_loss | -0.00805     |
|    std                  | 103          |
|    value_loss           | 0.142        |
------------------------------------------
[ADAPTIVE] Episode 744 reward: -0.074774
[ADAPTIVE] Mean reward over last 20 episodes: -0.017467
[ADAPTIVE] Plateau counter: 474/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.24672459   |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 730          |
|    time_elapsed         | 2386         |
|    total_timesteps      | 2990080      |
| train/                  |              |
|    approx_kl            | 0.0091098305 |
|    clip_fraction        | 0.0499       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.4        |
|    explained_variance   | 0.811        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.07        |
|    n_updates            | 12090        |
|    policy_gradient_loss | -0.0082      |
|    std                  | 104          |
|    value_loss           | 0.141        |
------------------------------------------
[ADAPTIVE] Episode 745 reward: 0.070172
[ADAPTIVE] Mean reward over last 20 episodes: -0.017650
[ADAPTIVE] Plateau counter: 475/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.2707144    |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 731          |
|    time_elapsed         | 2389         |
|    total_timesteps      | 2994176      |
| train/                  |              |
|    approx_kl            | 0.0075357785 |
|    clip_fraction        | 0.0557       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.4        |
|    explained_variance   | 0.75         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 12105        |
|    policy_gradient_loss | -0.0098      |
|    std                  | 104          |
|    value_loss           | 0.122        |
------------------------------------------
[ADAPTIVE] Episode 746 reward: 0.035091
[ADAPTIVE] Mean reward over last 20 episodes: -0.017648
[ADAPTIVE] Plateau counter: 476/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.26560146   |
| time/                   |              |
|    fps                  | 1252         |
|    iterations           | 732          |
|    time_elapsed         | 2393         |
|    total_timesteps      | 2998272      |
| train/                  |              |
|    approx_kl            | 0.0054886867 |
|    clip_fraction        | 0.0558       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.4        |
|    explained_variance   | 0.795        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 12120        |
|    policy_gradient_loss | -0.00928     |
|    std                  | 105          |
|    value_loss           | 0.171        |
------------------------------------------
[ADAPTIVE] Episode 747 reward: 0.062725
[ADAPTIVE] Mean reward over last 20 episodes: -0.011665
[ADAPTIVE] Plateau counter: 477/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.37928516   |
| time/                   |              |
|    fps                  | 1253         |
|    iterations           | 733          |
|    time_elapsed         | 2396         |
|    total_timesteps      | 3002368      |
| train/                  |              |
|    approx_kl            | 0.0076594586 |
|    clip_fraction        | 0.0709       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.5        |
|    explained_variance   | 0.753        |
|    learning_rate        | 0.00025      |
|    loss                 | -1           |
|    n_updates            | 12135        |
|    policy_gradient_loss | -0.00919     |
|    std                  | 105          |
|    value_loss           | 0.203        |
------------------------------------------
2025-07-08 16:15:45,775 2000932 INFO [TRAIN] Training complete.
2025-07-08 16:15:45,811 2000932 INFO [SAVE] Model saved to: adaptive_curriculum_on_ppo/adaptive_curriculum_on_ppo
