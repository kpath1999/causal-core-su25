2025-07-18 22:50:13,911 2896843 INFO [PRETRAINED] Using pretrained model path: ppo_pushing_sb3/final_model.zip
2025-07-18 22:50:13,912 2896843 INFO Starting with 7 interventions
2025-07-18 22:50:13,913 2896843 INFO ===final evaluation===
2025-07-18 22:50:24,518 2896843 INFO Final performance
2025-07-18 22:50:24,518 2896843 INFO average reward: 3.394 +/- 0.000
2025-07-18 22:50:24,518 2896843 INFO success rate: 1.000
2025-07-18 22:50:24,518 2896843 INFO average episode length: 501.0
2025-07-18 22:50:24,519 2896843 INFO initial performance: {'avg_reward': 3.393721938342554, 'reward_std': 4.440892098500626e-16, 'avg_length': 501.0, 'success_rate': 1.0, 'total_episodes': 10}
2025-07-18 22:50:24,519 2896843 INFO CURRICULUM STAGE 1/7
2025-07-18 22:50:24,519 2896843 INFO Remaining interventions: ['goal', 'mass', 'friction', 'visual', 'position', 'angle', 'random']
2025-07-18 22:50:24,519 2896843 INFO
Testing intervention 1/7: goal
2025-07-18 22:50:24,519 2896843 INFO testing intervention: goal
IntervenedCausalWorld created with goal intervention
Reset #1: goal intervention applied (success: True)
2025-07-18 22:50:25,544 2896843 INFO Episode 1: reward=1.123, length=501, success=False
Reset #2: goal intervention applied (success: True)
2025-07-18 22:50:25,634 2896843 INFO Episode 2: reward=0.146, length=19, success=True
Reset #3: goal intervention applied (success: True)
2025-07-18 22:50:26,636 2896843 INFO Episode 3: reward=-1.371, length=501, success=False
2025-07-18 22:50:31,871 2896843 INFO Results: avg_reward=-0.206, success_rate=0.300, avg_length=356.2
2025-07-18 22:50:31,872 2896843 INFO
Testing intervention 2/7: mass
2025-07-18 22:50:31,872 2896843 INFO testing intervention: mass
IntervenedCausalWorld created with mass intervention
Reset #1: mass intervention applied (success: True)
2025-07-18 22:50:31,991 2896843 INFO Episode 1: reward=-0.213, length=31, success=True
Reset #2: mass intervention applied (success: True)
2025-07-18 22:50:32,102 2896843 INFO Episode 2: reward=-0.206, length=31, success=True
Reset #3: mass intervention applied (success: True)
2025-07-18 22:50:32,211 2896843 INFO Episode 3: reward=-0.939, length=30, success=True
2025-07-18 22:50:32,968 2896843 INFO Results: avg_reward=-0.679, success_rate=1.000, avg_length=30.1
2025-07-18 22:50:32,969 2896843 INFO
Testing intervention 3/7: friction
2025-07-18 22:50:32,969 2896843 INFO testing intervention: friction
IntervenedCausalWorld created with friction intervention
Reset #1: friction intervention applied (success: True)
2025-07-18 22:50:33,081 2896843 INFO Episode 1: reward=-0.773, length=27, success=True
Reset #2: friction intervention applied (success: True)
2025-07-18 22:50:33,187 2896843 INFO Episode 2: reward=-0.928, length=28, success=True
Reset #3: friction intervention applied (success: True)
2025-07-18 22:50:33,292 2896843 INFO Episode 3: reward=-0.876, length=28, success=True
2025-07-18 22:50:34,024 2896843 INFO Results: avg_reward=-0.866, success_rate=1.000, avg_length=27.8
2025-07-18 22:50:34,024 2896843 INFO
Testing intervention 4/7: visual
2025-07-18 22:50:34,024 2896843 INFO testing intervention: visual
IntervenedCausalWorld created with visual intervention
Reset #1: visual intervention applied (success: True)
2025-07-18 22:50:34,137 2896843 INFO Episode 1: reward=-0.773, length=27, success=True
Reset #2: visual intervention applied (success: True)
2025-07-18 22:50:34,242 2896843 INFO Episode 2: reward=-0.773, length=27, success=True
Reset #3: visual intervention applied (success: True)
2025-07-18 22:50:34,346 2896843 INFO Episode 3: reward=-0.773, length=27, success=True
2025-07-18 22:50:35,072 2896843 INFO Results: avg_reward=-0.773, success_rate=1.000, avg_length=27.0
2025-07-18 22:50:35,073 2896843 INFO
Testing intervention 5/7: position
2025-07-18 22:50:35,073 2896843 INFO testing intervention: position
IntervenedCausalWorld created with position intervention
Reset #1: position intervention applied (success: True)
2025-07-18 22:50:35,184 2896843 INFO Episode 1: reward=-1.696, length=26, success=True
Reset #2: position intervention applied (success: True)
2025-07-18 22:50:36,244 2896843 INFO Episode 2: reward=3.985, length=501, success=False
Reset #3: position intervention applied (success: True)
2025-07-18 22:50:37,259 2896843 INFO Episode 3: reward=2.355, length=501, success=False
2025-07-18 22:50:42,535 2896843 INFO Results: avg_reward=0.904, success_rate=0.300, avg_length=358.8
2025-07-18 22:50:42,535 2896843 INFO
Testing intervention 6/7: angle
2025-07-18 22:50:42,535 2896843 INFO testing intervention: angle
IntervenedCausalWorld created with angle intervention
Reset #1: angle intervention applied (success: True)
2025-07-18 22:50:43,571 2896843 INFO Episode 1: reward=1.732, length=501, success=False
Reset #2: angle intervention applied (success: True)
2025-07-18 22:50:44,624 2896843 INFO Episode 2: reward=2.632, length=501, success=False
Reset #3: angle intervention applied (success: True)
2025-07-18 22:50:45,607 2896843 INFO Episode 3: reward=0.852, length=501, success=False
2025-07-18 22:50:52,880 2896843 INFO Results: avg_reward=1.159, success_rate=0.000, avg_length=501.0
2025-07-18 22:50:52,880 2896843 INFO
Testing intervention 7/7: random
2025-07-18 22:50:52,880 2896843 INFO testing intervention: random
IntervenedCausalWorld created with random intervention
Reset #1: random intervention applied (success: True)
2025-07-18 22:50:53,897 2896843 INFO Episode 1: reward=4.543, length=501, success=False
Reset #2: random intervention applied (success: True)
2025-07-18 22:50:54,932 2896843 INFO Episode 2: reward=-2.501, length=501, success=False
Reset #3: random intervention applied (success: True)
2025-07-18 22:50:55,930 2896843 INFO Episode 3: reward=6.793, length=501, success=False
2025-07-18 22:51:02,891 2896843 INFO Results: avg_reward=2.650, success_rate=0.000, avg_length=501.0
2025-07-18 22:51:02,892 2896843 INFO best intervention for stage 1: random
2025-07-18 22:51:02,892 2896843 INFO average reward: 2.650
2025-07-18 22:51:02,892 2896843 INFO success rate: 0.000
2025-07-18 22:51:02,892 2896843 INFO average length: 501.0
2025-07-18 22:51:02,892 2896843 INFO === stage 1/7: training on random intervention ===
IntervenedCausalWorld created with random intervention
Reset #1: random intervention applied (success: True)
Logging to ppo_pushing_sb3/PPO_0
Reset #2: random intervention applied (success: True)
Reset #3: random intervention applied (success: True)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 267       |
|    ep_rew_mean     | 2.0352743 |
| time/              |           |
|    fps             | 449       |
|    iterations      | 1         |
|    time_elapsed    | 9         |
|    total_timesteps | 5050368   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 282        |
|    ep_rew_mean          | 1.8775079  |
| time/                   |            |
|    fps                  | 278        |
|    iterations           | 2          |
|    time_elapsed         | 29         |
|    total_timesteps      | 5054464    |
| train/                  |            |
|    approx_kl            | 0.03358264 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -21.6      |
|    explained_variance   | 0.336      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.479     |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.0773    |
|    std                  | 2.68       |
|    value_loss           | 0.0988     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 302        |
|    ep_rew_mean          | 1.8642348  |
| time/                   |            |
|    fps                  | 248        |
|    iterations           | 3          |
|    time_elapsed         | 49         |
|    total_timesteps      | 5058560    |
| train/                  |            |
|    approx_kl            | 0.04088657 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -21.7      |
|    explained_variance   | 0.635      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.526     |
|    n_updates            | 1185       |
|    policy_gradient_loss | -0.0794    |
|    std                  | 2.72       |
|    value_loss           | 0.0415     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 319         |
|    ep_rew_mean          | 1.8797176   |
| time/                   |             |
|    fps                  | 235         |
|    iterations           | 4           |
|    time_elapsed         | 69          |
|    total_timesteps      | 5062656     |
| train/                  |             |
|    approx_kl            | 0.040596083 |
|    clip_fraction        | 0.476       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.9       |
|    explained_variance   | 0.757       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0914     |
|    std                  | 2.76        |
|    value_loss           | 0.0317      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 339        |
|    ep_rew_mean          | 1.7659507  |
| time/                   |            |
|    fps                  | 228        |
|    iterations           | 5          |
|    time_elapsed         | 89         |
|    total_timesteps      | 5066752    |
| train/                  |            |
|    approx_kl            | 0.04988959 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.1      |
|    explained_variance   | 0.121      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.486     |
|    n_updates            | 1215       |
|    policy_gradient_loss | -0.0589    |
|    std                  | 2.84       |
|    value_loss           | 0.117      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 359       |
|    ep_rew_mean          | 1.7642426 |
| time/                   |           |
|    fps                  | 223       |
|    iterations           | 6         |
|    time_elapsed         | 109       |
|    total_timesteps      | 5070848   |
| train/                  |           |
|    approx_kl            | 0.0411368 |
|    clip_fraction        | 0.463     |
|    clip_range           | 0.2       |
|    entropy_loss         | -22.2     |
|    explained_variance   | 0.678     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.522    |
|    n_updates            | 1230      |
|    policy_gradient_loss | -0.0901   |
|    std                  | 2.86      |
|    value_loss           | 0.0648    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 382         |
|    ep_rew_mean          | 1.7214574   |
| time/                   |             |
|    fps                  | 220         |
|    iterations           | 7           |
|    time_elapsed         | 129         |
|    total_timesteps      | 5074944     |
| train/                  |             |
|    approx_kl            | 0.051021874 |
|    clip_fraction        | 0.531       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.3       |
|    explained_variance   | 0.437       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.52       |
|    n_updates            | 1245        |
|    policy_gradient_loss | -0.0846     |
|    std                  | 2.91        |
|    value_loss           | 0.0965      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 400        |
|    ep_rew_mean          | 1.5748848  |
| time/                   |            |
|    fps                  | 218        |
|    iterations           | 8          |
|    time_elapsed         | 149        |
|    total_timesteps      | 5079040    |
| train/                  |            |
|    approx_kl            | 0.08102546 |
|    clip_fraction        | 0.598      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.5      |
|    explained_variance   | 0.486      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.542     |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0913    |
|    std                  | 2.96       |
|    value_loss           | 0.129      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 420        |
|    ep_rew_mean          | 1.4576712  |
| time/                   |            |
|    fps                  | 216        |
|    iterations           | 9          |
|    time_elapsed         | 170        |
|    total_timesteps      | 5083136    |
| train/                  |            |
|    approx_kl            | 0.03957784 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.6      |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.537     |
|    n_updates            | 1275       |
|    policy_gradient_loss | -0.0924    |
|    std                  | 2.98       |
|    value_loss           | 0.0578     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 440         |
|    ep_rew_mean          | 1.3762034   |
| time/                   |             |
|    fps                  | 215         |
|    iterations           | 10          |
|    time_elapsed         | 190         |
|    total_timesteps      | 5087232     |
| train/                  |             |
|    approx_kl            | 0.050730415 |
|    clip_fraction        | 0.538       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.604       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.568      |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.105      |
|    std                  | 3           |
|    value_loss           | 0.039       |
-----------------------------------------
