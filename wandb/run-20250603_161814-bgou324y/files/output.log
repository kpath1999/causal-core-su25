🚀 Initializing GraphBasedCurriculumManager with 50000 timesteps
🎲 Exploration rate: 0.95, Learning rate: 0.2
🏗️  Building intervention dependency graph...
🔧 Created intervention node: goal_basic with params: {}
🔧 Created intervention node: pose_position with params: {'positions': True, 'orientations': False}
🔧 Created intervention node: pose_full with params: {'positions': True, 'orientations': True}
🔧 Created intervention node: physics_friction with params: {'group': 'friction'}
🔧 Created intervention node: physics_mass with params: {'group': 'mass'}
🔧 Created intervention node: visual with params: {}
🔧 Created intervention node: random_full with params: {}
➕ Added node to graph: goal_basic
➕ Added node to graph: pose_position
➕ Added node to graph: pose_full
➕ Added node to graph: physics_friction
➕ Added node to graph: physics_mass
➕ Added node to graph: visual
➕ Added node to graph: random_full
🔗 Setting up dependencies:
   goal_basic → pose_position
⚔️  Setting up conflicts:
   physics_mass ⚔️ physics_friction
✅ Graph construction complete: 7 nodes, 3 edges

🎓 Generating curriculum configuration...

🎲 Selecting active interventions...

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=0, success_rate=0.000000)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
📋 Processing 7 eligible interventions...
   goal_basic: NEW intervention (score=∞)
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
🎭 Creating actor instance for: goal_basic
   goal_basic: ✅ ACTIVATED with strength 1.000
   pose_position: NEW intervention (score=∞)
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_position
   pose_position: ✅ ACTIVATED with strength 1.000
   pose_full: NEW intervention (score=∞)
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_full
   pose_full: ✅ ACTIVATED with strength 1.000
   physics_friction: NEW intervention (score=∞)
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
🎭 Creating actor instance for: physics_friction
   physics_friction: ✅ ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=∞)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
   physics_mass: ⚔️  CONFLICT with ['physics_friction'] - skipping
   visual: NEW intervention (score=∞)
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
🎭 Creating actor instance for: visual
   visual: ✅ ACTIVATED with strength 1.000
   random_full: NEW intervention (score=∞)
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>-0.010000 or random<0.95 or history<5 or attempts<3)
🎭 Creating actor instance for: random_full
   random_full: ✅ ACTIVATED with strength 1.000

🎉 FINAL SELECTION: 6 interventions activated
   🚀 goal_basic (strength: 1.000)
   🚀 pose_position (strength: 1.000)
   🚀 pose_full (strength: 1.000)
   🚀 physics_friction (strength: 1.000)
   🚀 visual (strength: 1.000)
   🚀 random_full (strength: 1.000)
🔧 Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
✅ Curriculum config ready: 6 actors, 6 active nodes
🔄 Curriculum callback initialized: adaptation every 30 episodes
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Logging to baseline_picking_her_sac_curriculum\her_sac_curriculum_2
📊 Episode completed: reward=0.012964, success=True

📈 Updating graph performance: episode_reward=0.012964, episode_success=True, active_nodes=[]
   Episode 1: Baseline reward updated 0.000000 → 0.012964
📊 Episode completed: reward=0.021572, success=True

📈 Updating graph performance: episode_reward=0.021572, episode_success=True, active_nodes=[]
   Episode 2: Baseline reward updated 0.012964 → 0.017268
📊 Episode completed: reward=0.011025, success=True

📈 Updating graph performance: episode_reward=0.011025, episode_success=True, active_nodes=[]
   Episode 3: Baseline reward updated 0.017268 → 0.015187
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0114   |
| time/              |          |
|    episodes        | 4        |
|    fps             | 177      |
|    time_elapsed    | 4        |
|    total_timesteps | 804      |
---------------------------------
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 4: Baseline reward updated 0.015187 → 0.011390
📊 Episode completed: reward=0.011391, success=True

📈 Updating graph performance: episode_reward=0.011391, episode_success=True, active_nodes=[]
   Episode 5: Baseline reward updated 0.011390 → 0.011390
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 6: Baseline reward updated 0.011390 → 0.009492
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 7: Baseline reward updated 0.009492 → 0.008136
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.00712  |
| time/              |          |
|    episodes        | 8        |
|    fps             | 47       |
|    time_elapsed    | 33       |
|    total_timesteps | 1608     |
| train/             |          |
|    actor_loss      | -38.2    |
|    critic_loss     | 87.1     |
|    ent_coef        | 0.869    |
|    ent_coef_loss   | -1.38    |
|    learning_rate   | 0.00025  |
|    n_updates       | 607      |
---------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 8: Baseline reward updated 0.008136 → 0.007119
📊 Episode completed: reward=0.100298, success=True

📈 Updating graph performance: episode_reward=0.100298, episode_success=True, active_nodes=[]
   Episode 9: Baseline reward updated 0.007119 → 0.017472
📊 Episode completed: reward=0.012852, success=True

📈 Updating graph performance: episode_reward=0.012852, episode_success=True, active_nodes=[]
   Episode 10: Baseline reward updated 0.017472 → 0.017010
📊 Episode completed: reward=0.001078, success=True

📈 Updating graph performance: episode_reward=0.001078, episode_success=True, active_nodes=[]
   Episode 11: Baseline reward updated 0.017010 → 0.015822
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0143   |
| time/              |          |
|    episodes        | 12       |
|    fps             | 30       |
|    time_elapsed    | 80       |
|    total_timesteps | 2412     |
| train/             |          |
|    actor_loss      | -141     |
|    critic_loss     | 173      |
|    ent_coef        | 0.791    |
|    ent_coef_loss   | 0.0765   |
|    learning_rate   | 0.00025  |
|    n_updates       | 1411     |
---------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 12: Baseline reward updated 0.015822 → 0.013664
📊 Episode completed: reward=0.027717, success=True

📈 Updating graph performance: episode_reward=0.027717, episode_success=True, active_nodes=[]
   Episode 13: Baseline reward updated 0.013664 → 0.015334
📊 Episode completed: reward=0.356540, success=True

📈 Updating graph performance: episode_reward=0.356540, episode_success=True, active_nodes=[]
   Episode 14: Baseline reward updated 0.015334 → 0.050988
📊 Episode completed: reward=0.016303, success=True

📈 Updating graph performance: episode_reward=0.016303, episode_success=True, active_nodes=[]
   Episode 15: Baseline reward updated 0.050988 → 0.051479
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0357   |
| time/              |          |
|    episodes        | 16       |
|    fps             | 26       |
|    time_elapsed    | 120      |
|    total_timesteps | 3216     |
| train/             |          |
|    actor_loss      | -448     |
|    critic_loss     | 1.63e+03 |
|    ent_coef        | 0.925    |
|    ent_coef_loss   | 0.714    |
|    learning_rate   | 0.00025  |
|    n_updates       | 2215     |
---------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 16: Baseline reward updated 0.051479 → 0.051479
📊 Episode completed: reward=0.665082, success=True

📈 Updating graph performance: episode_reward=0.665082, episode_success=True, active_nodes=[]
   Episode 17: Baseline reward updated 0.051479 → 0.117987
📊 Episode completed: reward=0.148452, success=True

📈 Updating graph performance: episode_reward=0.148452, episode_success=True, active_nodes=[]
   Episode 18: Baseline reward updated 0.117987 → 0.132832
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 19: Baseline reward updated 0.132832 → 0.122802
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0693    |
| time/              |           |
|    episodes        | 20        |
|    fps             | 23        |
|    time_elapsed    | 169       |
|    total_timesteps | 4020      |
| train/             |           |
|    actor_loss      | -1.04e+03 |
|    critic_loss     | 1.45e+04  |
|    ent_coef        | 1.21      |
|    ent_coef_loss   | -3.46     |
|    learning_rate   | 0.00025   |
|    n_updates       | 3019      |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 20: Baseline reward updated 0.122802 → 0.121517
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 21: Baseline reward updated 0.121517 → 0.121409
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 22: Baseline reward updated 0.121409 → 0.121409
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 23: Baseline reward updated 0.121409 → 0.118638
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.079     |
| time/              |           |
|    episodes        | 24        |
|    fps             | 22        |
|    time_elapsed    | 216       |
|    total_timesteps | 4824      |
| train/             |           |
|    actor_loss      | -2.72e+03 |
|    critic_loss     | 1.21e+05  |
|    ent_coef        | 1.58      |
|    ent_coef_loss   | -9.57     |
|    learning_rate   | 0.00025   |
|    n_updates       | 3823      |
----------------------------------
📊 Episode completed: reward=0.510618, success=True

📈 Updating graph performance: episode_reward=0.510618, episode_success=True, active_nodes=[]
   Episode 24: Baseline reward updated 0.118638 → 0.134045
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.001407, success=True

📈 Updating graph performance: episode_reward=0.001407, episode_success=True, active_nodes=[]
   Episode 25: Baseline reward updated 0.134045 → 0.132556
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 26: Baseline reward updated 0.132556 → 0.132556
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 27: Baseline reward updated 0.132556 → 0.066048
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0678    |
| time/              |           |
|    episodes        | 28        |
|    fps             | 20        |
|    time_elapsed    | 268       |
|    total_timesteps | 5628      |
| train/             |           |
|    actor_loss      | -6.95e+03 |
|    critic_loss     | 1.45e+06  |
|    ent_coef        | 2.1       |
|    ent_coef_loss   | -24.2     |
|    learning_rate   | 0.00025   |
|    n_updates       | 4627      |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 28: Baseline reward updated 0.066048 → 0.051203
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=[]
   Episode 29: Baseline reward updated 0.051203 → 0.051203

🔄 CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
🔄 Adapting curriculum...

🎓 Generating curriculum configuration...

🎲 Selecting active interventions...

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=0, success_rate=0.000000)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
📋 Processing 7 eligible interventions...
   goal_basic: NEW intervention (score=∞)
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
🎭 Creating actor instance for: goal_basic
   goal_basic: ✅ ACTIVATED with strength 1.000
   pose_position: NEW intervention (score=∞)
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_position
   pose_position: ✅ ACTIVATED with strength 1.000
   pose_full: NEW intervention (score=∞)
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_full
   pose_full: ✅ ACTIVATED with strength 1.000
   physics_friction: NEW intervention (score=∞)
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
🎭 Creating actor instance for: physics_friction
   physics_friction: ✅ ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=∞)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
   physics_mass: ⚔️  CONFLICT with ['physics_friction'] - skipping
   visual: NEW intervention (score=∞)
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
🎭 Creating actor instance for: visual
   visual: ✅ ACTIVATED with strength 1.000
   random_full: NEW intervention (score=∞)
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.041203 or random<0.9472488535309557 or history<5 or attempts<3)
🎭 Creating actor instance for: random_full
   random_full: ✅ ACTIVATED with strength 1.000

🎉 FINAL SELECTION: 6 interventions activated
   🚀 goal_basic (strength: 1.000)
   🚀 pose_position (strength: 1.000)
   🚀 pose_full (strength: 1.000)
   🚀 physics_friction (strength: 1.000)
   🚀 visual (strength: 1.000)
   🚀 random_full (strength: 1.000)
🔧 Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
✅ Curriculum config ready: 6 actors, 6 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
[34m[1mwandb[0m: [33mWARNING[0m Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
✅ Curriculum updated successfully!
   📊 Active interventions: 6
   🎯 Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   🎲 Exploration rate: 0.9472
   📈 Baseline reward: 0.051203
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 30: Baseline reward updated 0.051203 → 0.051203
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 31: Baseline reward updated 0.051203 → 0.051203
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 2
🎯 Node goal_basic: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 2
🎯 Node pose_position: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 2
🎯 Node pose_full: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 2
🎯 Node physics_friction: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 2
🎯 Node visual: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 2
🎯 Node random_full: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0593   |
| time/              |          |
|    episodes        | 32       |
|    fps             | 20       |
|    time_elapsed    | 313      |
|    total_timesteps | 6432     |
| train/             |          |
|    actor_loss      | -1.5e+04 |
|    critic_loss     | 8.03e+06 |
|    ent_coef        | 2.71     |
|    ent_coef_loss   | -46.3    |
|    learning_rate   | 0.00025  |
|    n_updates       | 5431     |
---------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 32: Baseline reward updated 0.051203 → 0.051203
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 3
🎯 Node goal_basic: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 3
🎯 Node pose_position: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 3
🎯 Node pose_full: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 3
🎯 Node physics_friction: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 3
🎯 Node visual: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 3
🎯 Node random_full: Causal impact = -0.051203 (avg: 0.000000 vs baseline: 0.051203)
📊 Episode completed: reward=0.005459, success=True

📈 Updating graph performance: episode_reward=0.005459, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 33: Baseline reward updated 0.051203 → 0.051748
📊 Node goal_basic: Updated performance - Recent avg reward: 0.001365, Times activated: 4
🎯 Node goal_basic: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
📊 Node pose_position: Updated performance - Recent avg reward: 0.001365, Times activated: 4
🎯 Node pose_position: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
📊 Node pose_full: Updated performance - Recent avg reward: 0.001365, Times activated: 4
🎯 Node pose_full: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.001365, Times activated: 4
🎯 Node physics_friction: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
📊 Node visual: Updated performance - Recent avg reward: 0.001365, Times activated: 4
🎯 Node visual: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
📊 Node random_full: Updated performance - Recent avg reward: 0.001365, Times activated: 4
🎯 Node random_full: Causal impact = -0.050384 (avg: 0.001365 vs baseline: 0.051748)
📊 Episode completed: reward=0.004722, success=True

📈 Updating graph performance: episode_reward=0.004722, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 34: Baseline reward updated 0.051748 → 0.001159
📊 Node goal_basic: Updated performance - Recent avg reward: 0.002036, Times activated: 5
🎯 Node goal_basic: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
📊 Node pose_position: Updated performance - Recent avg reward: 0.002036, Times activated: 5
🎯 Node pose_position: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
📊 Node pose_full: Updated performance - Recent avg reward: 0.002036, Times activated: 5
🎯 Node pose_full: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.002036, Times activated: 5
🎯 Node physics_friction: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
📊 Node visual: Updated performance - Recent avg reward: 0.002036, Times activated: 5
🎯 Node visual: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
📊 Node random_full: Updated performance - Recent avg reward: 0.002036, Times activated: 5
🎯 Node random_full: Causal impact = 0.000877 (avg: 0.002036 vs baseline: 0.001159)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 35: Baseline reward updated 0.001159 → 0.001018
📊 Node goal_basic: Updated performance - Recent avg reward: 0.002036, Times activated: 6
🎯 Node goal_basic: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
📊 Node pose_position: Updated performance - Recent avg reward: 0.002036, Times activated: 6
🎯 Node pose_position: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
📊 Node pose_full: Updated performance - Recent avg reward: 0.002036, Times activated: 6
🎯 Node pose_full: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.002036, Times activated: 6
🎯 Node physics_friction: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
📊 Node visual: Updated performance - Recent avg reward: 0.002036, Times activated: 6
🎯 Node visual: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
📊 Node random_full: Updated performance - Recent avg reward: 0.002036, Times activated: 6
🎯 Node random_full: Causal impact = 0.000679 (avg: 0.001697 vs baseline: 0.001018)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0558    |
| time/              |           |
|    episodes        | 36        |
|    fps             | 20        |
|    time_elapsed    | 356       |
|    total_timesteps | 7236      |
| train/             |           |
|    actor_loss      | -2.55e+04 |
|    critic_loss     | 3.3e+07   |
|    ent_coef        | 3.48      |
|    ent_coef_loss   | -57       |
|    learning_rate   | 0.00025   |
|    n_updates       | 6235      |
----------------------------------
📊 Episode completed: reward=0.100792, success=True

📈 Updating graph performance: episode_reward=0.100792, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 36: Baseline reward updated 0.001018 → 0.011097
📊 Node goal_basic: Updated performance - Recent avg reward: 0.022195, Times activated: 7
🎯 Node goal_basic: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
📊 Node pose_position: Updated performance - Recent avg reward: 0.022195, Times activated: 7
🎯 Node pose_position: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
📊 Node pose_full: Updated performance - Recent avg reward: 0.022195, Times activated: 7
🎯 Node pose_full: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.022195, Times activated: 7
🎯 Node physics_friction: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
📊 Node visual: Updated performance - Recent avg reward: 0.022195, Times activated: 7
🎯 Node visual: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
📊 Node random_full: Updated performance - Recent avg reward: 0.022195, Times activated: 7
🎯 Node random_full: Causal impact = 0.004756 (avg: 0.015853 vs baseline: 0.011097)
📊 Episode completed: reward=0.000001, success=False

📈 Updating graph performance: episode_reward=0.000001, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 37: Baseline reward updated 0.011097 → 0.011097
📊 Node goal_basic: Updated performance - Recent avg reward: 0.022195, Times activated: 8
🎯 Node goal_basic: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
📊 Node pose_position: Updated performance - Recent avg reward: 0.022195, Times activated: 8
🎯 Node pose_position: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
📊 Node pose_full: Updated performance - Recent avg reward: 0.022195, Times activated: 8
🎯 Node pose_full: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.022195, Times activated: 8
🎯 Node physics_friction: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
📊 Node visual: Updated performance - Recent avg reward: 0.022195, Times activated: 8
🎯 Node visual: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
📊 Node random_full: Updated performance - Recent avg reward: 0.022195, Times activated: 8
🎯 Node random_full: Causal impact = 0.002774 (avg: 0.013872 vs baseline: 0.011097)
📊 Episode completed: reward=0.031173, success=True

📈 Updating graph performance: episode_reward=0.031173, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 38: Baseline reward updated 0.011097 → 0.014215
📊 Node goal_basic: Updated performance - Recent avg reward: 0.027338, Times activated: 9
🎯 Node goal_basic: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
📊 Node pose_position: Updated performance - Recent avg reward: 0.027338, Times activated: 9
🎯 Node pose_position: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
📊 Node pose_full: Updated performance - Recent avg reward: 0.027338, Times activated: 9
🎯 Node pose_full: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.027338, Times activated: 9
🎯 Node physics_friction: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
📊 Node visual: Updated performance - Recent avg reward: 0.027338, Times activated: 9
🎯 Node visual: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
📊 Node random_full: Updated performance - Recent avg reward: 0.027338, Times activated: 9
🎯 Node random_full: Causal impact = 0.001579 (avg: 0.015794 vs baseline: 0.014215)
📊 Episode completed: reward=0.200617, success=True

📈 Updating graph performance: episode_reward=0.200617, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 39: Baseline reward updated 0.014215 → 0.034276
📊 Node goal_basic: Updated performance - Recent avg reward: 0.066517, Times activated: 10
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
📊 Node pose_position: Updated performance - Recent avg reward: 0.066517, Times activated: 10
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
📊 Node pose_full: Updated performance - Recent avg reward: 0.066517, Times activated: 10
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.066517, Times activated: 10
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
📊 Node visual: Updated performance - Recent avg reward: 0.066517, Times activated: 10
🎯 Node visual: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
📊 Node random_full: Updated performance - Recent avg reward: 0.066517, Times activated: 10
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.034276 vs baseline: 0.034276)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0573    |
| time/              |           |
|    episodes        | 40        |
|    fps             | 19        |
|    time_elapsed    | 402       |
|    total_timesteps | 8040      |
| train/             |           |
|    actor_loss      | -3.87e+04 |
|    critic_loss     | 8.33e+07  |
|    ent_coef        | 4.38      |
|    ent_coef_loss   | -72.6     |
|    learning_rate   | 0.00025   |
|    n_updates       | 7039      |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.052205, success=True

📈 Updating graph performance: episode_reward=0.052205, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 40: Baseline reward updated 0.034276 → 0.039497
📊 Node goal_basic: Updated performance - Recent avg reward: 0.076958, Times activated: 11
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node pose_position: Updated performance - Recent avg reward: 0.076958, Times activated: 11
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node pose_full: Updated performance - Recent avg reward: 0.076958, Times activated: 11
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.076958, Times activated: 11
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node visual: Updated performance - Recent avg reward: 0.076958, Times activated: 11
🎯 Node visual: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node random_full: Updated performance - Recent avg reward: 0.076958, Times activated: 11
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 41: Baseline reward updated 0.039497 → 0.039497
📊 Node goal_basic: Updated performance - Recent avg reward: 0.056799, Times activated: 12
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node pose_position: Updated performance - Recent avg reward: 0.056799, Times activated: 12
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node pose_full: Updated performance - Recent avg reward: 0.056799, Times activated: 12
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.056799, Times activated: 12
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node visual: Updated performance - Recent avg reward: 0.056799, Times activated: 12
🎯 Node visual: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node random_full: Updated performance - Recent avg reward: 0.056799, Times activated: 12
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 42: Baseline reward updated 0.039497 → 0.039497
📊 Node goal_basic: Updated performance - Recent avg reward: 0.056799, Times activated: 13
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node pose_position: Updated performance - Recent avg reward: 0.056799, Times activated: 13
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node pose_full: Updated performance - Recent avg reward: 0.056799, Times activated: 13
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.056799, Times activated: 13
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node visual: Updated performance - Recent avg reward: 0.056799, Times activated: 13
🎯 Node visual: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Node random_full: Updated performance - Recent avg reward: 0.056799, Times activated: 13
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.039497 vs baseline: 0.039497)
📊 Episode completed: reward=0.029870, success=True

📈 Updating graph performance: episode_reward=0.029870, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 43: Baseline reward updated 0.039497 → 0.041938
📊 Node goal_basic: Updated performance - Recent avg reward: 0.056538, Times activated: 14
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
📊 Node pose_position: Updated performance - Recent avg reward: 0.056538, Times activated: 14
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
📊 Node pose_full: Updated performance - Recent avg reward: 0.056538, Times activated: 14
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.056538, Times activated: 14
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
📊 Node visual: Updated performance - Recent avg reward: 0.056538, Times activated: 14
🎯 Node visual: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
📊 Node random_full: Updated performance - Recent avg reward: 0.056538, Times activated: 14
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.041938 vs baseline: 0.041938)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0528    |
| time/              |           |
|    episodes        | 44        |
|    fps             | 20        |
|    time_elapsed    | 441       |
|    total_timesteps | 8844      |
| train/             |           |
|    actor_loss      | -5.86e+04 |
|    critic_loss     | 1.64e+08  |
|    ent_coef        | 5.47      |
|    ent_coef_loss   | -88.9     |
|    learning_rate   | 0.00025   |
|    n_updates       | 7843      |
----------------------------------
📊 Episode completed: reward=0.000005, success=False

📈 Updating graph performance: episode_reward=0.000005, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 44: Baseline reward updated 0.041938 → 0.041466
📊 Node goal_basic: Updated performance - Recent avg reward: 0.016416, Times activated: 15
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Node pose_position: Updated performance - Recent avg reward: 0.016416, Times activated: 15
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Node pose_full: Updated performance - Recent avg reward: 0.016416, Times activated: 15
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.016416, Times activated: 15
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Node visual: Updated performance - Recent avg reward: 0.016416, Times activated: 15
🎯 Node visual: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Node random_full: Updated performance - Recent avg reward: 0.016416, Times activated: 15
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 45: Baseline reward updated 0.041466 → 0.041466
📊 Node goal_basic: Updated performance - Recent avg reward: 0.005975, Times activated: 16
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Node pose_position: Updated performance - Recent avg reward: 0.005975, Times activated: 16
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Node pose_full: Updated performance - Recent avg reward: 0.005975, Times activated: 16
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.005975, Times activated: 16
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Node visual: Updated performance - Recent avg reward: 0.005975, Times activated: 16
🎯 Node visual: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Node random_full: Updated performance - Recent avg reward: 0.005975, Times activated: 16
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.041466 vs baseline: 0.041466)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 46: Baseline reward updated 0.041466 → 0.031387
📊 Node goal_basic: Updated performance - Recent avg reward: 0.005975, Times activated: 17
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Node pose_position: Updated performance - Recent avg reward: 0.005975, Times activated: 17
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Node pose_full: Updated performance - Recent avg reward: 0.005975, Times activated: 17
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.005975, Times activated: 17
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Node visual: Updated performance - Recent avg reward: 0.005975, Times activated: 17
🎯 Node visual: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Node random_full: Updated performance - Recent avg reward: 0.005975, Times activated: 17
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 47: Baseline reward updated 0.031387 → 0.031387
📊 Node goal_basic: Updated performance - Recent avg reward: 0.005975, Times activated: 18
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Node pose_position: Updated performance - Recent avg reward: 0.005975, Times activated: 18
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Node pose_full: Updated performance - Recent avg reward: 0.005975, Times activated: 18
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.005975, Times activated: 18
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Node visual: Updated performance - Recent avg reward: 0.005975, Times activated: 18
🎯 Node visual: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
📊 Node random_full: Updated performance - Recent avg reward: 0.005975, Times activated: 18
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.031387 vs baseline: 0.031387)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0491   |
| time/              |          |
|    episodes        | 48       |
|    fps             | 20       |
|    time_elapsed    | 480      |
|    total_timesteps | 9648     |
| train/             |          |
|    actor_loss      | -7.5e+04 |
|    critic_loss     | 3.9e+08  |
|    ent_coef        | 6.76     |
|    ent_coef_loss   | -103     |
|    learning_rate   | 0.00025  |
|    n_updates       | 8647     |
---------------------------------
📊 Episode completed: reward=0.036051, success=True

📈 Updating graph performance: episode_reward=0.036051, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 48: Baseline reward updated 0.031387 → 0.031875
📊 Node goal_basic: Updated performance - Recent avg reward: 0.007211, Times activated: 19
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
📊 Node pose_position: Updated performance - Recent avg reward: 0.007211, Times activated: 19
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
📊 Node pose_full: Updated performance - Recent avg reward: 0.007211, Times activated: 19
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.007211, Times activated: 19
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
📊 Node visual: Updated performance - Recent avg reward: 0.007211, Times activated: 19
🎯 Node visual: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
📊 Node random_full: Updated performance - Recent avg reward: 0.007211, Times activated: 19
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.031875 vs baseline: 0.031875)
📊 Episode completed: reward=0.038879, success=True

📈 Updating graph performance: episode_reward=0.038879, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 49: Baseline reward updated 0.031875 → 0.015701
📊 Node goal_basic: Updated performance - Recent avg reward: 0.014986, Times activated: 20
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
📊 Node pose_position: Updated performance - Recent avg reward: 0.014986, Times activated: 20
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
📊 Node pose_full: Updated performance - Recent avg reward: 0.014986, Times activated: 20
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.014986, Times activated: 20
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
📊 Node visual: Updated performance - Recent avg reward: 0.014986, Times activated: 20
🎯 Node visual: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
📊 Node random_full: Updated performance - Recent avg reward: 0.014986, Times activated: 20
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.015701 vs baseline: 0.015701)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.038990, success=True

📈 Updating graph performance: episode_reward=0.038990, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 50: Baseline reward updated 0.015701 → 0.014379
📊 Node goal_basic: Updated performance - Recent avg reward: 0.022784, Times activated: 21
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
📊 Node pose_position: Updated performance - Recent avg reward: 0.022784, Times activated: 21
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
📊 Node pose_full: Updated performance - Recent avg reward: 0.022784, Times activated: 21
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.022784, Times activated: 21
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
📊 Node visual: Updated performance - Recent avg reward: 0.022784, Times activated: 21
🎯 Node visual: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
📊 Node random_full: Updated performance - Recent avg reward: 0.022784, Times activated: 21
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.014379 vs baseline: 0.014379)
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.001756, success=True

📈 Updating graph performance: episode_reward=0.001756, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 51: Baseline reward updated 0.014379 → 0.014555
📊 Node goal_basic: Updated performance - Recent avg reward: 0.023135, Times activated: 22
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
📊 Node pose_position: Updated performance - Recent avg reward: 0.023135, Times activated: 22
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
📊 Node pose_full: Updated performance - Recent avg reward: 0.023135, Times activated: 22
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.023135, Times activated: 22
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
📊 Node visual: Updated performance - Recent avg reward: 0.023135, Times activated: 22
🎯 Node visual: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
📊 Node random_full: Updated performance - Recent avg reward: 0.023135, Times activated: 22
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.014555 vs baseline: 0.014555)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0504    |
| time/              |           |
|    episodes        | 52        |
|    fps             | 19        |
|    time_elapsed    | 526       |
|    total_timesteps | 10452     |
| train/             |           |
|    actor_loss      | -9.32e+04 |
|    critic_loss     | 6.31e+08  |
|    ent_coef        | 8.37      |
|    ent_coef_loss   | -136      |
|    learning_rate   | 0.00025   |
|    n_updates       | 9451      |
----------------------------------
📊 Episode completed: reward=0.180847, success=True

📈 Updating graph performance: episode_reward=0.180847, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 52: Baseline reward updated 0.014555 → 0.032640
📊 Node goal_basic: Updated performance - Recent avg reward: 0.059305, Times activated: 23
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
📊 Node pose_position: Updated performance - Recent avg reward: 0.059305, Times activated: 23
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
📊 Node pose_full: Updated performance - Recent avg reward: 0.059305, Times activated: 23
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.059305, Times activated: 23
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
📊 Node visual: Updated performance - Recent avg reward: 0.059305, Times activated: 23
🎯 Node visual: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
📊 Node random_full: Updated performance - Recent avg reward: 0.059305, Times activated: 23
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.032640 vs baseline: 0.032640)
📊 Episode completed: reward=0.033781, success=True

📈 Updating graph performance: episode_reward=0.033781, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 53: Baseline reward updated 0.032640 → 0.033031
📊 Node goal_basic: Updated performance - Recent avg reward: 0.058851, Times activated: 24
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
📊 Node pose_position: Updated performance - Recent avg reward: 0.058851, Times activated: 24
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
📊 Node pose_full: Updated performance - Recent avg reward: 0.058851, Times activated: 24
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.058851, Times activated: 24
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
📊 Node visual: Updated performance - Recent avg reward: 0.058851, Times activated: 24
🎯 Node visual: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
📊 Node random_full: Updated performance - Recent avg reward: 0.058851, Times activated: 24
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.033031 vs baseline: 0.033031)
📊 Episode completed: reward=0.073651, success=True

📈 Updating graph performance: episode_reward=0.073651, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 54: Baseline reward updated 0.033031 → 0.040396
📊 Node goal_basic: Updated performance - Recent avg reward: 0.065805, Times activated: 25
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
📊 Node pose_position: Updated performance - Recent avg reward: 0.065805, Times activated: 25
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
📊 Node pose_full: Updated performance - Recent avg reward: 0.065805, Times activated: 25
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.065805, Times activated: 25
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
📊 Node visual: Updated performance - Recent avg reward: 0.065805, Times activated: 25
🎯 Node visual: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
📊 Node random_full: Updated performance - Recent avg reward: 0.065805, Times activated: 25
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.040396 vs baseline: 0.040396)
📊 Episode completed: reward=0.025576, success=True

📈 Updating graph performance: episode_reward=0.025576, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 55: Baseline reward updated 0.040396 → 0.042953
📊 Node goal_basic: Updated performance - Recent avg reward: 0.063122, Times activated: 26
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
📊 Node pose_position: Updated performance - Recent avg reward: 0.063122, Times activated: 26
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
📊 Node pose_full: Updated performance - Recent avg reward: 0.063122, Times activated: 26
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.063122, Times activated: 26
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
📊 Node visual: Updated performance - Recent avg reward: 0.063122, Times activated: 26
🎯 Node visual: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
📊 Node random_full: Updated performance - Recent avg reward: 0.063122, Times activated: 26
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.042953 vs baseline: 0.042953)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0505    |
| time/              |           |
|    episodes        | 56        |
|    fps             | 19        |
|    time_elapsed    | 573       |
|    total_timesteps | 11256     |
| train/             |           |
|    actor_loss      | -1.17e+05 |
|    critic_loss     | 8.79e+08  |
|    ent_coef        | 10.5      |
|    ent_coef_loss   | -161      |
|    learning_rate   | 0.00025   |
|    n_updates       | 10255     |
----------------------------------
📊 Episode completed: reward=0.077191, success=True

📈 Updating graph performance: episode_reward=0.077191, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 56: Baseline reward updated 0.042953 → 0.050672
📊 Node goal_basic: Updated performance - Recent avg reward: 0.078209, Times activated: 27
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
📊 Node pose_position: Updated performance - Recent avg reward: 0.078209, Times activated: 27
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
📊 Node pose_full: Updated performance - Recent avg reward: 0.078209, Times activated: 27
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.078209, Times activated: 27
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
📊 Node visual: Updated performance - Recent avg reward: 0.078209, Times activated: 27
🎯 Node visual: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
📊 Node random_full: Updated performance - Recent avg reward: 0.078209, Times activated: 27
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.050672 vs baseline: 0.050672)
📊 Episode completed: reward=0.160712, success=True

📈 Updating graph performance: episode_reward=0.160712, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 57: Baseline reward updated 0.050672 → 0.066743
📊 Node goal_basic: Updated performance - Recent avg reward: 0.074182, Times activated: 28
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
📊 Node pose_position: Updated performance - Recent avg reward: 0.074182, Times activated: 28
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
📊 Node pose_full: Updated performance - Recent avg reward: 0.074182, Times activated: 28
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.074182, Times activated: 28
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
📊 Node visual: Updated performance - Recent avg reward: 0.074182, Times activated: 28
🎯 Node visual: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
📊 Node random_full: Updated performance - Recent avg reward: 0.074182, Times activated: 28
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.066743 vs baseline: 0.066743)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 58: Baseline reward updated 0.066743 → 0.063138
📊 Node goal_basic: Updated performance - Recent avg reward: 0.067426, Times activated: 29
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
📊 Node pose_position: Updated performance - Recent avg reward: 0.067426, Times activated: 29
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
📊 Node pose_full: Updated performance - Recent avg reward: 0.067426, Times activated: 29
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.067426, Times activated: 29
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
📊 Node visual: Updated performance - Recent avg reward: 0.067426, Times activated: 29
🎯 Node visual: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
📊 Node random_full: Updated performance - Recent avg reward: 0.067426, Times activated: 29
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.063138 vs baseline: 0.063138)
📊 Episode completed: reward=0.193863, success=True

📈 Updating graph performance: episode_reward=0.193863, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 59: Baseline reward updated 0.063138 → 0.078637
📊 Node goal_basic: Updated performance - Recent avg reward: 0.091468, Times activated: 30
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)
📊 Node pose_position: Updated performance - Recent avg reward: 0.091468, Times activated: 30
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)
📊 Node pose_full: Updated performance - Recent avg reward: 0.091468, Times activated: 30
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.091468, Times activated: 30
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)
📊 Node visual: Updated performance - Recent avg reward: 0.091468, Times activated: 30
🎯 Node visual: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)
📊 Node random_full: Updated performance - Recent avg reward: 0.091468, Times activated: 30
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.078637 vs baseline: 0.078637)

🔄 CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
🔄 Adapting curriculum...

🎓 Generating curriculum configuration...

🎲 Selecting active interventions...

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=30, success_rate=0.091468)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
📋 Processing 7 eligible interventions...
   goal_basic: avg_reward=0.091468, confidence=0.521379, score=1.655605
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
🎭 Creating actor instance for: goal_basic
   goal_basic: ✅ ACTIVATED with strength 1.000
   pose_position: avg_reward=0.091468, confidence=0.521379, score=1.655605
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_position
   pose_position: ✅ ACTIVATED with strength 1.000
   pose_full: avg_reward=0.091468, confidence=0.521379, score=1.655605
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_full
   pose_full: ✅ ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.091468, confidence=0.521379, score=1.655605
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
🎭 Creating actor instance for: physics_friction
   physics_friction: ✅ ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=∞)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
   physics_mass: ⚔️  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.091468, confidence=0.521379, score=1.655605
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
🎭 Creating actor instance for: visual
   visual: ✅ ACTIVATED with strength 1.000
   random_full: avg_reward=0.091468, confidence=0.521379, score=1.655605
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.068637 or random<0.9444112236596403 or history<5 or attempts<3)
🎭 Creating actor instance for: random_full
   random_full: ✅ ACTIVATED with strength 1.000

🎉 FINAL SELECTION: 6 interventions activated
   🚀 goal_basic (strength: 1.000)
   🚀 pose_position (strength: 1.000)
   🚀 pose_full (strength: 1.000)
   🚀 physics_friction (strength: 1.000)
   🚀 visual (strength: 1.000)
   🚀 random_full (strength: 1.000)
🔧 Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
✅ Curriculum config ready: 6 actors, 6 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 6
   🎯 Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   🎲 Exploration rate: 0.9444
   📈 Baseline reward: 0.078637
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0532    |
| time/              |           |
|    episodes        | 60        |
|    fps             | 19        |
|    time_elapsed    | 614       |
|    total_timesteps | 12060     |
| train/             |           |
|    actor_loss      | -1.39e+05 |
|    critic_loss     | 1.31e+09  |
|    ent_coef        | 13.1      |
|    ent_coef_loss   | -170      |
|    learning_rate   | 0.00025   |
|    n_updates       | 11059     |
----------------------------------
📊 Episode completed: reward=0.008286, success=True

📈 Updating graph performance: episode_reward=0.008286, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 60: Baseline reward updated 0.078637 → 0.075566
📊 Node goal_basic: Updated performance - Recent avg reward: 0.088010, Times activated: 31
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
📊 Node pose_position: Updated performance - Recent avg reward: 0.088010, Times activated: 31
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
📊 Node pose_full: Updated performance - Recent avg reward: 0.088010, Times activated: 31
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.088010, Times activated: 31
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
📊 Node visual: Updated performance - Recent avg reward: 0.088010, Times activated: 31
🎯 Node visual: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
📊 Node random_full: Updated performance - Recent avg reward: 0.088010, Times activated: 31
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.075566 vs baseline: 0.075566)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 61: Baseline reward updated 0.075566 → 0.075391
📊 Node goal_basic: Updated performance - Recent avg reward: 0.072572, Times activated: 32
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
📊 Node pose_position: Updated performance - Recent avg reward: 0.072572, Times activated: 32
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
📊 Node pose_full: Updated performance - Recent avg reward: 0.072572, Times activated: 32
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.072572, Times activated: 32
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
📊 Node visual: Updated performance - Recent avg reward: 0.072572, Times activated: 32
🎯 Node visual: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
📊 Node random_full: Updated performance - Recent avg reward: 0.072572, Times activated: 32
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.075391 vs baseline: 0.075391)
📊 Episode completed: reward=0.022052, success=True

📈 Updating graph performance: episode_reward=0.022052, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 62: Baseline reward updated 0.075391 → 0.059511
📊 Node goal_basic: Updated performance - Recent avg reward: 0.044840, Times activated: 33
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
📊 Node pose_position: Updated performance - Recent avg reward: 0.044840, Times activated: 33
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
📊 Node pose_full: Updated performance - Recent avg reward: 0.044840, Times activated: 33
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.044840, Times activated: 33
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
📊 Node visual: Updated performance - Recent avg reward: 0.044840, Times activated: 33
🎯 Node visual: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
📊 Node random_full: Updated performance - Recent avg reward: 0.044840, Times activated: 33
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.059511 vs baseline: 0.059511)
📊 Episode completed: reward=0.243648, success=True

📈 Updating graph performance: episode_reward=0.243648, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 63: Baseline reward updated 0.059511 → 0.080498
📊 Node goal_basic: Updated performance - Recent avg reward: 0.093570, Times activated: 34
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
📊 Node pose_position: Updated performance - Recent avg reward: 0.093570, Times activated: 34
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
📊 Node pose_full: Updated performance - Recent avg reward: 0.093570, Times activated: 34
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.093570, Times activated: 34
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
📊 Node visual: Updated performance - Recent avg reward: 0.093570, Times activated: 34
🎯 Node visual: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
📊 Node random_full: Updated performance - Recent avg reward: 0.093570, Times activated: 34
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.080498 vs baseline: 0.080498)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.054     |
| time/              |           |
|    episodes        | 64        |
|    fps             | 19        |
|    time_elapsed    | 654       |
|    total_timesteps | 12864     |
| train/             |           |
|    actor_loss      | -1.75e+05 |
|    critic_loss     | 1.85e+09  |
|    ent_coef        | 16        |
|    ent_coef_loss   | -188      |
|    learning_rate   | 0.00025   |
|    n_updates       | 11863     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 64: Baseline reward updated 0.080498 → 0.073133
📊 Node goal_basic: Updated performance - Recent avg reward: 0.054797, Times activated: 35
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
📊 Node pose_position: Updated performance - Recent avg reward: 0.054797, Times activated: 35
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
📊 Node pose_full: Updated performance - Recent avg reward: 0.054797, Times activated: 35
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.054797, Times activated: 35
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
📊 Node visual: Updated performance - Recent avg reward: 0.054797, Times activated: 35
🎯 Node visual: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
📊 Node random_full: Updated performance - Recent avg reward: 0.054797, Times activated: 35
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.073133 vs baseline: 0.073133)
📊 Episode completed: reward=0.511136, success=True

📈 Updating graph performance: episode_reward=0.511136, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 65: Baseline reward updated 0.073133 → 0.121689
📊 Node goal_basic: Updated performance - Recent avg reward: 0.155367, Times activated: 36
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
📊 Node pose_position: Updated performance - Recent avg reward: 0.155367, Times activated: 36
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
📊 Node pose_full: Updated performance - Recent avg reward: 0.155367, Times activated: 36
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.155367, Times activated: 36
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
📊 Node visual: Updated performance - Recent avg reward: 0.155367, Times activated: 36
🎯 Node visual: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
📊 Node random_full: Updated performance - Recent avg reward: 0.155367, Times activated: 36
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.121689 vs baseline: 0.121689)
📊 Episode completed: reward=0.398641, success=True

📈 Updating graph performance: episode_reward=0.398641, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 66: Baseline reward updated 0.121689 → 0.153834
📊 Node goal_basic: Updated performance - Recent avg reward: 0.235095, Times activated: 37
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
📊 Node pose_position: Updated performance - Recent avg reward: 0.235095, Times activated: 37
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
📊 Node pose_full: Updated performance - Recent avg reward: 0.235095, Times activated: 37
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.235095, Times activated: 37
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
📊 Node visual: Updated performance - Recent avg reward: 0.235095, Times activated: 37
🎯 Node visual: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
📊 Node random_full: Updated performance - Recent avg reward: 0.235095, Times activated: 37
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.153834 vs baseline: 0.153834)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=1.227558, success=True

📈 Updating graph performance: episode_reward=1.227558, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 67: Baseline reward updated 0.153834 → 0.260518
📊 Node goal_basic: Updated performance - Recent avg reward: 0.476197, Times activated: 38
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
📊 Node pose_position: Updated performance - Recent avg reward: 0.476197, Times activated: 38
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
📊 Node pose_full: Updated performance - Recent avg reward: 0.476197, Times activated: 38
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.476197, Times activated: 38
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
📊 Node visual: Updated performance - Recent avg reward: 0.476197, Times activated: 38
🎯 Node visual: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
📊 Node random_full: Updated performance - Recent avg reward: 0.476197, Times activated: 38
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.260518 vs baseline: 0.260518)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0823    |
| time/              |           |
|    episodes        | 68        |
|    fps             | 19        |
|    time_elapsed    | 701       |
|    total_timesteps | 13668     |
| train/             |           |
|    actor_loss      | -2.02e+05 |
|    critic_loss     | 2.34e+09  |
|    ent_coef        | 19.7      |
|    ent_coef_loss   | -206      |
|    learning_rate   | 0.00025   |
|    n_updates       | 12667     |
----------------------------------
📊 Episode completed: reward=0.002884, success=True

📈 Updating graph performance: episode_reward=0.002884, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 68: Baseline reward updated 0.260518 → 0.260807
📊 Node goal_basic: Updated performance - Recent avg reward: 0.428044, Times activated: 39
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
📊 Node pose_position: Updated performance - Recent avg reward: 0.428044, Times activated: 39
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
📊 Node pose_full: Updated performance - Recent avg reward: 0.428044, Times activated: 39
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.428044, Times activated: 39
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
📊 Node visual: Updated performance - Recent avg reward: 0.428044, Times activated: 39
🎯 Node visual: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
📊 Node random_full: Updated performance - Recent avg reward: 0.428044, Times activated: 39
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.260807 vs baseline: 0.260807)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 69: Baseline reward updated 0.260807 → 0.241420
📊 Node goal_basic: Updated performance - Recent avg reward: 0.428044, Times activated: 40
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
📊 Node pose_position: Updated performance - Recent avg reward: 0.428044, Times activated: 40
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
📊 Node pose_full: Updated performance - Recent avg reward: 0.428044, Times activated: 40
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.428044, Times activated: 40
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
📊 Node visual: Updated performance - Recent avg reward: 0.428044, Times activated: 40
🎯 Node visual: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
📊 Node random_full: Updated performance - Recent avg reward: 0.428044, Times activated: 40
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.241420 vs baseline: 0.241420)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 70: Baseline reward updated 0.241420 → 0.240592
📊 Node goal_basic: Updated performance - Recent avg reward: 0.325817, Times activated: 41
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Node pose_position: Updated performance - Recent avg reward: 0.325817, Times activated: 41
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Node pose_full: Updated performance - Recent avg reward: 0.325817, Times activated: 41
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.325817, Times activated: 41
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Node visual: Updated performance - Recent avg reward: 0.325817, Times activated: 41
🎯 Node visual: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Node random_full: Updated performance - Recent avg reward: 0.325817, Times activated: 41
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 71: Baseline reward updated 0.240592 → 0.240592
📊 Node goal_basic: Updated performance - Recent avg reward: 0.246088, Times activated: 42
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Node pose_position: Updated performance - Recent avg reward: 0.246088, Times activated: 42
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Node pose_full: Updated performance - Recent avg reward: 0.246088, Times activated: 42
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.246088, Times activated: 42
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Node visual: Updated performance - Recent avg reward: 0.246088, Times activated: 42
🎯 Node visual: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
📊 Node random_full: Updated performance - Recent avg reward: 0.246088, Times activated: 42
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.240592 vs baseline: 0.240592)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0777    |
| time/              |           |
|    episodes        | 72        |
|    fps             | 19        |
|    time_elapsed    | 743       |
|    total_timesteps | 14472     |
| train/             |           |
|    actor_loss      | -2.28e+05 |
|    critic_loss     | 3.42e+09  |
|    ent_coef        | 24.1      |
|    ent_coef_loss   | -228      |
|    learning_rate   | 0.00025   |
|    n_updates       | 13471     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 72: Baseline reward updated 0.240592 → 0.238387
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000577, Times activated: 43
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000577, Times activated: 43
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000577, Times activated: 43
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000577, Times activated: 43
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
📊 Node visual: Updated performance - Recent avg reward: 0.000577, Times activated: 43
🎯 Node visual: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
📊 Node random_full: Updated performance - Recent avg reward: 0.000577, Times activated: 43
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.238387 vs baseline: 0.238387)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 73: Baseline reward updated 0.238387 → 0.214022
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 44
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 44
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 44
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 44
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 44
🎯 Node visual: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 44
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.214022 vs baseline: 0.214022)
📊 Episode completed: reward=0.123864, success=True

📈 Updating graph performance: episode_reward=0.123864, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 74: Baseline reward updated 0.214022 → 0.226408
📊 Node goal_basic: Updated performance - Recent avg reward: 0.024773, Times activated: 45
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
📊 Node pose_position: Updated performance - Recent avg reward: 0.024773, Times activated: 45
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
📊 Node pose_full: Updated performance - Recent avg reward: 0.024773, Times activated: 45
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.024773, Times activated: 45
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
📊 Node visual: Updated performance - Recent avg reward: 0.024773, Times activated: 45
🎯 Node visual: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
📊 Node random_full: Updated performance - Recent avg reward: 0.024773, Times activated: 45
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.226408 vs baseline: 0.226408)
📊 Episode completed: reward=0.008742, success=True

📈 Updating graph performance: episode_reward=0.008742, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 75: Baseline reward updated 0.226408 → 0.176169
📊 Node goal_basic: Updated performance - Recent avg reward: 0.026521, Times activated: 46
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
📊 Node pose_position: Updated performance - Recent avg reward: 0.026521, Times activated: 46
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
📊 Node pose_full: Updated performance - Recent avg reward: 0.026521, Times activated: 46
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.026521, Times activated: 46
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
📊 Node visual: Updated performance - Recent avg reward: 0.026521, Times activated: 46
🎯 Node visual: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
📊 Node random_full: Updated performance - Recent avg reward: 0.026521, Times activated: 46
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.176169 vs baseline: 0.176169)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0765    |
| time/              |           |
|    episodes        | 76        |
|    fps             | 19        |
|    time_elapsed    | 785       |
|    total_timesteps | 15276     |
| train/             |           |
|    actor_loss      | -2.27e+05 |
|    critic_loss     | 3.36e+09  |
|    ent_coef        | 29.5      |
|    ent_coef_loss   | -234      |
|    learning_rate   | 0.00025   |
|    n_updates       | 14275     |
----------------------------------
📊 Episode completed: reward=0.085126, success=True

📈 Updating graph performance: episode_reward=0.085126, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 76: Baseline reward updated 0.176169 → 0.144817
📊 Node goal_basic: Updated performance - Recent avg reward: 0.043546, Times activated: 47
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
📊 Node pose_position: Updated performance - Recent avg reward: 0.043546, Times activated: 47
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
📊 Node pose_full: Updated performance - Recent avg reward: 0.043546, Times activated: 47
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.043546, Times activated: 47
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
📊 Node visual: Updated performance - Recent avg reward: 0.043546, Times activated: 47
🎯 Node visual: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
📊 Node random_full: Updated performance - Recent avg reward: 0.043546, Times activated: 47
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.144817 vs baseline: 0.144817)
📊 Episode completed: reward=0.072760, success=True

📈 Updating graph performance: episode_reward=0.072760, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 77: Baseline reward updated 0.144817 → 0.029338
📊 Node goal_basic: Updated performance - Recent avg reward: 0.058098, Times activated: 48
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
📊 Node pose_position: Updated performance - Recent avg reward: 0.058098, Times activated: 48
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
📊 Node pose_full: Updated performance - Recent avg reward: 0.058098, Times activated: 48
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.058098, Times activated: 48
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
📊 Node visual: Updated performance - Recent avg reward: 0.058098, Times activated: 48
🎯 Node visual: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
📊 Node random_full: Updated performance - Recent avg reward: 0.058098, Times activated: 48
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.029338 vs baseline: 0.029338)
📊 Episode completed: reward=1.207320, success=True

📈 Updating graph performance: episode_reward=1.207320, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 78: Baseline reward updated 0.029338 → 0.149781
📊 Node goal_basic: Updated performance - Recent avg reward: 0.299562, Times activated: 49
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
📊 Node pose_position: Updated performance - Recent avg reward: 0.299562, Times activated: 49
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
📊 Node pose_full: Updated performance - Recent avg reward: 0.299562, Times activated: 49
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.299562, Times activated: 49
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
📊 Node visual: Updated performance - Recent avg reward: 0.299562, Times activated: 49
🎯 Node visual: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
📊 Node random_full: Updated performance - Recent avg reward: 0.299562, Times activated: 49
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.149781 vs baseline: 0.149781)
📊 Episode completed: reward=0.647630, success=True

📈 Updating graph performance: episode_reward=0.647630, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 79: Baseline reward updated 0.149781 → 0.214544
📊 Node goal_basic: Updated performance - Recent avg reward: 0.404316, Times activated: 50
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
📊 Node pose_position: Updated performance - Recent avg reward: 0.404316, Times activated: 50
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
📊 Node pose_full: Updated performance - Recent avg reward: 0.404316, Times activated: 50
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.404316, Times activated: 50
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
📊 Node visual: Updated performance - Recent avg reward: 0.404316, Times activated: 50
🎯 Node visual: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
📊 Node random_full: Updated performance - Recent avg reward: 0.404316, Times activated: 50
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.214544 vs baseline: 0.214544)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0978    |
| time/              |           |
|    episodes        | 80        |
|    fps             | 19        |
|    time_elapsed    | 829       |
|    total_timesteps | 16080     |
| train/             |           |
|    actor_loss      | -2.89e+05 |
|    critic_loss     | 4.99e+09  |
|    ent_coef        | 36.2      |
|    ent_coef_loss   | -261      |
|    learning_rate   | 0.00025   |
|    n_updates       | 15079     |
----------------------------------
📊 Episode completed: reward=0.081927, success=True

📈 Updating graph performance: episode_reward=0.081927, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 80: Baseline reward updated 0.214544 → 0.222737
📊 Node goal_basic: Updated performance - Recent avg reward: 0.418953, Times activated: 51
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Node pose_position: Updated performance - Recent avg reward: 0.418953, Times activated: 51
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Node pose_full: Updated performance - Recent avg reward: 0.418953, Times activated: 51
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.418953, Times activated: 51
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Node visual: Updated performance - Recent avg reward: 0.418953, Times activated: 51
🎯 Node visual: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Node random_full: Updated performance - Recent avg reward: 0.418953, Times activated: 51
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 81: Baseline reward updated 0.222737 → 0.222737
📊 Node goal_basic: Updated performance - Recent avg reward: 0.401927, Times activated: 52
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Node pose_position: Updated performance - Recent avg reward: 0.401927, Times activated: 52
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Node pose_full: Updated performance - Recent avg reward: 0.401927, Times activated: 52
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.401927, Times activated: 52
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Node visual: Updated performance - Recent avg reward: 0.401927, Times activated: 52
🎯 Node visual: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Node random_full: Updated performance - Recent avg reward: 0.401927, Times activated: 52
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.222737 vs baseline: 0.222737)
📊 Episode completed: reward=0.000016, success=False

📈 Updating graph performance: episode_reward=0.000016, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 82: Baseline reward updated 0.222737 → 0.222738
📊 Node goal_basic: Updated performance - Recent avg reward: 0.387379, Times activated: 53
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
📊 Node pose_position: Updated performance - Recent avg reward: 0.387379, Times activated: 53
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
📊 Node pose_full: Updated performance - Recent avg reward: 0.387379, Times activated: 53
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.387379, Times activated: 53
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
📊 Node visual: Updated performance - Recent avg reward: 0.387379, Times activated: 53
🎯 Node visual: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
📊 Node random_full: Updated performance - Recent avg reward: 0.387379, Times activated: 53
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.222738 vs baseline: 0.222738)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 83: Baseline reward updated 0.222738 → 0.222739
📊 Node goal_basic: Updated performance - Recent avg reward: 0.145915, Times activated: 54
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
📊 Node pose_position: Updated performance - Recent avg reward: 0.145915, Times activated: 54
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
📊 Node pose_full: Updated performance - Recent avg reward: 0.145915, Times activated: 54
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.145915, Times activated: 54
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
📊 Node visual: Updated performance - Recent avg reward: 0.145915, Times activated: 54
🎯 Node visual: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
📊 Node random_full: Updated performance - Recent avg reward: 0.145915, Times activated: 54
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.222739 vs baseline: 0.222739)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0932    |
| time/              |           |
|    episodes        | 84        |
|    fps             | 19        |
|    time_elapsed    | 881       |
|    total_timesteps | 16884     |
| train/             |           |
|    actor_loss      | -2.66e+05 |
|    critic_loss     | 5.17e+09  |
|    ent_coef        | 44.3      |
|    ent_coef_loss   | -264      |
|    learning_rate   | 0.00025   |
|    n_updates       | 15883     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 84: Baseline reward updated 0.222739 → 0.210352
📊 Node goal_basic: Updated performance - Recent avg reward: 0.016389, Times activated: 55
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
📊 Node pose_position: Updated performance - Recent avg reward: 0.016389, Times activated: 55
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
📊 Node pose_full: Updated performance - Recent avg reward: 0.016389, Times activated: 55
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.016389, Times activated: 55
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
📊 Node visual: Updated performance - Recent avg reward: 0.016389, Times activated: 55
🎯 Node visual: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
📊 Node random_full: Updated performance - Recent avg reward: 0.016389, Times activated: 55
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.210352 vs baseline: 0.210352)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 85: Baseline reward updated 0.210352 → 0.209478
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000003, Times activated: 56
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000003, Times activated: 56
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000003, Times activated: 56
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000003, Times activated: 56
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
📊 Node visual: Updated performance - Recent avg reward: 0.000003, Times activated: 56
🎯 Node visual: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
📊 Node random_full: Updated performance - Recent avg reward: 0.000003, Times activated: 56
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.209478 vs baseline: 0.209478)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 86: Baseline reward updated 0.209478 → 0.200965
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000003, Times activated: 57
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000003, Times activated: 57
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000003, Times activated: 57
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000003, Times activated: 57
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
📊 Node visual: Updated performance - Recent avg reward: 0.000003, Times activated: 57
🎯 Node visual: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
📊 Node random_full: Updated performance - Recent avg reward: 0.000003, Times activated: 57
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.200965 vs baseline: 0.200965)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 87: Baseline reward updated 0.200965 → 0.193689
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 58
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 58
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 58
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 58
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 58
🎯 Node visual: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 58
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.193689 vs baseline: 0.193689)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0889    |
| time/              |           |
|    episodes        | 88        |
|    fps             | 19        |
|    time_elapsed    | 923       |
|    total_timesteps | 17688     |
| train/             |           |
|    actor_loss      | -3.66e+05 |
|    critic_loss     | 9.28e+09  |
|    ent_coef        | 54        |
|    ent_coef_loss   | -278      |
|    learning_rate   | 0.00025   |
|    n_updates       | 16687     |
----------------------------------
📊 Episode completed: reward=0.000755, success=False

📈 Updating graph performance: episode_reward=0.000755, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 88: Baseline reward updated 0.193689 → 0.073033
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000151, Times activated: 59
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000151, Times activated: 59
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000151, Times activated: 59
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000151, Times activated: 59
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
📊 Node visual: Updated performance - Recent avg reward: 0.000151, Times activated: 59
🎯 Node visual: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
📊 Node random_full: Updated performance - Recent avg reward: 0.000151, Times activated: 59
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.073033 vs baseline: 0.073033)
📊 Episode completed: reward=0.003412, success=True

📈 Updating graph performance: episode_reward=0.003412, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 89: Baseline reward updated 0.073033 → 0.008611
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000833, Times activated: 60
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000833, Times activated: 60
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000833, Times activated: 60
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000833, Times activated: 60
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)
📊 Node visual: Updated performance - Recent avg reward: 0.000833, Times activated: 60
🎯 Node visual: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)
📊 Node random_full: Updated performance - Recent avg reward: 0.000833, Times activated: 60
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.008611 vs baseline: 0.008611)

🔄 CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
🔄 Adapting curriculum...

🎓 Generating curriculum configuration...

🎲 Selecting active interventions...

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.000833)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
📋 Processing 7 eligible interventions...
   goal_basic: avg_reward=0.000833, confidence=0.423728, score=1.272018
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
🎭 Creating actor instance for: goal_basic
   goal_basic: ✅ ACTIVATED with strength 1.000
   pose_position: avg_reward=0.000833, confidence=0.423728, score=1.272018
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_position
   pose_position: ✅ ACTIVATED with strength 1.000
   pose_full: avg_reward=0.000833, confidence=0.423728, score=1.272018
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_full
   pose_full: ✅ ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.000833, confidence=0.423728, score=1.272018
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
🎭 Creating actor instance for: physics_friction
   physics_friction: ✅ ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=∞)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
   physics_mass: ⚔️  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.000833, confidence=0.423728, score=1.272018
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
🎭 Creating actor instance for: visual
   visual: ✅ ACTIVATED with strength 1.000
   random_full: avg_reward=0.000833, confidence=0.423728, score=1.272018
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>-0.001389 or random<0.9415820943457617 or history<5 or attempts<3)
🎭 Creating actor instance for: random_full
   random_full: ✅ ACTIVATED with strength 1.000

🎉 FINAL SELECTION: 6 interventions activated
   🚀 goal_basic (strength: 1.000)
   🚀 pose_position (strength: 1.000)
   🚀 pose_full (strength: 1.000)
   🚀 physics_friction (strength: 1.000)
   🚀 visual (strength: 1.000)
   🚀 random_full (strength: 1.000)
🔧 Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
✅ Curriculum config ready: 6 actors, 6 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 6
   🎯 Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   🎲 Exploration rate: 0.9416
   📈 Baseline reward: 0.008611
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 90: Baseline reward updated 0.008611 → 0.000418
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000833, Times activated: 61
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000833, Times activated: 61
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000833, Times activated: 61
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000833, Times activated: 61
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
📊 Node visual: Updated performance - Recent avg reward: 0.000833, Times activated: 61
🎯 Node visual: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
📊 Node random_full: Updated performance - Recent avg reward: 0.000833, Times activated: 61
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.000418 vs baseline: 0.000418)
📊 Episode completed: reward=0.004987, success=True

📈 Updating graph performance: episode_reward=0.004987, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 91: Baseline reward updated 0.000418 → 0.000917
📊 Node goal_basic: Updated performance - Recent avg reward: 0.001831, Times activated: 62
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
📊 Node pose_position: Updated performance - Recent avg reward: 0.001831, Times activated: 62
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
📊 Node pose_full: Updated performance - Recent avg reward: 0.001831, Times activated: 62
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.001831, Times activated: 62
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
📊 Node visual: Updated performance - Recent avg reward: 0.001831, Times activated: 62
🎯 Node visual: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
📊 Node random_full: Updated performance - Recent avg reward: 0.001831, Times activated: 62
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.000917 vs baseline: 0.000917)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0852    |
| time/              |           |
|    episodes        | 92        |
|    fps             | 19        |
|    time_elapsed    | 960       |
|    total_timesteps | 18492     |
| train/             |           |
|    actor_loss      | -3.39e+05 |
|    critic_loss     | 9.09e+09  |
|    ent_coef        | 65.8      |
|    ent_coef_loss   | -277      |
|    learning_rate   | 0.00025   |
|    n_updates       | 17491     |
----------------------------------
📊 Episode completed: reward=0.002488, success=True

📈 Updating graph performance: episode_reward=0.002488, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 92: Baseline reward updated 0.000917 → 0.001164
📊 Node goal_basic: Updated performance - Recent avg reward: 0.002328, Times activated: 63
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
📊 Node pose_position: Updated performance - Recent avg reward: 0.002328, Times activated: 63
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
📊 Node pose_full: Updated performance - Recent avg reward: 0.002328, Times activated: 63
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.002328, Times activated: 63
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
📊 Node visual: Updated performance - Recent avg reward: 0.002328, Times activated: 63
🎯 Node visual: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
📊 Node random_full: Updated performance - Recent avg reward: 0.002328, Times activated: 63
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.001164 vs baseline: 0.001164)
📊 Episode completed: reward=0.980391, success=True

📈 Updating graph performance: episode_reward=0.980391, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 93: Baseline reward updated 0.001164 → 0.099203
📊 Node goal_basic: Updated performance - Recent avg reward: 0.198256, Times activated: 64
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node pose_position: Updated performance - Recent avg reward: 0.198256, Times activated: 64
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node pose_full: Updated performance - Recent avg reward: 0.198256, Times activated: 64
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.198256, Times activated: 64
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node visual: Updated performance - Recent avg reward: 0.198256, Times activated: 64
🎯 Node visual: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node random_full: Updated performance - Recent avg reward: 0.198256, Times activated: 64
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 94: Baseline reward updated 0.099203 → 0.099203
📊 Node goal_basic: Updated performance - Recent avg reward: 0.197573, Times activated: 65
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node pose_position: Updated performance - Recent avg reward: 0.197573, Times activated: 65
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node pose_full: Updated performance - Recent avg reward: 0.197573, Times activated: 65
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.197573, Times activated: 65
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node visual: Updated performance - Recent avg reward: 0.197573, Times activated: 65
🎯 Node visual: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node random_full: Updated performance - Recent avg reward: 0.197573, Times activated: 65
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 95: Baseline reward updated 0.099203 → 0.099203
📊 Node goal_basic: Updated performance - Recent avg reward: 0.197573, Times activated: 66
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node pose_position: Updated performance - Recent avg reward: 0.197573, Times activated: 66
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node pose_full: Updated performance - Recent avg reward: 0.197573, Times activated: 66
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.197573, Times activated: 66
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node visual: Updated performance - Recent avg reward: 0.197573, Times activated: 66
🎯 Node visual: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node random_full: Updated performance - Recent avg reward: 0.197573, Times activated: 66
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0918    |
| time/              |           |
|    episodes        | 96        |
|    fps             | 19        |
|    time_elapsed    | 998       |
|    total_timesteps | 19296     |
| train/             |           |
|    actor_loss      | -3.59e+05 |
|    critic_loss     | 8.2e+09   |
|    ent_coef        | 80.1      |
|    ent_coef_loss   | -285      |
|    learning_rate   | 0.00025   |
|    n_updates       | 18295     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 96: Baseline reward updated 0.099203 → 0.099203
📊 Node goal_basic: Updated performance - Recent avg reward: 0.196576, Times activated: 67
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node pose_position: Updated performance - Recent avg reward: 0.196576, Times activated: 67
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node pose_full: Updated performance - Recent avg reward: 0.196576, Times activated: 67
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.196576, Times activated: 67
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node visual: Updated performance - Recent avg reward: 0.196576, Times activated: 67
🎯 Node visual: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Node random_full: Updated performance - Recent avg reward: 0.196576, Times activated: 67
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.099203 vs baseline: 0.099203)
📊 Episode completed: reward=0.026716, success=True

📈 Updating graph performance: episode_reward=0.026716, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 97: Baseline reward updated 0.099203 → 0.101875
📊 Node goal_basic: Updated performance - Recent avg reward: 0.201421, Times activated: 68
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
📊 Node pose_position: Updated performance - Recent avg reward: 0.201421, Times activated: 68
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
📊 Node pose_full: Updated performance - Recent avg reward: 0.201421, Times activated: 68
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.201421, Times activated: 68
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
📊 Node visual: Updated performance - Recent avg reward: 0.201421, Times activated: 68
🎯 Node visual: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
📊 Node random_full: Updated performance - Recent avg reward: 0.201421, Times activated: 68
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.101875 vs baseline: 0.101875)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.030207, success=True

📈 Updating graph performance: episode_reward=0.030207, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 98: Baseline reward updated 0.101875 → 0.104820
📊 Node goal_basic: Updated performance - Recent avg reward: 0.011385, Times activated: 69
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
📊 Node pose_position: Updated performance - Recent avg reward: 0.011385, Times activated: 69
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
📊 Node pose_full: Updated performance - Recent avg reward: 0.011385, Times activated: 69
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.011385, Times activated: 69
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
📊 Node visual: Updated performance - Recent avg reward: 0.011385, Times activated: 69
🎯 Node visual: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
📊 Node random_full: Updated performance - Recent avg reward: 0.011385, Times activated: 69
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.104820 vs baseline: 0.104820)
📊 Episode completed: reward=0.057371, success=True

📈 Updating graph performance: episode_reward=0.057371, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 99: Baseline reward updated 0.104820 → 0.110216
📊 Node goal_basic: Updated performance - Recent avg reward: 0.022859, Times activated: 70
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
📊 Node pose_position: Updated performance - Recent avg reward: 0.022859, Times activated: 70
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
📊 Node pose_full: Updated performance - Recent avg reward: 0.022859, Times activated: 70
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.022859, Times activated: 70
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
📊 Node visual: Updated performance - Recent avg reward: 0.022859, Times activated: 70
🎯 Node visual: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
📊 Node random_full: Updated performance - Recent avg reward: 0.022859, Times activated: 70
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.110216 vs baseline: 0.110216)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0893    |
| time/              |           |
|    episodes        | 100       |
|    fps             | 19        |
|    time_elapsed    | 1038      |
|    total_timesteps | 20100     |
| train/             |           |
|    actor_loss      | -3.85e+05 |
|    critic_loss     | 9.35e+09  |
|    ent_coef        | 97.3      |
|    ent_coef_loss   | -306      |
|    learning_rate   | 0.00025   |
|    n_updates       | 19099     |
----------------------------------
📊 Episode completed: reward=0.000813, success=False

📈 Updating graph performance: episode_reward=0.000813, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 100: Baseline reward updated 0.110216 → 0.110297
📊 Node goal_basic: Updated performance - Recent avg reward: 0.023021, Times activated: 71
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
📊 Node pose_position: Updated performance - Recent avg reward: 0.023021, Times activated: 71
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
📊 Node pose_full: Updated performance - Recent avg reward: 0.023021, Times activated: 71
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.023021, Times activated: 71
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
📊 Node visual: Updated performance - Recent avg reward: 0.023021, Times activated: 71
🎯 Node visual: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
📊 Node random_full: Updated performance - Recent avg reward: 0.023021, Times activated: 71
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.110297 vs baseline: 0.110297)
📊 Episode completed: reward=0.003152, success=True

📈 Updating graph performance: episode_reward=0.003152, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 101: Baseline reward updated 0.110297 → 0.110114
📊 Node goal_basic: Updated performance - Recent avg reward: 0.023652, Times activated: 72
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
📊 Node pose_position: Updated performance - Recent avg reward: 0.023652, Times activated: 72
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
📊 Node pose_full: Updated performance - Recent avg reward: 0.023652, Times activated: 72
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.023652, Times activated: 72
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
📊 Node visual: Updated performance - Recent avg reward: 0.023652, Times activated: 72
🎯 Node visual: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
📊 Node random_full: Updated performance - Recent avg reward: 0.023652, Times activated: 72
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.110114 vs baseline: 0.110114)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 102: Baseline reward updated 0.110114 → 0.109865
📊 Node goal_basic: Updated performance - Recent avg reward: 0.018309, Times activated: 73
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
📊 Node pose_position: Updated performance - Recent avg reward: 0.018309, Times activated: 73
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
📊 Node pose_full: Updated performance - Recent avg reward: 0.018309, Times activated: 73
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.018309, Times activated: 73
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
📊 Node visual: Updated performance - Recent avg reward: 0.018309, Times activated: 73
🎯 Node visual: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
📊 Node random_full: Updated performance - Recent avg reward: 0.018309, Times activated: 73
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.109865 vs baseline: 0.109865)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 103: Baseline reward updated 0.109865 → 0.011826
📊 Node goal_basic: Updated performance - Recent avg reward: 0.012267, Times activated: 74
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Node pose_position: Updated performance - Recent avg reward: 0.012267, Times activated: 74
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Node pose_full: Updated performance - Recent avg reward: 0.012267, Times activated: 74
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.012267, Times activated: 74
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Node visual: Updated performance - Recent avg reward: 0.012267, Times activated: 74
🎯 Node visual: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Node random_full: Updated performance - Recent avg reward: 0.012267, Times activated: 74
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0889    |
| time/              |           |
|    episodes        | 104       |
|    fps             | 19        |
|    time_elapsed    | 1086      |
|    total_timesteps | 20904     |
| train/             |           |
|    actor_loss      | -3.46e+05 |
|    critic_loss     | 8.57e+09  |
|    ent_coef        | 118       |
|    ent_coef_loss   | -282      |
|    learning_rate   | 0.00025   |
|    n_updates       | 19903     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 104: Baseline reward updated 0.011826 → 0.011826
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000793, Times activated: 75
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000793, Times activated: 75
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000793, Times activated: 75
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000793, Times activated: 75
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Node visual: Updated performance - Recent avg reward: 0.000793, Times activated: 75
🎯 Node visual: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Node random_full: Updated performance - Recent avg reward: 0.000793, Times activated: 75
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.011826 vs baseline: 0.011826)
📊 Episode completed: reward=0.000736, success=False

📈 Updating graph performance: episode_reward=0.000736, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 105: Baseline reward updated 0.011826 → 0.011900
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000778, Times activated: 76
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000778, Times activated: 76
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000778, Times activated: 76
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000778, Times activated: 76
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Node visual: Updated performance - Recent avg reward: 0.000778, Times activated: 76
🎯 Node visual: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Node random_full: Updated performance - Recent avg reward: 0.000778, Times activated: 76
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 106: Baseline reward updated 0.011900 → 0.011900
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000147, Times activated: 77
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000147, Times activated: 77
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000147, Times activated: 77
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000147, Times activated: 77
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Node visual: Updated performance - Recent avg reward: 0.000147, Times activated: 77
🎯 Node visual: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Node random_full: Updated performance - Recent avg reward: 0.000147, Times activated: 77
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.011900 vs baseline: 0.011900)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 107: Baseline reward updated 0.011900 → 0.009228
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000147, Times activated: 78
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000147, Times activated: 78
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000147, Times activated: 78
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000147, Times activated: 78
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
📊 Node visual: Updated performance - Recent avg reward: 0.000147, Times activated: 78
🎯 Node visual: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
📊 Node random_full: Updated performance - Recent avg reward: 0.000147, Times activated: 78
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.009228 vs baseline: 0.009228)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0888    |
| time/              |           |
|    episodes        | 108       |
|    fps             | 19        |
|    time_elapsed    | 1127      |
|    total_timesteps | 21708     |
| train/             |           |
|    actor_loss      | -3.87e+05 |
|    critic_loss     | 1.19e+10  |
|    ent_coef        | 143       |
|    ent_coef_loss   | -292      |
|    learning_rate   | 0.00025   |
|    n_updates       | 20707     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 108: Baseline reward updated 0.009228 → 0.006207
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000147, Times activated: 79
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000147, Times activated: 79
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000147, Times activated: 79
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000147, Times activated: 79
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
📊 Node visual: Updated performance - Recent avg reward: 0.000147, Times activated: 79
🎯 Node visual: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
📊 Node random_full: Updated performance - Recent avg reward: 0.000147, Times activated: 79
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.006207 vs baseline: 0.006207)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 109: Baseline reward updated 0.006207 → 0.000470
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000147, Times activated: 80
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000147, Times activated: 80
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000147, Times activated: 80
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000147, Times activated: 80
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
📊 Node visual: Updated performance - Recent avg reward: 0.000147, Times activated: 80
🎯 Node visual: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
📊 Node random_full: Updated performance - Recent avg reward: 0.000147, Times activated: 80
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.000470 vs baseline: 0.000470)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 110: Baseline reward updated 0.000470 → 0.000389
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 81
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 81
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 81
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 81
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 81
🎯 Node visual: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 81
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.000389 vs baseline: 0.000389)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 111: Baseline reward updated 0.000389 → 0.000074
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 82
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 82
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 82
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 82
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 82
🎯 Node visual: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 82
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0876    |
| time/              |           |
|    episodes        | 112       |
|    fps             | 19        |
|    time_elapsed    | 1170      |
|    total_timesteps | 22512     |
| train/             |           |
|    actor_loss      | -3.86e+05 |
|    critic_loss     | 1.33e+10  |
|    ent_coef        | 174       |
|    ent_coef_loss   | -302      |
|    learning_rate   | 0.00025   |
|    n_updates       | 21511     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 112: Baseline reward updated 0.000074 → 0.000074
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 83
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 83
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 83
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 83
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 83
🎯 Node visual: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 83
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 113: Baseline reward updated 0.000074 → 0.000074
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 84
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 84
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 84
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 84
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 84
🎯 Node visual: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 84
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 114: Baseline reward updated 0.000074 → 0.000074
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 85
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 85
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 85
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 85
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 85
🎯 Node visual: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 85
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.000074 vs baseline: 0.000074)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 115: Baseline reward updated 0.000074 → 0.000000
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 86
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 86
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 86
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 86
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 86
🎯 Node visual: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 86
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0836    |
| time/              |           |
|    episodes        | 116       |
|    fps             | 19        |
|    time_elapsed    | 1216      |
|    total_timesteps | 23316     |
| train/             |           |
|    actor_loss      | -3.97e+05 |
|    critic_loss     | 8.6e+09   |
|    ent_coef        | 211       |
|    ent_coef_loss   | -279      |
|    learning_rate   | 0.00025   |
|    n_updates       | 22315     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 116: Baseline reward updated 0.000000 → 0.000000
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 87
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 87
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 87
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 87
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 87
🎯 Node visual: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 87
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.000000 vs baseline: 0.000000)
📊 Episode completed: reward=0.030460, success=True

📈 Updating graph performance: episode_reward=0.030460, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 117: Baseline reward updated 0.000000 → 0.003046
📊 Node goal_basic: Updated performance - Recent avg reward: 0.006092, Times activated: 88
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
📊 Node pose_position: Updated performance - Recent avg reward: 0.006092, Times activated: 88
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
📊 Node pose_full: Updated performance - Recent avg reward: 0.006092, Times activated: 88
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.006092, Times activated: 88
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
📊 Node visual: Updated performance - Recent avg reward: 0.006092, Times activated: 88
🎯 Node visual: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
📊 Node random_full: Updated performance - Recent avg reward: 0.006092, Times activated: 88
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.003046 vs baseline: 0.003046)
📊 Episode completed: reward=0.255239, success=True

📈 Updating graph performance: episode_reward=0.255239, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 118: Baseline reward updated 0.003046 → 0.028570
📊 Node goal_basic: Updated performance - Recent avg reward: 0.057140, Times activated: 89
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
📊 Node pose_position: Updated performance - Recent avg reward: 0.057140, Times activated: 89
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
📊 Node pose_full: Updated performance - Recent avg reward: 0.057140, Times activated: 89
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.057140, Times activated: 89
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
📊 Node visual: Updated performance - Recent avg reward: 0.057140, Times activated: 89
🎯 Node visual: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
📊 Node random_full: Updated performance - Recent avg reward: 0.057140, Times activated: 89
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.028570 vs baseline: 0.028570)
📊 Episode completed: reward=0.012488, success=True

📈 Updating graph performance: episode_reward=0.012488, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 119: Baseline reward updated 0.028570 → 0.029819
📊 Node goal_basic: Updated performance - Recent avg reward: 0.059637, Times activated: 90
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)
📊 Node pose_position: Updated performance - Recent avg reward: 0.059637, Times activated: 90
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)
📊 Node pose_full: Updated performance - Recent avg reward: 0.059637, Times activated: 90
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.059637, Times activated: 90
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)
📊 Node visual: Updated performance - Recent avg reward: 0.059637, Times activated: 90
🎯 Node visual: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)
📊 Node random_full: Updated performance - Recent avg reward: 0.059637, Times activated: 90
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.029819 vs baseline: 0.029819)

🔄 CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
🔄 Adapting curriculum...

🎓 Generating curriculum configuration...

🎲 Selecting active interventions...

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.059637)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
📋 Processing 7 eligible interventions...
   goal_basic: avg_reward=0.059637, confidence=0.437224, score=1.371310
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
🎭 Creating actor instance for: goal_basic
   goal_basic: ✅ ACTIVATED with strength 1.000
   pose_position: avg_reward=0.059637, confidence=0.437224, score=1.371310
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_position
   pose_position: ✅ ACTIVATED with strength 1.000
   pose_full: avg_reward=0.059637, confidence=0.437224, score=1.371310
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_full
   pose_full: ✅ ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.059637, confidence=0.437224, score=1.371310
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
🎭 Creating actor instance for: physics_friction
   physics_friction: ✅ ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=∞)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
   physics_mass: ⚔️  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.059637, confidence=0.437224, score=1.371310
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
🎭 Creating actor instance for: visual
   visual: ✅ ACTIVATED with strength 1.000
   random_full: avg_reward=0.059637, confidence=0.437224, score=1.371310
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.019819 or random<0.9387614401245905 or history<5 or attempts<3)
🎭 Creating actor instance for: random_full
   random_full: ✅ ACTIVATED with strength 1.000

🎉 FINAL SELECTION: 6 interventions activated
   🚀 goal_basic (strength: 1.000)
   🚀 pose_position (strength: 1.000)
   🚀 pose_full (strength: 1.000)
   🚀 physics_friction (strength: 1.000)
   🚀 visual (strength: 1.000)
   🚀 random_full (strength: 1.000)
🔧 Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
✅ Curriculum config ready: 6 actors, 6 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 6
   🎯 Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   🎲 Exploration rate: 0.9388
   📈 Baseline reward: 0.029819
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0787    |
| time/              |           |
|    episodes        | 120       |
|    fps             | 19        |
|    time_elapsed    | 1269      |
|    total_timesteps | 24120     |
| train/             |           |
|    actor_loss      | -4.46e+05 |
|    critic_loss     | 1.42e+10  |
|    ent_coef        | 255       |
|    ent_coef_loss   | -300      |
|    learning_rate   | 0.00025   |
|    n_updates       | 23119     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.021400, success=True

📈 Updating graph performance: episode_reward=0.021400, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 120: Baseline reward updated 0.029819 → 0.031959
📊 Node goal_basic: Updated performance - Recent avg reward: 0.063917, Times activated: 91
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
📊 Node pose_position: Updated performance - Recent avg reward: 0.063917, Times activated: 91
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
📊 Node pose_full: Updated performance - Recent avg reward: 0.063917, Times activated: 91
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.063917, Times activated: 91
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
📊 Node visual: Updated performance - Recent avg reward: 0.063917, Times activated: 91
🎯 Node visual: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
📊 Node random_full: Updated performance - Recent avg reward: 0.063917, Times activated: 91
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.031959 vs baseline: 0.031959)
📊 Episode completed: reward=0.045957, success=True

📈 Updating graph performance: episode_reward=0.045957, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 121: Baseline reward updated 0.031959 → 0.036554
📊 Node goal_basic: Updated performance - Recent avg reward: 0.073109, Times activated: 92
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Node pose_position: Updated performance - Recent avg reward: 0.073109, Times activated: 92
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Node pose_full: Updated performance - Recent avg reward: 0.073109, Times activated: 92
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.073109, Times activated: 92
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Node visual: Updated performance - Recent avg reward: 0.073109, Times activated: 92
🎯 Node visual: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Node random_full: Updated performance - Recent avg reward: 0.073109, Times activated: 92
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 122: Baseline reward updated 0.036554 → 0.036554
📊 Node goal_basic: Updated performance - Recent avg reward: 0.067017, Times activated: 93
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Node pose_position: Updated performance - Recent avg reward: 0.067017, Times activated: 93
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Node pose_full: Updated performance - Recent avg reward: 0.067017, Times activated: 93
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.067017, Times activated: 93
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Node visual: Updated performance - Recent avg reward: 0.067017, Times activated: 93
🎯 Node visual: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Node random_full: Updated performance - Recent avg reward: 0.067017, Times activated: 93
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.036554 vs baseline: 0.036554)
📊 Episode completed: reward=0.000148, success=False

📈 Updating graph performance: episode_reward=0.000148, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 123: Baseline reward updated 0.036554 → 0.036569
📊 Node goal_basic: Updated performance - Recent avg reward: 0.015999, Times activated: 94
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
📊 Node pose_position: Updated performance - Recent avg reward: 0.015999, Times activated: 94
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
📊 Node pose_full: Updated performance - Recent avg reward: 0.015999, Times activated: 94
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.015999, Times activated: 94
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
📊 Node visual: Updated performance - Recent avg reward: 0.015999, Times activated: 94
🎯 Node visual: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
📊 Node random_full: Updated performance - Recent avg reward: 0.015999, Times activated: 94
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.036569 vs baseline: 0.036569)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0743    |
| time/              |           |
|    episodes        | 124       |
|    fps             | 18        |
|    time_elapsed    | 1314      |
|    total_timesteps | 24924     |
| train/             |           |
|    actor_loss      | -4.62e+05 |
|    critic_loss     | 1.43e+10  |
|    ent_coef        | 309       |
|    ent_coef_loss   | -284      |
|    learning_rate   | 0.00025   |
|    n_updates       | 23923     |
----------------------------------
📊 Episode completed: reward=0.026449, success=True

📈 Updating graph performance: episode_reward=0.026449, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 124: Baseline reward updated 0.036569 → 0.039214
📊 Node goal_basic: Updated performance - Recent avg reward: 0.018791, Times activated: 95
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
📊 Node pose_position: Updated performance - Recent avg reward: 0.018791, Times activated: 95
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
📊 Node pose_full: Updated performance - Recent avg reward: 0.018791, Times activated: 95
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.018791, Times activated: 95
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
📊 Node visual: Updated performance - Recent avg reward: 0.018791, Times activated: 95
🎯 Node visual: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
📊 Node random_full: Updated performance - Recent avg reward: 0.018791, Times activated: 95
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.039214 vs baseline: 0.039214)
📊 Episode completed: reward=0.050833, success=True

📈 Updating graph performance: episode_reward=0.050833, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 125: Baseline reward updated 0.039214 → 0.044297
📊 Node goal_basic: Updated performance - Recent avg reward: 0.024677, Times activated: 96
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
📊 Node pose_position: Updated performance - Recent avg reward: 0.024677, Times activated: 96
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
📊 Node pose_full: Updated performance - Recent avg reward: 0.024677, Times activated: 96
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.024677, Times activated: 96
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
📊 Node visual: Updated performance - Recent avg reward: 0.024677, Times activated: 96
🎯 Node visual: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
📊 Node random_full: Updated performance - Recent avg reward: 0.024677, Times activated: 96
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.044297 vs baseline: 0.044297)
📊 Episode completed: reward=0.092653, success=True

📈 Updating graph performance: episode_reward=0.092653, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 126: Baseline reward updated 0.044297 → 0.053563
📊 Node goal_basic: Updated performance - Recent avg reward: 0.034017, Times activated: 97
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
📊 Node pose_position: Updated performance - Recent avg reward: 0.034017, Times activated: 97
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
📊 Node pose_full: Updated performance - Recent avg reward: 0.034017, Times activated: 97
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.034017, Times activated: 97
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
📊 Node visual: Updated performance - Recent avg reward: 0.034017, Times activated: 97
🎯 Node visual: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
📊 Node random_full: Updated performance - Recent avg reward: 0.034017, Times activated: 97
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.053563 vs baseline: 0.053563)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 127: Baseline reward updated 0.053563 → 0.050517
📊 Node goal_basic: Updated performance - Recent avg reward: 0.034017, Times activated: 98
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
📊 Node pose_position: Updated performance - Recent avg reward: 0.034017, Times activated: 98
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
📊 Node pose_full: Updated performance - Recent avg reward: 0.034017, Times activated: 98
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.034017, Times activated: 98
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
📊 Node visual: Updated performance - Recent avg reward: 0.034017, Times activated: 98
🎯 Node visual: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
📊 Node random_full: Updated performance - Recent avg reward: 0.034017, Times activated: 98
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.050517 vs baseline: 0.050517)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0757    |
| time/              |           |
|    episodes        | 128       |
|    fps             | 18        |
|    time_elapsed    | 1358      |
|    total_timesteps | 25728     |
| train/             |           |
|    actor_loss      | -4.44e+05 |
|    critic_loss     | 1.1e+10   |
|    ent_coef        | 374       |
|    ent_coef_loss   | -281      |
|    learning_rate   | 0.00025   |
|    n_updates       | 24727     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 128: Baseline reward updated 0.050517 → 0.024993
📊 Node goal_basic: Updated performance - Recent avg reward: 0.033987, Times activated: 99
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
📊 Node pose_position: Updated performance - Recent avg reward: 0.033987, Times activated: 99
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
📊 Node pose_full: Updated performance - Recent avg reward: 0.033987, Times activated: 99
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.033987, Times activated: 99
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
📊 Node visual: Updated performance - Recent avg reward: 0.033987, Times activated: 99
🎯 Node visual: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
📊 Node random_full: Updated performance - Recent avg reward: 0.033987, Times activated: 99
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.024993 vs baseline: 0.024993)
📊 Episode completed: reward=0.010516, success=True

📈 Updating graph performance: episode_reward=0.010516, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 129: Baseline reward updated 0.024993 → 0.024796
📊 Node goal_basic: Updated performance - Recent avg reward: 0.030800, Times activated: 100
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
📊 Node pose_position: Updated performance - Recent avg reward: 0.030800, Times activated: 100
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
📊 Node pose_full: Updated performance - Recent avg reward: 0.030800, Times activated: 100
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.030800, Times activated: 100
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
📊 Node visual: Updated performance - Recent avg reward: 0.030800, Times activated: 100
🎯 Node visual: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
📊 Node random_full: Updated performance - Recent avg reward: 0.030800, Times activated: 100
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.024796 vs baseline: 0.024796)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 130: Baseline reward updated 0.024796 → 0.022656
📊 Node goal_basic: Updated performance - Recent avg reward: 0.020634, Times activated: 101
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
📊 Node pose_position: Updated performance - Recent avg reward: 0.020634, Times activated: 101
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
📊 Node pose_full: Updated performance - Recent avg reward: 0.020634, Times activated: 101
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.020634, Times activated: 101
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
📊 Node visual: Updated performance - Recent avg reward: 0.020634, Times activated: 101
🎯 Node visual: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
📊 Node random_full: Updated performance - Recent avg reward: 0.020634, Times activated: 101
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.022656 vs baseline: 0.022656)
📊 Episode completed: reward=0.140889, success=True

📈 Updating graph performance: episode_reward=0.140889, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 131: Baseline reward updated 0.022656 → 0.032149
📊 Node goal_basic: Updated performance - Recent avg reward: 0.030281, Times activated: 102
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
📊 Node pose_position: Updated performance - Recent avg reward: 0.030281, Times activated: 102
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
📊 Node pose_full: Updated performance - Recent avg reward: 0.030281, Times activated: 102
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.030281, Times activated: 102
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
📊 Node visual: Updated performance - Recent avg reward: 0.030281, Times activated: 102
🎯 Node visual: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
📊 Node random_full: Updated performance - Recent avg reward: 0.030281, Times activated: 102
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.032149 vs baseline: 0.032149)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0774    |
| time/              |           |
|    episodes        | 132       |
|    fps             | 18        |
|    time_elapsed    | 1409      |
|    total_timesteps | 26532     |
| train/             |           |
|    actor_loss      | -4.16e+05 |
|    critic_loss     | 1.17e+10  |
|    ent_coef        | 451       |
|    ent_coef_loss   | -299      |
|    learning_rate   | 0.00025   |
|    n_updates       | 25531     |
----------------------------------
📊 Episode completed: reward=0.011189, success=True

📈 Updating graph performance: episode_reward=0.011189, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 132: Baseline reward updated 0.032149 → 0.033268
📊 Node goal_basic: Updated performance - Recent avg reward: 0.032519, Times activated: 103
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
📊 Node pose_position: Updated performance - Recent avg reward: 0.032519, Times activated: 103
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
📊 Node pose_full: Updated performance - Recent avg reward: 0.032519, Times activated: 103
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.032519, Times activated: 103
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
📊 Node visual: Updated performance - Recent avg reward: 0.032519, Times activated: 103
🎯 Node visual: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
📊 Node random_full: Updated performance - Recent avg reward: 0.032519, Times activated: 103
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.033268 vs baseline: 0.033268)
📊 Episode completed: reward=0.025897, success=True

📈 Updating graph performance: episode_reward=0.025897, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 133: Baseline reward updated 0.033268 → 0.035843
📊 Node goal_basic: Updated performance - Recent avg reward: 0.037698, Times activated: 104
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
📊 Node pose_position: Updated performance - Recent avg reward: 0.037698, Times activated: 104
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
📊 Node pose_full: Updated performance - Recent avg reward: 0.037698, Times activated: 104
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.037698, Times activated: 104
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
📊 Node visual: Updated performance - Recent avg reward: 0.037698, Times activated: 104
🎯 Node visual: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
📊 Node random_full: Updated performance - Recent avg reward: 0.037698, Times activated: 104
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.035843 vs baseline: 0.035843)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000867, success=False

📈 Updating graph performance: episode_reward=0.000867, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 134: Baseline reward updated 0.035843 → 0.033284
📊 Node goal_basic: Updated performance - Recent avg reward: 0.035768, Times activated: 105
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
📊 Node pose_position: Updated performance - Recent avg reward: 0.035768, Times activated: 105
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
📊 Node pose_full: Updated performance - Recent avg reward: 0.035768, Times activated: 105
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.035768, Times activated: 105
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
📊 Node visual: Updated performance - Recent avg reward: 0.035768, Times activated: 105
🎯 Node visual: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
📊 Node random_full: Updated performance - Recent avg reward: 0.035768, Times activated: 105
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.033284 vs baseline: 0.033284)
📊 Episode completed: reward=0.970089, success=True

📈 Updating graph performance: episode_reward=0.970089, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 135: Baseline reward updated 0.033284 → 0.125210
📊 Node goal_basic: Updated performance - Recent avg reward: 0.229786, Times activated: 106
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
📊 Node pose_position: Updated performance - Recent avg reward: 0.229786, Times activated: 106
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
📊 Node pose_full: Updated performance - Recent avg reward: 0.229786, Times activated: 106
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.229786, Times activated: 106
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
📊 Node visual: Updated performance - Recent avg reward: 0.229786, Times activated: 106
🎯 Node visual: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
📊 Node random_full: Updated performance - Recent avg reward: 0.229786, Times activated: 106
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.125210 vs baseline: 0.125210)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0988    |
| time/              |           |
|    episodes        | 136       |
|    fps             | 18        |
|    time_elapsed    | 1453      |
|    total_timesteps | 27336     |
| train/             |           |
|    actor_loss      | -5.29e+05 |
|    critic_loss     | 1.59e+10  |
|    ent_coef        | 544       |
|    ent_coef_loss   | -278      |
|    learning_rate   | 0.00025   |
|    n_updates       | 26335     |
----------------------------------
📊 Episode completed: reward=1.261031, success=True

📈 Updating graph performance: episode_reward=1.261031, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 136: Baseline reward updated 0.125210 → 0.242048
📊 Node goal_basic: Updated performance - Recent avg reward: 0.453815, Times activated: 107
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
📊 Node pose_position: Updated performance - Recent avg reward: 0.453815, Times activated: 107
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
📊 Node pose_full: Updated performance - Recent avg reward: 0.453815, Times activated: 107
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.453815, Times activated: 107
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
📊 Node visual: Updated performance - Recent avg reward: 0.453815, Times activated: 107
🎯 Node visual: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
📊 Node random_full: Updated performance - Recent avg reward: 0.453815, Times activated: 107
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.242048 vs baseline: 0.242048)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.096810, success=True

📈 Updating graph performance: episode_reward=0.096810, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 137: Baseline reward updated 0.242048 → 0.251729
📊 Node goal_basic: Updated performance - Recent avg reward: 0.470939, Times activated: 108
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
📊 Node pose_position: Updated performance - Recent avg reward: 0.470939, Times activated: 108
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
📊 Node pose_full: Updated performance - Recent avg reward: 0.470939, Times activated: 108
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.470939, Times activated: 108
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
📊 Node visual: Updated performance - Recent avg reward: 0.470939, Times activated: 108
🎯 Node visual: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
📊 Node random_full: Updated performance - Recent avg reward: 0.470939, Times activated: 108
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.251729 vs baseline: 0.251729)
📊 Episode completed: reward=0.011230, success=True

📈 Updating graph performance: episode_reward=0.011230, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 138: Baseline reward updated 0.251729 → 0.252852
📊 Node goal_basic: Updated performance - Recent avg reward: 0.468005, Times activated: 109
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
📊 Node pose_position: Updated performance - Recent avg reward: 0.468005, Times activated: 109
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
📊 Node pose_full: Updated performance - Recent avg reward: 0.468005, Times activated: 109
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.468005, Times activated: 109
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
📊 Node visual: Updated performance - Recent avg reward: 0.468005, Times activated: 109
🎯 Node visual: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
📊 Node random_full: Updated performance - Recent avg reward: 0.468005, Times activated: 109
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.252852 vs baseline: 0.252852)
📊 Episode completed: reward=0.001182, success=True

📈 Updating graph performance: episode_reward=0.001182, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 139: Baseline reward updated 0.252852 → 0.251918
📊 Node goal_basic: Updated performance - Recent avg reward: 0.468068, Times activated: 110
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
📊 Node pose_position: Updated performance - Recent avg reward: 0.468068, Times activated: 110
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
📊 Node pose_full: Updated performance - Recent avg reward: 0.468068, Times activated: 110
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.468068, Times activated: 110
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
📊 Node visual: Updated performance - Recent avg reward: 0.468068, Times activated: 110
🎯 Node visual: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
📊 Node random_full: Updated performance - Recent avg reward: 0.468068, Times activated: 110
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.251918 vs baseline: 0.251918)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0971    |
| time/              |           |
|    episodes        | 140       |
|    fps             | 18        |
|    time_elapsed    | 1496      |
|    total_timesteps | 28140     |
| train/             |           |
|    actor_loss      | -4.37e+05 |
|    critic_loss     | 1.33e+10  |
|    ent_coef        | 654       |
|    ent_coef_loss   | -265      |
|    learning_rate   | 0.00025   |
|    n_updates       | 27139     |
----------------------------------
📊 Episode completed: reward=0.004404, success=True

📈 Updating graph performance: episode_reward=0.004404, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 140: Baseline reward updated 0.251918 → 0.252359
📊 Node goal_basic: Updated performance - Recent avg reward: 0.274931, Times activated: 111
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
📊 Node pose_position: Updated performance - Recent avg reward: 0.274931, Times activated: 111
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
📊 Node pose_full: Updated performance - Recent avg reward: 0.274931, Times activated: 111
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.274931, Times activated: 111
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
📊 Node visual: Updated performance - Recent avg reward: 0.274931, Times activated: 111
🎯 Node visual: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
📊 Node random_full: Updated performance - Recent avg reward: 0.274931, Times activated: 111
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.252359 vs baseline: 0.252359)
📊 Episode completed: reward=0.006409, success=True

📈 Updating graph performance: episode_reward=0.006409, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 141: Baseline reward updated 0.252359 → 0.238911
📊 Node goal_basic: Updated performance - Recent avg reward: 0.024007, Times activated: 112
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
📊 Node pose_position: Updated performance - Recent avg reward: 0.024007, Times activated: 112
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
📊 Node pose_full: Updated performance - Recent avg reward: 0.024007, Times activated: 112
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.024007, Times activated: 112
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
📊 Node visual: Updated performance - Recent avg reward: 0.024007, Times activated: 112
🎯 Node visual: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
📊 Node random_full: Updated performance - Recent avg reward: 0.024007, Times activated: 112
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.238911 vs baseline: 0.238911)
📊 Episode completed: reward=0.009936, success=True

📈 Updating graph performance: episode_reward=0.009936, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 142: Baseline reward updated 0.238911 → 0.238786
📊 Node goal_basic: Updated performance - Recent avg reward: 0.006632, Times activated: 113
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
📊 Node pose_position: Updated performance - Recent avg reward: 0.006632, Times activated: 113
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
📊 Node pose_full: Updated performance - Recent avg reward: 0.006632, Times activated: 113
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.006632, Times activated: 113
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
📊 Node visual: Updated performance - Recent avg reward: 0.006632, Times activated: 113
🎯 Node visual: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
📊 Node random_full: Updated performance - Recent avg reward: 0.006632, Times activated: 113
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.238786 vs baseline: 0.238786)
📊 Episode completed: reward=0.004708, success=True

📈 Updating graph performance: episode_reward=0.004708, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 143: Baseline reward updated 0.238786 → 0.236667
📊 Node goal_basic: Updated performance - Recent avg reward: 0.005328, Times activated: 114
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
📊 Node pose_position: Updated performance - Recent avg reward: 0.005328, Times activated: 114
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
📊 Node pose_full: Updated performance - Recent avg reward: 0.005328, Times activated: 114
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.005328, Times activated: 114
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
📊 Node visual: Updated performance - Recent avg reward: 0.005328, Times activated: 114
🎯 Node visual: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
📊 Node random_full: Updated performance - Recent avg reward: 0.005328, Times activated: 114
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.236667 vs baseline: 0.236667)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0971    |
| time/              |           |
|    episodes        | 144       |
|    fps             | 18        |
|    time_elapsed    | 1543      |
|    total_timesteps | 28944     |
| train/             |           |
|    actor_loss      | -4.52e+05 |
|    critic_loss     | 1.22e+10  |
|    ent_coef        | 783       |
|    ent_coef_loss   | -228      |
|    learning_rate   | 0.00025   |
|    n_updates       | 27943     |
----------------------------------
📊 Episode completed: reward=0.001642, success=True

📈 Updating graph performance: episode_reward=0.001642, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 144: Baseline reward updated 0.236667 → 0.236744
📊 Node goal_basic: Updated performance - Recent avg reward: 0.005420, Times activated: 115
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
📊 Node pose_position: Updated performance - Recent avg reward: 0.005420, Times activated: 115
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
📊 Node pose_full: Updated performance - Recent avg reward: 0.005420, Times activated: 115
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.005420, Times activated: 115
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
📊 Node visual: Updated performance - Recent avg reward: 0.005420, Times activated: 115
🎯 Node visual: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
📊 Node random_full: Updated performance - Recent avg reward: 0.005420, Times activated: 115
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.236744 vs baseline: 0.236744)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 145: Baseline reward updated 0.236744 → 0.139735
📊 Node goal_basic: Updated performance - Recent avg reward: 0.004539, Times activated: 116
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
📊 Node pose_position: Updated performance - Recent avg reward: 0.004539, Times activated: 116
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
📊 Node pose_full: Updated performance - Recent avg reward: 0.004539, Times activated: 116
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.004539, Times activated: 116
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
📊 Node visual: Updated performance - Recent avg reward: 0.004539, Times activated: 116
🎯 Node visual: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
📊 Node random_full: Updated performance - Recent avg reward: 0.004539, Times activated: 116
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.139735 vs baseline: 0.139735)
📊 Episode completed: reward=0.004205, success=True

📈 Updating graph performance: episode_reward=0.004205, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 146: Baseline reward updated 0.139735 → 0.014053
📊 Node goal_basic: Updated performance - Recent avg reward: 0.004098, Times activated: 117
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
📊 Node pose_position: Updated performance - Recent avg reward: 0.004098, Times activated: 117
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
📊 Node pose_full: Updated performance - Recent avg reward: 0.004098, Times activated: 117
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.004098, Times activated: 117
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
📊 Node visual: Updated performance - Recent avg reward: 0.004098, Times activated: 117
🎯 Node visual: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
📊 Node random_full: Updated performance - Recent avg reward: 0.004098, Times activated: 117
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.014053 vs baseline: 0.014053)
📊 Episode completed: reward=0.028618, success=True

📈 Updating graph performance: episode_reward=0.028618, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 147: Baseline reward updated 0.014053 → 0.007233
📊 Node goal_basic: Updated performance - Recent avg reward: 0.007835, Times activated: 118
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
📊 Node pose_position: Updated performance - Recent avg reward: 0.007835, Times activated: 118
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
📊 Node pose_full: Updated performance - Recent avg reward: 0.007835, Times activated: 118
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.007835, Times activated: 118
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
📊 Node visual: Updated performance - Recent avg reward: 0.007835, Times activated: 118
🎯 Node visual: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
📊 Node random_full: Updated performance - Recent avg reward: 0.007835, Times activated: 118
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.007233 vs baseline: 0.007233)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.097     |
| time/              |           |
|    episodes        | 148       |
|    fps             | 18        |
|    time_elapsed    | 1588      |
|    total_timesteps | 29748     |
| train/             |           |
|    actor_loss      | -4.88e+05 |
|    critic_loss     | 9.85e+09  |
|    ent_coef        | 935       |
|    ent_coef_loss   | -220      |
|    learning_rate   | 0.00025   |
|    n_updates       | 28747     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 148: Baseline reward updated 0.007233 → 0.006110
📊 Node goal_basic: Updated performance - Recent avg reward: 0.006893, Times activated: 119
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
📊 Node pose_position: Updated performance - Recent avg reward: 0.006893, Times activated: 119
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
📊 Node pose_full: Updated performance - Recent avg reward: 0.006893, Times activated: 119
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.006893, Times activated: 119
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
📊 Node visual: Updated performance - Recent avg reward: 0.006893, Times activated: 119
🎯 Node visual: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
📊 Node random_full: Updated performance - Recent avg reward: 0.006893, Times activated: 119
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.006110 vs baseline: 0.006110)
📊 Episode completed: reward=0.521702, success=True

📈 Updating graph performance: episode_reward=0.521702, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 149: Baseline reward updated 0.006110 → 0.058162
📊 Node goal_basic: Updated performance - Recent avg reward: 0.110905, Times activated: 120
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)
📊 Node pose_position: Updated performance - Recent avg reward: 0.110905, Times activated: 120
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)
📊 Node pose_full: Updated performance - Recent avg reward: 0.110905, Times activated: 120
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.110905, Times activated: 120
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)
📊 Node visual: Updated performance - Recent avg reward: 0.110905, Times activated: 120
🎯 Node visual: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)
📊 Node random_full: Updated performance - Recent avg reward: 0.110905, Times activated: 120
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.058162 vs baseline: 0.058162)

🔄 CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
🔄 Adapting curriculum...

🎓 Generating curriculum configuration...

🎲 Selecting active interventions...

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.110905)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
📋 Processing 7 eligible interventions...
   goal_basic: avg_reward=0.110905, confidence=0.447390, score=1.453075
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
🎭 Creating actor instance for: goal_basic
   goal_basic: ✅ ACTIVATED with strength 1.000
   pose_position: avg_reward=0.110905, confidence=0.447390, score=1.453075
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_position
   pose_position: ✅ ACTIVATED with strength 1.000
   pose_full: avg_reward=0.110905, confidence=0.447390, score=1.453075
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_full
   pose_full: ✅ ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.110905, confidence=0.447390, score=1.453075
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
🎭 Creating actor instance for: physics_friction
   physics_friction: ✅ ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=∞)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
   physics_mass: ⚔️  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.110905, confidence=0.447390, score=1.453075
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
🎭 Creating actor instance for: visual
   visual: ✅ ACTIVATED with strength 1.000
   random_full: avg_reward=0.110905, confidence=0.447390, score=1.453075
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.048162 or random<0.9359492356076812 or history<5 or attempts<3)
🎭 Creating actor instance for: random_full
   random_full: ✅ ACTIVATED with strength 1.000

🎉 FINAL SELECTION: 6 interventions activated
   🚀 goal_basic (strength: 1.000)
   🚀 pose_position (strength: 1.000)
   🚀 pose_full (strength: 1.000)
   🚀 physics_friction (strength: 1.000)
   🚀 visual (strength: 1.000)
   🚀 random_full (strength: 1.000)
🔧 Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
✅ Curriculum config ready: 6 actors, 6 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 6
   🎯 Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   🎲 Exploration rate: 0.9359
   📈 Baseline reward: 0.058162
📊 Episode completed: reward=0.401109, success=True

📈 Updating graph performance: episode_reward=0.401109, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 150: Baseline reward updated 0.058162 → 0.097833
📊 Node goal_basic: Updated performance - Recent avg reward: 0.191127, Times activated: 121
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
📊 Node pose_position: Updated performance - Recent avg reward: 0.191127, Times activated: 121
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
📊 Node pose_full: Updated performance - Recent avg reward: 0.191127, Times activated: 121
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.191127, Times activated: 121
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
📊 Node visual: Updated performance - Recent avg reward: 0.191127, Times activated: 121
🎯 Node visual: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
📊 Node random_full: Updated performance - Recent avg reward: 0.191127, Times activated: 121
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.097833 vs baseline: 0.097833)
📊 Episode completed: reward=0.140064, success=True

📈 Updating graph performance: episode_reward=0.140064, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 151: Baseline reward updated 0.097833 → 0.111198
📊 Node goal_basic: Updated performance - Recent avg reward: 0.218299, Times activated: 122
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
📊 Node pose_position: Updated performance - Recent avg reward: 0.218299, Times activated: 122
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
📊 Node pose_full: Updated performance - Recent avg reward: 0.218299, Times activated: 122
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.218299, Times activated: 122
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
📊 Node visual: Updated performance - Recent avg reward: 0.218299, Times activated: 122
🎯 Node visual: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
📊 Node random_full: Updated performance - Recent avg reward: 0.218299, Times activated: 122
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.111198 vs baseline: 0.111198)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.106     |
| time/              |           |
|    episodes        | 152       |
|    fps             | 18        |
|    time_elapsed    | 1639      |
|    total_timesteps | 30552     |
| train/             |           |
|    actor_loss      | -4.35e+05 |
|    critic_loss     | 2.73e+10  |
|    ent_coef        | 1.11e+03  |
|    ent_coef_loss   | -194      |
|    learning_rate   | 0.00025   |
|    n_updates       | 29551     |
----------------------------------
📊 Episode completed: reward=0.130756, success=True

📈 Updating graph performance: episode_reward=0.130756, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 152: Baseline reward updated 0.111198 → 0.123280
📊 Node goal_basic: Updated performance - Recent avg reward: 0.238726, Times activated: 123
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
📊 Node pose_position: Updated performance - Recent avg reward: 0.238726, Times activated: 123
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
📊 Node pose_full: Updated performance - Recent avg reward: 0.238726, Times activated: 123
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.238726, Times activated: 123
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
📊 Node visual: Updated performance - Recent avg reward: 0.238726, Times activated: 123
🎯 Node visual: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
📊 Node random_full: Updated performance - Recent avg reward: 0.238726, Times activated: 123
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.123280 vs baseline: 0.123280)
📊 Episode completed: reward=0.193382, success=True

📈 Updating graph performance: episode_reward=0.193382, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 153: Baseline reward updated 0.123280 → 0.142148
📊 Node goal_basic: Updated performance - Recent avg reward: 0.277403, Times activated: 124
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
📊 Node pose_position: Updated performance - Recent avg reward: 0.277403, Times activated: 124
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
📊 Node pose_full: Updated performance - Recent avg reward: 0.277403, Times activated: 124
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.277403, Times activated: 124
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
📊 Node visual: Updated performance - Recent avg reward: 0.277403, Times activated: 124
🎯 Node visual: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
📊 Node random_full: Updated performance - Recent avg reward: 0.277403, Times activated: 124
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.142148 vs baseline: 0.142148)
📊 Episode completed: reward=0.034141, success=True

📈 Updating graph performance: episode_reward=0.034141, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 154: Baseline reward updated 0.142148 → 0.145398
📊 Node goal_basic: Updated performance - Recent avg reward: 0.179890, Times activated: 125
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
📊 Node pose_position: Updated performance - Recent avg reward: 0.179890, Times activated: 125
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
📊 Node pose_full: Updated performance - Recent avg reward: 0.179890, Times activated: 125
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.179890, Times activated: 125
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
📊 Node visual: Updated performance - Recent avg reward: 0.179890, Times activated: 125
🎯 Node visual: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
📊 Node random_full: Updated performance - Recent avg reward: 0.179890, Times activated: 125
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.145398 vs baseline: 0.145398)
📊 Episode completed: reward=0.029054, success=True

📈 Updating graph performance: episode_reward=0.029054, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 155: Baseline reward updated 0.145398 → 0.148303
📊 Node goal_basic: Updated performance - Recent avg reward: 0.105479, Times activated: 126
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
📊 Node pose_position: Updated performance - Recent avg reward: 0.105479, Times activated: 126
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
📊 Node pose_full: Updated performance - Recent avg reward: 0.105479, Times activated: 126
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.105479, Times activated: 126
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
📊 Node visual: Updated performance - Recent avg reward: 0.105479, Times activated: 126
🎯 Node visual: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
📊 Node random_full: Updated performance - Recent avg reward: 0.105479, Times activated: 126
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.148303 vs baseline: 0.148303)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.108    |
| time/              |          |
|    episodes        | 156      |
|    fps             | 18       |
|    time_elapsed    | 1685     |
|    total_timesteps | 31356    |
| train/             |          |
|    actor_loss      | -4.1e+05 |
|    critic_loss     | 1.47e+10 |
|    ent_coef        | 1.3e+03  |
|    ent_coef_loss   | -147     |
|    learning_rate   | 0.00025  |
|    n_updates       | 30355    |
---------------------------------
📊 Episode completed: reward=0.107341, success=True

📈 Updating graph performance: episode_reward=0.107341, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 156: Baseline reward updated 0.148303 → 0.158617
📊 Node goal_basic: Updated performance - Recent avg reward: 0.098935, Times activated: 127
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
📊 Node pose_position: Updated performance - Recent avg reward: 0.098935, Times activated: 127
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
📊 Node pose_full: Updated performance - Recent avg reward: 0.098935, Times activated: 127
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.098935, Times activated: 127
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
📊 Node visual: Updated performance - Recent avg reward: 0.098935, Times activated: 127
🎯 Node visual: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
📊 Node random_full: Updated performance - Recent avg reward: 0.098935, Times activated: 127
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.158617 vs baseline: 0.158617)
📊 Episode completed: reward=0.005784, success=True

📈 Updating graph performance: episode_reward=0.005784, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 157: Baseline reward updated 0.158617 → 0.156333
📊 Node goal_basic: Updated performance - Recent avg reward: 0.073940, Times activated: 128
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Node pose_position: Updated performance - Recent avg reward: 0.073940, Times activated: 128
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Node pose_full: Updated performance - Recent avg reward: 0.073940, Times activated: 128
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.073940, Times activated: 128
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Node visual: Updated performance - Recent avg reward: 0.073940, Times activated: 128
🎯 Node visual: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Node random_full: Updated performance - Recent avg reward: 0.073940, Times activated: 128
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 158: Baseline reward updated 0.156333 → 0.156333
📊 Node goal_basic: Updated performance - Recent avg reward: 0.035264, Times activated: 129
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Node pose_position: Updated performance - Recent avg reward: 0.035264, Times activated: 129
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Node pose_full: Updated performance - Recent avg reward: 0.035264, Times activated: 129
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.035264, Times activated: 129
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Node visual: Updated performance - Recent avg reward: 0.035264, Times activated: 129
🎯 Node visual: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Node random_full: Updated performance - Recent avg reward: 0.035264, Times activated: 129
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.156333 vs baseline: 0.156333)
📊 Episode completed: reward=0.196334, success=True

📈 Updating graph performance: episode_reward=0.196334, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 159: Baseline reward updated 0.156333 → 0.123797
📊 Node goal_basic: Updated performance - Recent avg reward: 0.067703, Times activated: 130
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
📊 Node pose_position: Updated performance - Recent avg reward: 0.067703, Times activated: 130
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
📊 Node pose_full: Updated performance - Recent avg reward: 0.067703, Times activated: 130
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.067703, Times activated: 130
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
📊 Node visual: Updated performance - Recent avg reward: 0.067703, Times activated: 130
🎯 Node visual: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
📊 Node random_full: Updated performance - Recent avg reward: 0.067703, Times activated: 130
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.123797 vs baseline: 0.123797)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.106     |
| time/              |           |
|    episodes        | 160       |
|    fps             | 18        |
|    time_elapsed    | 1726      |
|    total_timesteps | 32160     |
| train/             |           |
|    actor_loss      | -4.85e+05 |
|    critic_loss     | 1.45e+10  |
|    ent_coef        | 1.51e+03  |
|    ent_coef_loss   | -132      |
|    learning_rate   | 0.00025   |
|    n_updates       | 31159     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 160: Baseline reward updated 0.123797 → 0.083686
📊 Node goal_basic: Updated performance - Recent avg reward: 0.061892, Times activated: 131
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
📊 Node pose_position: Updated performance - Recent avg reward: 0.061892, Times activated: 131
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
📊 Node pose_full: Updated performance - Recent avg reward: 0.061892, Times activated: 131
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.061892, Times activated: 131
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
📊 Node visual: Updated performance - Recent avg reward: 0.061892, Times activated: 131
🎯 Node visual: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
📊 Node random_full: Updated performance - Recent avg reward: 0.061892, Times activated: 131
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.083686 vs baseline: 0.083686)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 161: Baseline reward updated 0.083686 → 0.069679
📊 Node goal_basic: Updated performance - Recent avg reward: 0.040424, Times activated: 132
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
📊 Node pose_position: Updated performance - Recent avg reward: 0.040424, Times activated: 132
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
📊 Node pose_full: Updated performance - Recent avg reward: 0.040424, Times activated: 132
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.040424, Times activated: 132
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
📊 Node visual: Updated performance - Recent avg reward: 0.040424, Times activated: 132
🎯 Node visual: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
📊 Node random_full: Updated performance - Recent avg reward: 0.040424, Times activated: 132
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.069679 vs baseline: 0.069679)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 162: Baseline reward updated 0.069679 → 0.056604
📊 Node goal_basic: Updated performance - Recent avg reward: 0.039267, Times activated: 133
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
📊 Node pose_position: Updated performance - Recent avg reward: 0.039267, Times activated: 133
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
📊 Node pose_full: Updated performance - Recent avg reward: 0.039267, Times activated: 133
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.039267, Times activated: 133
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
📊 Node visual: Updated performance - Recent avg reward: 0.039267, Times activated: 133
🎯 Node visual: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
📊 Node random_full: Updated performance - Recent avg reward: 0.039267, Times activated: 133
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.056604 vs baseline: 0.056604)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 163: Baseline reward updated 0.056604 → 0.037265
📊 Node goal_basic: Updated performance - Recent avg reward: 0.039267, Times activated: 134
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
📊 Node pose_position: Updated performance - Recent avg reward: 0.039267, Times activated: 134
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
📊 Node pose_full: Updated performance - Recent avg reward: 0.039267, Times activated: 134
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.039267, Times activated: 134
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
📊 Node visual: Updated performance - Recent avg reward: 0.039267, Times activated: 134
🎯 Node visual: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
📊 Node random_full: Updated performance - Recent avg reward: 0.039267, Times activated: 134
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.037265 vs baseline: 0.037265)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.104     |
| time/              |           |
|    episodes        | 164       |
|    fps             | 18        |
|    time_elapsed    | 1771      |
|    total_timesteps | 32964     |
| train/             |           |
|    actor_loss      | -5.39e+05 |
|    critic_loss     | 1.68e+10  |
|    ent_coef        | 1.74e+03  |
|    ent_coef_loss   | -111      |
|    learning_rate   | 0.00025   |
|    n_updates       | 31963     |
----------------------------------
📊 Episode completed: reward=0.038771, success=True

📈 Updating graph performance: episode_reward=0.038771, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 164: Baseline reward updated 0.037265 → 0.037728
📊 Node goal_basic: Updated performance - Recent avg reward: 0.007754, Times activated: 135
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
📊 Node pose_position: Updated performance - Recent avg reward: 0.007754, Times activated: 135
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
📊 Node pose_full: Updated performance - Recent avg reward: 0.007754, Times activated: 135
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.007754, Times activated: 135
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
📊 Node visual: Updated performance - Recent avg reward: 0.007754, Times activated: 135
🎯 Node visual: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
📊 Node random_full: Updated performance - Recent avg reward: 0.007754, Times activated: 135
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.037728 vs baseline: 0.037728)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 165: Baseline reward updated 0.037728 → 0.034823
📊 Node goal_basic: Updated performance - Recent avg reward: 0.007754, Times activated: 136
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
📊 Node pose_position: Updated performance - Recent avg reward: 0.007754, Times activated: 136
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
📊 Node pose_full: Updated performance - Recent avg reward: 0.007754, Times activated: 136
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.007754, Times activated: 136
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
📊 Node visual: Updated performance - Recent avg reward: 0.007754, Times activated: 136
🎯 Node visual: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
📊 Node random_full: Updated performance - Recent avg reward: 0.007754, Times activated: 136
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.034823 vs baseline: 0.034823)
📊 Episode completed: reward=0.023678, success=True

📈 Updating graph performance: episode_reward=0.023678, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 166: Baseline reward updated 0.034823 → 0.026457
📊 Node goal_basic: Updated performance - Recent avg reward: 0.012490, Times activated: 137
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
📊 Node pose_position: Updated performance - Recent avg reward: 0.012490, Times activated: 137
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
📊 Node pose_full: Updated performance - Recent avg reward: 0.012490, Times activated: 137
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.012490, Times activated: 137
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
📊 Node visual: Updated performance - Recent avg reward: 0.012490, Times activated: 137
🎯 Node visual: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
📊 Node random_full: Updated performance - Recent avg reward: 0.012490, Times activated: 137
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.026457 vs baseline: 0.026457)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.015789, success=True

📈 Updating graph performance: episode_reward=0.015789, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 167: Baseline reward updated 0.026457 → 0.027457
📊 Node goal_basic: Updated performance - Recent avg reward: 0.015648, Times activated: 138
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
📊 Node pose_position: Updated performance - Recent avg reward: 0.015648, Times activated: 138
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
📊 Node pose_full: Updated performance - Recent avg reward: 0.015648, Times activated: 138
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.015648, Times activated: 138
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
📊 Node visual: Updated performance - Recent avg reward: 0.015648, Times activated: 138
🎯 Node visual: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
📊 Node random_full: Updated performance - Recent avg reward: 0.015648, Times activated: 138
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.027457 vs baseline: 0.027457)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0834    |
| time/              |           |
|    episodes        | 168       |
|    fps             | 18        |
|    time_elapsed    | 1811      |
|    total_timesteps | 33768     |
| train/             |           |
|    actor_loss      | -4.49e+05 |
|    critic_loss     | 9.77e+09  |
|    ent_coef        | 2.01e+03  |
|    ent_coef_loss   | -88.4     |
|    learning_rate   | 0.00025   |
|    n_updates       | 32767     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.043065, success=True

📈 Updating graph performance: episode_reward=0.043065, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 168: Baseline reward updated 0.027457 → 0.031764
📊 Node goal_basic: Updated performance - Recent avg reward: 0.024261, Times activated: 139
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
📊 Node pose_position: Updated performance - Recent avg reward: 0.024261, Times activated: 139
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
📊 Node pose_full: Updated performance - Recent avg reward: 0.024261, Times activated: 139
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.024261, Times activated: 139
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
📊 Node visual: Updated performance - Recent avg reward: 0.024261, Times activated: 139
🎯 Node visual: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
📊 Node random_full: Updated performance - Recent avg reward: 0.024261, Times activated: 139
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.031764 vs baseline: 0.031764)
📊 Episode completed: reward=0.186323, success=True

📈 Updating graph performance: episode_reward=0.186323, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 169: Baseline reward updated 0.031764 → 0.030763
📊 Node goal_basic: Updated performance - Recent avg reward: 0.053771, Times activated: 140
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
📊 Node pose_position: Updated performance - Recent avg reward: 0.053771, Times activated: 140
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
📊 Node pose_full: Updated performance - Recent avg reward: 0.053771, Times activated: 140
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.053771, Times activated: 140
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
📊 Node visual: Updated performance - Recent avg reward: 0.053771, Times activated: 140
🎯 Node visual: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
📊 Node random_full: Updated performance - Recent avg reward: 0.053771, Times activated: 140
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 170: Baseline reward updated 0.030763 → 0.030763
📊 Node goal_basic: Updated performance - Recent avg reward: 0.053771, Times activated: 141
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
📊 Node pose_position: Updated performance - Recent avg reward: 0.053771, Times activated: 141
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
📊 Node pose_full: Updated performance - Recent avg reward: 0.053771, Times activated: 141
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.053771, Times activated: 141
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
📊 Node visual: Updated performance - Recent avg reward: 0.053771, Times activated: 141
🎯 Node visual: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
📊 Node random_full: Updated performance - Recent avg reward: 0.053771, Times activated: 141
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.030763 vs baseline: 0.030763)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.061025, success=True

📈 Updating graph performance: episode_reward=0.061025, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 171: Baseline reward updated 0.030763 → 0.036865
📊 Node goal_basic: Updated performance - Recent avg reward: 0.061240, Times activated: 142
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node pose_position: Updated performance - Recent avg reward: 0.061240, Times activated: 142
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node pose_full: Updated performance - Recent avg reward: 0.061240, Times activated: 142
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.061240, Times activated: 142
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node visual: Updated performance - Recent avg reward: 0.061240, Times activated: 142
🎯 Node visual: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node random_full: Updated performance - Recent avg reward: 0.061240, Times activated: 142
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.0859   |
| time/              |          |
|    episodes        | 172      |
|    fps             | 18       |
|    time_elapsed    | 1850     |
|    total_timesteps | 34572    |
| train/             |          |
|    actor_loss      | -4.8e+05 |
|    critic_loss     | 1.47e+10 |
|    ent_coef        | 2.32e+03 |
|    ent_coef_loss   | -81.9    |
|    learning_rate   | 0.00025  |
|    n_updates       | 33571    |
---------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 172: Baseline reward updated 0.036865 → 0.036865
📊 Node goal_basic: Updated performance - Recent avg reward: 0.058083, Times activated: 143
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node pose_position: Updated performance - Recent avg reward: 0.058083, Times activated: 143
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node pose_full: Updated performance - Recent avg reward: 0.058083, Times activated: 143
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.058083, Times activated: 143
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node visual: Updated performance - Recent avg reward: 0.058083, Times activated: 143
🎯 Node visual: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node random_full: Updated performance - Recent avg reward: 0.058083, Times activated: 143
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 173: Baseline reward updated 0.036865 → 0.036865
📊 Node goal_basic: Updated performance - Recent avg reward: 0.049470, Times activated: 144
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node pose_position: Updated performance - Recent avg reward: 0.049470, Times activated: 144
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node pose_full: Updated performance - Recent avg reward: 0.049470, Times activated: 144
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.049470, Times activated: 144
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node visual: Updated performance - Recent avg reward: 0.049470, Times activated: 144
🎯 Node visual: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Node random_full: Updated performance - Recent avg reward: 0.049470, Times activated: 144
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.036865 vs baseline: 0.036865)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 174: Baseline reward updated 0.036865 → 0.032988
📊 Node goal_basic: Updated performance - Recent avg reward: 0.012205, Times activated: 145
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Node pose_position: Updated performance - Recent avg reward: 0.012205, Times activated: 145
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Node pose_full: Updated performance - Recent avg reward: 0.012205, Times activated: 145
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.012205, Times activated: 145
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Node visual: Updated performance - Recent avg reward: 0.012205, Times activated: 145
🎯 Node visual: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Node random_full: Updated performance - Recent avg reward: 0.012205, Times activated: 145
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 175: Baseline reward updated 0.032988 → 0.032988
📊 Node goal_basic: Updated performance - Recent avg reward: 0.012205, Times activated: 146
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Node pose_position: Updated performance - Recent avg reward: 0.012205, Times activated: 146
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Node pose_full: Updated performance - Recent avg reward: 0.012205, Times activated: 146
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.012205, Times activated: 146
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Node visual: Updated performance - Recent avg reward: 0.012205, Times activated: 146
🎯 Node visual: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
📊 Node random_full: Updated performance - Recent avg reward: 0.012205, Times activated: 146
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.032988 vs baseline: 0.032988)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.0868    |
| time/              |           |
|    episodes        | 176       |
|    fps             | 18        |
|    time_elapsed    | 1889      |
|    total_timesteps | 35376     |
| train/             |           |
|    actor_loss      | -4.24e+05 |
|    critic_loss     | 1.83e+10  |
|    ent_coef        | 2.68e+03  |
|    ent_coef_loss   | -55.9     |
|    learning_rate   | 0.00025   |
|    n_updates       | 34375     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.307742, success=True

📈 Updating graph performance: episode_reward=0.307742, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 176: Baseline reward updated 0.032988 → 0.061394
📊 Node goal_basic: Updated performance - Recent avg reward: 0.061548, Times activated: 147
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
📊 Node pose_position: Updated performance - Recent avg reward: 0.061548, Times activated: 147
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
📊 Node pose_full: Updated performance - Recent avg reward: 0.061548, Times activated: 147
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.061548, Times activated: 147
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
📊 Node visual: Updated performance - Recent avg reward: 0.061548, Times activated: 147
🎯 Node visual: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
📊 Node random_full: Updated performance - Recent avg reward: 0.061548, Times activated: 147
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.061394 vs baseline: 0.061394)
📊 Episode completed: reward=0.031673, success=True

📈 Updating graph performance: episode_reward=0.031673, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 177: Baseline reward updated 0.061394 → 0.062983
📊 Node goal_basic: Updated performance - Recent avg reward: 0.067883, Times activated: 148
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
📊 Node pose_position: Updated performance - Recent avg reward: 0.067883, Times activated: 148
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
📊 Node pose_full: Updated performance - Recent avg reward: 0.067883, Times activated: 148
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.067883, Times activated: 148
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
📊 Node visual: Updated performance - Recent avg reward: 0.067883, Times activated: 148
🎯 Node visual: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
📊 Node random_full: Updated performance - Recent avg reward: 0.067883, Times activated: 148
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.062983 vs baseline: 0.062983)
📊 Episode completed: reward=0.257322, success=True

📈 Updating graph performance: episode_reward=0.257322, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 178: Baseline reward updated 0.062983 → 0.084408
📊 Node goal_basic: Updated performance - Recent avg reward: 0.119347, Times activated: 149
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
📊 Node pose_position: Updated performance - Recent avg reward: 0.119347, Times activated: 149
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
📊 Node pose_full: Updated performance - Recent avg reward: 0.119347, Times activated: 149
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.119347, Times activated: 149
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
📊 Node visual: Updated performance - Recent avg reward: 0.119347, Times activated: 149
🎯 Node visual: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
📊 Node random_full: Updated performance - Recent avg reward: 0.119347, Times activated: 149
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.084408 vs baseline: 0.084408)
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=1.205853, success=True

📈 Updating graph performance: episode_reward=1.205853, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 179: Baseline reward updated 0.084408 → 0.186362
📊 Node goal_basic: Updated performance - Recent avg reward: 0.360518, Times activated: 150
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)
📊 Node pose_position: Updated performance - Recent avg reward: 0.360518, Times activated: 150
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)
📊 Node pose_full: Updated performance - Recent avg reward: 0.360518, Times activated: 150
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.360518, Times activated: 150
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)
📊 Node visual: Updated performance - Recent avg reward: 0.360518, Times activated: 150
🎯 Node visual: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)
📊 Node random_full: Updated performance - Recent avg reward: 0.360518, Times activated: 150
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.186362 vs baseline: 0.186362)

🔄 CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
🔄 Adapting curriculum...

🎓 Generating curriculum configuration...

🎲 Selecting active interventions...

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.360518)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
📋 Processing 7 eligible interventions...
   goal_basic: avg_reward=0.360518, confidence=0.455517, score=1.727068
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
🎭 Creating actor instance for: goal_basic
   goal_basic: ✅ ACTIVATED with strength 1.000
   pose_position: avg_reward=0.360518, confidence=0.455517, score=1.727068
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_position
   pose_position: ✅ ACTIVATED with strength 1.000
   pose_full: avg_reward=0.360518, confidence=0.455517, score=1.727068
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_full
   pose_full: ✅ ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.360518, confidence=0.455517, score=1.727068
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
🎭 Creating actor instance for: physics_friction
   physics_friction: ✅ ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=∞)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
   physics_mass: ⚔️  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.360518, confidence=0.455517, score=1.727068
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
🎭 Creating actor instance for: visual
   visual: ✅ ACTIVATED with strength 1.000
   random_full: avg_reward=0.360518, confidence=0.455517, score=1.727068
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.176362 or random<0.9331454554826433 or history<5 or attempts<3)
🎭 Creating actor instance for: random_full
   random_full: ✅ ACTIVATED with strength 1.000

🎉 FINAL SELECTION: 6 interventions activated
   🚀 goal_basic (strength: 1.000)
   🚀 pose_position (strength: 1.000)
   🚀 pose_full (strength: 1.000)
   🚀 physics_friction (strength: 1.000)
   🚀 visual (strength: 1.000)
   🚀 random_full (strength: 1.000)
🔧 Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
✅ Curriculum config ready: 6 actors, 6 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 6
   🎯 Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   🎲 Exploration rate: 0.9331
   📈 Baseline reward: 0.186362
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.098     |
| time/              |           |
|    episodes        | 180       |
|    fps             | 18        |
|    time_elapsed    | 1931      |
|    total_timesteps | 36180     |
| train/             |           |
|    actor_loss      | -4.05e+05 |
|    critic_loss     | 9.69e+09  |
|    ent_coef        | 3.1e+03   |
|    ent_coef_loss   | -46.8     |
|    learning_rate   | 0.00025   |
|    n_updates       | 35179     |
----------------------------------
📊 Episode completed: reward=1.632383, success=True

📈 Updating graph performance: episode_reward=1.632383, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 180: Baseline reward updated 0.186362 → 0.349600
📊 Node goal_basic: Updated performance - Recent avg reward: 0.686995, Times activated: 151
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
📊 Node pose_position: Updated performance - Recent avg reward: 0.686995, Times activated: 151
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
📊 Node pose_full: Updated performance - Recent avg reward: 0.686995, Times activated: 151
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.686995, Times activated: 151
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
📊 Node visual: Updated performance - Recent avg reward: 0.686995, Times activated: 151
🎯 Node visual: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
📊 Node random_full: Updated performance - Recent avg reward: 0.686995, Times activated: 151
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.349600 vs baseline: 0.349600)
📊 Episode completed: reward=0.642162, success=True

📈 Updating graph performance: episode_reward=0.642162, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 181: Baseline reward updated 0.349600 → 0.407714
📊 Node goal_basic: Updated performance - Recent avg reward: 0.753879, Times activated: 152
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
📊 Node pose_position: Updated performance - Recent avg reward: 0.753879, Times activated: 152
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
📊 Node pose_full: Updated performance - Recent avg reward: 0.753879, Times activated: 152
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.753879, Times activated: 152
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
📊 Node visual: Updated performance - Recent avg reward: 0.753879, Times activated: 152
🎯 Node visual: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
📊 Node random_full: Updated performance - Recent avg reward: 0.753879, Times activated: 152
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 182: Baseline reward updated 0.407714 → 0.407714
📊 Node goal_basic: Updated performance - Recent avg reward: 0.747544, Times activated: 153
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
📊 Node pose_position: Updated performance - Recent avg reward: 0.747544, Times activated: 153
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
📊 Node pose_full: Updated performance - Recent avg reward: 0.747544, Times activated: 153
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.747544, Times activated: 153
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
📊 Node visual: Updated performance - Recent avg reward: 0.747544, Times activated: 153
🎯 Node visual: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
📊 Node random_full: Updated performance - Recent avg reward: 0.747544, Times activated: 153
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.407714 vs baseline: 0.407714)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.025365, success=True

📈 Updating graph performance: episode_reward=0.025365, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 183: Baseline reward updated 0.407714 → 0.410250
📊 Node goal_basic: Updated performance - Recent avg reward: 0.701153, Times activated: 154
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
📊 Node pose_position: Updated performance - Recent avg reward: 0.701153, Times activated: 154
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
📊 Node pose_full: Updated performance - Recent avg reward: 0.701153, Times activated: 154
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.701153, Times activated: 154
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
📊 Node visual: Updated performance - Recent avg reward: 0.701153, Times activated: 154
🎯 Node visual: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
📊 Node random_full: Updated performance - Recent avg reward: 0.701153, Times activated: 154
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.410250 vs baseline: 0.410250)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.105     |
| time/              |           |
|    episodes        | 184       |
|    fps             | 18        |
|    time_elapsed    | 1978      |
|    total_timesteps | 36984     |
| train/             |           |
|    actor_loss      | -5.38e+05 |
|    critic_loss     | 1.67e+10  |
|    ent_coef        | 3.54e+03  |
|    ent_coef_loss   | -38.9     |
|    learning_rate   | 0.00025   |
|    n_updates       | 35983     |
----------------------------------
📊 Episode completed: reward=0.029861, success=True

📈 Updating graph performance: episode_reward=0.029861, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 184: Baseline reward updated 0.410250 → 0.413236
📊 Node goal_basic: Updated performance - Recent avg reward: 0.465954, Times activated: 155
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
📊 Node pose_position: Updated performance - Recent avg reward: 0.465954, Times activated: 155
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
📊 Node pose_full: Updated performance - Recent avg reward: 0.465954, Times activated: 155
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.465954, Times activated: 155
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
📊 Node visual: Updated performance - Recent avg reward: 0.465954, Times activated: 155
🎯 Node visual: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
📊 Node random_full: Updated performance - Recent avg reward: 0.465954, Times activated: 155
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.413236 vs baseline: 0.413236)
📊 Episode completed: reward=0.024048, success=True

📈 Updating graph performance: episode_reward=0.024048, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 185: Baseline reward updated 0.413236 → 0.415641
📊 Node goal_basic: Updated performance - Recent avg reward: 0.144287, Times activated: 156
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
📊 Node pose_position: Updated performance - Recent avg reward: 0.144287, Times activated: 156
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
📊 Node pose_full: Updated performance - Recent avg reward: 0.144287, Times activated: 156
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.144287, Times activated: 156
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
📊 Node visual: Updated performance - Recent avg reward: 0.144287, Times activated: 156
🎯 Node visual: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
📊 Node random_full: Updated performance - Recent avg reward: 0.144287, Times activated: 156
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.415641 vs baseline: 0.415641)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.037822, success=True

📈 Updating graph performance: episode_reward=0.037822, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 186: Baseline reward updated 0.415641 → 0.388649
📊 Node goal_basic: Updated performance - Recent avg reward: 0.023419, Times activated: 157
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
📊 Node pose_position: Updated performance - Recent avg reward: 0.023419, Times activated: 157
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
📊 Node pose_full: Updated performance - Recent avg reward: 0.023419, Times activated: 157
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.023419, Times activated: 157
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
📊 Node visual: Updated performance - Recent avg reward: 0.023419, Times activated: 157
🎯 Node visual: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
📊 Node random_full: Updated performance - Recent avg reward: 0.023419, Times activated: 157
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.388649 vs baseline: 0.388649)
📊 Episode completed: reward=0.054971, success=True

📈 Updating graph performance: episode_reward=0.054971, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 187: Baseline reward updated 0.388649 → 0.390979
📊 Node goal_basic: Updated performance - Recent avg reward: 0.034413, Times activated: 158
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
📊 Node pose_position: Updated performance - Recent avg reward: 0.034413, Times activated: 158
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
📊 Node pose_full: Updated performance - Recent avg reward: 0.034413, Times activated: 158
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.034413, Times activated: 158
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
📊 Node visual: Updated performance - Recent avg reward: 0.034413, Times activated: 158
🎯 Node visual: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
📊 Node random_full: Updated performance - Recent avg reward: 0.034413, Times activated: 158
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.390979 vs baseline: 0.390979)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.106     |
| time/              |           |
|    episodes        | 188       |
|    fps             | 18        |
|    time_elapsed    | 2024      |
|    total_timesteps | 37788     |
| train/             |           |
|    actor_loss      | -4.73e+05 |
|    critic_loss     | 1.5e+10   |
|    ent_coef        | 4e+03     |
|    ent_coef_loss   | -15.7     |
|    learning_rate   | 0.00025   |
|    n_updates       | 36787     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 188: Baseline reward updated 0.390979 → 0.365247
📊 Node goal_basic: Updated performance - Recent avg reward: 0.029340, Times activated: 159
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
📊 Node pose_position: Updated performance - Recent avg reward: 0.029340, Times activated: 159
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
📊 Node pose_full: Updated performance - Recent avg reward: 0.029340, Times activated: 159
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.029340, Times activated: 159
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
📊 Node visual: Updated performance - Recent avg reward: 0.029340, Times activated: 159
🎯 Node visual: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
📊 Node random_full: Updated performance - Recent avg reward: 0.029340, Times activated: 159
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.365247 vs baseline: 0.365247)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 189: Baseline reward updated 0.365247 → 0.244661
📊 Node goal_basic: Updated performance - Recent avg reward: 0.023368, Times activated: 160
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
📊 Node pose_position: Updated performance - Recent avg reward: 0.023368, Times activated: 160
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
📊 Node pose_full: Updated performance - Recent avg reward: 0.023368, Times activated: 160
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.023368, Times activated: 160
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
📊 Node visual: Updated performance - Recent avg reward: 0.023368, Times activated: 160
🎯 Node visual: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
📊 Node random_full: Updated performance - Recent avg reward: 0.023368, Times activated: 160
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.244661 vs baseline: 0.244661)
📊 Episode completed: reward=0.266884, success=True

📈 Updating graph performance: episode_reward=0.266884, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 190: Baseline reward updated 0.244661 → 0.108111
📊 Node goal_basic: Updated performance - Recent avg reward: 0.071935, Times activated: 161
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
📊 Node pose_position: Updated performance - Recent avg reward: 0.071935, Times activated: 161
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
📊 Node pose_full: Updated performance - Recent avg reward: 0.071935, Times activated: 161
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.071935, Times activated: 161
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
📊 Node visual: Updated performance - Recent avg reward: 0.071935, Times activated: 161
🎯 Node visual: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
📊 Node random_full: Updated performance - Recent avg reward: 0.071935, Times activated: 161
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.108111 vs baseline: 0.108111)
📊 Episode completed: reward=0.025756, success=True

📈 Updating graph performance: episode_reward=0.025756, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 191: Baseline reward updated 0.108111 → 0.046471
📊 Node goal_basic: Updated performance - Recent avg reward: 0.069522, Times activated: 162
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
📊 Node pose_position: Updated performance - Recent avg reward: 0.069522, Times activated: 162
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
📊 Node pose_full: Updated performance - Recent avg reward: 0.069522, Times activated: 162
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.069522, Times activated: 162
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
📊 Node visual: Updated performance - Recent avg reward: 0.069522, Times activated: 162
🎯 Node visual: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
📊 Node random_full: Updated performance - Recent avg reward: 0.069522, Times activated: 162
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.046471 vs baseline: 0.046471)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.109    |
| time/              |          |
|    episodes        | 192      |
|    fps             | 18       |
|    time_elapsed    | 2066     |
|    total_timesteps | 38592    |
| train/             |          |
|    actor_loss      | -4.4e+05 |
|    critic_loss     | 1.05e+10 |
|    ent_coef        | 4.47e+03 |
|    ent_coef_loss   | -24.5    |
|    learning_rate   | 0.00025  |
|    n_updates       | 37591    |
---------------------------------
📊 Episode completed: reward=0.000322, success=False

📈 Updating graph performance: episode_reward=0.000322, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 192: Baseline reward updated 0.046471 → 0.046503
📊 Node goal_basic: Updated performance - Recent avg reward: 0.058592, Times activated: 163
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
📊 Node pose_position: Updated performance - Recent avg reward: 0.058592, Times activated: 163
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
📊 Node pose_full: Updated performance - Recent avg reward: 0.058592, Times activated: 163
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.058592, Times activated: 163
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
📊 Node visual: Updated performance - Recent avg reward: 0.058592, Times activated: 163
🎯 Node visual: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
📊 Node random_full: Updated performance - Recent avg reward: 0.058592, Times activated: 163
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.046503 vs baseline: 0.046503)
📊 Episode completed: reward=0.008974, success=True

📈 Updating graph performance: episode_reward=0.008974, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 193: Baseline reward updated 0.046503 → 0.044864
📊 Node goal_basic: Updated performance - Recent avg reward: 0.060387, Times activated: 164
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
📊 Node pose_position: Updated performance - Recent avg reward: 0.060387, Times activated: 164
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
📊 Node pose_full: Updated performance - Recent avg reward: 0.060387, Times activated: 164
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.060387, Times activated: 164
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
📊 Node visual: Updated performance - Recent avg reward: 0.060387, Times activated: 164
🎯 Node visual: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
📊 Node random_full: Updated performance - Recent avg reward: 0.060387, Times activated: 164
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.044864 vs baseline: 0.044864)
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.034258, success=True

📈 Updating graph performance: episode_reward=0.034258, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 194: Baseline reward updated 0.044864 → 0.045304
📊 Node goal_basic: Updated performance - Recent avg reward: 0.067239, Times activated: 165
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
📊 Node pose_position: Updated performance - Recent avg reward: 0.067239, Times activated: 165
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
📊 Node pose_full: Updated performance - Recent avg reward: 0.067239, Times activated: 165
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.067239, Times activated: 165
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
📊 Node visual: Updated performance - Recent avg reward: 0.067239, Times activated: 165
🎯 Node visual: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
📊 Node random_full: Updated performance - Recent avg reward: 0.067239, Times activated: 165
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.045304 vs baseline: 0.045304)
📊 Episode completed: reward=0.019627, success=True

📈 Updating graph performance: episode_reward=0.019627, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 195: Baseline reward updated 0.045304 → 0.044861
📊 Node goal_basic: Updated performance - Recent avg reward: 0.017787, Times activated: 166
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
📊 Node pose_position: Updated performance - Recent avg reward: 0.017787, Times activated: 166
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
📊 Node pose_full: Updated performance - Recent avg reward: 0.017787, Times activated: 166
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.017787, Times activated: 166
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
📊 Node visual: Updated performance - Recent avg reward: 0.017787, Times activated: 166
🎯 Node visual: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
📊 Node random_full: Updated performance - Recent avg reward: 0.017787, Times activated: 166
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.044861 vs baseline: 0.044861)
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 0.101    |
| time/              |          |
|    episodes        | 196      |
|    fps             | 18       |
|    time_elapsed    | 2100     |
|    total_timesteps | 39396    |
| train/             |          |
|    actor_loss      | -4.1e+05 |
|    critic_loss     | 1.23e+10 |
|    ent_coef        | 4.89e+03 |
|    ent_coef_loss   | -8.69    |
|    learning_rate   | 0.00025  |
|    n_updates       | 38395    |
---------------------------------
📊 Episode completed: reward=0.112557, success=True

📈 Updating graph performance: episode_reward=0.112557, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 196: Baseline reward updated 0.044861 → 0.052335
📊 Node goal_basic: Updated performance - Recent avg reward: 0.035148, Times activated: 167
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
📊 Node pose_position: Updated performance - Recent avg reward: 0.035148, Times activated: 167
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
📊 Node pose_full: Updated performance - Recent avg reward: 0.035148, Times activated: 167
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.035148, Times activated: 167
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
📊 Node visual: Updated performance - Recent avg reward: 0.035148, Times activated: 167
🎯 Node visual: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
📊 Node random_full: Updated performance - Recent avg reward: 0.035148, Times activated: 167
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.052335 vs baseline: 0.052335)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 197: Baseline reward updated 0.052335 → 0.046838
📊 Node goal_basic: Updated performance - Recent avg reward: 0.035083, Times activated: 168
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
📊 Node pose_position: Updated performance - Recent avg reward: 0.035083, Times activated: 168
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
📊 Node pose_full: Updated performance - Recent avg reward: 0.035083, Times activated: 168
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.035083, Times activated: 168
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
📊 Node visual: Updated performance - Recent avg reward: 0.035083, Times activated: 168
🎯 Node visual: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
📊 Node random_full: Updated performance - Recent avg reward: 0.035083, Times activated: 168
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.046838 vs baseline: 0.046838)
📊 Episode completed: reward=0.287306, success=True

📈 Updating graph performance: episode_reward=0.287306, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 198: Baseline reward updated 0.046838 → 0.075568
📊 Node goal_basic: Updated performance - Recent avg reward: 0.090750, Times activated: 169
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
📊 Node pose_position: Updated performance - Recent avg reward: 0.090750, Times activated: 169
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
📊 Node pose_full: Updated performance - Recent avg reward: 0.090750, Times activated: 169
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.090750, Times activated: 169
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
📊 Node visual: Updated performance - Recent avg reward: 0.090750, Times activated: 169
🎯 Node visual: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
📊 Node random_full: Updated performance - Recent avg reward: 0.090750, Times activated: 169
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.075568 vs baseline: 0.075568)
📊 Episode completed: reward=0.002035, success=True

📈 Updating graph performance: episode_reward=0.002035, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 199: Baseline reward updated 0.075568 → 0.075772
📊 Node goal_basic: Updated performance - Recent avg reward: 0.084305, Times activated: 170
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
📊 Node pose_position: Updated performance - Recent avg reward: 0.084305, Times activated: 170
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
📊 Node pose_full: Updated performance - Recent avg reward: 0.084305, Times activated: 170
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.084305, Times activated: 170
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
📊 Node visual: Updated performance - Recent avg reward: 0.084305, Times activated: 170
🎯 Node visual: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
📊 Node random_full: Updated performance - Recent avg reward: 0.084305, Times activated: 170
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.075772 vs baseline: 0.075772)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.103     |
| time/              |           |
|    episodes        | 200       |
|    fps             | 18        |
|    time_elapsed    | 2138      |
|    total_timesteps | 40200     |
| train/             |           |
|    actor_loss      | -4.16e+05 |
|    critic_loss     | 9.08e+09  |
|    ent_coef        | 5.19e+03  |
|    ent_coef_loss   | -4.27     |
|    learning_rate   | 0.00025   |
|    n_updates       | 39199     |
----------------------------------
📊 Episode completed: reward=0.001385, success=True

📈 Updating graph performance: episode_reward=0.001385, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 200: Baseline reward updated 0.075772 → 0.049222
📊 Node goal_basic: Updated performance - Recent avg reward: 0.080657, Times activated: 171
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
📊 Node pose_position: Updated performance - Recent avg reward: 0.080657, Times activated: 171
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
📊 Node pose_full: Updated performance - Recent avg reward: 0.080657, Times activated: 171
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.080657, Times activated: 171
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
📊 Node visual: Updated performance - Recent avg reward: 0.080657, Times activated: 171
🎯 Node visual: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
📊 Node random_full: Updated performance - Recent avg reward: 0.080657, Times activated: 171
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.049222 vs baseline: 0.049222)
📊 Episode completed: reward=0.000227, success=False

📈 Updating graph performance: episode_reward=0.000227, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 201: Baseline reward updated 0.049222 → 0.046669
📊 Node goal_basic: Updated performance - Recent avg reward: 0.058191, Times activated: 172
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
📊 Node pose_position: Updated performance - Recent avg reward: 0.058191, Times activated: 172
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
📊 Node pose_full: Updated performance - Recent avg reward: 0.058191, Times activated: 172
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.058191, Times activated: 172
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
📊 Node visual: Updated performance - Recent avg reward: 0.058191, Times activated: 172
🎯 Node visual: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
📊 Node random_full: Updated performance - Recent avg reward: 0.058191, Times activated: 172
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.046669 vs baseline: 0.046669)
📊 Episode completed: reward=0.009083, success=True

📈 Updating graph performance: episode_reward=0.009083, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 202: Baseline reward updated 0.046669 → 0.047545
📊 Node goal_basic: Updated performance - Recent avg reward: 0.060007, Times activated: 173
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
📊 Node pose_position: Updated performance - Recent avg reward: 0.060007, Times activated: 173
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
📊 Node pose_full: Updated performance - Recent avg reward: 0.060007, Times activated: 173
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.060007, Times activated: 173
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
📊 Node visual: Updated performance - Recent avg reward: 0.060007, Times activated: 173
🎯 Node visual: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
📊 Node random_full: Updated performance - Recent avg reward: 0.060007, Times activated: 173
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.047545 vs baseline: 0.047545)
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.011106, success=True

📈 Updating graph performance: episode_reward=0.011106, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 203: Baseline reward updated 0.047545 → 0.047758
📊 Node goal_basic: Updated performance - Recent avg reward: 0.004767, Times activated: 174
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
📊 Node pose_position: Updated performance - Recent avg reward: 0.004767, Times activated: 174
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
📊 Node pose_full: Updated performance - Recent avg reward: 0.004767, Times activated: 174
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.004767, Times activated: 174
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
📊 Node visual: Updated performance - Recent avg reward: 0.004767, Times activated: 174
🎯 Node visual: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
📊 Node random_full: Updated performance - Recent avg reward: 0.004767, Times activated: 174
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.047758 vs baseline: 0.047758)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.109     |
| time/              |           |
|    episodes        | 204       |
|    fps             | 18        |
|    time_elapsed    | 2178      |
|    total_timesteps | 41004     |
| train/             |           |
|    actor_loss      | -4.88e+05 |
|    critic_loss     | 9.76e+09  |
|    ent_coef        | 5.24e+03  |
|    ent_coef_loss   | 3.84      |
|    learning_rate   | 0.00025   |
|    n_updates       | 40003     |
----------------------------------
📊 Episode completed: reward=0.577836, success=True

📈 Updating graph performance: episode_reward=0.577836, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 204: Baseline reward updated 0.047758 → 0.102116
📊 Node goal_basic: Updated performance - Recent avg reward: 0.119927, Times activated: 175
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
📊 Node pose_position: Updated performance - Recent avg reward: 0.119927, Times activated: 175
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
📊 Node pose_full: Updated performance - Recent avg reward: 0.119927, Times activated: 175
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.119927, Times activated: 175
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
📊 Node visual: Updated performance - Recent avg reward: 0.119927, Times activated: 175
🎯 Node visual: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
📊 Node random_full: Updated performance - Recent avg reward: 0.119927, Times activated: 175
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.102116 vs baseline: 0.102116)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 205: Baseline reward updated 0.102116 → 0.100154
📊 Node goal_basic: Updated performance - Recent avg reward: 0.119650, Times activated: 176
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
📊 Node pose_position: Updated performance - Recent avg reward: 0.119650, Times activated: 176
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
📊 Node pose_full: Updated performance - Recent avg reward: 0.119650, Times activated: 176
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.119650, Times activated: 176
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
📊 Node visual: Updated performance - Recent avg reward: 0.119650, Times activated: 176
🎯 Node visual: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
📊 Node random_full: Updated performance - Recent avg reward: 0.119650, Times activated: 176
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.100154 vs baseline: 0.100154)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 206: Baseline reward updated 0.100154 → 0.088898
📊 Node goal_basic: Updated performance - Recent avg reward: 0.119605, Times activated: 177
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Node pose_position: Updated performance - Recent avg reward: 0.119605, Times activated: 177
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Node pose_full: Updated performance - Recent avg reward: 0.119605, Times activated: 177
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.119605, Times activated: 177
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Node visual: Updated performance - Recent avg reward: 0.119605, Times activated: 177
🎯 Node visual: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Node random_full: Updated performance - Recent avg reward: 0.119605, Times activated: 177
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 207: Baseline reward updated 0.088898 → 0.088898
📊 Node goal_basic: Updated performance - Recent avg reward: 0.117788, Times activated: 178
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Node pose_position: Updated performance - Recent avg reward: 0.117788, Times activated: 178
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Node pose_full: Updated performance - Recent avg reward: 0.117788, Times activated: 178
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.117788, Times activated: 178
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Node visual: Updated performance - Recent avg reward: 0.117788, Times activated: 178
🎯 Node visual: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
📊 Node random_full: Updated performance - Recent avg reward: 0.117788, Times activated: 178
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.088898 vs baseline: 0.088898)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.109     |
| time/              |           |
|    episodes        | 208       |
|    fps             | 18        |
|    time_elapsed    | 2225      |
|    total_timesteps | 41808     |
| train/             |           |
|    actor_loss      | -4.89e+05 |
|    critic_loss     | 1.6e+10   |
|    ent_coef        | 5.13e+03  |
|    ent_coef_loss   | -0.0354   |
|    learning_rate   | 0.00025   |
|    n_updates       | 40807     |
----------------------------------
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 208: Baseline reward updated 0.088898 → 0.060167
📊 Node goal_basic: Updated performance - Recent avg reward: 0.115567, Times activated: 179
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
📊 Node pose_position: Updated performance - Recent avg reward: 0.115567, Times activated: 179
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
📊 Node pose_full: Updated performance - Recent avg reward: 0.115567, Times activated: 179
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.115567, Times activated: 179
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
📊 Node visual: Updated performance - Recent avg reward: 0.115567, Times activated: 179
🎯 Node visual: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
📊 Node random_full: Updated performance - Recent avg reward: 0.115567, Times activated: 179
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.060167 vs baseline: 0.060167)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 209: Baseline reward updated 0.060167 → 0.059964
📊 Node goal_basic: Updated performance - Recent avg reward: 0.000000, Times activated: 180
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)
📊 Node pose_position: Updated performance - Recent avg reward: 0.000000, Times activated: 180
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)
📊 Node pose_full: Updated performance - Recent avg reward: 0.000000, Times activated: 180
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.000000, Times activated: 180
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)
📊 Node visual: Updated performance - Recent avg reward: 0.000000, Times activated: 180
🎯 Node visual: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)
📊 Node random_full: Updated performance - Recent avg reward: 0.000000, Times activated: 180
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.059964 vs baseline: 0.059964)

🔄 CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
🔄 Adapting curriculum...

🎓 Generating curriculum configuration...

🎲 Selecting active interventions...

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.000000)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
📋 Processing 7 eligible interventions...
   goal_basic: avg_reward=0.000000, confidence=0.462270, score=1.386809
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
🎭 Creating actor instance for: goal_basic
   goal_basic: ✅ ACTIVATED with strength 1.000
   pose_position: avg_reward=0.000000, confidence=0.462270, score=1.386809
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_position
   pose_position: ✅ ACTIVATED with strength 1.000
   pose_full: avg_reward=0.000000, confidence=0.462270, score=1.386809
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_full
   pose_full: ✅ ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.000000, confidence=0.462270, score=1.386809
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
🎭 Creating actor instance for: physics_friction
   physics_friction: ✅ ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=∞)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
   physics_mass: ⚔️  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.000000, confidence=0.462270, score=1.386809
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
🎭 Creating actor instance for: visual
   visual: ✅ ACTIVATED with strength 1.000
   random_full: avg_reward=0.000000, confidence=0.462270, score=1.386809
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.049964 or random<0.9303500745129124 or history<5 or attempts<3)
🎭 Creating actor instance for: random_full
   random_full: ✅ ACTIVATED with strength 1.000

🎉 FINAL SELECTION: 6 interventions activated
   🚀 goal_basic (strength: 1.000)
   🚀 pose_position (strength: 1.000)
   🚀 pose_full (strength: 1.000)
   🚀 physics_friction (strength: 1.000)
   🚀 visual (strength: 1.000)
   🚀 random_full (strength: 1.000)
🔧 Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
✅ Curriculum config ready: 6 actors, 6 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 6
   🎯 Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   🎲 Exploration rate: 0.9304
   📈 Baseline reward: 0.059964
📊 Episode completed: reward=0.015555, success=True

📈 Updating graph performance: episode_reward=0.015555, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 210: Baseline reward updated 0.059964 → 0.061381
📊 Node goal_basic: Updated performance - Recent avg reward: 0.003111, Times activated: 181
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
📊 Node pose_position: Updated performance - Recent avg reward: 0.003111, Times activated: 181
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
📊 Node pose_full: Updated performance - Recent avg reward: 0.003111, Times activated: 181
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.003111, Times activated: 181
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
📊 Node visual: Updated performance - Recent avg reward: 0.003111, Times activated: 181
🎯 Node visual: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
📊 Node random_full: Updated performance - Recent avg reward: 0.003111, Times activated: 181
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.061381 vs baseline: 0.061381)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.012837, success=True

📈 Updating graph performance: episode_reward=0.012837, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 211: Baseline reward updated 0.061381 → 0.062642
📊 Node goal_basic: Updated performance - Recent avg reward: 0.005678, Times activated: 182
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
📊 Node pose_position: Updated performance - Recent avg reward: 0.005678, Times activated: 182
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
📊 Node pose_full: Updated performance - Recent avg reward: 0.005678, Times activated: 182
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.005678, Times activated: 182
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
📊 Node visual: Updated performance - Recent avg reward: 0.005678, Times activated: 182
🎯 Node visual: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
📊 Node random_full: Updated performance - Recent avg reward: 0.005678, Times activated: 182
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.062642 vs baseline: 0.062642)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.109     |
| time/              |           |
|    episodes        | 212       |
|    fps             | 18        |
|    time_elapsed    | 2268      |
|    total_timesteps | 42612     |
| train/             |           |
|    actor_loss      | -3.56e+05 |
|    critic_loss     | 7.11e+09  |
|    ent_coef        | 5.03e+03  |
|    ent_coef_loss   | -3.71     |
|    learning_rate   | 0.00025   |
|    n_updates       | 41611     |
----------------------------------
📊 Episode completed: reward=0.004916, success=True

📈 Updating graph performance: episode_reward=0.004916, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 212: Baseline reward updated 0.062642 → 0.062225
📊 Node goal_basic: Updated performance - Recent avg reward: 0.006662, Times activated: 183
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
📊 Node pose_position: Updated performance - Recent avg reward: 0.006662, Times activated: 183
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
📊 Node pose_full: Updated performance - Recent avg reward: 0.006662, Times activated: 183
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.006662, Times activated: 183
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
📊 Node visual: Updated performance - Recent avg reward: 0.006662, Times activated: 183
🎯 Node visual: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
📊 Node random_full: Updated performance - Recent avg reward: 0.006662, Times activated: 183
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.062225 vs baseline: 0.062225)
📊 Episode completed: reward=0.102006, success=True

📈 Updating graph performance: episode_reward=0.102006, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 213: Baseline reward updated 0.062225 → 0.071315
📊 Node goal_basic: Updated performance - Recent avg reward: 0.027063, Times activated: 184
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
📊 Node pose_position: Updated performance - Recent avg reward: 0.027063, Times activated: 184
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
📊 Node pose_full: Updated performance - Recent avg reward: 0.027063, Times activated: 184
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.027063, Times activated: 184
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
📊 Node visual: Updated performance - Recent avg reward: 0.027063, Times activated: 184
🎯 Node visual: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
📊 Node random_full: Updated performance - Recent avg reward: 0.027063, Times activated: 184
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.071315 vs baseline: 0.071315)
📊 Episode completed: reward=0.018248, success=True

📈 Updating graph performance: episode_reward=0.018248, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 214: Baseline reward updated 0.071315 → 0.015356
📊 Node goal_basic: Updated performance - Recent avg reward: 0.030712, Times activated: 185
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
📊 Node pose_position: Updated performance - Recent avg reward: 0.030712, Times activated: 185
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
📊 Node pose_full: Updated performance - Recent avg reward: 0.030712, Times activated: 185
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.030712, Times activated: 185
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
📊 Node visual: Updated performance - Recent avg reward: 0.030712, Times activated: 185
🎯 Node visual: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
📊 Node random_full: Updated performance - Recent avg reward: 0.030712, Times activated: 185
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.015356 vs baseline: 0.015356)
📊 Episode completed: reward=0.175099, success=True

📈 Updating graph performance: episode_reward=0.175099, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 215: Baseline reward updated 0.015356 → 0.032866
📊 Node goal_basic: Updated performance - Recent avg reward: 0.062621, Times activated: 186
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
📊 Node pose_position: Updated performance - Recent avg reward: 0.062621, Times activated: 186
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
📊 Node pose_full: Updated performance - Recent avg reward: 0.062621, Times activated: 186
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.062621, Times activated: 186
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
📊 Node visual: Updated performance - Recent avg reward: 0.062621, Times activated: 186
🎯 Node visual: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
📊 Node random_full: Updated performance - Recent avg reward: 0.062621, Times activated: 186
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.032866 vs baseline: 0.032866)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.117     |
| time/              |           |
|    episodes        | 216       |
|    fps             | 18        |
|    time_elapsed    | 2314      |
|    total_timesteps | 43416     |
| train/             |           |
|    actor_loss      | -4.26e+05 |
|    critic_loss     | 1.06e+10  |
|    ent_coef        | 5.11e+03  |
|    ent_coef_loss   | 1.24      |
|    learning_rate   | 0.00025   |
|    n_updates       | 42415     |
----------------------------------
📊 Episode completed: reward=0.490746, success=True

📈 Updating graph performance: episode_reward=0.490746, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 216: Baseline reward updated 0.032866 → 0.081941
📊 Node goal_basic: Updated performance - Recent avg reward: 0.158203, Times activated: 187
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
📊 Node pose_position: Updated performance - Recent avg reward: 0.158203, Times activated: 187
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
📊 Node pose_full: Updated performance - Recent avg reward: 0.158203, Times activated: 187
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.158203, Times activated: 187
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
📊 Node visual: Updated performance - Recent avg reward: 0.158203, Times activated: 187
🎯 Node visual: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
📊 Node random_full: Updated performance - Recent avg reward: 0.158203, Times activated: 187
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.081941 vs baseline: 0.081941)
📊 Episode completed: reward=0.108767, success=True

📈 Updating graph performance: episode_reward=0.108767, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 217: Baseline reward updated 0.081941 → 0.092817
📊 Node goal_basic: Updated performance - Recent avg reward: 0.178973, Times activated: 188
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
📊 Node pose_position: Updated performance - Recent avg reward: 0.178973, Times activated: 188
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
📊 Node pose_full: Updated performance - Recent avg reward: 0.178973, Times activated: 188
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.178973, Times activated: 188
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
📊 Node visual: Updated performance - Recent avg reward: 0.178973, Times activated: 188
🎯 Node visual: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
📊 Node random_full: Updated performance - Recent avg reward: 0.178973, Times activated: 188
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.092817 vs baseline: 0.092817)
📊 Episode completed: reward=0.067003, success=True

📈 Updating graph performance: episode_reward=0.067003, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 218: Baseline reward updated 0.092817 → 0.099518
📊 Node goal_basic: Updated performance - Recent avg reward: 0.171973, Times activated: 189
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
📊 Node pose_position: Updated performance - Recent avg reward: 0.171973, Times activated: 189
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
📊 Node pose_full: Updated performance - Recent avg reward: 0.171973, Times activated: 189
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.171973, Times activated: 189
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
📊 Node visual: Updated performance - Recent avg reward: 0.171973, Times activated: 189
🎯 Node visual: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
📊 Node random_full: Updated performance - Recent avg reward: 0.171973, Times activated: 189
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.099518 vs baseline: 0.099518)
📊 Episode completed: reward=1.858594, success=True

📈 Updating graph performance: episode_reward=1.858594, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 219: Baseline reward updated 0.099518 → 0.285377
📊 Node goal_basic: Updated performance - Recent avg reward: 0.540042, Times activated: 190
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
📊 Node pose_position: Updated performance - Recent avg reward: 0.540042, Times activated: 190
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
📊 Node pose_full: Updated performance - Recent avg reward: 0.540042, Times activated: 190
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.540042, Times activated: 190
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
📊 Node visual: Updated performance - Recent avg reward: 0.540042, Times activated: 190
🎯 Node visual: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
📊 Node random_full: Updated performance - Recent avg reward: 0.540042, Times activated: 190
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.285377 vs baseline: 0.285377)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.15      |
| time/              |           |
|    episodes        | 220       |
|    fps             | 18        |
|    time_elapsed    | 2362      |
|    total_timesteps | 44220     |
| train/             |           |
|    actor_loss      | -4.72e+05 |
|    critic_loss     | 1.8e+10   |
|    ent_coef        | 5.34e+03  |
|    ent_coef_loss   | 0.652     |
|    learning_rate   | 0.00025   |
|    n_updates       | 43219     |
----------------------------------
📊 Episode completed: reward=1.650443, success=True

📈 Updating graph performance: episode_reward=1.650443, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 220: Baseline reward updated 0.285377 → 0.448866
📊 Node goal_basic: Updated performance - Recent avg reward: 0.835111, Times activated: 191
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
📊 Node pose_position: Updated performance - Recent avg reward: 0.835111, Times activated: 191
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
📊 Node pose_full: Updated performance - Recent avg reward: 0.835111, Times activated: 191
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.835111, Times activated: 191
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
📊 Node visual: Updated performance - Recent avg reward: 0.835111, Times activated: 191
🎯 Node visual: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
📊 Node random_full: Updated performance - Recent avg reward: 0.835111, Times activated: 191
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.448866 vs baseline: 0.448866)
📊 Episode completed: reward=0.978346, success=True

📈 Updating graph performance: episode_reward=0.978346, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 221: Baseline reward updated 0.448866 → 0.545417
📊 Node goal_basic: Updated performance - Recent avg reward: 0.932631, Times activated: 192
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
📊 Node pose_position: Updated performance - Recent avg reward: 0.932631, Times activated: 192
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
📊 Node pose_full: Updated performance - Recent avg reward: 0.932631, Times activated: 192
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.932631, Times activated: 192
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
📊 Node visual: Updated performance - Recent avg reward: 0.932631, Times activated: 192
🎯 Node visual: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
📊 Node random_full: Updated performance - Recent avg reward: 0.932631, Times activated: 192
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.545417 vs baseline: 0.545417)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 222: Baseline reward updated 0.545417 → 0.544925
📊 Node goal_basic: Updated performance - Recent avg reward: 0.910877, Times activated: 193
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
📊 Node pose_position: Updated performance - Recent avg reward: 0.910877, Times activated: 193
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
📊 Node pose_full: Updated performance - Recent avg reward: 0.910877, Times activated: 193
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.910877, Times activated: 193
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
📊 Node visual: Updated performance - Recent avg reward: 0.910877, Times activated: 193
🎯 Node visual: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
📊 Node random_full: Updated performance - Recent avg reward: 0.910877, Times activated: 193
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.544925 vs baseline: 0.544925)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 223: Baseline reward updated 0.544925 → 0.534725
📊 Node goal_basic: Updated performance - Recent avg reward: 0.897477, Times activated: 194
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
📊 Node pose_position: Updated performance - Recent avg reward: 0.897477, Times activated: 194
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
📊 Node pose_full: Updated performance - Recent avg reward: 0.897477, Times activated: 194
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.897477, Times activated: 194
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
📊 Node visual: Updated performance - Recent avg reward: 0.897477, Times activated: 194
🎯 Node visual: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
📊 Node random_full: Updated performance - Recent avg reward: 0.897477, Times activated: 194
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.534725 vs baseline: 0.534725)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.16      |
| time/              |           |
|    episodes        | 224       |
|    fps             | 18        |
|    time_elapsed    | 2409      |
|    total_timesteps | 45024     |
| train/             |           |
|    actor_loss      | -4.52e+05 |
|    critic_loss     | 1.35e+10  |
|    ent_coef        | 5.3e+03   |
|    ent_coef_loss   | -0.0339   |
|    learning_rate   | 0.00025   |
|    n_updates       | 44023     |
----------------------------------
📊 Episode completed: reward=0.084203, success=True

📈 Updating graph performance: episode_reward=0.084203, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 224: Baseline reward updated 0.534725 → 0.541320
📊 Node goal_basic: Updated performance - Recent avg reward: 0.542598, Times activated: 195
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
📊 Node pose_position: Updated performance - Recent avg reward: 0.542598, Times activated: 195
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
📊 Node pose_full: Updated performance - Recent avg reward: 0.542598, Times activated: 195
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.542598, Times activated: 195
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
📊 Node visual: Updated performance - Recent avg reward: 0.542598, Times activated: 195
🎯 Node visual: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
📊 Node random_full: Updated performance - Recent avg reward: 0.542598, Times activated: 195
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.541320 vs baseline: 0.541320)
📊 Episode completed: reward=0.021830, success=True

📈 Updating graph performance: episode_reward=0.021830, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 225: Baseline reward updated 0.541320 → 0.525993
📊 Node goal_basic: Updated performance - Recent avg reward: 0.216876, Times activated: 196
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
📊 Node pose_position: Updated performance - Recent avg reward: 0.216876, Times activated: 196
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
📊 Node pose_full: Updated performance - Recent avg reward: 0.216876, Times activated: 196
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.216876, Times activated: 196
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
📊 Node visual: Updated performance - Recent avg reward: 0.216876, Times activated: 196
🎯 Node visual: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
📊 Node random_full: Updated performance - Recent avg reward: 0.216876, Times activated: 196
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.525993 vs baseline: 0.525993)
📊 Episode completed: reward=0.008150, success=True

📈 Updating graph performance: episode_reward=0.008150, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 226: Baseline reward updated 0.525993 → 0.477734
📊 Node goal_basic: Updated performance - Recent avg reward: 0.022837, Times activated: 197
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
📊 Node pose_position: Updated performance - Recent avg reward: 0.022837, Times activated: 197
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
📊 Node pose_full: Updated performance - Recent avg reward: 0.022837, Times activated: 197
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.022837, Times activated: 197
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
📊 Node visual: Updated performance - Recent avg reward: 0.022837, Times activated: 197
🎯 Node visual: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
📊 Node random_full: Updated performance - Recent avg reward: 0.022837, Times activated: 197
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.477734 vs baseline: 0.477734)
📊 Episode completed: reward=0.007036, success=True

📈 Updating graph performance: episode_reward=0.007036, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 227: Baseline reward updated 0.477734 → 0.467560
📊 Node goal_basic: Updated performance - Recent avg reward: 0.024244, Times activated: 198
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
📊 Node pose_position: Updated performance - Recent avg reward: 0.024244, Times activated: 198
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
📊 Node pose_full: Updated performance - Recent avg reward: 0.024244, Times activated: 198
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.024244, Times activated: 198
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
📊 Node visual: Updated performance - Recent avg reward: 0.024244, Times activated: 198
🎯 Node visual: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
📊 Node random_full: Updated performance - Recent avg reward: 0.024244, Times activated: 198
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.467560 vs baseline: 0.467560)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.161     |
| time/              |           |
|    episodes        | 228       |
|    fps             | 18        |
|    time_elapsed    | 2459      |
|    total_timesteps | 45828     |
| train/             |           |
|    actor_loss      | -5.08e+05 |
|    critic_loss     | 1.26e+10  |
|    ent_coef        | 5.28e+03  |
|    ent_coef_loss   | -1.79     |
|    learning_rate   | 0.00025   |
|    n_updates       | 44827     |
----------------------------------
📊 Episode completed: reward=0.194129, success=True

📈 Updating graph performance: episode_reward=0.194129, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 228: Baseline reward updated 0.467560 → 0.480273
📊 Node goal_basic: Updated performance - Recent avg reward: 0.063070, Times activated: 199
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
📊 Node pose_position: Updated performance - Recent avg reward: 0.063070, Times activated: 199
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
📊 Node pose_full: Updated performance - Recent avg reward: 0.063070, Times activated: 199
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.063070, Times activated: 199
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
📊 Node visual: Updated performance - Recent avg reward: 0.063070, Times activated: 199
🎯 Node visual: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
📊 Node random_full: Updated performance - Recent avg reward: 0.063070, Times activated: 199
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.480273 vs baseline: 0.480273)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 229: Baseline reward updated 0.480273 → 0.294414
📊 Node goal_basic: Updated performance - Recent avg reward: 0.046229, Times activated: 200
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
📊 Node pose_position: Updated performance - Recent avg reward: 0.046229, Times activated: 200
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
📊 Node pose_full: Updated performance - Recent avg reward: 0.046229, Times activated: 200
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.046229, Times activated: 200
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
📊 Node visual: Updated performance - Recent avg reward: 0.046229, Times activated: 200
🎯 Node visual: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
📊 Node random_full: Updated performance - Recent avg reward: 0.046229, Times activated: 200
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.294414 vs baseline: 0.294414)
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 230: Baseline reward updated 0.294414 → 0.129369
📊 Node goal_basic: Updated performance - Recent avg reward: 0.041863, Times activated: 201
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
📊 Node pose_position: Updated performance - Recent avg reward: 0.041863, Times activated: 201
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
📊 Node pose_full: Updated performance - Recent avg reward: 0.041863, Times activated: 201
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.041863, Times activated: 201
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
📊 Node visual: Updated performance - Recent avg reward: 0.041863, Times activated: 201
🎯 Node visual: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
📊 Node random_full: Updated performance - Recent avg reward: 0.041863, Times activated: 201
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.129369 vs baseline: 0.129369)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 231: Baseline reward updated 0.129369 → 0.031535
📊 Node goal_basic: Updated performance - Recent avg reward: 0.040233, Times activated: 202
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
📊 Node pose_position: Updated performance - Recent avg reward: 0.040233, Times activated: 202
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
📊 Node pose_full: Updated performance - Recent avg reward: 0.040233, Times activated: 202
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.040233, Times activated: 202
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
📊 Node visual: Updated performance - Recent avg reward: 0.040233, Times activated: 202
🎯 Node visual: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
📊 Node random_full: Updated performance - Recent avg reward: 0.040233, Times activated: 202
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.031535 vs baseline: 0.031535)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.16      |
| time/              |           |
|    episodes        | 232       |
|    fps             | 18        |
|    time_elapsed    | 2500      |
|    total_timesteps | 46632     |
| train/             |           |
|    actor_loss      | -5.57e+05 |
|    critic_loss     | 1.14e+10  |
|    ent_coef        | 5.3e+03   |
|    ent_coef_loss   | -2.89     |
|    learning_rate   | 0.00025   |
|    n_updates       | 45631     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.021839, success=True

📈 Updating graph performance: episode_reward=0.021839, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 232: Baseline reward updated 0.031535 → 0.033719
📊 Node goal_basic: Updated performance - Recent avg reward: 0.043194, Times activated: 203
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
📊 Node pose_position: Updated performance - Recent avg reward: 0.043194, Times activated: 203
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
📊 Node pose_full: Updated performance - Recent avg reward: 0.043194, Times activated: 203
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.043194, Times activated: 203
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
📊 Node visual: Updated performance - Recent avg reward: 0.043194, Times activated: 203
🎯 Node visual: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
📊 Node random_full: Updated performance - Recent avg reward: 0.043194, Times activated: 203
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.033719 vs baseline: 0.033719)
📊 Episode completed: reward=0.097112, success=True

📈 Updating graph performance: episode_reward=0.097112, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 233: Baseline reward updated 0.033719 → 0.043430
📊 Node goal_basic: Updated performance - Recent avg reward: 0.023790, Times activated: 204
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
📊 Node pose_position: Updated performance - Recent avg reward: 0.023790, Times activated: 204
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
📊 Node pose_full: Updated performance - Recent avg reward: 0.023790, Times activated: 204
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.023790, Times activated: 204
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
📊 Node visual: Updated performance - Recent avg reward: 0.023790, Times activated: 204
🎯 Node visual: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
📊 Node random_full: Updated performance - Recent avg reward: 0.023790, Times activated: 204
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.043430 vs baseline: 0.043430)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 234: Baseline reward updated 0.043430 → 0.035010
📊 Node goal_basic: Updated performance - Recent avg reward: 0.023790, Times activated: 205
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
📊 Node pose_position: Updated performance - Recent avg reward: 0.023790, Times activated: 205
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
📊 Node pose_full: Updated performance - Recent avg reward: 0.023790, Times activated: 205
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.023790, Times activated: 205
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
📊 Node visual: Updated performance - Recent avg reward: 0.023790, Times activated: 205
🎯 Node visual: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
📊 Node random_full: Updated performance - Recent avg reward: 0.023790, Times activated: 205
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.035010 vs baseline: 0.035010)
📊 Episode completed: reward=0.271736, success=True

📈 Updating graph performance: episode_reward=0.271736, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 235: Baseline reward updated 0.035010 → 0.060000
📊 Node goal_basic: Updated performance - Recent avg reward: 0.078137, Times activated: 206
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
📊 Node pose_position: Updated performance - Recent avg reward: 0.078137, Times activated: 206
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
📊 Node pose_full: Updated performance - Recent avg reward: 0.078137, Times activated: 206
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.078137, Times activated: 206
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
📊 Node visual: Updated performance - Recent avg reward: 0.078137, Times activated: 206
🎯 Node visual: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
📊 Node random_full: Updated performance - Recent avg reward: 0.078137, Times activated: 206
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.060000 vs baseline: 0.060000)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.142     |
| time/              |           |
|    episodes        | 236       |
|    fps             | 18        |
|    time_elapsed    | 2538      |
|    total_timesteps | 47436     |
| train/             |           |
|    actor_loss      | -4.48e+05 |
|    critic_loss     | 1.73e+10  |
|    ent_coef        | 5.3e+03   |
|    ent_coef_loss   | -0.173    |
|    learning_rate   | 0.00025   |
|    n_updates       | 46435     |
----------------------------------
📊 Episode completed: reward=0.080955, success=True

📈 Updating graph performance: episode_reward=0.080955, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 236: Baseline reward updated 0.060000 → 0.067281
📊 Node goal_basic: Updated performance - Recent avg reward: 0.094328, Times activated: 207
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
📊 Node pose_position: Updated performance - Recent avg reward: 0.094328, Times activated: 207
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
📊 Node pose_full: Updated performance - Recent avg reward: 0.094328, Times activated: 207
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.094328, Times activated: 207
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
📊 Node visual: Updated performance - Recent avg reward: 0.094328, Times activated: 207
🎯 Node visual: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
📊 Node random_full: Updated performance - Recent avg reward: 0.094328, Times activated: 207
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.067281 vs baseline: 0.067281)
📊 Episode completed: reward=0.077665, success=True

📈 Updating graph performance: episode_reward=0.077665, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 237: Baseline reward updated 0.067281 → 0.074344
📊 Node goal_basic: Updated performance - Recent avg reward: 0.105494, Times activated: 208
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
📊 Node pose_position: Updated performance - Recent avg reward: 0.105494, Times activated: 208
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
📊 Node pose_full: Updated performance - Recent avg reward: 0.105494, Times activated: 208
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.105494, Times activated: 208
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
📊 Node visual: Updated performance - Recent avg reward: 0.105494, Times activated: 208
🎯 Node visual: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
📊 Node random_full: Updated performance - Recent avg reward: 0.105494, Times activated: 208
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.074344 vs baseline: 0.074344)
📊 Episode completed: reward=0.066917, success=True

📈 Updating graph performance: episode_reward=0.066917, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 238: Baseline reward updated 0.074344 → 0.061622
📊 Node goal_basic: Updated performance - Recent avg reward: 0.099455, Times activated: 209
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
📊 Node pose_position: Updated performance - Recent avg reward: 0.099455, Times activated: 209
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
📊 Node pose_full: Updated performance - Recent avg reward: 0.099455, Times activated: 209
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.099455, Times activated: 209
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
📊 Node visual: Updated performance - Recent avg reward: 0.099455, Times activated: 209
🎯 Node visual: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
📊 Node random_full: Updated performance - Recent avg reward: 0.099455, Times activated: 209
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.061622 vs baseline: 0.061622)
📊 Episode completed: reward=0.061312, success=True

📈 Updating graph performance: episode_reward=0.061312, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 239: Baseline reward updated 0.061622 → 0.067754
📊 Node goal_basic: Updated performance - Recent avg reward: 0.111717, Times activated: 210
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)
📊 Node pose_position: Updated performance - Recent avg reward: 0.111717, Times activated: 210
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)
📊 Node pose_full: Updated performance - Recent avg reward: 0.111717, Times activated: 210
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.111717, Times activated: 210
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)
📊 Node visual: Updated performance - Recent avg reward: 0.111717, Times activated: 210
🎯 Node visual: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)
📊 Node random_full: Updated performance - Recent avg reward: 0.111717, Times activated: 210
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.067754 vs baseline: 0.067754)

🔄 CURRICULUM ADAPTATION TRIGGERED (after 30 episodes)
🔄 Adapting curriculum...

🎓 Generating curriculum configuration...

🎲 Selecting active interventions...

🔍 Checking intervention eligibility...
   Node goal_basic: prerequisites_met=True
   ✅ goal_basic is ELIGIBLE
   Node pose_position: prerequisites_met=True
      Prerequisites: goal_basic(satisfied=True, history_len=50, success_rate=0.111717)
   ✅ pose_position is ELIGIBLE
   Node pose_full: prerequisites_met=True
   ✅ pose_full is ELIGIBLE
   Node physics_friction: prerequisites_met=True
   ✅ physics_friction is ELIGIBLE
   Node physics_mass: prerequisites_met=True
   ✅ physics_mass is ELIGIBLE
   Node visual: prerequisites_met=True
   ✅ visual is ELIGIBLE
   Node random_full: prerequisites_met=True
   ✅ random_full is ELIGIBLE
🎯 Final eligible interventions: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'physics_mass', 'visual', 'random_full']
📋 Processing 7 eligible interventions...
   goal_basic: avg_reward=0.111717, confidence=0.468037, score=1.515828
   goal_basic: BOOSTING strength to 1.000
   goal_basic: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
🎭 Creating actor instance for: goal_basic
   goal_basic: ✅ ACTIVATED with strength 1.000
   pose_position: avg_reward=0.111717, confidence=0.468037, score=1.515828
   pose_position: BOOSTING strength to 1.000
   pose_position: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_position
   pose_position: ✅ ACTIVATED with strength 1.000
   pose_full: avg_reward=0.111717, confidence=0.468037, score=1.515828
   pose_full: BOOSTING strength to 1.000
   pose_full: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
🎭 Creating actor instance for: pose_full
   pose_full: ✅ ACTIVATED with strength 1.000
   physics_friction: avg_reward=0.111717, confidence=0.468037, score=1.515828
   physics_friction: BOOSTING strength to 1.000
   physics_friction: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
🎭 Creating actor instance for: physics_friction
   physics_friction: ✅ ACTIVATED with strength 1.000
   physics_mass: NEW intervention (score=∞)
   physics_mass: BOOSTING strength to 1.000
   physics_mass: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
   physics_mass: ⚔️  CONFLICT with ['physics_friction'] - skipping
   visual: avg_reward=0.111717, confidence=0.468037, score=1.515828
   visual: BOOSTING strength to 1.000
   visual: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
🎭 Creating actor instance for: visual
   visual: ✅ ACTIVATED with strength 1.000
   random_full: avg_reward=0.111717, confidence=0.468037, score=1.515828
   random_full: BOOSTING strength to 1.000
   random_full: should_activate=True (score>0.057754 or random<0.9275630675375247 or history<5 or attempts<3)
🎭 Creating actor instance for: random_full
   random_full: ✅ ACTIVATED with strength 1.000

🎉 FINAL SELECTION: 6 interventions activated
   🚀 goal_basic (strength: 1.000)
   🚀 pose_position (strength: 1.000)
   🚀 pose_full (strength: 1.000)
   🚀 physics_friction (strength: 1.000)
   🚀 visual (strength: 1.000)
   🚀 random_full (strength: 1.000)
🔧 Building curriculum configuration:
   goal_basic: frequency=1 (strength=1.000)
   pose_position: frequency=1 (strength=1.000)
   pose_full: frequency=1 (strength=1.000)
   physics_friction: frequency=1 (strength=1.000)
   visual: frequency=1 (strength=1.000)
   random_full: frequency=1 (strength=1.000)
✅ Curriculum config ready: 6 actors, 6 active nodes
🔧 Updating curriculum wrapper...
🔧 Updating internal curriculum object...
🔧 Reinitializing curriculum actors...
✅ Curriculum updated successfully!
   📊 Active interventions: 6
   🎯 Active nodes: ['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   🎲 Exploration rate: 0.9276
   📈 Baseline reward: 0.067754
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.143     |
| time/              |           |
|    episodes        | 240       |
|    fps             | 18        |
|    time_elapsed    | 2581      |
|    total_timesteps | 48240     |
| train/             |           |
|    actor_loss      | -5.82e+05 |
|    critic_loss     | 1.58e+10  |
|    ent_coef        | 5.29e+03  |
|    ent_coef_loss   | 2.04      |
|    learning_rate   | 0.00025   |
|    n_updates       | 47239     |
----------------------------------
📊 Episode completed: reward=0.081696, success=True

📈 Updating graph performance: episode_reward=0.081696, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 240: Baseline reward updated 0.067754 → 0.075923
📊 Node goal_basic: Updated performance - Recent avg reward: 0.073709, Times activated: 211
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
📊 Node pose_position: Updated performance - Recent avg reward: 0.073709, Times activated: 211
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
📊 Node pose_full: Updated performance - Recent avg reward: 0.073709, Times activated: 211
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.073709, Times activated: 211
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
📊 Node visual: Updated performance - Recent avg reward: 0.073709, Times activated: 211
🎯 Node visual: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
📊 Node random_full: Updated performance - Recent avg reward: 0.073709, Times activated: 211
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.075923 vs baseline: 0.075923)
📊 Episode completed: reward=0.201440, success=True

📈 Updating graph performance: episode_reward=0.201440, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 241: Baseline reward updated 0.075923 → 0.096067
📊 Node goal_basic: Updated performance - Recent avg reward: 0.097806, Times activated: 212
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
📊 Node pose_position: Updated performance - Recent avg reward: 0.097806, Times activated: 212
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
📊 Node pose_full: Updated performance - Recent avg reward: 0.097806, Times activated: 212
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.097806, Times activated: 212
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
📊 Node visual: Updated performance - Recent avg reward: 0.097806, Times activated: 212
🎯 Node visual: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
📊 Node random_full: Updated performance - Recent avg reward: 0.097806, Times activated: 212
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.096067 vs baseline: 0.096067)
📊 Episode completed: reward=0.024661, success=True

📈 Updating graph performance: episode_reward=0.024661, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 242: Baseline reward updated 0.096067 → 0.096349
📊 Node goal_basic: Updated performance - Recent avg reward: 0.087205, Times activated: 213
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
📊 Node pose_position: Updated performance - Recent avg reward: 0.087205, Times activated: 213
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
📊 Node pose_full: Updated performance - Recent avg reward: 0.087205, Times activated: 213
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.087205, Times activated: 213
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
📊 Node visual: Updated performance - Recent avg reward: 0.087205, Times activated: 213
🎯 Node visual: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
📊 Node random_full: Updated performance - Recent avg reward: 0.087205, Times activated: 213
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.096349 vs baseline: 0.096349)
📊 Episode completed: reward=0.004470, success=True

📈 Updating graph performance: episode_reward=0.004470, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 243: Baseline reward updated 0.096349 → 0.087085
📊 Node goal_basic: Updated performance - Recent avg reward: 0.074716, Times activated: 214
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
📊 Node pose_position: Updated performance - Recent avg reward: 0.074716, Times activated: 214
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
📊 Node pose_full: Updated performance - Recent avg reward: 0.074716, Times activated: 214
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.074716, Times activated: 214
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
📊 Node visual: Updated performance - Recent avg reward: 0.074716, Times activated: 214
🎯 Node visual: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
📊 Node random_full: Updated performance - Recent avg reward: 0.074716, Times activated: 214
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.087085 vs baseline: 0.087085)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.147     |
| time/              |           |
|    episodes        | 244       |
|    fps             | 18        |
|    time_elapsed    | 2632      |
|    total_timesteps | 49044     |
| train/             |           |
|    actor_loss      | -4.06e+05 |
|    critic_loss     | 8.73e+09  |
|    ent_coef        | 5.28e+03  |
|    ent_coef_loss   | -3.29     |
|    learning_rate   | 0.00025   |
|    n_updates       | 48043     |
----------------------------------
WARNING:root:Applying intervention lead to infeasibility of the stage
WARNING:root:Applying intervention lead to infeasibility of the robot
WARNING:root:Invalid Intervention was just executed!
📊 Episode completed: reward=0.176748, success=True

📈 Updating graph performance: episode_reward=0.176748, episode_success=True, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 244: Baseline reward updated 0.087085 → 0.104760
📊 Node goal_basic: Updated performance - Recent avg reward: 0.097803, Times activated: 215
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
📊 Node pose_position: Updated performance - Recent avg reward: 0.097803, Times activated: 215
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
📊 Node pose_full: Updated performance - Recent avg reward: 0.097803, Times activated: 215
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.097803, Times activated: 215
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
📊 Node visual: Updated performance - Recent avg reward: 0.097803, Times activated: 215
🎯 Node visual: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
📊 Node random_full: Updated performance - Recent avg reward: 0.097803, Times activated: 215
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.104760 vs baseline: 0.104760)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 245: Baseline reward updated 0.104760 → 0.077586
📊 Node goal_basic: Updated performance - Recent avg reward: 0.081464, Times activated: 216
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
📊 Node pose_position: Updated performance - Recent avg reward: 0.081464, Times activated: 216
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
📊 Node pose_full: Updated performance - Recent avg reward: 0.081464, Times activated: 216
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.081464, Times activated: 216
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
📊 Node visual: Updated performance - Recent avg reward: 0.081464, Times activated: 216
🎯 Node visual: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
📊 Node random_full: Updated performance - Recent avg reward: 0.081464, Times activated: 216
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.077586 vs baseline: 0.077586)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 246: Baseline reward updated 0.077586 → 0.069491
📊 Node goal_basic: Updated performance - Recent avg reward: 0.041176, Times activated: 217
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
📊 Node pose_position: Updated performance - Recent avg reward: 0.041176, Times activated: 217
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
📊 Node pose_full: Updated performance - Recent avg reward: 0.041176, Times activated: 217
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.041176, Times activated: 217
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
📊 Node visual: Updated performance - Recent avg reward: 0.041176, Times activated: 217
🎯 Node visual: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
📊 Node random_full: Updated performance - Recent avg reward: 0.041176, Times activated: 217
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.069491 vs baseline: 0.069491)
📊 Episode completed: reward=0.000000, success=False

📈 Updating graph performance: episode_reward=0.000000, episode_success=False, active_nodes=['goal_basic', 'pose_position', 'pose_full', 'physics_friction', 'visual', 'random_full']
   Episode 247: Baseline reward updated 0.069491 → 0.061724
📊 Node goal_basic: Updated performance - Recent avg reward: 0.036244, Times activated: 218
🎯 Node goal_basic: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
📊 Node pose_position: Updated performance - Recent avg reward: 0.036244, Times activated: 218
🎯 Node pose_position: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
📊 Node pose_full: Updated performance - Recent avg reward: 0.036244, Times activated: 218
🎯 Node pose_full: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
📊 Node physics_friction: Updated performance - Recent avg reward: 0.036244, Times activated: 218
🎯 Node physics_friction: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
📊 Node visual: Updated performance - Recent avg reward: 0.036244, Times activated: 218
🎯 Node visual: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
📊 Node random_full: Updated performance - Recent avg reward: 0.036244, Times activated: 218
🎯 Node random_full: Causal impact = 0.000000 (avg: 0.061724 vs baseline: 0.061724)
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 201       |
|    ep_rew_mean     | 0.147     |
| time/              |           |
|    episodes        | 248       |
|    fps             | 18        |
|    time_elapsed    | 2669      |
|    total_timesteps | 49848     |
| train/             |           |
|    actor_loss      | -5.88e+05 |
|    critic_loss     | 1.51e+10  |
|    ent_coef        | 5.25e+03  |
|    ent_coef_loss   | 1.88      |
|    learning_rate   | 0.00025   |
|    n_updates       | 48847     |
----------------------------------
Traceback (most recent call last):
  File "her_sac.py", line 175, in <module>
    wandb_config=wandb_config
  File "her_sac.py", line 128, in train_policy
    callback=callbacks)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\sac\sac.py", line 301, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\off_policy_algorithm.py", line 375, in learn
    callback.on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\callbacks.py", line 91, in on_training_end
    self._on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\callbacks.py", line 201, in _on_training_end
    callback.on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\stable_baselines3\common\callbacks.py", line 91, in on_training_end
    self._on_training_end()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\integration\sb3\sb3.py", line 147, in _on_training_end
    self.save_model()
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\integration\sb3\sb3.py", line 151, in save_model
    wandb.save(self.path, base_path=self.model_save_path)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 403, in wrapper_fn
    return func(self, *args, **kwargs)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 393, in wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 2027, in save
    policy,
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\site-packages\wandb\sdk\wandb_run.py", line 2088, in _save
    target_path.symlink_to(source_path)
  File "C:\Users\Admin\anaconda3\envs\causal_world\lib\pathlib.py", line 1337, in symlink_to
    self._accessor.symlink(target, self, target_is_directory)
OSError: symbolic link privilege not held
