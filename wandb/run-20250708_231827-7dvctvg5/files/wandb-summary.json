{"_step":617,"cm_eval/goal_cm_details":{"state":1.055718183517456,"action":0.5784872770309448,"transition":0.40987128019332886,"reward":0.0672290101647377},"time/fps":182,"train/entropy_loss":-24.858284,"cm_eval/friction_cm_details":{"action":0.587361752986908,"transition":0.43039393424987793,"reward":0.3331121802330017,"state":1.0182234048843384},"train/ep_reward_mean":-0.00994943268597126,"cm_eval/mass_cm_score":2.231359638273716,"cm_eval/pose_cm_details":{"state":1.094647765159607,"action":0.5572925806045532,"transition":0.37987005710601807,"reward":0.3769860565662384},"cm_eval/visual_reward":1.0195326140696281,"cm_eval/visual_cm_score":2.2085533514618874,"cm_eval/random_cm_score":2.1341607198119164,"cm_eval/pose_cm_score":2.4087964594364166,"train/episode_reward":-0.006966129876673222,"cm_eval/joints_cm_details":{"state":1.05158269405365,"action":0.5563095211982727,"transition":0.4100658595561981,"reward":0.11556344479322433},"_wandb":{"runtime":400},"train/learning_rate":0.00025,"train/approx_kl":0.052215613,"cm_eval/random_reward":1.0195326140696281,"cm_eval/friction_cm_score":2.369091272354126,"cm_eval/visual_cm_details":{"reward":0.11863140016794205,"state":1.1212166547775269,"action":0.5706138610839844,"transition":0.3980914354324341},"cm_eval/intervention_ranking":["pose","friction","mass","visual","random","joints","goal"],"global_step":63488,"train/loss":-0.5904061,"train/intervention_idx":1,"cm_eval/friction_reward":1.0195326140696281,"_runtime":400.022579273,"cm_eval/goal_cm_score":2.1113057509064674,"cm_eval/joints_cm_score":2.133521519601345,"cm_eval/mass_reward":1.0195326140696281,"train/std":3.861,"train/explained_variance":0.406183,"curriculum/current_intervention":"pose","cm_eval/joints_reward":1.0195326140696281,"train/policy_gradient_loss":-0.09228876,"_timestamp":1.752031505318042e+09,"cm_eval/random_cm_details":{"state":1.0645427703857422,"action":0.5852739214897156,"transition":0.40871044993400574,"reward":0.07563357800245285},"cm_eval/mass_cm_details":{"transition":0.44587576389312744,"reward":0.12048891931772232,"state":1.0983772277832031,"action":0.5666177272796631},"cm_eval/goal_reward":1.0195326140696281,"train/clip_fraction":0.5052083,"train/clip_range":0.2,"train/current_intervention":"pose","cm_eval/pose_reward":1.0195326140696281,"train/value_loss":0.041532483,"train/episode":252,"curriculum/intervention_rank":1}