2025-07-08 15:06:21,998 1941474 INFO [WANDB] Initialized with project: adaptive-curriculum-ppo-pushing and run name: adaptive_curriculum_ppo_pushing_seed0
2025-07-08 15:06:21,999 1941474 INFO [LOGDIR] Log directory: adaptive_curriculum_on_ppo
2025-07-08 15:06:21,999 1941474 INFO [CURRICULUM] Interventions: ['GoalInterventionActorPolicy', 'PhysicalPropertiesInterventionActorPolicy', 'VisualInterventionActorPolicy', 'JointsInterventionActorPolicy', 'RigidPoseInterventionActorPolicy', 'RandomInterventionActorPolicy']
[ADAPTIVE] Initialized with 6 interventions.
2025-07-08 15:06:22,000 1941474 INFO [ENV] Creating 16 parallel training environments for task: pushing
2025-07-08 15:06:26,722 1941474 INFO [ENV] Creating evaluation environment for task: pushing
2025-07-08 15:06:26,831 1941474 INFO [MODEL] PPO model loaded from: ppo_pushing_sb3/final_model.zip
2025-07-08 15:06:28,055 1941474 INFO [CALLBACKS] Callbacks set up: ['CheckpointCallback', 'EvalCallback', 'AdaptiveCurriculumCallback', 'WandbCallback']
2025-07-08 15:06:28,056 1941474 INFO [TRAIN] Starting training for 3000000 timesteps...
Logging to adaptive_curriculum_on_ppo/adaptive_curriculum_on_ppo_1
/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/stable_baselines3/common/callbacks.py:337: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_monitor.VecMonitor object at 0x7f1569a6fb10> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f1569997550>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
[ADAPTIVE] Episode 1 reward: 0.044508
[34m[1mwandb[0m: [33mWARNING[0m Step cannot be set when using tensorboard syncing. Please use `run.define_metric(...)` to define a custom metric to log your step values.
-----------------------------------
| rollout/           |            |
|    ep_len_mean     | 251        |
|    ep_rew_mean     | 0.44771796 |
| time/              |            |
|    fps             | 1525       |
|    iterations      | 1          |
|    time_elapsed    | 2          |
|    total_timesteps | 4096       |
-----------------------------------
[ADAPTIVE] Episode 2 reward: -0.019474
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.54302555  |
| time/                   |             |
|    fps                  | 1389        |
|    iterations           | 2           |
|    time_elapsed         | 5           |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.020774283 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.6       |
|    explained_variance   | 0.319       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.444      |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 2.67        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 3 reward: 0.058256
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.50937486  |
| time/                   |             |
|    fps                  | 1373        |
|    iterations           | 3           |
|    time_elapsed         | 8           |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.015857464 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.6       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.452      |
|    n_updates            | 1185        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 2.69        |
|    value_loss           | 0.0826      |
-----------------------------------------
[ADAPTIVE] Episode 4 reward: 0.022794
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.71154886  |
| time/                   |             |
|    fps                  | 1337        |
|    iterations           | 4           |
|    time_elapsed         | 12          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.012181164 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.7       |
|    explained_variance   | 0.65        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.416      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 2.7         |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 5 reward: 0.065724
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.7426218   |
| time/                   |             |
|    fps                  | 1327        |
|    iterations           | 5           |
|    time_elapsed         | 15          |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.013972141 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.7       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.458      |
|    n_updates            | 1215        |
|    policy_gradient_loss | -0.0345     |
|    std                  | 2.71        |
|    value_loss           | 0.0794      |
-----------------------------------------
[ADAPTIVE] Episode 6 reward: 0.046310
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8336002   |
| time/                   |             |
|    fps                  | 1299        |
|    iterations           | 6           |
|    time_elapsed         | 18          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.020464005 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.8       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.453      |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0381     |
|    std                  | 2.73        |
|    value_loss           | 0.0914      |
-----------------------------------------
[ADAPTIVE] Episode 7 reward: 0.086479
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96656466  |
| time/                   |             |
|    fps                  | 1303        |
|    iterations           | 7           |
|    time_elapsed         | 21          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.015610911 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.8       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.474      |
|    n_updates            | 1245        |
|    policy_gradient_loss | -0.0396     |
|    std                  | 2.75        |
|    value_loss           | 0.0793      |
-----------------------------------------
[ADAPTIVE] Episode 8 reward: 0.000106
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98293823  |
| time/                   |             |
|    fps                  | 1297        |
|    iterations           | 8           |
|    time_elapsed         | 25          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.015538834 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.9       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.464      |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.0328     |
|    std                  | 2.76        |
|    value_loss           | 0.069       |
-----------------------------------------
[ADAPTIVE] Episode 9 reward: 0.069685
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1524526   |
| time/                   |             |
|    fps                  | 1294        |
|    iterations           | 9           |
|    time_elapsed         | 28          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.015828885 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.9       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.463      |
|    n_updates            | 1275        |
|    policy_gradient_loss | -0.0393     |
|    std                  | 2.77        |
|    value_loss           | 0.078       |
-----------------------------------------
[ADAPTIVE] Episode 10 reward: 0.007708
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0824707   |
| time/                   |             |
|    fps                  | 1285        |
|    iterations           | 10          |
|    time_elapsed         | 31          |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 0.017265957 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22         |
|    explained_variance   | 0.628       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.452      |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 2.79        |
|    value_loss           | 0.0836      |
-----------------------------------------
[ADAPTIVE] Episode 11 reward: -0.014539
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1893039   |
| time/                   |             |
|    fps                  | 1280        |
|    iterations           | 11          |
|    time_elapsed         | 35          |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.021542298 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22         |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.443      |
|    n_updates            | 1305        |
|    policy_gradient_loss | -0.033      |
|    std                  | 2.81        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 12 reward: -0.070326
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1348537   |
| time/                   |             |
|    fps                  | 1275        |
|    iterations           | 12          |
|    time_elapsed         | 38          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.012048994 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.1       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.464      |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.03       |
|    std                  | 2.82        |
|    value_loss           | 0.0722      |
-----------------------------------------
[ADAPTIVE] Episode 13 reward: -0.039777
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0850974  |
| time/                   |            |
|    fps                  | 1275       |
|    iterations           | 13         |
|    time_elapsed         | 41         |
|    total_timesteps      | 53248      |
| train/                  |            |
|    approx_kl            | 0.01477824 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.1      |
|    explained_variance   | 0.575      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.442     |
|    n_updates            | 1335       |
|    policy_gradient_loss | -0.038     |
|    std                  | 2.83       |
|    value_loss           | 0.12       |
----------------------------------------
[ADAPTIVE] Episode 14 reward: -0.021250
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0364498   |
| time/                   |             |
|    fps                  | 1271        |
|    iterations           | 14          |
|    time_elapsed         | 45          |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.013529695 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.1       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.453      |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.0357     |
|    std                  | 2.84        |
|    value_loss           | 0.0744      |
-----------------------------------------
[ADAPTIVE] Episode 15 reward: 0.016976
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1043496   |
| time/                   |             |
|    fps                  | 1262        |
|    iterations           | 15          |
|    time_elapsed         | 48          |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.019558478 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.2       |
|    explained_variance   | 0.673       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.462      |
|    n_updates            | 1365        |
|    policy_gradient_loss | -0.0387     |
|    std                  | 2.85        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 16 reward: -0.020608
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1040657   |
| time/                   |             |
|    fps                  | 1267        |
|    iterations           | 16          |
|    time_elapsed         | 51          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.016971081 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.2       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.471      |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0356     |
|    std                  | 2.88        |
|    value_loss           | 0.0724      |
-----------------------------------------
[ADAPTIVE] Episode 17 reward: 0.052910
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0130414   |
| time/                   |             |
|    fps                  | 1259        |
|    iterations           | 17          |
|    time_elapsed         | 55          |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.017253805 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.3       |
|    explained_variance   | 0.618       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.467      |
|    n_updates            | 1395        |
|    policy_gradient_loss | -0.039      |
|    std                  | 2.88        |
|    value_loss           | 0.0941      |
-----------------------------------------
[ADAPTIVE] Episode 18 reward: 0.012119
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1000907  |
| time/                   |            |
|    fps                  | 1263       |
|    iterations           | 18         |
|    time_elapsed         | 58         |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.01577152 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.3      |
|    explained_variance   | 0.65       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.45      |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0382    |
|    std                  | 2.91       |
|    value_loss           | 0.118      |
----------------------------------------
[ADAPTIVE] Episode 19 reward: -0.018569
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.141419    |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 19          |
|    time_elapsed         | 61          |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.022263343 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.4       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.469      |
|    n_updates            | 1425        |
|    policy_gradient_loss | -0.0403     |
|    std                  | 2.92        |
|    value_loss           | 0.0836      |
-----------------------------------------
[ADAPTIVE] Episode 20 reward: 0.062665
[ADAPTIVE] Mean reward over last 20 episodes: 0.017085
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2471058  |
| time/                   |            |
|    fps                  | 1261       |
|    iterations           | 20         |
|    time_elapsed         | 64         |
|    total_timesteps      | 81920      |
| train/                  |            |
|    approx_kl            | 0.02762944 |
|    clip_fraction        | 0.185      |
|    clip_range           | 0.2        |
|    entropy_loss         | -22.5      |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.44      |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.0364    |
|    std                  | 2.95       |
|    value_loss           | 0.121      |
----------------------------------------
[ADAPTIVE] Episode 21 reward: 0.063045
[ADAPTIVE] Mean reward over last 20 episodes: 0.018012
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0500066   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 21          |
|    time_elapsed         | 68          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.020719958 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.5       |
|    explained_variance   | 0.597       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.46       |
|    n_updates            | 1455        |
|    policy_gradient_loss | -0.0328     |
|    std                  | 2.96        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 22 reward: -0.026625
[ADAPTIVE] Mean reward over last 20 episodes: 0.017654
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0539143   |
| time/                   |             |
|    fps                  | 1258        |
|    iterations           | 22          |
|    time_elapsed         | 71          |
|    total_timesteps      | 90112       |
| train/                  |             |
|    approx_kl            | 0.022521704 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.662       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.477      |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0399     |
|    std                  | 2.97        |
|    value_loss           | 0.0841      |
-----------------------------------------
[ADAPTIVE] Episode 23 reward: -0.078636
[ADAPTIVE] Mean reward over last 20 episodes: 0.010810
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9087077   |
| time/                   |             |
|    fps                  | 1252        |
|    iterations           | 23          |
|    time_elapsed         | 75          |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.015333629 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.504       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.409      |
|    n_updates            | 1485        |
|    policy_gradient_loss | -0.028      |
|    std                  | 2.98        |
|    value_loss           | 0.19        |
-----------------------------------------
[ADAPTIVE] Episode 24 reward: -0.030189
[ADAPTIVE] Mean reward over last 20 episodes: 0.008160
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.86970985  |
| time/                   |             |
|    fps                  | 1249        |
|    iterations           | 24          |
|    time_elapsed         | 78          |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.022468707 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.6       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.48       |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0388     |
|    std                  | 3           |
|    value_loss           | 0.0911      |
-----------------------------------------
[ADAPTIVE] Episode 25 reward: -0.021722
[ADAPTIVE] Mean reward over last 20 episodes: 0.003788
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96936834  |
| time/                   |             |
|    fps                  | 1241        |
|    iterations           | 25          |
|    time_elapsed         | 82          |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.018136121 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.7       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.458      |
|    n_updates            | 1515        |
|    policy_gradient_loss | -0.0373     |
|    std                  | 3.02        |
|    value_loss           | 0.0974      |
-----------------------------------------
[ADAPTIVE] Episode 26 reward: -0.025693
[ADAPTIVE] Mean reward over last 20 episodes: 0.000188
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9557821   |
| time/                   |             |
|    fps                  | 1238        |
|    iterations           | 26          |
|    time_elapsed         | 85          |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.020904409 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.7       |
|    explained_variance   | 0.676       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.481      |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.0395     |
|    std                  | 3.04        |
|    value_loss           | 0.0787      |
-----------------------------------------
[ADAPTIVE] Episode 27 reward: 0.059015
[ADAPTIVE] Mean reward over last 20 episodes: -0.001185
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9789924   |
| time/                   |             |
|    fps                  | 1234        |
|    iterations           | 27          |
|    time_elapsed         | 89          |
|    total_timesteps      | 110592      |
| train/                  |             |
|    approx_kl            | 0.014926747 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.8       |
|    explained_variance   | 0.715       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.463      |
|    n_updates            | 1545        |
|    policy_gradient_loss | -0.039      |
|    std                  | 3.06        |
|    value_loss           | 0.0832      |
-----------------------------------------
[ADAPTIVE] Episode 28 reward: 0.081077
[ADAPTIVE] Mean reward over last 20 episodes: 0.002863
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1057986   |
| time/                   |             |
|    fps                  | 1238        |
|    iterations           | 28          |
|    time_elapsed         | 92          |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.019043531 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.9       |
|    explained_variance   | 0.612       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.458      |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0332     |
|    std                  | 3.08        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 29 reward: 0.015579
[ADAPTIVE] Mean reward over last 20 episodes: 0.000158
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2044342   |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 29          |
|    time_elapsed         | 96          |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.015171533 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -22.9       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.483      |
|    n_updates            | 1575        |
|    policy_gradient_loss | -0.0327     |
|    std                  | 3.1         |
|    value_loss           | 0.0748      |
-----------------------------------------
[ADAPTIVE] Episode 30 reward: -0.025975
[ADAPTIVE] Mean reward over last 20 episodes: -0.001526
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 1: PhysicalPropertiesInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 1
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1818559   |
| time/                   |             |
|    fps                  | 1236        |
|    iterations           | 30          |
|    time_elapsed         | 99          |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.013834863 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23         |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.477      |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.03       |
|    std                  | 3.1         |
|    value_loss           | 0.0825      |
-----------------------------------------
[ADAPTIVE] Episode 31 reward: -0.027172
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.04637     |
| time/                   |             |
|    fps                  | 1236        |
|    iterations           | 31          |
|    time_elapsed         | 102         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.018948209 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -23         |
|    explained_variance   | 0.713       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.465      |
|    n_updates            | 1605        |
|    policy_gradient_loss | -0.0324     |
|    std                  | 3.12        |
|    value_loss           | 0.0978      |
-----------------------------------------
[ADAPTIVE] Episode 32 reward: 0.029283
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0675187   |
| time/                   |             |
|    fps                  | 1233        |
|    iterations           | 32          |
|    time_elapsed         | 106         |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.025537875 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23         |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.492      |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.0421     |
|    std                  | 3.13        |
|    value_loss           | 0.0792      |
-----------------------------------------
[ADAPTIVE] Episode 33 reward: -0.008576
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0413319   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 33          |
|    time_elapsed         | 110         |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.021335056 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23         |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.464      |
|    n_updates            | 1635        |
|    policy_gradient_loss | -0.0376     |
|    std                  | 3.14        |
|    value_loss           | 0.0936      |
-----------------------------------------
[ADAPTIVE] Episode 34 reward: -0.015551
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0927085  |
| time/                   |            |
|    fps                  | 1229       |
|    iterations           | 34         |
|    time_elapsed         | 113        |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.01746878 |
|    clip_fraction        | 0.203      |
|    clip_range           | 0.2        |
|    entropy_loss         | -23.1      |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.483     |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.0383    |
|    std                  | 3.16       |
|    value_loss           | 0.082      |
----------------------------------------
[ADAPTIVE] Episode 35 reward: -0.044469
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0222694   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 35          |
|    time_elapsed         | 116         |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.013225276 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.1       |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.472      |
|    n_updates            | 1665        |
|    policy_gradient_loss | -0.0351     |
|    std                  | 3.17        |
|    value_loss           | 0.0879      |
-----------------------------------------
[ADAPTIVE] Episode 36 reward: -0.017195
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0033824   |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 36          |
|    time_elapsed         | 120         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.019060869 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.2       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.48       |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.04       |
|    std                  | 3.2         |
|    value_loss           | 0.0919      |
-----------------------------------------
[ADAPTIVE] Episode 37 reward: 0.013848
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0448024  |
| time/                   |            |
|    fps                  | 1226       |
|    iterations           | 37         |
|    time_elapsed         | 123        |
|    total_timesteps      | 151552     |
| train/                  |            |
|    approx_kl            | 0.02105745 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -23.2      |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.474     |
|    n_updates            | 1695       |
|    policy_gradient_loss | -0.0314    |
|    std                  | 3.21       |
|    value_loss           | 0.0933     |
----------------------------------------
[ADAPTIVE] Episode 38 reward: 0.071811
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1585339   |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 38          |
|    time_elapsed         | 127         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.015794441 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.3       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.488      |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 3.22        |
|    value_loss           | 0.0778      |
-----------------------------------------
[ADAPTIVE] Episode 39 reward: 0.028382
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3083081   |
| time/                   |             |
|    fps                  | 1219        |
|    iterations           | 39          |
|    time_elapsed         | 130         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.015058219 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.3       |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.479      |
|    n_updates            | 1725        |
|    policy_gradient_loss | -0.0313     |
|    std                  | 3.24        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 40 reward: 0.054088
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1657004   |
| time/                   |             |
|    fps                  | 1218        |
|    iterations           | 40          |
|    time_elapsed         | 134         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.010429297 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.4       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.445      |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0261     |
|    std                  | 3.25        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 41 reward: -0.024105
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2458134   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 41          |
|    time_elapsed         | 138         |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.019600667 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.4       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.492      |
|    n_updates            | 1755        |
|    policy_gradient_loss | -0.0326     |
|    std                  | 3.28        |
|    value_loss           | 0.0725      |
-----------------------------------------
[ADAPTIVE] Episode 42 reward: 0.015823
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2807112   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 42          |
|    time_elapsed         | 141         |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 0.021193272 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.5       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.485      |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0312     |
|    std                  | 3.31        |
|    value_loss           | 0.0879      |
-----------------------------------------
[ADAPTIVE] Episode 43 reward: 0.061919
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.321983    |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 43          |
|    time_elapsed         | 144         |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.015442745 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.6       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.474      |
|    n_updates            | 1785        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 3.33        |
|    value_loss           | 0.0961      |
-----------------------------------------
[ADAPTIVE] Episode 44 reward: 0.032840
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1027924   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 44          |
|    time_elapsed         | 148         |
|    total_timesteps      | 180224      |
| train/                  |             |
|    approx_kl            | 0.018268377 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.6       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.489      |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.0372     |
|    std                  | 3.33        |
|    value_loss           | 0.0873      |
-----------------------------------------
[ADAPTIVE] Episode 45 reward: 0.050526
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.97182035  |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 45          |
|    time_elapsed         | 151         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.017068168 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.6       |
|    explained_variance   | 0.607       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.484      |
|    n_updates            | 1815        |
|    policy_gradient_loss | -0.0341     |
|    std                  | 3.36        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 46 reward: -0.010387
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1305399   |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 46          |
|    time_elapsed         | 155         |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.016958421 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.7       |
|    explained_variance   | 0.658       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.486      |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.0331     |
|    std                  | 3.38        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 47 reward: -0.005466
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1928399   |
| time/                   |             |
|    fps                  | 1206        |
|    iterations           | 47          |
|    time_elapsed         | 159         |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.014202407 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.7       |
|    explained_variance   | 0.819       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.476      |
|    n_updates            | 1845        |
|    policy_gradient_loss | -0.0327     |
|    std                  | 3.39        |
|    value_loss           | 0.0856      |
-----------------------------------------
[ADAPTIVE] Episode 48 reward: -0.077222
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 1.1433355 |
| time/                   |           |
|    fps                  | 1207      |
|    iterations           | 48        |
|    time_elapsed         | 162       |
|    total_timesteps      | 196608    |
| train/                  |           |
|    approx_kl            | 0.0160141 |
|    clip_fraction        | 0.204     |
|    clip_range           | 0.2       |
|    entropy_loss         | -23.8     |
|    explained_variance   | 0.739     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.478    |
|    n_updates            | 1860      |
|    policy_gradient_loss | -0.0354   |
|    std                  | 3.41      |
|    value_loss           | 0.0949    |
---------------------------------------
[ADAPTIVE] Episode 49 reward: -0.019899
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0877333  |
| time/                   |            |
|    fps                  | 1206       |
|    iterations           | 49         |
|    time_elapsed         | 166        |
|    total_timesteps      | 200704     |
| train/                  |            |
|    approx_kl            | 0.01426198 |
|    clip_fraction        | 0.174      |
|    clip_range           | 0.2        |
|    entropy_loss         | -23.8      |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.469     |
|    n_updates            | 1875       |
|    policy_gradient_loss | -0.031     |
|    std                  | 3.43       |
|    value_loss           | 0.0966     |
----------------------------------------
[ADAPTIVE] Episode 50 reward: -0.083347
[ADAPTIVE] Mean reward over last 20 episodes: 0.001257
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2666099   |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 50          |
|    time_elapsed         | 169         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.010665098 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.9       |
|    explained_variance   | 0.792       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.474      |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0276     |
|    std                  | 3.44        |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 51 reward: 0.018486
[ADAPTIVE] Mean reward over last 20 episodes: 0.003540
[ADAPTIVE] Plateau counter: 1/10
[ADAPTIVE] Episode 52 reward: -0.151266
[ADAPTIVE] Mean reward over last 20 episodes: -0.005488
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3942035   |
| time/                   |             |
|    fps                  | 1206        |
|    iterations           | 51          |
|    time_elapsed         | 173         |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.010491675 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.9       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.482      |
|    n_updates            | 1905        |
|    policy_gradient_loss | -0.028      |
|    std                  | 3.45        |
|    value_loss           | 0.09        |
-----------------------------------------
[ADAPTIVE] Episode 53 reward: 0.005522
[ADAPTIVE] Mean reward over last 20 episodes: -0.004783
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2790476   |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 52          |
|    time_elapsed         | 176         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.019669866 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -23.9       |
|    explained_variance   | 0.803       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.49       |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.0335     |
|    std                  | 3.47        |
|    value_loss           | 0.0871      |
-----------------------------------------
[ADAPTIVE] Episode 54 reward: 0.078810
[ADAPTIVE] Mean reward over last 20 episodes: -0.000065
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3208289   |
| time/                   |             |
|    fps                  | 1203        |
|    iterations           | 53          |
|    time_elapsed         | 180         |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.021043856 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24         |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.485      |
|    n_updates            | 1935        |
|    policy_gradient_loss | -0.0395     |
|    std                  | 3.5         |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 55 reward: -0.027081
[ADAPTIVE] Mean reward over last 20 episodes: 0.000805
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1462083   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 54          |
|    time_elapsed         | 183         |
|    total_timesteps      | 221184      |
| train/                  |             |
|    approx_kl            | 0.021826934 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.1       |
|    explained_variance   | 0.674       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.474      |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0327     |
|    std                  | 3.52        |
|    value_loss           | 0.0999      |
-----------------------------------------
[ADAPTIVE] Episode 56 reward: 0.056124
[ADAPTIVE] Mean reward over last 20 episodes: 0.004471
[ADAPTIVE] Plateau counter: 6/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.051534   |
| time/                   |            |
|    fps                  | 1202       |
|    iterations           | 55         |
|    time_elapsed         | 187        |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.01722091 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -24.1      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.503     |
|    n_updates            | 1965       |
|    policy_gradient_loss | -0.0361    |
|    std                  | 3.55       |
|    value_loss           | 0.105      |
----------------------------------------
[ADAPTIVE] Episode 57 reward: -0.009945
[ADAPTIVE] Mean reward over last 20 episodes: 0.003281
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.122803    |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 56          |
|    time_elapsed         | 190         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.022081705 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.2       |
|    explained_variance   | 0.631       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.472      |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 3.57        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 58 reward: -0.094070
[ADAPTIVE] Mean reward over last 20 episodes: -0.005013
[ADAPTIVE] Plateau counter: 8/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.9006927  |
| time/                   |            |
|    fps                  | 1202       |
|    iterations           | 57         |
|    time_elapsed         | 194        |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.01946148 |
|    clip_fraction        | 0.201      |
|    clip_range           | 0.2        |
|    entropy_loss         | -24.2      |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.465     |
|    n_updates            | 1995       |
|    policy_gradient_loss | -0.0302    |
|    std                  | 3.59       |
|    value_loss           | 0.121      |
----------------------------------------
[ADAPTIVE] Episode 59 reward: -0.001222
[ADAPTIVE] Mean reward over last 20 episodes: -0.006493
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0020285   |
| time/                   |             |
|    fps                  | 1203        |
|    iterations           | 58          |
|    time_elapsed         | 197         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.012404215 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.3       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.473      |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.025      |
|    std                  | 3.61        |
|    value_loss           | 0.154       |
-----------------------------------------
[ADAPTIVE] Episode 60 reward: 0.011296
[ADAPTIVE] Mean reward over last 20 episodes: -0.008633
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 2: VisualInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 2
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.92483884  |
| time/                   |             |
|    fps                  | 1203        |
|    iterations           | 59          |
|    time_elapsed         | 200         |
|    total_timesteps      | 241664      |
| train/                  |             |
|    approx_kl            | 0.018646121 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.4       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.503      |
|    n_updates            | 2025        |
|    policy_gradient_loss | -0.0338     |
|    std                  | 3.64        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 61 reward: -0.017152
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9909243   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 60          |
|    time_elapsed         | 204         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.016031494 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.4       |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.481      |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.0357     |
|    std                  | 3.65        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 62 reward: -0.002607
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1220025   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 61          |
|    time_elapsed         | 207         |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.014353046 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.4       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.488      |
|    n_updates            | 2055        |
|    policy_gradient_loss | -0.0283     |
|    std                  | 3.67        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 63 reward: 0.001548
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1666433   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 62          |
|    time_elapsed         | 210         |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.017318536 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.5       |
|    explained_variance   | 0.705       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.491      |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.0355     |
|    std                  | 3.68        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 64 reward: -0.122004
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1856991   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 63          |
|    time_elapsed         | 214         |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.016546406 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.5       |
|    explained_variance   | 0.712       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.506      |
|    n_updates            | 2085        |
|    policy_gradient_loss | -0.0346     |
|    std                  | 3.71        |
|    value_loss           | 0.0976      |
-----------------------------------------
[ADAPTIVE] Episode 65 reward: 0.011830
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1649231   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 64          |
|    time_elapsed         | 217         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.021926045 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.6       |
|    explained_variance   | 0.552       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.486      |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.0315     |
|    std                  | 3.75        |
|    value_loss           | 0.126       |
-----------------------------------------
[ADAPTIVE] Episode 66 reward: -0.039127
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2728815   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 65          |
|    time_elapsed         | 221         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.024571074 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.7       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.504      |
|    n_updates            | 2115        |
|    policy_gradient_loss | -0.0327     |
|    std                  | 3.78        |
|    value_loss           | 0.0964      |
-----------------------------------------
[ADAPTIVE] Episode 67 reward: 0.038854
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2846745   |
| time/                   |             |
|    fps                  | 1203        |
|    iterations           | 66          |
|    time_elapsed         | 224         |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 0.019098368 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.7       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.502      |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0333     |
|    std                  | 3.8         |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 68 reward: 0.040830
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2059298   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 67          |
|    time_elapsed         | 228         |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.021459408 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.8       |
|    explained_variance   | 0.752       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.531      |
|    n_updates            | 2145        |
|    policy_gradient_loss | -0.04       |
|    std                  | 3.83        |
|    value_loss           | 0.0707      |
-----------------------------------------
[ADAPTIVE] Episode 69 reward: 0.041781
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1353115   |
| time/                   |             |
|    fps                  | 1203        |
|    iterations           | 68          |
|    time_elapsed         | 231         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.018971156 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.9       |
|    explained_variance   | 0.676       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.507      |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.0344     |
|    std                  | 3.84        |
|    value_loss           | 0.0989      |
-----------------------------------------
[ADAPTIVE] Episode 70 reward: -0.117079
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0807084   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 69          |
|    time_elapsed         | 235         |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.015059566 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.9       |
|    explained_variance   | 0.61        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.497      |
|    n_updates            | 2175        |
|    policy_gradient_loss | -0.0369     |
|    std                  | 3.85        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 71 reward: 0.006229
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.143145    |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 70          |
|    time_elapsed         | 238         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.024262646 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -24.9       |
|    explained_variance   | 0.67        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.51       |
|    n_updates            | 2190        |
|    policy_gradient_loss | -0.0376     |
|    std                  | 3.89        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 72 reward: -0.038425
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0834309   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 71          |
|    time_elapsed         | 242         |
|    total_timesteps      | 290816      |
| train/                  |             |
|    approx_kl            | 0.016692083 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25         |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.505      |
|    n_updates            | 2205        |
|    policy_gradient_loss | -0.0295     |
|    std                  | 3.91        |
|    value_loss           | 0.119       |
-----------------------------------------
[ADAPTIVE] Episode 73 reward: 0.090466
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0181537   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 72          |
|    time_elapsed         | 245         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.012196705 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.1       |
|    explained_variance   | 0.797       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.497      |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.0336     |
|    std                  | 3.93        |
|    value_loss           | 0.0919      |
-----------------------------------------
[ADAPTIVE] Episode 74 reward: 0.061469
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2535493   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 73          |
|    time_elapsed         | 249         |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.020585839 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.1       |
|    explained_variance   | 0.576       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.451      |
|    n_updates            | 2235        |
|    policy_gradient_loss | -0.0284     |
|    std                  | 3.96        |
|    value_loss           | 0.18        |
-----------------------------------------
[ADAPTIVE] Episode 75 reward: -0.036679
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2232175   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 74          |
|    time_elapsed         | 252         |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.010551136 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.2       |
|    explained_variance   | 0.673       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.482      |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 3.97        |
|    value_loss           | 0.152       |
-----------------------------------------
[ADAPTIVE] Episode 76 reward: -0.027913
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2689918   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 75          |
|    time_elapsed         | 255         |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.018642912 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.2       |
|    explained_variance   | 0.665       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.519      |
|    n_updates            | 2265        |
|    policy_gradient_loss | -0.036      |
|    std                  | 4           |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 77 reward: 0.012242
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2199531  |
| time/                   |            |
|    fps                  | 1202       |
|    iterations           | 76         |
|    time_elapsed         | 258        |
|    total_timesteps      | 311296     |
| train/                  |            |
|    approx_kl            | 0.01838511 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -25.3      |
|    explained_variance   | 0.747      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.516     |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.0359    |
|    std                  | 4.02       |
|    value_loss           | 0.0833     |
----------------------------------------
[ADAPTIVE] Episode 78 reward: -0.049829
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1634523   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 77          |
|    time_elapsed         | 262         |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.013008167 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.3       |
|    explained_variance   | 0.687       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.475      |
|    n_updates            | 2295        |
|    policy_gradient_loss | -0.0309     |
|    std                  | 4.03        |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 79 reward: -0.033852
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1086161   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 78          |
|    time_elapsed         | 265         |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.024078818 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.4       |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.494      |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.0361     |
|    std                  | 4.07        |
|    value_loss           | 0.154       |
-----------------------------------------
[ADAPTIVE] Episode 80 reward: 0.111336
[ADAPTIVE] Mean reward over last 20 episodes: -0.003404
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9862988   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 79          |
|    time_elapsed         | 269         |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.010484086 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.4       |
|    explained_variance   | 0.665       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.492      |
|    n_updates            | 2325        |
|    policy_gradient_loss | -0.0288     |
|    std                  | 4.08        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 81 reward: -0.001178
[ADAPTIVE] Mean reward over last 20 episodes: -0.002605
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.78907555  |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 80          |
|    time_elapsed         | 272         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.020633228 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.4       |
|    explained_variance   | 0.688       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.525      |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.0371     |
|    std                  | 4.1         |
|    value_loss           | 0.0842      |
-----------------------------------------
[ADAPTIVE] Episode 82 reward: -0.005628
[ADAPTIVE] Mean reward over last 20 episodes: -0.002756
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8521732   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 81          |
|    time_elapsed         | 276         |
|    total_timesteps      | 331776      |
| train/                  |             |
|    approx_kl            | 0.016090015 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.5       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.522      |
|    n_updates            | 2355        |
|    policy_gradient_loss | -0.0315     |
|    std                  | 4.12        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 83 reward: 0.001011
[ADAPTIVE] Mean reward over last 20 episodes: -0.002783
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.88541     |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 82          |
|    time_elapsed         | 279         |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.019715888 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.6       |
|    explained_variance   | 0.455       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.491      |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.0344     |
|    std                  | 4.16        |
|    value_loss           | 0.231       |
-----------------------------------------
[ADAPTIVE] Episode 84 reward: -0.082258
[ADAPTIVE] Mean reward over last 20 episodes: -0.000796
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.93244743  |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 83          |
|    time_elapsed         | 283         |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.017478818 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.6       |
|    explained_variance   | 0.569       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.467      |
|    n_updates            | 2385        |
|    policy_gradient_loss | -0.0268     |
|    std                  | 4.2         |
|    value_loss           | 0.198       |
-----------------------------------------
[ADAPTIVE] Episode 85 reward: -0.018717
[ADAPTIVE] Mean reward over last 20 episodes: -0.002323
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98388344  |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 84          |
|    time_elapsed         | 286         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.017182322 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.7       |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.537      |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 4.22        |
|    value_loss           | 0.0873      |
-----------------------------------------
[ADAPTIVE] Episode 86 reward: -0.070760
[ADAPTIVE] Mean reward over last 20 episodes: -0.003905
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0462632   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 85          |
|    time_elapsed         | 289         |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.012757886 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.7       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.526      |
|    n_updates            | 2415        |
|    policy_gradient_loss | -0.0315     |
|    std                  | 4.24        |
|    value_loss           | 0.0776      |
-----------------------------------------
[ADAPTIVE] Episode 87 reward: -0.148765
[ADAPTIVE] Mean reward over last 20 episodes: -0.013286
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1593008   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 86          |
|    time_elapsed         | 292         |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.017986838 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.8       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.521      |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 4.26        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 88 reward: 0.000897
[ADAPTIVE] Mean reward over last 20 episodes: -0.015283
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2299042   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 87          |
|    time_elapsed         | 296         |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.019456968 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.8       |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.53       |
|    n_updates            | 2445        |
|    policy_gradient_loss | -0.0277     |
|    std                  | 4.29        |
|    value_loss           | 0.0929      |
-----------------------------------------
[ADAPTIVE] Episode 89 reward: 0.012286
[ADAPTIVE] Mean reward over last 20 episodes: -0.016757
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2077968   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 88          |
|    time_elapsed         | 299         |
|    total_timesteps      | 360448      |
| train/                  |             |
|    approx_kl            | 0.015253494 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -25.9       |
|    explained_variance   | 0.72        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.521      |
|    n_updates            | 2460        |
|    policy_gradient_loss | -0.0304     |
|    std                  | 4.32        |
|    value_loss           | 0.0889      |
-----------------------------------------
[ADAPTIVE] Episode 90 reward: 0.045860
[ADAPTIVE] Mean reward over last 20 episodes: -0.008610
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 3: JointsInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 3
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0757102   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 89          |
|    time_elapsed         | 303         |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.015318577 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26         |
|    explained_variance   | 0.702       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.529      |
|    n_updates            | 2475        |
|    policy_gradient_loss | -0.0326     |
|    std                  | 4.35        |
|    value_loss           | 0.0929      |
-----------------------------------------
[ADAPTIVE] Episode 91 reward: 0.081037
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.173399    |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 90          |
|    time_elapsed         | 306         |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.013954305 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26         |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.506      |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.0352     |
|    std                  | 4.36        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 92 reward: -0.015699
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1217806   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 91          |
|    time_elapsed         | 310         |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.015833924 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26         |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.546      |
|    n_updates            | 2505        |
|    policy_gradient_loss | -0.0369     |
|    std                  | 4.38        |
|    value_loss           | 0.0642      |
-----------------------------------------
[ADAPTIVE] Episode 93 reward: -0.024424
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0455964   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 92          |
|    time_elapsed         | 313         |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.015787747 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.1       |
|    explained_variance   | 0.595       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.513      |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 4.4         |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 94 reward: -0.028211
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.056597    |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 93          |
|    time_elapsed         | 317         |
|    total_timesteps      | 380928      |
| train/                  |             |
|    approx_kl            | 0.018527804 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.1       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.533      |
|    n_updates            | 2535        |
|    policy_gradient_loss | -0.0324     |
|    std                  | 4.42        |
|    value_loss           | 0.0903      |
-----------------------------------------
[ADAPTIVE] Episode 95 reward: 0.025026
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9311919   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 94          |
|    time_elapsed         | 320         |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.017194401 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.2       |
|    explained_variance   | 0.651       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.542      |
|    n_updates            | 2550        |
|    policy_gradient_loss | -0.0346     |
|    std                  | 4.44        |
|    value_loss           | 0.0939      |
-----------------------------------------
[ADAPTIVE] Episode 96 reward: 0.041982
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.92029727  |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 95          |
|    time_elapsed         | 324         |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.016550561 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.2       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.537      |
|    n_updates            | 2565        |
|    policy_gradient_loss | -0.0332     |
|    std                  | 4.47        |
|    value_loss           | 0.0939      |
-----------------------------------------
[ADAPTIVE] Episode 97 reward: 0.102442
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0007175   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 96          |
|    time_elapsed         | 327         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.016268615 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.3       |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.029      |
|    std                  | 4.49        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 98 reward: 0.053252
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0425643   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 97          |
|    time_elapsed         | 331         |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.019946357 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.3       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.521      |
|    n_updates            | 2595        |
|    policy_gradient_loss | -0.0297     |
|    std                  | 4.51        |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 99 reward: -0.011959
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0338801   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 98          |
|    time_elapsed         | 334         |
|    total_timesteps      | 401408      |
| train/                  |             |
|    approx_kl            | 0.013418187 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.3       |
|    explained_variance   | 0.669       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.0302     |
|    std                  | 4.53        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 100 reward: 0.000131
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0923859   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 99          |
|    time_elapsed         | 337         |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.018615324 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.4       |
|    explained_variance   | 0.813       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.559      |
|    n_updates            | 2625        |
|    policy_gradient_loss | -0.0399     |
|    std                  | 4.54        |
|    value_loss           | 0.0678      |
-----------------------------------------
[ADAPTIVE] Episode 101 reward: 0.024608
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1755078   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 100         |
|    time_elapsed         | 341         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.016222883 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.4       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.531      |
|    n_updates            | 2640        |
|    policy_gradient_loss | -0.0315     |
|    std                  | 4.58        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 102 reward: 0.034773
[ADAPTIVE] Episode 103 reward: -0.013524
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2919773   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 101         |
|    time_elapsed         | 344         |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.015056327 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.5       |
|    explained_variance   | 0.795       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.529      |
|    n_updates            | 2655        |
|    policy_gradient_loss | -0.031      |
|    std                  | 4.61        |
|    value_loss           | 0.0821      |
-----------------------------------------
[ADAPTIVE] Episode 104 reward: -0.019109
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2157185   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 102         |
|    time_elapsed         | 348         |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.016725836 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.5       |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.54       |
|    n_updates            | 2670        |
|    policy_gradient_loss | -0.0365     |
|    std                  | 4.64        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 105 reward: 0.004739
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3996218   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 103         |
|    time_elapsed         | 352         |
|    total_timesteps      | 421888      |
| train/                  |             |
|    approx_kl            | 0.018471321 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.6       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.546      |
|    n_updates            | 2685        |
|    policy_gradient_loss | -0.0374     |
|    std                  | 4.68        |
|    value_loss           | 0.0963      |
-----------------------------------------
[ADAPTIVE] Episode 106 reward: 0.028298
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.3097637  |
| time/                   |            |
|    fps                  | 1198       |
|    iterations           | 104        |
|    time_elapsed         | 355        |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.01621155 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | -26.7      |
|    explained_variance   | 0.764      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.557     |
|    n_updates            | 2700       |
|    policy_gradient_loss | -0.0367    |
|    std                  | 4.7        |
|    value_loss           | 0.0717     |
----------------------------------------
[ADAPTIVE] Episode 107 reward: -0.063539
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4479076   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 105         |
|    time_elapsed         | 359         |
|    total_timesteps      | 430080      |
| train/                  |             |
|    approx_kl            | 0.015248419 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.7       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.531      |
|    n_updates            | 2715        |
|    policy_gradient_loss | -0.0353     |
|    std                  | 4.72        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 108 reward: 0.041153
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.323547   |
| time/                   |            |
|    fps                  | 1197       |
|    iterations           | 106        |
|    time_elapsed         | 362        |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.02210462 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -26.8      |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.563     |
|    n_updates            | 2730       |
|    policy_gradient_loss | -0.0305    |
|    std                  | 4.75       |
|    value_loss           | 0.0895     |
----------------------------------------
[ADAPTIVE] Episode 109 reward: -0.099304
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3994014   |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 107         |
|    time_elapsed         | 366         |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.013945712 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.8       |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.538      |
|    n_updates            | 2745        |
|    policy_gradient_loss | -0.0319     |
|    std                  | 4.78        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 110 reward: -0.003484
[ADAPTIVE] Mean reward over last 20 episodes: 0.007909
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4262111   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 108         |
|    time_elapsed         | 369         |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.021442574 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.9       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.549      |
|    n_updates            | 2760        |
|    policy_gradient_loss | -0.0341     |
|    std                  | 4.82        |
|    value_loss           | 0.0989      |
-----------------------------------------
[ADAPTIVE] Episode 111 reward: 0.032966
[ADAPTIVE] Mean reward over last 20 episodes: 0.005506
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2393209   |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 109         |
|    time_elapsed         | 373         |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.012853323 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.9       |
|    explained_variance   | 0.719       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.538      |
|    n_updates            | 2775        |
|    policy_gradient_loss | -0.0283     |
|    std                  | 4.83        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 112 reward: -0.040213
[ADAPTIVE] Mean reward over last 20 episodes: 0.004280
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2041267   |
| time/                   |             |
|    fps                  | 1194        |
|    iterations           | 110         |
|    time_elapsed         | 377         |
|    total_timesteps      | 450560      |
| train/                  |             |
|    approx_kl            | 0.016425032 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -26.9       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.53       |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0278     |
|    std                  | 4.85        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 113 reward: 0.011110
[ADAPTIVE] Mean reward over last 20 episodes: 0.006057
[ADAPTIVE] Plateau counter: 3/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2217009  |
| time/                   |            |
|    fps                  | 1194       |
|    iterations           | 111        |
|    time_elapsed         | 380        |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.01302216 |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.2        |
|    entropy_loss         | -27        |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.551     |
|    n_updates            | 2805       |
|    policy_gradient_loss | -0.0335    |
|    std                  | 4.88       |
|    value_loss           | 0.1        |
----------------------------------------
[ADAPTIVE] Episode 114 reward: 0.024977
[ADAPTIVE] Mean reward over last 20 episodes: 0.008716
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0611088   |
| time/                   |             |
|    fps                  | 1193        |
|    iterations           | 112         |
|    time_elapsed         | 384         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.015358339 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27         |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.529      |
|    n_updates            | 2820        |
|    policy_gradient_loss | -0.0316     |
|    std                  | 4.9         |
|    value_loss           | 0.144       |
-----------------------------------------
[ADAPTIVE] Episode 115 reward: -0.015649
[ADAPTIVE] Mean reward over last 20 episodes: 0.006682
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0721573   |
| time/                   |             |
|    fps                  | 1192        |
|    iterations           | 113         |
|    time_elapsed         | 388         |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.018914886 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.1       |
|    explained_variance   | 0.542       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.459      |
|    n_updates            | 2835        |
|    policy_gradient_loss | -0.0265     |
|    std                  | 4.92        |
|    value_loss           | 0.239       |
-----------------------------------------
[ADAPTIVE] Episode 116 reward: 0.044296
[ADAPTIVE] Mean reward over last 20 episodes: 0.006798
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9923775   |
| time/                   |             |
|    fps                  | 1192        |
|    iterations           | 114         |
|    time_elapsed         | 391         |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.018007407 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.1       |
|    explained_variance   | 0.553       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.528      |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.0296     |
|    std                  | 4.94        |
|    value_loss           | 0.154       |
-----------------------------------------
[ADAPTIVE] Episode 117 reward: -0.045677
[ADAPTIVE] Mean reward over last 20 episodes: -0.000608
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9010344   |
| time/                   |             |
|    fps                  | 1192        |
|    iterations           | 115         |
|    time_elapsed         | 394         |
|    total_timesteps      | 471040      |
| train/                  |             |
|    approx_kl            | 0.016801734 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.2       |
|    explained_variance   | 0.552       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.521      |
|    n_updates            | 2865        |
|    policy_gradient_loss | -0.0298     |
|    std                  | 4.97        |
|    value_loss           | 0.191       |
-----------------------------------------
[ADAPTIVE] Episode 118 reward: -0.055846
[ADAPTIVE] Mean reward over last 20 episodes: -0.006063
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.044918    |
| time/                   |             |
|    fps                  | 1192        |
|    iterations           | 116         |
|    time_elapsed         | 398         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.014530515 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.2       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.553      |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.033      |
|    std                  | 4.98        |
|    value_loss           | 0.084       |
-----------------------------------------
[ADAPTIVE] Episode 119 reward: 0.006538
[ADAPTIVE] Mean reward over last 20 episodes: -0.005138
[ADAPTIVE] Plateau counter: 9/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0024989  |
| time/                   |            |
|    fps                  | 1191       |
|    iterations           | 117        |
|    time_elapsed         | 402        |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.01602051 |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.2        |
|    entropy_loss         | -27.2      |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.548     |
|    n_updates            | 2895       |
|    policy_gradient_loss | -0.0318    |
|    std                  | 5.01       |
|    value_loss           | 0.104      |
----------------------------------------
[ADAPTIVE] Episode 120 reward: -0.046038
[ADAPTIVE] Mean reward over last 20 episodes: -0.007446
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 4: RigidPoseInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 4
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0902067   |
| time/                   |             |
|    fps                  | 1190        |
|    iterations           | 118         |
|    time_elapsed         | 405         |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.014356058 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.3       |
|    explained_variance   | 0.683       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.539      |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.0256     |
|    std                  | 5.03        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 121 reward: 0.008910
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 1.1087826 |
| time/                   |           |
|    fps                  | 1190      |
|    iterations           | 119       |
|    time_elapsed         | 409       |
|    total_timesteps      | 487424    |
| train/                  |           |
|    approx_kl            | 0.0161378 |
|    clip_fraction        | 0.168     |
|    clip_range           | 0.2       |
|    entropy_loss         | -27.3     |
|    explained_variance   | 0.729     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.541    |
|    n_updates            | 2925      |
|    policy_gradient_loss | -0.0332   |
|    std                  | 5.05      |
|    value_loss           | 0.103     |
---------------------------------------
[ADAPTIVE] Episode 122 reward: -0.018288
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1855626   |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 120         |
|    time_elapsed         | 413         |
|    total_timesteps      | 491520      |
| train/                  |             |
|    approx_kl            | 0.011902136 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.4       |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.555      |
|    n_updates            | 2940        |
|    policy_gradient_loss | -0.0323     |
|    std                  | 5.09        |
|    value_loss           | 0.0852      |
-----------------------------------------
[ADAPTIVE] Episode 123 reward: -0.211543
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.262931    |
| time/                   |             |
|    fps                  | 1189        |
|    iterations           | 121         |
|    time_elapsed         | 416         |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.014931698 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.4       |
|    explained_variance   | 0.67        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.559      |
|    n_updates            | 2955        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 5.11        |
|    value_loss           | 0.0784      |
-----------------------------------------
[ADAPTIVE] Episode 124 reward: -0.023296
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.246522    |
| time/                   |             |
|    fps                  | 1187        |
|    iterations           | 122         |
|    time_elapsed         | 420         |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.015811132 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.5       |
|    explained_variance   | 0.675       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.565      |
|    n_updates            | 2970        |
|    policy_gradient_loss | -0.0349     |
|    std                  | 5.15        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 125 reward: -0.003358
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2029979  |
| time/                   |            |
|    fps                  | 1189       |
|    iterations           | 123        |
|    time_elapsed         | 423        |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.01587731 |
|    clip_fraction        | 0.177      |
|    clip_range           | 0.2        |
|    entropy_loss         | -27.5      |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.513     |
|    n_updates            | 2985       |
|    policy_gradient_loss | -0.0291    |
|    std                  | 5.17       |
|    value_loss           | 0.185      |
----------------------------------------
[ADAPTIVE] Episode 126 reward: -0.051689
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1810625  |
| time/                   |            |
|    fps                  | 1187       |
|    iterations           | 124        |
|    time_elapsed         | 427        |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.01629512 |
|    clip_fraction        | 0.201      |
|    clip_range           | 0.2        |
|    entropy_loss         | -27.6      |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.557     |
|    n_updates            | 3000       |
|    policy_gradient_loss | -0.0355    |
|    std                  | 5.19       |
|    value_loss           | 0.11       |
----------------------------------------
[ADAPTIVE] Episode 127 reward: -0.133469
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0864427  |
| time/                   |            |
|    fps                  | 1188       |
|    iterations           | 125        |
|    time_elapsed         | 430        |
|    total_timesteps      | 512000     |
| train/                  |            |
|    approx_kl            | 0.01861752 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -27.6      |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.563     |
|    n_updates            | 3015       |
|    policy_gradient_loss | -0.0348    |
|    std                  | 5.23       |
|    value_loss           | 0.111      |
----------------------------------------
[ADAPTIVE] Episode 128 reward: 0.036062
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1328235   |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 126         |
|    time_elapsed         | 434         |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.010233931 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.6       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.534      |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.0249     |
|    std                  | 5.24        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 129 reward: -0.050949
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2114198  |
| time/                   |            |
|    fps                  | 1187       |
|    iterations           | 127        |
|    time_elapsed         | 437        |
|    total_timesteps      | 520192     |
| train/                  |            |
|    approx_kl            | 0.02043419 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.2        |
|    entropy_loss         | -27.7      |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.569     |
|    n_updates            | 3045       |
|    policy_gradient_loss | -0.0326    |
|    std                  | 5.28       |
|    value_loss           | 0.0844     |
----------------------------------------
[ADAPTIVE] Episode 130 reward: 0.082551
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2701111   |
| time/                   |             |
|    fps                  | 1187        |
|    iterations           | 128         |
|    time_elapsed         | 441         |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.009841122 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.7       |
|    explained_variance   | 0.761       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.554      |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.0282     |
|    std                  | 5.3         |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 131 reward: 0.080909
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4649245   |
| time/                   |             |
|    fps                  | 1186        |
|    iterations           | 129         |
|    time_elapsed         | 445         |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.016552413 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.8       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.523      |
|    n_updates            | 3075        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 5.33        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 132 reward: -0.007133
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4157535   |
| time/                   |             |
|    fps                  | 1186        |
|    iterations           | 130         |
|    time_elapsed         | 448         |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.019437797 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.9       |
|    explained_variance   | 0.656       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.542      |
|    n_updates            | 3090        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 5.38        |
|    value_loss           | 0.0996      |
-----------------------------------------
[ADAPTIVE] Episode 133 reward: 0.064504
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4954517   |
| time/                   |             |
|    fps                  | 1186        |
|    iterations           | 131         |
|    time_elapsed         | 452         |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.013564767 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -27.9       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.565      |
|    n_updates            | 3105        |
|    policy_gradient_loss | -0.0287     |
|    std                  | 5.41        |
|    value_loss           | 0.0997      |
-----------------------------------------
[ADAPTIVE] Episode 134 reward: -0.071699
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.5366932  |
| time/                   |            |
|    fps                  | 1186       |
|    iterations           | 132        |
|    time_elapsed         | 455        |
|    total_timesteps      | 540672     |
| train/                  |            |
|    approx_kl            | 0.01704504 |
|    clip_fraction        | 0.212      |
|    clip_range           | 0.2        |
|    entropy_loss         | -28        |
|    explained_variance   | 0.732      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.578     |
|    n_updates            | 3120       |
|    policy_gradient_loss | -0.0295    |
|    std                  | 5.43       |
|    value_loss           | 0.0904     |
----------------------------------------
[ADAPTIVE] Episode 135 reward: -0.025806
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4742814   |
| time/                   |             |
|    fps                  | 1185        |
|    iterations           | 133         |
|    time_elapsed         | 459         |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.014878927 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28         |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.571      |
|    n_updates            | 3135        |
|    policy_gradient_loss | -0.0312     |
|    std                  | 5.47        |
|    value_loss           | 0.0947      |
-----------------------------------------
[ADAPTIVE] Episode 136 reward: -0.034789
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.473482    |
| time/                   |             |
|    fps                  | 1185        |
|    iterations           | 134         |
|    time_elapsed         | 463         |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.012786293 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.1       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.56       |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.0299     |
|    std                  | 5.51        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 137 reward: -0.004239
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4895909  |
| time/                   |            |
|    fps                  | 1184       |
|    iterations           | 135        |
|    time_elapsed         | 466        |
|    total_timesteps      | 552960     |
| train/                  |            |
|    approx_kl            | 0.01351475 |
|    clip_fraction        | 0.185      |
|    clip_range           | 0.2        |
|    entropy_loss         | -28.1      |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.575     |
|    n_updates            | 3165       |
|    policy_gradient_loss | -0.0316    |
|    std                  | 5.54       |
|    value_loss           | 0.0685     |
----------------------------------------
[ADAPTIVE] Episode 138 reward: -0.077228
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5805695   |
| time/                   |             |
|    fps                  | 1184        |
|    iterations           | 136         |
|    time_elapsed         | 470         |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.015824623 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.2       |
|    explained_variance   | 0.836       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.584      |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.0318     |
|    std                  | 5.56        |
|    value_loss           | 0.0594      |
-----------------------------------------
[ADAPTIVE] Episode 139 reward: -0.008713
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.46369    |
| time/                   |            |
|    fps                  | 1184       |
|    iterations           | 137        |
|    time_elapsed         | 473        |
|    total_timesteps      | 561152     |
| train/                  |            |
|    approx_kl            | 0.01767463 |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.2        |
|    entropy_loss         | -28.2      |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.568     |
|    n_updates            | 3195       |
|    policy_gradient_loss | -0.0313    |
|    std                  | 5.59       |
|    value_loss           | 0.0869     |
----------------------------------------
[ADAPTIVE] Episode 140 reward: 0.047115
[ADAPTIVE] Mean reward over last 20 episodes: -0.020107
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4834193   |
| time/                   |             |
|    fps                  | 1184        |
|    iterations           | 138         |
|    time_elapsed         | 477         |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.014391622 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.3       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.567      |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.0325     |
|    std                  | 5.63        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 141 reward: 0.051972
[ADAPTIVE] Mean reward over last 20 episodes: -0.017954
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4869919   |
| time/                   |             |
|    fps                  | 1184        |
|    iterations           | 139         |
|    time_elapsed         | 480         |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.017238356 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.3       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.587      |
|    n_updates            | 3225        |
|    policy_gradient_loss | -0.0326     |
|    std                  | 5.67        |
|    value_loss           | 0.0739      |
-----------------------------------------
[ADAPTIVE] Episode 142 reward: 0.018411
[ADAPTIVE] Mean reward over last 20 episodes: -0.016119
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6073675   |
| time/                   |             |
|    fps                  | 1184        |
|    iterations           | 140         |
|    time_elapsed         | 484         |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.019849727 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.4       |
|    explained_variance   | 0.77        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.57       |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.028      |
|    std                  | 5.7         |
|    value_loss           | 0.097       |
-----------------------------------------
[ADAPTIVE] Episode 143 reward: -0.023177
[ADAPTIVE] Mean reward over last 20 episodes: -0.006701
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 1.3685777 |
| time/                   |           |
|    fps                  | 1183      |
|    iterations           | 141       |
|    time_elapsed         | 487       |
|    total_timesteps      | 577536    |
| train/                  |           |
|    approx_kl            | 0.0128269 |
|    clip_fraction        | 0.138     |
|    clip_range           | 0.2       |
|    entropy_loss         | -28.4     |
|    explained_variance   | 0.699     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.569    |
|    n_updates            | 3255      |
|    policy_gradient_loss | -0.0314   |
|    std                  | 5.72      |
|    value_loss           | 0.106     |
---------------------------------------
[ADAPTIVE] Episode 144 reward: -0.062314
[ADAPTIVE] Mean reward over last 20 episodes: -0.008652
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2916074   |
| time/                   |             |
|    fps                  | 1183        |
|    iterations           | 142         |
|    time_elapsed         | 491         |
|    total_timesteps      | 581632      |
| train/                  |             |
|    approx_kl            | 0.015984382 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.5       |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.543      |
|    n_updates            | 3270        |
|    policy_gradient_loss | -0.0284     |
|    std                  | 5.73        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 145 reward: -0.045379
[ADAPTIVE] Mean reward over last 20 episodes: -0.010753
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.342034    |
| time/                   |             |
|    fps                  | 1183        |
|    iterations           | 143         |
|    time_elapsed         | 494         |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.017230839 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.5       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.584      |
|    n_updates            | 3285        |
|    policy_gradient_loss | -0.0287     |
|    std                  | 5.77        |
|    value_loss           | 0.0775      |
-----------------------------------------
[ADAPTIVE] Episode 146 reward: 0.071332
[ADAPTIVE] Mean reward over last 20 episodes: -0.004602
[ADAPTIVE] Plateau counter: 3/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1468502  |
| time/                   |            |
|    fps                  | 1182       |
|    iterations           | 144        |
|    time_elapsed         | 498        |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.01440057 |
|    clip_fraction        | 0.177      |
|    clip_range           | 0.2        |
|    entropy_loss         | -28.6      |
|    explained_variance   | 0.56       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.547     |
|    n_updates            | 3300       |
|    policy_gradient_loss | -0.0241    |
|    std                  | 5.82       |
|    value_loss           | 0.165      |
----------------------------------------
[ADAPTIVE] Episode 147 reward: 0.093803
[ADAPTIVE] Mean reward over last 20 episodes: 0.006762
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0941288   |
| time/                   |             |
|    fps                  | 1182        |
|    iterations           | 145         |
|    time_elapsed         | 502         |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.017871007 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.6       |
|    explained_variance   | 0.799       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.596      |
|    n_updates            | 3315        |
|    policy_gradient_loss | -0.0306     |
|    std                  | 5.86        |
|    value_loss           | 0.0712      |
-----------------------------------------
[ADAPTIVE] Episode 148 reward: -0.028999
[ADAPTIVE] Mean reward over last 20 episodes: 0.003508
[ADAPTIVE] Plateau counter: 1/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1547232  |
| time/                   |            |
|    fps                  | 1181       |
|    iterations           | 146        |
|    time_elapsed         | 506        |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.01337953 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -28.7      |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.587     |
|    n_updates            | 3330       |
|    policy_gradient_loss | -0.0303    |
|    std                  | 5.89       |
|    value_loss           | 0.0909     |
----------------------------------------
[ADAPTIVE] Episode 149 reward: -0.019367
[ADAPTIVE] Mean reward over last 20 episodes: 0.005088
[ADAPTIVE] Plateau counter: 2/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1875587    |
| time/                   |              |
|    fps                  | 1181         |
|    iterations           | 147          |
|    time_elapsed         | 509          |
|    total_timesteps      | 602112       |
| train/                  |              |
|    approx_kl            | 0.0130726155 |
|    clip_fraction        | 0.167        |
|    clip_range           | 0.2          |
|    entropy_loss         | -28.7        |
|    explained_variance   | 0.683        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.55        |
|    n_updates            | 3345         |
|    policy_gradient_loss | -0.0222      |
|    std                  | 5.93         |
|    value_loss           | 0.186        |
------------------------------------------
[ADAPTIVE] Episode 150 reward: 0.006720
[ADAPTIVE] Mean reward over last 20 episodes: 0.001296
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1384423   |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 148         |
|    time_elapsed         | 513         |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.014648328 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.8       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.56       |
|    n_updates            | 3360        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 5.97        |
|    value_loss           | 0.186       |
-----------------------------------------
[ADAPTIVE] Episode 151 reward: -0.017327
[ADAPTIVE] Mean reward over last 20 episodes: -0.003616
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.23235     |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 149         |
|    time_elapsed         | 516         |
|    total_timesteps      | 610304      |
| train/                  |             |
|    approx_kl            | 0.018593933 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.9       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.583      |
|    n_updates            | 3375        |
|    policy_gradient_loss | -0.0262     |
|    std                  | 6.01        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 152 reward: 0.075086
[ADAPTIVE] Mean reward over last 20 episodes: 0.000495
[ADAPTIVE] Plateau counter: 5/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.4378233    |
| time/                   |              |
|    fps                  | 1179         |
|    iterations           | 150          |
|    time_elapsed         | 520          |
|    total_timesteps      | 614400       |
| train/                  |              |
|    approx_kl            | 0.0137205515 |
|    clip_fraction        | 0.205        |
|    clip_range           | 0.2          |
|    entropy_loss         | -28.9        |
|    explained_variance   | 0.768        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.581       |
|    n_updates            | 3390         |
|    policy_gradient_loss | -0.029       |
|    std                  | 6.01         |
|    value_loss           | 0.108        |
------------------------------------------
[ADAPTIVE] Episode 153 reward: 0.029608
[ADAPTIVE] Mean reward over last 20 episodes: -0.001250
[ADAPTIVE] Plateau counter: 6/10
[ADAPTIVE] Episode 154 reward: 0.097403
[ADAPTIVE] Mean reward over last 20 episodes: 0.007206
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5383152   |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 151         |
|    time_elapsed         | 524         |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.019830506 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.9       |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.582      |
|    n_updates            | 3405        |
|    policy_gradient_loss | -0.0254     |
|    std                  | 6.04        |
|    value_loss           | 0.0918      |
-----------------------------------------
[ADAPTIVE] Episode 155 reward: 0.017297
[ADAPTIVE] Mean reward over last 20 episodes: 0.009361
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6453305   |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 152         |
|    time_elapsed         | 528         |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.011384688 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -28.9       |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.532      |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.0267     |
|    std                  | 6.06        |
|    value_loss           | 0.183       |
-----------------------------------------
[ADAPTIVE] Episode 156 reward: -0.031387
[ADAPTIVE] Mean reward over last 20 episodes: 0.009531
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6333456   |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 153         |
|    time_elapsed         | 531         |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.017786892 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29         |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.595      |
|    n_updates            | 3435        |
|    policy_gradient_loss | -0.0305     |
|    std                  | 6.08        |
|    value_loss           | 0.112       |
-----------------------------------------
[ADAPTIVE] Episode 157 reward: -0.113732
[ADAPTIVE] Mean reward over last 20 episodes: 0.004056
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Advancing to intervention 5: RandomInterventionActorPolicy
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6144944   |
| time/                   |             |
|    fps                  | 1179        |
|    iterations           | 154         |
|    time_elapsed         | 534         |
|    total_timesteps      | 630784      |
| train/                  |             |
|    approx_kl            | 0.017575623 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29         |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.573      |
|    n_updates            | 3450        |
|    policy_gradient_loss | -0.029      |
|    std                  | 6.11        |
|    value_loss           | 0.096       |
-----------------------------------------
[ADAPTIVE] Episode 158 reward: 0.050798
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6441013   |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 155         |
|    time_elapsed         | 537         |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.010240277 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29         |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.564      |
|    n_updates            | 3465        |
|    policy_gradient_loss | -0.0267     |
|    std                  | 6.12        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 159 reward: 0.079964
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6331651   |
| time/                   |             |
|    fps                  | 1180        |
|    iterations           | 156         |
|    time_elapsed         | 541         |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.014549822 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.1       |
|    explained_variance   | 0.712       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.541      |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 6.17        |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 160 reward: -0.025424
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6725267   |
| time/                   |             |
|    fps                  | 1181        |
|    iterations           | 157         |
|    time_elapsed         | 544         |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.014884769 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.1       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.569      |
|    n_updates            | 3495        |
|    policy_gradient_loss | -0.0293     |
|    std                  | 6.2         |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 161 reward: -0.128527
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.7399945   |
| time/                   |             |
|    fps                  | 1181        |
|    iterations           | 158         |
|    time_elapsed         | 547         |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.014716918 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.2       |
|    explained_variance   | 0.773       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.601      |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.0281     |
|    std                  | 6.23        |
|    value_loss           | 0.0966      |
-----------------------------------------
[ADAPTIVE] Episode 162 reward: -0.077657
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.7080705  |
| time/                   |            |
|    fps                  | 1182       |
|    iterations           | 159        |
|    time_elapsed         | 550        |
|    total_timesteps      | 651264     |
| train/                  |            |
|    approx_kl            | 0.01844621 |
|    clip_fraction        | 0.193      |
|    clip_range           | 0.2        |
|    entropy_loss         | -29.2      |
|    explained_variance   | 0.787      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.578     |
|    n_updates            | 3525       |
|    policy_gradient_loss | -0.0327    |
|    std                  | 6.24       |
|    value_loss           | 0.109      |
----------------------------------------
[ADAPTIVE] Episode 163 reward: -0.053067
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.763006    |
| time/                   |             |
|    fps                  | 1183        |
|    iterations           | 160         |
|    time_elapsed         | 553         |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.019542834 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.3       |
|    explained_variance   | 0.529       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.469      |
|    n_updates            | 3540        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 6.3         |
|    value_loss           | 0.298       |
-----------------------------------------
[ADAPTIVE] Episode 164 reward: -0.050935
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.6454967  |
| time/                   |            |
|    fps                  | 1184       |
|    iterations           | 161        |
|    time_elapsed         | 556        |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.01776951 |
|    clip_fraction        | 0.193      |
|    clip_range           | 0.2        |
|    entropy_loss         | -29.3      |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.581     |
|    n_updates            | 3555       |
|    policy_gradient_loss | -0.0309    |
|    std                  | 6.34       |
|    value_loss           | 0.104      |
----------------------------------------
[ADAPTIVE] Episode 165 reward: 0.030486
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5790917   |
| time/                   |             |
|    fps                  | 1184        |
|    iterations           | 162         |
|    time_elapsed         | 560         |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.016211148 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.4       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.575      |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.0255     |
|    std                  | 6.39        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 166 reward: 0.017742
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4868916   |
| time/                   |             |
|    fps                  | 1185        |
|    iterations           | 163         |
|    time_elapsed         | 563         |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.015172767 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.4       |
|    explained_variance   | 0.69        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.594      |
|    n_updates            | 3585        |
|    policy_gradient_loss | -0.0301     |
|    std                  | 6.41        |
|    value_loss           | 0.126       |
-----------------------------------------
[ADAPTIVE] Episode 167 reward: -0.112537
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2512069   |
| time/                   |             |
|    fps                  | 1184        |
|    iterations           | 164         |
|    time_elapsed         | 566         |
|    total_timesteps      | 671744      |
| train/                  |             |
|    approx_kl            | 0.015590702 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.5       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.593      |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.0306     |
|    std                  | 6.45        |
|    value_loss           | 0.163       |
-----------------------------------------
[ADAPTIVE] Episode 168 reward: -0.026608
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.5095689  |
| time/                   |            |
|    fps                  | 1185       |
|    iterations           | 165        |
|    time_elapsed         | 569        |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.01623311 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -29.6      |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.588     |
|    n_updates            | 3615       |
|    policy_gradient_loss | -0.0257    |
|    std                  | 6.5        |
|    value_loss           | 0.173      |
----------------------------------------
[ADAPTIVE] Episode 169 reward: 0.018221
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5729445   |
| time/                   |             |
|    fps                  | 1185        |
|    iterations           | 166         |
|    time_elapsed         | 573         |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.015390085 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.6       |
|    explained_variance   | 0.65        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.567      |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.0301     |
|    std                  | 6.53        |
|    value_loss           | 0.12        |
-----------------------------------------
[ADAPTIVE] Episode 170 reward: -0.050748
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5654553   |
| time/                   |             |
|    fps                  | 1186        |
|    iterations           | 167         |
|    time_elapsed         | 576         |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.013827467 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.7       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.586      |
|    n_updates            | 3645        |
|    policy_gradient_loss | -0.0256     |
|    std                  | 6.56        |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 171 reward: -0.016588
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5739577   |
| time/                   |             |
|    fps                  | 1186        |
|    iterations           | 168         |
|    time_elapsed         | 580         |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.015894838 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.7       |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.608      |
|    n_updates            | 3660        |
|    policy_gradient_loss | -0.0295     |
|    std                  | 6.6         |
|    value_loss           | 0.0892      |
-----------------------------------------
[ADAPTIVE] Episode 172 reward: -0.055404
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4810991  |
| time/                   |            |
|    fps                  | 1186       |
|    iterations           | 169        |
|    time_elapsed         | 583        |
|    total_timesteps      | 692224     |
| train/                  |            |
|    approx_kl            | 0.01364609 |
|    clip_fraction        | 0.153      |
|    clip_range           | 0.2        |
|    entropy_loss         | -29.7      |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.575     |
|    n_updates            | 3675       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 6.62       |
|    value_loss           | 0.157      |
----------------------------------------
[ADAPTIVE] Episode 173 reward: 0.007980
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5460063   |
| time/                   |             |
|    fps                  | 1186        |
|    iterations           | 170         |
|    time_elapsed         | 586         |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.014470794 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.8       |
|    explained_variance   | 0.761       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.616      |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.0322     |
|    std                  | 6.65        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 174 reward: -0.019301
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5005008   |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 171         |
|    time_elapsed         | 589         |
|    total_timesteps      | 700416      |
| train/                  |             |
|    approx_kl            | 0.012653021 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.8       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.599      |
|    n_updates            | 3705        |
|    policy_gradient_loss | -0.0262     |
|    std                  | 6.69        |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 175 reward: 0.002958
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4056535   |
| time/                   |             |
|    fps                  | 1187        |
|    iterations           | 172         |
|    time_elapsed         | 593         |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.014299752 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.9       |
|    explained_variance   | 0.548       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.612      |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.0313     |
|    std                  | 6.73        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 176 reward: 0.015714
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4785424   |
| time/                   |             |
|    fps                  | 1187        |
|    iterations           | 173         |
|    time_elapsed         | 596         |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.015581828 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -29.9       |
|    explained_variance   | 0.627       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.614      |
|    n_updates            | 3735        |
|    policy_gradient_loss | -0.0284     |
|    std                  | 6.79        |
|    value_loss           | 0.137       |
-----------------------------------------
[ADAPTIVE] Episode 177 reward: -0.031283
[ADAPTIVE] Mean reward over last 20 episodes: -0.021211
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4937497   |
| time/                   |             |
|    fps                  | 1187        |
|    iterations           | 174         |
|    time_elapsed         | 600         |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.010658676 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30         |
|    explained_variance   | 0.803       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.592      |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.028      |
|    std                  | 6.82        |
|    value_loss           | 0.0827      |
-----------------------------------------
[ADAPTIVE] Episode 178 reward: -0.028578
[ADAPTIVE] Mean reward over last 20 episodes: -0.025180
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6621784   |
| time/                   |             |
|    fps                  | 1188        |
|    iterations           | 175         |
|    time_elapsed         | 603         |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.014483605 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30         |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.611      |
|    n_updates            | 3765        |
|    policy_gradient_loss | -0.026      |
|    std                  | 6.86        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 179 reward: -0.038723
[ADAPTIVE] Mean reward over last 20 episodes: -0.031114
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6334263   |
| time/                   |             |
|    fps                  | 1189        |
|    iterations           | 176         |
|    time_elapsed         | 605         |
|    total_timesteps      | 720896      |
| train/                  |             |
|    approx_kl            | 0.014707848 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.1       |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.577      |
|    n_updates            | 3780        |
|    policy_gradient_loss | -0.024      |
|    std                  | 6.88        |
|    value_loss           | 0.144       |
-----------------------------------------
[ADAPTIVE] Episode 180 reward: 0.002491
[ADAPTIVE] Mean reward over last 20 episodes: -0.029718
[ADAPTIVE] Plateau counter: 3/10
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 1.7048869 |
| time/                   |           |
|    fps                  | 1190      |
|    iterations           | 177       |
|    time_elapsed         | 609       |
|    total_timesteps      | 724992    |
| train/                  |           |
|    approx_kl            | 0.0125425 |
|    clip_fraction        | 0.188     |
|    clip_range           | 0.2       |
|    entropy_loss         | -30.1     |
|    explained_variance   | 0.7       |
|    learning_rate        | 0.00025   |
|    loss                 | -0.594    |
|    n_updates            | 3795      |
|    policy_gradient_loss | -0.0263   |
|    std                  | 6.9       |
|    value_loss           | 0.155     |
---------------------------------------
[ADAPTIVE] Episode 181 reward: 0.018128
[ADAPTIVE] Mean reward over last 20 episodes: -0.022385
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8802587   |
| time/                   |             |
|    fps                  | 1190        |
|    iterations           | 178         |
|    time_elapsed         | 612         |
|    total_timesteps      | 729088      |
| train/                  |             |
|    approx_kl            | 0.010027405 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.1       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.49       |
|    n_updates            | 3810        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 6.91        |
|    value_loss           | 0.17        |
-----------------------------------------
[ADAPTIVE] Episode 182 reward: -0.062139
[ADAPTIVE] Mean reward over last 20 episodes: -0.021609
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.7364949   |
| time/                   |             |
|    fps                  | 1190        |
|    iterations           | 179         |
|    time_elapsed         | 615         |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.014296698 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.2       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.604      |
|    n_updates            | 3825        |
|    policy_gradient_loss | -0.0244     |
|    std                  | 6.97        |
|    value_loss           | 0.081       |
-----------------------------------------
[ADAPTIVE] Episode 183 reward: 0.042834
[ADAPTIVE] Mean reward over last 20 episodes: -0.016814
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.7734923   |
| time/                   |             |
|    fps                  | 1191        |
|    iterations           | 180         |
|    time_elapsed         | 618         |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.015940692 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.3       |
|    explained_variance   | 0.78        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.592      |
|    n_updates            | 3840        |
|    policy_gradient_loss | -0.0253     |
|    std                  | 7.02        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 184 reward: 0.006058
[ADAPTIVE] Mean reward over last 20 episodes: -0.013965
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6937543   |
| time/                   |             |
|    fps                  | 1192        |
|    iterations           | 181         |
|    time_elapsed         | 621         |
|    total_timesteps      | 741376      |
| train/                  |             |
|    approx_kl            | 0.016178407 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.3       |
|    explained_variance   | 0.797       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.611      |
|    n_updates            | 3855        |
|    policy_gradient_loss | -0.0319     |
|    std                  | 7.08        |
|    value_loss           | 0.0961      |
-----------------------------------------
[ADAPTIVE] Episode 185 reward: -0.018742
[ADAPTIVE] Mean reward over last 20 episodes: -0.016426
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.7099991   |
| time/                   |             |
|    fps                  | 1193        |
|    iterations           | 182         |
|    time_elapsed         | 624         |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.012371422 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.4       |
|    explained_variance   | 0.727       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.607      |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.0271     |
|    std                  | 7.1         |
|    value_loss           | 0.138       |
-----------------------------------------
[ADAPTIVE] Episode 186 reward: -0.030874
[ADAPTIVE] Mean reward over last 20 episodes: -0.018857
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5853369   |
| time/                   |             |
|    fps                  | 1194        |
|    iterations           | 183         |
|    time_elapsed         | 627         |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.014965461 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.4       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.597      |
|    n_updates            | 3885        |
|    policy_gradient_loss | -0.0277     |
|    std                  | 7.15        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 187 reward: -0.017613
[ADAPTIVE] Mean reward over last 20 episodes: -0.014111
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4390268   |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 184         |
|    time_elapsed         | 630         |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.019121984 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.5       |
|    explained_variance   | 0.576       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.555      |
|    n_updates            | 3900        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 7.19        |
|    value_loss           | 0.282       |
-----------------------------------------
[ADAPTIVE] Episode 188 reward: -0.028404
[ADAPTIVE] Mean reward over last 20 episodes: -0.014201
[ADAPTIVE] Plateau counter: 11/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4311126   |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 185         |
|    time_elapsed         | 633         |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.016067721 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.5       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.613      |
|    n_updates            | 3915        |
|    policy_gradient_loss | -0.0271     |
|    std                  | 7.2         |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 189 reward: -0.072443
[ADAPTIVE] Mean reward over last 20 episodes: -0.018734
[ADAPTIVE] Plateau counter: 12/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3880763   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 186         |
|    time_elapsed         | 636         |
|    total_timesteps      | 761856      |
| train/                  |             |
|    approx_kl            | 0.018230911 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.5       |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.623      |
|    n_updates            | 3930        |
|    policy_gradient_loss | -0.0269     |
|    std                  | 7.23        |
|    value_loss           | 0.079       |
-----------------------------------------
[ADAPTIVE] Episode 190 reward: -0.018201
[ADAPTIVE] Mean reward over last 20 episodes: -0.017106
[ADAPTIVE] Plateau counter: 13/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.3445525  |
| time/                   |            |
|    fps                  | 1196       |
|    iterations           | 187        |
|    time_elapsed         | 639        |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.01443213 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.6      |
|    explained_variance   | 0.627      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.553     |
|    n_updates            | 3945       |
|    policy_gradient_loss | -0.0267    |
|    std                  | 7.28       |
|    value_loss           | 0.18       |
----------------------------------------
[ADAPTIVE] Episode 191 reward: -0.017274
[ADAPTIVE] Mean reward over last 20 episodes: -0.017141
[ADAPTIVE] Plateau counter: 14/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3589544   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 188         |
|    time_elapsed         | 643         |
|    total_timesteps      | 770048      |
| train/                  |             |
|    approx_kl            | 0.014781096 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.6       |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.627      |
|    n_updates            | 3960        |
|    policy_gradient_loss | -0.0273     |
|    std                  | 7.31        |
|    value_loss           | 0.0865      |
-----------------------------------------
[ADAPTIVE] Episode 192 reward: -0.135439
[ADAPTIVE] Mean reward over last 20 episodes: -0.021142
[ADAPTIVE] Plateau counter: 15/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4928353   |
| time/                   |             |
|    fps                  | 1198        |
|    iterations           | 189         |
|    time_elapsed         | 646         |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.011038043 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.7       |
|    explained_variance   | 0.846       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.624      |
|    n_updates            | 3975        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 7.36        |
|    value_loss           | 0.0826      |
-----------------------------------------
[ADAPTIVE] Episode 193 reward: 0.040722
[ADAPTIVE] Mean reward over last 20 episodes: -0.019505
[ADAPTIVE] Plateau counter: 16/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.6063858  |
| time/                   |            |
|    fps                  | 1198       |
|    iterations           | 190        |
|    time_elapsed         | 649        |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.01623011 |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.7      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.615     |
|    n_updates            | 3990       |
|    policy_gradient_loss | -0.0288    |
|    std                  | 7.4        |
|    value_loss           | 0.0922     |
----------------------------------------
[ADAPTIVE] Episode 194 reward: 0.049389
[ADAPTIVE] Mean reward over last 20 episodes: -0.016071
[ADAPTIVE] Plateau counter: 17/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.651427    |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 191         |
|    time_elapsed         | 652         |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.015165763 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.8       |
|    explained_variance   | 0.783       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.603      |
|    n_updates            | 4005        |
|    policy_gradient_loss | -0.0309     |
|    std                  | 7.41        |
|    value_loss           | 0.0968      |
-----------------------------------------
[ADAPTIVE] Episode 195 reward: 0.009669
[ADAPTIVE] Mean reward over last 20 episodes: -0.015735
[ADAPTIVE] Plateau counter: 18/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.7521344   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 192         |
|    time_elapsed         | 655         |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.015673136 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.8       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.61       |
|    n_updates            | 4020        |
|    policy_gradient_loss | -0.0274     |
|    std                  | 7.47        |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 196 reward: -0.020908
[ADAPTIVE] Mean reward over last 20 episodes: -0.017566
[ADAPTIVE] Plateau counter: 19/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.7745589  |
| time/                   |            |
|    fps                  | 1200       |
|    iterations           | 193        |
|    time_elapsed         | 658        |
|    total_timesteps      | 790528     |
| train/                  |            |
|    approx_kl            | 0.01522908 |
|    clip_fraction        | 0.169      |
|    clip_range           | 0.2        |
|    entropy_loss         | -30.9      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.626     |
|    n_updates            | 4035       |
|    policy_gradient_loss | -0.028     |
|    std                  | 7.52       |
|    value_loss           | 0.0924     |
----------------------------------------
[ADAPTIVE] Episode 197 reward: 0.066509
[ADAPTIVE] Mean reward over last 20 episodes: -0.012677
[ADAPTIVE] Plateau counter: 20/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8087616   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 194         |
|    time_elapsed         | 661         |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.016707066 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -30.9       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.622      |
|    n_updates            | 4050        |
|    policy_gradient_loss | -0.0319     |
|    std                  | 7.57        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 198 reward: 0.033391
[ADAPTIVE] Mean reward over last 20 episodes: -0.009578
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.563047   |
| time/                   |            |
|    fps                  | 1202       |
|    iterations           | 195        |
|    time_elapsed         | 664        |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.01728506 |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.2        |
|    entropy_loss         | -31        |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.614     |
|    n_updates            | 4065       |
|    policy_gradient_loss | -0.0305    |
|    std                  | 7.64       |
|    value_loss           | 0.111      |
----------------------------------------
[ADAPTIVE] Episode 199 reward: -0.061828
[ADAPTIVE] Mean reward over last 20 episodes: -0.010734
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.499476    |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 196         |
|    time_elapsed         | 667         |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.012896855 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.1       |
|    explained_variance   | 0.702       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.61       |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.0255     |
|    std                  | 7.67        |
|    value_loss           | 0.148       |
-----------------------------------------
[ADAPTIVE] Episode 200 reward: 0.029594
[ADAPTIVE] Mean reward over last 20 episodes: -0.009378
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3460506   |
| time/                   |             |
|    fps                  | 1203        |
|    iterations           | 197         |
|    time_elapsed         | 670         |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.018909326 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.1       |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.625      |
|    n_updates            | 4095        |
|    policy_gradient_loss | -0.0295     |
|    std                  | 7.72        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 201 reward: -0.011109
[ADAPTIVE] Mean reward over last 20 episodes: -0.010840
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1688795   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 198         |
|    time_elapsed         | 673         |
|    total_timesteps      | 811008      |
| train/                  |             |
|    approx_kl            | 0.017517745 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.2       |
|    explained_variance   | 0.607       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.64       |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.0316     |
|    std                  | 7.77        |
|    value_loss           | 0.0948      |
-----------------------------------------
[ADAPTIVE] Episode 202 reward: 0.046764
[ADAPTIVE] Mean reward over last 20 episodes: -0.005395
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4212703   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 199         |
|    time_elapsed         | 676         |
|    total_timesteps      | 815104      |
| train/                  |             |
|    approx_kl            | 0.014923189 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.2       |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.556      |
|    n_updates            | 4125        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 7.81        |
|    value_loss           | 0.248       |
-----------------------------------------
[ADAPTIVE] Episode 203 reward: -0.001499
[ADAPTIVE] Mean reward over last 20 episodes: -0.007612
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4467545   |
| time/                   |             |
|    fps                  | 1206        |
|    iterations           | 200         |
|    time_elapsed         | 679         |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.015442598 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.3       |
|    explained_variance   | 0.635       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.624      |
|    n_updates            | 4140        |
|    policy_gradient_loss | -0.0311     |
|    std                  | 7.87        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 204 reward: -0.032170
[ADAPTIVE] Mean reward over last 20 episodes: -0.009523
[ADAPTIVE] Plateau counter: 6/10
[ADAPTIVE] Episode 205 reward: 0.002098
[ADAPTIVE] Mean reward over last 20 episodes: -0.008481
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6448711   |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 201         |
|    time_elapsed         | 682         |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.014614632 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.3       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.619      |
|    n_updates            | 4155        |
|    policy_gradient_loss | -0.0276     |
|    std                  | 7.89        |
|    value_loss           | 0.112       |
-----------------------------------------
[ADAPTIVE] Episode 206 reward: -0.039178
[ADAPTIVE] Mean reward over last 20 episodes: -0.008896
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5791316   |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 202         |
|    time_elapsed         | 685         |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.015326319 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.4       |
|    explained_variance   | 0.727       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.627      |
|    n_updates            | 4170        |
|    policy_gradient_loss | -0.0313     |
|    std                  | 7.93        |
|    value_loss           | 0.121       |
-----------------------------------------
[ADAPTIVE] Episode 207 reward: 0.044757
[ADAPTIVE] Mean reward over last 20 episodes: -0.005778
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6587507   |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 203         |
|    time_elapsed         | 688         |
|    total_timesteps      | 831488      |
| train/                  |             |
|    approx_kl            | 0.017851494 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.4       |
|    explained_variance   | 0.498       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.607      |
|    n_updates            | 4185        |
|    policy_gradient_loss | -0.0338     |
|    std                  | 7.99        |
|    value_loss           | 0.192       |
-----------------------------------------
[ADAPTIVE] Episode 208 reward: -0.025520
[ADAPTIVE] Mean reward over last 20 episodes: -0.005634
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4541256   |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 204         |
|    time_elapsed         | 691         |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.017158814 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.5       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.636      |
|    n_updates            | 4200        |
|    policy_gradient_loss | -0.0274     |
|    std                  | 8.03        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 209 reward: -0.077877
[ADAPTIVE] Mean reward over last 20 episodes: -0.005905
[ADAPTIVE] Plateau counter: 11/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.299427    |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 205         |
|    time_elapsed         | 694         |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.017428968 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.5       |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.616      |
|    n_updates            | 4215        |
|    policy_gradient_loss | -0.0309     |
|    std                  | 8.07        |
|    value_loss           | 0.147       |
-----------------------------------------
[ADAPTIVE] Episode 210 reward: -0.041320
[ADAPTIVE] Mean reward over last 20 episodes: -0.007061
[ADAPTIVE] Plateau counter: 12/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9948741   |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 206         |
|    time_elapsed         | 698         |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.014583763 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.5       |
|    explained_variance   | 0.544       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.592      |
|    n_updates            | 4230        |
|    policy_gradient_loss | -0.0232     |
|    std                  | 8.1         |
|    value_loss           | 0.206       |
-----------------------------------------
[ADAPTIVE] Episode 211 reward: -0.041507
[ADAPTIVE] Mean reward over last 20 episodes: -0.008273
[ADAPTIVE] Plateau counter: 13/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9085964   |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 207         |
|    time_elapsed         | 701         |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.017868305 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.6       |
|    explained_variance   | 0.611       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.627      |
|    n_updates            | 4245        |
|    policy_gradient_loss | -0.0269     |
|    std                  | 8.16        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 212 reward: -0.143573
[ADAPTIVE] Mean reward over last 20 episodes: -0.008680
[ADAPTIVE] Plateau counter: 14/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9679299   |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 208         |
|    time_elapsed         | 704         |
|    total_timesteps      | 851968      |
| train/                  |             |
|    approx_kl            | 0.013072584 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.7       |
|    explained_variance   | 0.6         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.63       |
|    n_updates            | 4260        |
|    policy_gradient_loss | -0.0311     |
|    std                  | 8.22        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 213 reward: -0.079997
[ADAPTIVE] Mean reward over last 20 episodes: -0.014716
[ADAPTIVE] Plateau counter: 15/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0695038   |
| time/                   |             |
|    fps                  | 1209        |
|    iterations           | 209         |
|    time_elapsed         | 707         |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.013634281 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.7       |
|    explained_variance   | 0.619       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.622      |
|    n_updates            | 4275        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 8.24        |
|    value_loss           | 0.126       |
-----------------------------------------
[ADAPTIVE] Episode 214 reward: -0.034470
[ADAPTIVE] Mean reward over last 20 episodes: -0.018909
[ADAPTIVE] Plateau counter: 16/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.088273   |
| time/                   |            |
|    fps                  | 1210       |
|    iterations           | 210        |
|    time_elapsed         | 710        |
|    total_timesteps      | 860160     |
| train/                  |            |
|    approx_kl            | 0.01748263 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -31.7      |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.00025    |
|    loss                 | -0.65      |
|    n_updates            | 4290       |
|    policy_gradient_loss | -0.0357    |
|    std                  | 8.25       |
|    value_loss           | 0.104      |
----------------------------------------
[ADAPTIVE] Episode 215 reward: -0.115274
[ADAPTIVE] Mean reward over last 20 episodes: -0.025156
[ADAPTIVE] Plateau counter: 17/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.009436    |
| time/                   |             |
|    fps                  | 1209        |
|    iterations           | 211         |
|    time_elapsed         | 714         |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.015123159 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.7       |
|    explained_variance   | 0.578       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.645      |
|    n_updates            | 4305        |
|    policy_gradient_loss | -0.0313     |
|    std                  | 8.28        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 216 reward: 0.006866
[ADAPTIVE] Mean reward over last 20 episodes: -0.023767
[ADAPTIVE] Plateau counter: 18/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0031805   |
| time/                   |             |
|    fps                  | 1209        |
|    iterations           | 212         |
|    time_elapsed         | 717         |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.015727166 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.8       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.642      |
|    n_updates            | 4320        |
|    policy_gradient_loss | -0.0315     |
|    std                  | 8.33        |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 217 reward: 0.037849
[ADAPTIVE] Mean reward over last 20 episodes: -0.025200
[ADAPTIVE] Plateau counter: 19/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.97059286   |
| time/                   |              |
|    fps                  | 1210         |
|    iterations           | 213          |
|    time_elapsed         | 720          |
|    total_timesteps      | 872448       |
| train/                  |              |
|    approx_kl            | 0.0133819105 |
|    clip_fraction        | 0.16         |
|    clip_range           | 0.2          |
|    entropy_loss         | -31.8        |
|    explained_variance   | 0.448        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.487       |
|    n_updates            | 4335         |
|    policy_gradient_loss | -0.0222      |
|    std                  | 8.38         |
|    value_loss           | 0.38         |
------------------------------------------
[ADAPTIVE] Episode 218 reward: 0.057882
[ADAPTIVE] Mean reward over last 20 episodes: -0.023976
[ADAPTIVE] Plateau counter: 20/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0597167   |
| time/                   |             |
|    fps                  | 1210        |
|    iterations           | 214         |
|    time_elapsed         | 724         |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.013434493 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.9       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.618      |
|    n_updates            | 4350        |
|    policy_gradient_loss | -0.0314     |
|    std                  | 8.42        |
|    value_loss           | 0.177       |
-----------------------------------------
[ADAPTIVE] Episode 219 reward: 0.044554
[ADAPTIVE] Mean reward over last 20 episodes: -0.018657
[ADAPTIVE] Plateau counter: 21/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0635114   |
| time/                   |             |
|    fps                  | 1210        |
|    iterations           | 215         |
|    time_elapsed         | 727         |
|    total_timesteps      | 880640      |
| train/                  |             |
|    approx_kl            | 0.014352443 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -31.9       |
|    explained_variance   | 0.535       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.594      |
|    n_updates            | 4365        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 8.47        |
|    value_loss           | 0.281       |
-----------------------------------------
[ADAPTIVE] Episode 220 reward: 0.011069
[ADAPTIVE] Mean reward over last 20 episodes: -0.019583
[ADAPTIVE] Plateau counter: 22/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0332313   |
| time/                   |             |
|    fps                  | 1210        |
|    iterations           | 216         |
|    time_elapsed         | 730         |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.017104767 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32         |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.579      |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.025      |
|    std                  | 8.5         |
|    value_loss           | 0.178       |
-----------------------------------------
[ADAPTIVE] Episode 221 reward: -0.127136
[ADAPTIVE] Mean reward over last 20 episodes: -0.025384
[ADAPTIVE] Plateau counter: 23/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2485728   |
| time/                   |             |
|    fps                  | 1210        |
|    iterations           | 217         |
|    time_elapsed         | 734         |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.015247475 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32         |
|    explained_variance   | 0.688       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.623      |
|    n_updates            | 4395        |
|    policy_gradient_loss | -0.0285     |
|    std                  | 8.55        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 222 reward: -0.052880
[ADAPTIVE] Mean reward over last 20 episodes: -0.030366
[ADAPTIVE] Plateau counter: 24/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2456812    |
| time/                   |              |
|    fps                  | 1210         |
|    iterations           | 218          |
|    time_elapsed         | 737          |
|    total_timesteps      | 892928       |
| train/                  |              |
|    approx_kl            | 0.0118393265 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.2          |
|    entropy_loss         | -32.1        |
|    explained_variance   | 0.32         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.491       |
|    n_updates            | 4410         |
|    policy_gradient_loss | -0.0238      |
|    std                  | 8.59         |
|    value_loss           | 0.432        |
------------------------------------------
[ADAPTIVE] Episode 223 reward: -0.037841
[ADAPTIVE] Mean reward over last 20 episodes: -0.032183
[ADAPTIVE] Plateau counter: 25/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3467206   |
| time/                   |             |
|    fps                  | 1211        |
|    iterations           | 219         |
|    time_elapsed         | 740         |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.012744962 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.1       |
|    explained_variance   | 0.614       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.602      |
|    n_updates            | 4425        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 8.61        |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 224 reward: 0.040792
[ADAPTIVE] Mean reward over last 20 episodes: -0.028535
[ADAPTIVE] Plateau counter: 26/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2525519   |
| time/                   |             |
|    fps                  | 1211        |
|    iterations           | 220         |
|    time_elapsed         | 743         |
|    total_timesteps      | 901120      |
| train/                  |             |
|    approx_kl            | 0.016202219 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.1       |
|    explained_variance   | 0.553       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.616      |
|    n_updates            | 4440        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 8.67        |
|    value_loss           | 0.202       |
-----------------------------------------
[ADAPTIVE] Episode 225 reward: -0.064860
[ADAPTIVE] Mean reward over last 20 episodes: -0.031883
[ADAPTIVE] Plateau counter: 27/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2024615   |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 221         |
|    time_elapsed         | 746         |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.013999103 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.2       |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.635      |
|    n_updates            | 4455        |
|    policy_gradient_loss | -0.0265     |
|    std                  | 8.73        |
|    value_loss           | 0.109       |
-----------------------------------------
[ADAPTIVE] Episode 226 reward: -0.036110
[ADAPTIVE] Mean reward over last 20 episodes: -0.031730
[ADAPTIVE] Plateau counter: 28/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1686108   |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 222         |
|    time_elapsed         | 749         |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.016550506 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.3       |
|    explained_variance   | 0.554       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.648      |
|    n_updates            | 4470        |
|    policy_gradient_loss | -0.0277     |
|    std                  | 8.79        |
|    value_loss           | 0.109       |
-----------------------------------------
[ADAPTIVE] Episode 227 reward: -0.021213
[ADAPTIVE] Mean reward over last 20 episodes: -0.035028
[ADAPTIVE] Plateau counter: 29/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0176413   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 223         |
|    time_elapsed         | 752         |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.011153454 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.3       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.617      |
|    n_updates            | 4485        |
|    policy_gradient_loss | -0.025      |
|    std                  | 8.82        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 228 reward: 0.005149
[ADAPTIVE] Mean reward over last 20 episodes: -0.033495
[ADAPTIVE] Plateau counter: 30/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0635974   |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 224         |
|    time_elapsed         | 756         |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.016804637 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.4       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.647      |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.0326     |
|    std                  | 8.86        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 229 reward: -0.082125
[ADAPTIVE] Mean reward over last 20 episodes: -0.033707
[ADAPTIVE] Plateau counter: 31/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1132408   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 225         |
|    time_elapsed         | 759         |
|    total_timesteps      | 921600      |
| train/                  |             |
|    approx_kl            | 0.009543421 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.4       |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.628      |
|    n_updates            | 4515        |
|    policy_gradient_loss | -0.0232     |
|    std                  | 8.87        |
|    value_loss           | 0.122       |
-----------------------------------------
[ADAPTIVE] Episode 230 reward: -0.032084
[ADAPTIVE] Mean reward over last 20 episodes: -0.033245
[ADAPTIVE] Plateau counter: 32/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1814853   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 226         |
|    time_elapsed         | 763         |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.012724401 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.4       |
|    explained_variance   | 0.585       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.602      |
|    n_updates            | 4530        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 8.91        |
|    value_loss           | 0.187       |
-----------------------------------------
[ADAPTIVE] Episode 231 reward: 0.052773
[ADAPTIVE] Mean reward over last 20 episodes: -0.028531
[ADAPTIVE] Plateau counter: 33/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1832033   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 227         |
|    time_elapsed         | 765         |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.013708407 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.4       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.633      |
|    n_updates            | 4545        |
|    policy_gradient_loss | -0.0305     |
|    std                  | 8.93        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 232 reward: 0.069528
[ADAPTIVE] Mean reward over last 20 episodes: -0.017876
[ADAPTIVE] Plateau counter: 34/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2633655    |
| time/                   |              |
|    fps                  | 1213         |
|    iterations           | 228          |
|    time_elapsed         | 769          |
|    total_timesteps      | 933888       |
| train/                  |              |
|    approx_kl            | 0.0131911365 |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.2          |
|    entropy_loss         | -32.5        |
|    explained_variance   | 0.555        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.622       |
|    n_updates            | 4560         |
|    policy_gradient_loss | -0.0277      |
|    std                  | 8.97         |
|    value_loss           | 0.213        |
------------------------------------------
[ADAPTIVE] Episode 233 reward: -0.051942
[ADAPTIVE] Mean reward over last 20 episodes: -0.016474
[ADAPTIVE] Plateau counter: 35/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.3027824  |
| time/                   |            |
|    fps                  | 1214       |
|    iterations           | 229        |
|    time_elapsed         | 772        |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.01606525 |
|    clip_fraction        | 0.175      |
|    clip_range           | 0.2        |
|    entropy_loss         | -32.5      |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.591     |
|    n_updates            | 4575       |
|    policy_gradient_loss | -0.0263    |
|    std                  | 9.07       |
|    value_loss           | 0.185      |
----------------------------------------
[ADAPTIVE] Episode 234 reward: 0.006215
[ADAPTIVE] Mean reward over last 20 episodes: -0.014439
[ADAPTIVE] Plateau counter: 36/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2306601    |
| time/                   |              |
|    fps                  | 1214         |
|    iterations           | 230          |
|    time_elapsed         | 775          |
|    total_timesteps      | 942080       |
| train/                  |              |
|    approx_kl            | 0.0145352045 |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.2          |
|    entropy_loss         | -32.6        |
|    explained_variance   | 0.66         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.65        |
|    n_updates            | 4590         |
|    policy_gradient_loss | -0.0296      |
|    std                  | 9.14         |
|    value_loss           | 0.141        |
------------------------------------------
[ADAPTIVE] Episode 235 reward: -0.068606
[ADAPTIVE] Mean reward over last 20 episodes: -0.012106
[ADAPTIVE] Plateau counter: 37/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0578059   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 231         |
|    time_elapsed         | 778         |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.013644848 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.7       |
|    explained_variance   | 0.609       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.628      |
|    n_updates            | 4605        |
|    policy_gradient_loss | -0.0267     |
|    std                  | 9.18        |
|    value_loss           | 0.182       |
-----------------------------------------
[ADAPTIVE] Episode 236 reward: -0.016302
[ADAPTIVE] Mean reward over last 20 episodes: -0.013264
[ADAPTIVE] Plateau counter: 38/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9817284   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 232         |
|    time_elapsed         | 781         |
|    total_timesteps      | 950272      |
| train/                  |             |
|    approx_kl            | 0.017167373 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.7       |
|    explained_variance   | 0.592       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.599      |
|    n_updates            | 4620        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 9.21        |
|    value_loss           | 0.252       |
-----------------------------------------
[ADAPTIVE] Episode 237 reward: 0.008864
[ADAPTIVE] Mean reward over last 20 episodes: -0.014714
[ADAPTIVE] Plateau counter: 39/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9899019   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 233         |
|    time_elapsed         | 784         |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.014365367 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.7       |
|    explained_variance   | 0.715       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.648      |
|    n_updates            | 4635        |
|    policy_gradient_loss | -0.0263     |
|    std                  | 9.25        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 238 reward: -0.017029
[ADAPTIVE] Mean reward over last 20 episodes: -0.018459
[ADAPTIVE] Plateau counter: 40/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9007711   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 234         |
|    time_elapsed         | 787         |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.015549324 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.8       |
|    explained_variance   | 0.711       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.64       |
|    n_updates            | 4650        |
|    policy_gradient_loss | -0.0296     |
|    std                  | 9.27        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 239 reward: -0.100985
[ADAPTIVE] Mean reward over last 20 episodes: -0.025736
[ADAPTIVE] Plateau counter: 41/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0049173   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 235         |
|    time_elapsed         | 790         |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.013523746 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.8       |
|    explained_variance   | 0.596       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.612      |
|    n_updates            | 4665        |
|    policy_gradient_loss | -0.0249     |
|    std                  | 9.33        |
|    value_loss           | 0.224       |
-----------------------------------------
[ADAPTIVE] Episode 240 reward: -0.003463
[ADAPTIVE] Mean reward over last 20 episodes: -0.026463
[ADAPTIVE] Plateau counter: 42/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0995582   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 236         |
|    time_elapsed         | 794         |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.014178209 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.9       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.619      |
|    n_updates            | 4680        |
|    policy_gradient_loss | -0.0285     |
|    std                  | 9.39        |
|    value_loss           | 0.209       |
-----------------------------------------
[ADAPTIVE] Episode 241 reward: -0.001777
[ADAPTIVE] Mean reward over last 20 episodes: -0.020195
[ADAPTIVE] Plateau counter: 43/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2352928   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 237         |
|    time_elapsed         | 797         |
|    total_timesteps      | 970752      |
| train/                  |             |
|    approx_kl            | 0.010876364 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -32.9       |
|    explained_variance   | 0.671       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.619      |
|    n_updates            | 4695        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 9.42        |
|    value_loss           | 0.223       |
-----------------------------------------
[ADAPTIVE] Episode 242 reward: -0.017193
[ADAPTIVE] Mean reward over last 20 episodes: -0.018410
[ADAPTIVE] Plateau counter: 44/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1319407  |
| time/                   |            |
|    fps                  | 1217       |
|    iterations           | 238        |
|    time_elapsed         | 800        |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.01046513 |
|    clip_fraction        | 0.135      |
|    clip_range           | 0.2        |
|    entropy_loss         | -32.9      |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.625     |
|    n_updates            | 4710       |
|    policy_gradient_loss | -0.0285    |
|    std                  | 9.45       |
|    value_loss           | 0.187      |
----------------------------------------
[ADAPTIVE] Episode 243 reward: 0.021316
[ADAPTIVE] Mean reward over last 20 episodes: -0.015453
[ADAPTIVE] Plateau counter: 45/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2158465   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 239         |
|    time_elapsed         | 803         |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.015506669 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -33         |
|    explained_variance   | 0.495       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.61       |
|    n_updates            | 4725        |
|    policy_gradient_loss | -0.0256     |
|    std                  | 9.49        |
|    value_loss           | 0.233       |
-----------------------------------------
[ADAPTIVE] Episode 244 reward: -0.021672
[ADAPTIVE] Mean reward over last 20 episodes: -0.018576
[ADAPTIVE] Plateau counter: 46/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3254592   |
| time/                   |             |
|    fps                  | 1218        |
|    iterations           | 240         |
|    time_elapsed         | 807         |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.012015412 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33         |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.588      |
|    n_updates            | 4740        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 9.53        |
|    value_loss           | 0.226       |
-----------------------------------------
[ADAPTIVE] Episode 245 reward: 0.023432
[ADAPTIVE] Mean reward over last 20 episodes: -0.014161
[ADAPTIVE] Plateau counter: 47/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3542038   |
| time/                   |             |
|    fps                  | 1218        |
|    iterations           | 241         |
|    time_elapsed         | 810         |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.014308865 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33         |
|    explained_variance   | 0.689       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.646      |
|    n_updates            | 4755        |
|    policy_gradient_loss | -0.0261     |
|    std                  | 9.56        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 246 reward: 0.039981
[ADAPTIVE] Mean reward over last 20 episodes: -0.010357
[ADAPTIVE] Plateau counter: 48/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.052602    |
| time/                   |             |
|    fps                  | 1218        |
|    iterations           | 242         |
|    time_elapsed         | 813         |
|    total_timesteps      | 991232      |
| train/                  |             |
|    approx_kl            | 0.011345753 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.1       |
|    explained_variance   | 0.512       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.591      |
|    n_updates            | 4770        |
|    policy_gradient_loss | -0.027      |
|    std                  | 9.58        |
|    value_loss           | 0.236       |
-----------------------------------------
[ADAPTIVE] Episode 247 reward: 0.081816
[ADAPTIVE] Mean reward over last 20 episodes: -0.005205
[ADAPTIVE] Plateau counter: 49/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.001522    |
| time/                   |             |
|    fps                  | 1219        |
|    iterations           | 243         |
|    time_elapsed         | 816         |
|    total_timesteps      | 995328      |
| train/                  |             |
|    approx_kl            | 0.014605511 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.1       |
|    explained_variance   | 0.674       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.651      |
|    n_updates            | 4785        |
|    policy_gradient_loss | -0.0245     |
|    std                  | 9.64        |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 248 reward: -0.171103
[ADAPTIVE] Mean reward over last 20 episodes: -0.014018
[ADAPTIVE] Plateau counter: 50/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.108965     |
| time/                   |              |
|    fps                  | 1219         |
|    iterations           | 244          |
|    time_elapsed         | 819          |
|    total_timesteps      | 999424       |
| train/                  |              |
|    approx_kl            | 0.0135006625 |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.2          |
|    entropy_loss         | -33.1        |
|    explained_variance   | 0.542        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.62        |
|    n_updates            | 4800         |
|    policy_gradient_loss | -0.0225      |
|    std                  | 9.68         |
|    value_loss           | 0.209        |
------------------------------------------
[ADAPTIVE] Episode 249 reward: -0.003131
[ADAPTIVE] Mean reward over last 20 episodes: -0.010068
[ADAPTIVE] Plateau counter: 51/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0230856   |
| time/                   |             |
|    fps                  | 1218        |
|    iterations           | 245         |
|    time_elapsed         | 823         |
|    total_timesteps      | 1003520     |
| train/                  |             |
|    approx_kl            | 0.014621332 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.2       |
|    explained_variance   | 0.632       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.636      |
|    n_updates            | 4815        |
|    policy_gradient_loss | -0.0245     |
|    std                  | 9.72        |
|    value_loss           | 0.174       |
-----------------------------------------
[ADAPTIVE] Episode 250 reward: 0.015982
[ADAPTIVE] Mean reward over last 20 episodes: -0.007665
[ADAPTIVE] Plateau counter: 52/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.90308577  |
| time/                   |             |
|    fps                  | 1219        |
|    iterations           | 246         |
|    time_elapsed         | 826         |
|    total_timesteps      | 1007616     |
| train/                  |             |
|    approx_kl            | 0.014077013 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.2       |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.646      |
|    n_updates            | 4830        |
|    policy_gradient_loss | -0.03       |
|    std                  | 9.79        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 251 reward: -0.013418
[ADAPTIVE] Mean reward over last 20 episodes: -0.010974
[ADAPTIVE] Plateau counter: 53/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9275223    |
| time/                   |              |
|    fps                  | 1219         |
|    iterations           | 247          |
|    time_elapsed         | 829          |
|    total_timesteps      | 1011712      |
| train/                  |              |
|    approx_kl            | 0.0142839495 |
|    clip_fraction        | 0.197        |
|    clip_range           | 0.2          |
|    entropy_loss         | -33.3        |
|    explained_variance   | 0.711        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.651       |
|    n_updates            | 4845         |
|    policy_gradient_loss | -0.0277      |
|    std                  | 9.87         |
|    value_loss           | 0.139        |
------------------------------------------
[ADAPTIVE] Episode 252 reward: 0.062603
[ADAPTIVE] Mean reward over last 20 episodes: -0.011321
[ADAPTIVE] Plateau counter: 54/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0043283   |
| time/                   |             |
|    fps                  | 1220        |
|    iterations           | 248         |
|    time_elapsed         | 832         |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.014348366 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.4       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.608      |
|    n_updates            | 4860        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 9.91        |
|    value_loss           | 0.196       |
-----------------------------------------
[ADAPTIVE] Episode 253 reward: 0.091688
[ADAPTIVE] Mean reward over last 20 episodes: -0.004139
[ADAPTIVE] Plateau counter: 55/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0680128   |
| time/                   |             |
|    fps                  | 1220        |
|    iterations           | 249         |
|    time_elapsed         | 835         |
|    total_timesteps      | 1019904     |
| train/                  |             |
|    approx_kl            | 0.017247252 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.4       |
|    explained_variance   | 0.643       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.656      |
|    n_updates            | 4875        |
|    policy_gradient_loss | -0.0313     |
|    std                  | 9.97        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 254 reward: 0.002823
[ADAPTIVE] Mean reward over last 20 episodes: -0.004309
[ADAPTIVE] Plateau counter: 56/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0894184   |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 250         |
|    time_elapsed         | 838         |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.014194569 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.4       |
|    explained_variance   | 0.711       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.651      |
|    n_updates            | 4890        |
|    policy_gradient_loss | -0.0292     |
|    std                  | 10          |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 255 reward: 0.086899
[ADAPTIVE] Mean reward over last 20 episodes: 0.003467
[ADAPTIVE] Episode 256 reward: 0.065272
[ADAPTIVE] Mean reward over last 20 episodes: 0.007545
[ADAPTIVE] Plateau counter: 1/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1614035    |
| time/                   |              |
|    fps                  | 1220         |
|    iterations           | 251          |
|    time_elapsed         | 842          |
|    total_timesteps      | 1028096      |
| train/                  |              |
|    approx_kl            | 0.0129147135 |
|    clip_fraction        | 0.142        |
|    clip_range           | 0.2          |
|    entropy_loss         | -33.5        |
|    explained_variance   | 0.617        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.584       |
|    n_updates            | 4905         |
|    policy_gradient_loss | -0.0233      |
|    std                  | 10.1         |
|    value_loss           | 0.249        |
------------------------------------------
[ADAPTIVE] Episode 257 reward: -0.070267
[ADAPTIVE] Mean reward over last 20 episodes: 0.003589
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.168089    |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 252         |
|    time_elapsed         | 844         |
|    total_timesteps      | 1032192     |
| train/                  |             |
|    approx_kl            | 0.013230054 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.5       |
|    explained_variance   | 0.715       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.657      |
|    n_updates            | 4920        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 10.1        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 258 reward: -0.066232
[ADAPTIVE] Mean reward over last 20 episodes: 0.001129
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.10386     |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 253         |
|    time_elapsed         | 848         |
|    total_timesteps      | 1036288     |
| train/                  |             |
|    approx_kl            | 0.015552761 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.6       |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.65       |
|    n_updates            | 4935        |
|    policy_gradient_loss | -0.0273     |
|    std                  | 10.2        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 259 reward: -0.021114
[ADAPTIVE] Mean reward over last 20 episodes: 0.005122
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9627053   |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 254         |
|    time_elapsed         | 851         |
|    total_timesteps      | 1040384     |
| train/                  |             |
|    approx_kl            | 0.017456558 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.6       |
|    explained_variance   | 0.534       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.639      |
|    n_updates            | 4950        |
|    policy_gradient_loss | -0.0277     |
|    std                  | 10.2        |
|    value_loss           | 0.212       |
-----------------------------------------
[ADAPTIVE] Episode 260 reward: 0.002510
[ADAPTIVE] Mean reward over last 20 episodes: 0.005421
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.91496086  |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 255         |
|    time_elapsed         | 854         |
|    total_timesteps      | 1044480     |
| train/                  |             |
|    approx_kl            | 0.013001087 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.7       |
|    explained_variance   | 0.661       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.649      |
|    n_updates            | 4965        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 10.3        |
|    value_loss           | 0.177       |
-----------------------------------------
[ADAPTIVE] Episode 261 reward: -0.013005
[ADAPTIVE] Mean reward over last 20 episodes: 0.004859
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0769358   |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 256         |
|    time_elapsed         | 858         |
|    total_timesteps      | 1048576     |
| train/                  |             |
|    approx_kl            | 0.015842943 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.7       |
|    explained_variance   | 0.726       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.67       |
|    n_updates            | 4980        |
|    policy_gradient_loss | -0.0291     |
|    std                  | 10.4        |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 262 reward: -0.021094
[ADAPTIVE] Mean reward over last 20 episodes: 0.004664
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0697216   |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 257         |
|    time_elapsed         | 861         |
|    total_timesteps      | 1052672     |
| train/                  |             |
|    approx_kl            | 0.010411454 |
|    clip_fraction        | 0.0989      |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.8       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.658      |
|    n_updates            | 4995        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 10.4        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 263 reward: -0.008905
[ADAPTIVE] Mean reward over last 20 episodes: 0.003153
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9887369   |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 258         |
|    time_elapsed         | 864         |
|    total_timesteps      | 1056768     |
| train/                  |             |
|    approx_kl            | 0.014108084 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.8       |
|    explained_variance   | 0.685       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.661      |
|    n_updates            | 5010        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 10.5        |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 264 reward: 0.055537
[ADAPTIVE] Mean reward over last 20 episodes: 0.007014
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.125102    |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 259         |
|    time_elapsed         | 867         |
|    total_timesteps      | 1060864     |
| train/                  |             |
|    approx_kl            | 0.013316892 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -33.9       |
|    explained_variance   | 0.545       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.624      |
|    n_updates            | 5025        |
|    policy_gradient_loss | -0.0242     |
|    std                  | 10.5        |
|    value_loss           | 0.218       |
-----------------------------------------
[ADAPTIVE] Episode 265 reward: 0.007927
[ADAPTIVE] Mean reward over last 20 episodes: 0.006238
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3344165    |
| time/                   |              |
|    fps                  | 1222         |
|    iterations           | 260          |
|    time_elapsed         | 871          |
|    total_timesteps      | 1064960      |
| train/                  |              |
|    approx_kl            | 0.0148606915 |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.2          |
|    entropy_loss         | -33.9        |
|    explained_variance   | 0.734        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.68        |
|    n_updates            | 5040         |
|    policy_gradient_loss | -0.0287      |
|    std                  | 10.6         |
|    value_loss           | 0.0908       |
------------------------------------------
[ADAPTIVE] Episode 266 reward: 0.000890
[ADAPTIVE] Mean reward over last 20 episodes: 0.004284
[ADAPTIVE] Plateau counter: 11/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2803009    |
| time/                   |              |
|    fps                  | 1222         |
|    iterations           | 261          |
|    time_elapsed         | 874          |
|    total_timesteps      | 1069056      |
| train/                  |              |
|    approx_kl            | 0.0144420285 |
|    clip_fraction        | 0.176        |
|    clip_range           | 0.2          |
|    entropy_loss         | -34          |
|    explained_variance   | 0.551        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.669       |
|    n_updates            | 5055         |
|    policy_gradient_loss | -0.0283      |
|    std                  | 10.6         |
|    value_loss           | 0.169        |
------------------------------------------
[ADAPTIVE] Episode 267 reward: 0.129571
[ADAPTIVE] Mean reward over last 20 episodes: 0.006672
[ADAPTIVE] Plateau counter: 12/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1377435  |
| time/                   |            |
|    fps                  | 1222       |
|    iterations           | 262        |
|    time_elapsed         | 877        |
|    total_timesteps      | 1073152    |
| train/                  |            |
|    approx_kl            | 0.01607335 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.2        |
|    entropy_loss         | -34        |
|    explained_variance   | 0.691      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.679     |
|    n_updates            | 5070       |
|    policy_gradient_loss | -0.0285    |
|    std                  | 10.7       |
|    value_loss           | 0.1        |
----------------------------------------
[ADAPTIVE] Episode 268 reward: -0.051740
[ADAPTIVE] Mean reward over last 20 episodes: 0.012640
[ADAPTIVE] Plateau counter: 13/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0675623   |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 263         |
|    time_elapsed         | 881         |
|    total_timesteps      | 1077248     |
| train/                  |             |
|    approx_kl            | 0.013494302 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.1       |
|    explained_variance   | 0.682       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.67       |
|    n_updates            | 5085        |
|    policy_gradient_loss | -0.028      |
|    std                  | 10.7        |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 269 reward: 0.088717
[ADAPTIVE] Mean reward over last 20 episodes: 0.017232
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.97898394  |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 264         |
|    time_elapsed         | 884         |
|    total_timesteps      | 1081344     |
| train/                  |             |
|    approx_kl            | 0.015124533 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.1       |
|    explained_variance   | 0.219       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.559      |
|    n_updates            | 5100        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 10.8        |
|    value_loss           | 0.321       |
-----------------------------------------
[ADAPTIVE] Episode 270 reward: -0.063344
[ADAPTIVE] Mean reward over last 20 episodes: 0.013266
[ADAPTIVE] Plateau counter: 1/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.95969474   |
| time/                   |              |
|    fps                  | 1222         |
|    iterations           | 265          |
|    time_elapsed         | 887          |
|    total_timesteps      | 1085440      |
| train/                  |              |
|    approx_kl            | 0.0105878245 |
|    clip_fraction        | 0.146        |
|    clip_range           | 0.2          |
|    entropy_loss         | -34.2        |
|    explained_variance   | 0.547        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.637       |
|    n_updates            | 5115         |
|    policy_gradient_loss | -0.0216      |
|    std                  | 10.8         |
|    value_loss           | 0.233        |
------------------------------------------
[ADAPTIVE] Episode 271 reward: 0.003872
[ADAPTIVE] Mean reward over last 20 episodes: 0.014130
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0602094   |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 266         |
|    time_elapsed         | 890         |
|    total_timesteps      | 1089536     |
| train/                  |             |
|    approx_kl            | 0.014889015 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.2       |
|    explained_variance   | 0.595       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.654      |
|    n_updates            | 5130        |
|    policy_gradient_loss | -0.0254     |
|    std                  | 10.9        |
|    value_loss           | 0.175       |
-----------------------------------------
[ADAPTIVE] Episode 272 reward: -0.051045
[ADAPTIVE] Mean reward over last 20 episodes: 0.008448
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0724746   |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 267         |
|    time_elapsed         | 893         |
|    total_timesteps      | 1093632     |
| train/                  |             |
|    approx_kl            | 0.013200417 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.2       |
|    explained_variance   | 0.624       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.637      |
|    n_updates            | 5145        |
|    policy_gradient_loss | -0.023      |
|    std                  | 10.9        |
|    value_loss           | 0.187       |
-----------------------------------------
[ADAPTIVE] Episode 273 reward: 0.071303
[ADAPTIVE] Mean reward over last 20 episodes: 0.007429
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1778189   |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 268         |
|    time_elapsed         | 897         |
|    total_timesteps      | 1097728     |
| train/                  |             |
|    approx_kl            | 0.013085639 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.3       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.686      |
|    n_updates            | 5160        |
|    policy_gradient_loss | -0.0258     |
|    std                  | 11          |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 274 reward: -0.111939
[ADAPTIVE] Mean reward over last 20 episodes: 0.001691
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.219263    |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 269         |
|    time_elapsed         | 900         |
|    total_timesteps      | 1101824     |
| train/                  |             |
|    approx_kl            | 0.013968773 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.3       |
|    explained_variance   | 0.607       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.667      |
|    n_updates            | 5175        |
|    policy_gradient_loss | -0.0251     |
|    std                  | 11          |
|    value_loss           | 0.138       |
-----------------------------------------
[ADAPTIVE] Episode 275 reward: 0.045481
[ADAPTIVE] Mean reward over last 20 episodes: -0.000380
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0816137   |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 270         |
|    time_elapsed         | 903         |
|    total_timesteps      | 1105920     |
| train/                  |             |
|    approx_kl            | 0.009733928 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.3       |
|    explained_variance   | 0.676       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.657      |
|    n_updates            | 5190        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 11          |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 276 reward: -0.128299
[ADAPTIVE] Mean reward over last 20 episodes: -0.010059
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1406785   |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 271         |
|    time_elapsed         | 906         |
|    total_timesteps      | 1110016     |
| train/                  |             |
|    approx_kl            | 0.012998421 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.4       |
|    explained_variance   | 0.504       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.617      |
|    n_updates            | 5205        |
|    policy_gradient_loss | -0.0225     |
|    std                  | 11.1        |
|    value_loss           | 0.297       |
-----------------------------------------
[ADAPTIVE] Episode 277 reward: 0.068736
[ADAPTIVE] Mean reward over last 20 episodes: -0.003109
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1024472   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 272         |
|    time_elapsed         | 909         |
|    total_timesteps      | 1114112     |
| train/                  |             |
|    approx_kl            | 0.014872735 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.4       |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.686      |
|    n_updates            | 5220        |
|    policy_gradient_loss | -0.0259     |
|    std                  | 11.1        |
|    value_loss           | 0.112       |
-----------------------------------------
[ADAPTIVE] Episode 278 reward: -0.005752
[ADAPTIVE] Mean reward over last 20 episodes: -0.000085
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0384517   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 273         |
|    time_elapsed         | 913         |
|    total_timesteps      | 1118208     |
| train/                  |             |
|    approx_kl            | 0.017374625 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.5       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.649      |
|    n_updates            | 5235        |
|    policy_gradient_loss | -0.0214     |
|    std                  | 11.2        |
|    value_loss           | 0.202       |
-----------------------------------------
[ADAPTIVE] Episode 279 reward: -0.021639
[ADAPTIVE] Mean reward over last 20 episodes: -0.000111
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9240831   |
| time/                   |             |
|    fps                  | 1225        |
|    iterations           | 274         |
|    time_elapsed         | 916         |
|    total_timesteps      | 1122304     |
| train/                  |             |
|    approx_kl            | 0.014186166 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.5       |
|    explained_variance   | 0.591       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.667      |
|    n_updates            | 5250        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 11.3        |
|    value_loss           | 0.249       |
-----------------------------------------
[ADAPTIVE] Episode 280 reward: 0.073876
[ADAPTIVE] Mean reward over last 20 episodes: 0.003457
[ADAPTIVE] Plateau counter: 11/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0274732   |
| time/                   |             |
|    fps                  | 1225        |
|    iterations           | 275         |
|    time_elapsed         | 919         |
|    total_timesteps      | 1126400     |
| train/                  |             |
|    approx_kl            | 0.013195686 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.6       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.687      |
|    n_updates            | 5265        |
|    policy_gradient_loss | -0.0238     |
|    std                  | 11.3        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 281 reward: 0.027512
[ADAPTIVE] Mean reward over last 20 episodes: 0.005483
[ADAPTIVE] Plateau counter: 12/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.937318    |
| time/                   |             |
|    fps                  | 1225        |
|    iterations           | 276         |
|    time_elapsed         | 922         |
|    total_timesteps      | 1130496     |
| train/                  |             |
|    approx_kl            | 0.011631479 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.6       |
|    explained_variance   | 0.425       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.634      |
|    n_updates            | 5280        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 11.4        |
|    value_loss           | 0.291       |
-----------------------------------------
[ADAPTIVE] Episode 282 reward: 0.009370
[ADAPTIVE] Mean reward over last 20 episodes: 0.007006
[ADAPTIVE] Plateau counter: 13/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9907238   |
| time/                   |             |
|    fps                  | 1225        |
|    iterations           | 277         |
|    time_elapsed         | 925         |
|    total_timesteps      | 1134592     |
| train/                  |             |
|    approx_kl            | 0.013694018 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.7       |
|    explained_variance   | 0.627       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.654      |
|    n_updates            | 5295        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 11.5        |
|    value_loss           | 0.182       |
-----------------------------------------
[ADAPTIVE] Episode 283 reward: -0.072345
[ADAPTIVE] Mean reward over last 20 episodes: 0.003834
[ADAPTIVE] Plateau counter: 14/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.019985    |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 278         |
|    time_elapsed         | 928         |
|    total_timesteps      | 1138688     |
| train/                  |             |
|    approx_kl            | 0.011229855 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.7       |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.657      |
|    n_updates            | 5310        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 11.5        |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 284 reward: -0.016866
[ADAPTIVE] Mean reward over last 20 episodes: 0.000214
[ADAPTIVE] Plateau counter: 15/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.95090944  |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 279         |
|    time_elapsed         | 931         |
|    total_timesteps      | 1142784     |
| train/                  |             |
|    approx_kl            | 0.011259944 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.8       |
|    explained_variance   | 0.594       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.632      |
|    n_updates            | 5325        |
|    policy_gradient_loss | -0.0249     |
|    std                  | 11.6        |
|    value_loss           | 0.206       |
-----------------------------------------
[ADAPTIVE] Episode 285 reward: 0.056249
[ADAPTIVE] Mean reward over last 20 episodes: 0.002630
[ADAPTIVE] Plateau counter: 16/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.075752    |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 280         |
|    time_elapsed         | 934         |
|    total_timesteps      | 1146880     |
| train/                  |             |
|    approx_kl            | 0.014129901 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.8       |
|    explained_variance   | 0.488       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.556      |
|    n_updates            | 5340        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 11.6        |
|    value_loss           | 0.341       |
-----------------------------------------
[ADAPTIVE] Episode 286 reward: 0.016008
[ADAPTIVE] Mean reward over last 20 episodes: 0.003386
[ADAPTIVE] Plateau counter: 17/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1407092   |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 281         |
|    time_elapsed         | 938         |
|    total_timesteps      | 1150976     |
| train/                  |             |
|    approx_kl            | 0.008805395 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.8       |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.641      |
|    n_updates            | 5355        |
|    policy_gradient_loss | -0.023      |
|    std                  | 11.7        |
|    value_loss           | 0.216       |
-----------------------------------------
[ADAPTIVE] Episode 287 reward: -0.008219
[ADAPTIVE] Mean reward over last 20 episodes: -0.003503
[ADAPTIVE] Plateau counter: 18/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1355432   |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 282         |
|    time_elapsed         | 941         |
|    total_timesteps      | 1155072     |
| train/                  |             |
|    approx_kl            | 0.012016011 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.9       |
|    explained_variance   | 0.52        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.654      |
|    n_updates            | 5370        |
|    policy_gradient_loss | -0.022      |
|    std                  | 11.7        |
|    value_loss           | 0.195       |
-----------------------------------------
[ADAPTIVE] Episode 288 reward: -0.014609
[ADAPTIVE] Mean reward over last 20 episodes: -0.001647
[ADAPTIVE] Plateau counter: 19/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1503171  |
| time/                   |            |
|    fps                  | 1227       |
|    iterations           | 283        |
|    time_elapsed         | 944        |
|    total_timesteps      | 1159168    |
| train/                  |            |
|    approx_kl            | 0.01213915 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.2        |
|    entropy_loss         | -34.9      |
|    explained_variance   | 0.498      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.661     |
|    n_updates            | 5385       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 11.8       |
|    value_loss           | 0.224      |
----------------------------------------
[ADAPTIVE] Episode 289 reward: -0.028001
[ADAPTIVE] Mean reward over last 20 episodes: -0.007483
[ADAPTIVE] Plateau counter: 20/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0784818   |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 284         |
|    time_elapsed         | 947         |
|    total_timesteps      | 1163264     |
| train/                  |             |
|    approx_kl            | 0.011199003 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -34.9       |
|    explained_variance   | 0.554       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.651      |
|    n_updates            | 5400        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 11.8        |
|    value_loss           | 0.212       |
-----------------------------------------
[ADAPTIVE] Episode 290 reward: 0.006633
[ADAPTIVE] Mean reward over last 20 episodes: -0.003984
[ADAPTIVE] Plateau counter: 21/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2032418   |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 285         |
|    time_elapsed         | 950         |
|    total_timesteps      | 1167360     |
| train/                  |             |
|    approx_kl            | 0.015125243 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35         |
|    explained_variance   | 0.664       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.697      |
|    n_updates            | 5415        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 11.9        |
|    value_loss           | 0.142       |
-----------------------------------------
[ADAPTIVE] Episode 291 reward: 0.004178
[ADAPTIVE] Mean reward over last 20 episodes: -0.003968
[ADAPTIVE] Plateau counter: 22/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2470467   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 286         |
|    time_elapsed         | 953         |
|    total_timesteps      | 1171456     |
| train/                  |             |
|    approx_kl            | 0.014398619 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35         |
|    explained_variance   | 0.636       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.675      |
|    n_updates            | 5430        |
|    policy_gradient_loss | -0.0257     |
|    std                  | 11.9        |
|    value_loss           | 0.173       |
-----------------------------------------
[ADAPTIVE] Episode 292 reward: -0.165379
[ADAPTIVE] Mean reward over last 20 episodes: -0.009685
[ADAPTIVE] Plateau counter: 23/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0865763   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 287         |
|    time_elapsed         | 956         |
|    total_timesteps      | 1175552     |
| train/                  |             |
|    approx_kl            | 0.014067301 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.1       |
|    explained_variance   | 0.631       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.669      |
|    n_updates            | 5445        |
|    policy_gradient_loss | -0.0249     |
|    std                  | 12.1        |
|    value_loss           | 0.168       |
-----------------------------------------
[ADAPTIVE] Episode 293 reward: 0.014646
[ADAPTIVE] Mean reward over last 20 episodes: -0.012518
[ADAPTIVE] Plateau counter: 24/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0884969   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 288         |
|    time_elapsed         | 959         |
|    total_timesteps      | 1179648     |
| train/                  |             |
|    approx_kl            | 0.013933306 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.2       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.692      |
|    n_updates            | 5460        |
|    policy_gradient_loss | -0.028      |
|    std                  | 12.1        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 294 reward: -0.054385
[ADAPTIVE] Mean reward over last 20 episodes: -0.009640
[ADAPTIVE] Plateau counter: 25/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0213162   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 289         |
|    time_elapsed         | 963         |
|    total_timesteps      | 1183744     |
| train/                  |             |
|    approx_kl            | 0.012452092 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.2       |
|    explained_variance   | 0.644       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.679      |
|    n_updates            | 5475        |
|    policy_gradient_loss | -0.0263     |
|    std                  | 12.2        |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 295 reward: 0.081350
[ADAPTIVE] Mean reward over last 20 episodes: -0.007847
[ADAPTIVE] Plateau counter: 26/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.927212    |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 290         |
|    time_elapsed         | 966         |
|    total_timesteps      | 1187840     |
| train/                  |             |
|    approx_kl            | 0.014834181 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.2       |
|    explained_variance   | 0.669       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.701      |
|    n_updates            | 5490        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 12.2        |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 296 reward: 0.076836
[ADAPTIVE] Mean reward over last 20 episodes: 0.002410
[ADAPTIVE] Plateau counter: 27/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1390184  |
| time/                   |            |
|    fps                  | 1229       |
|    iterations           | 291        |
|    time_elapsed         | 969        |
|    total_timesteps      | 1191936    |
| train/                  |            |
|    approx_kl            | 0.01326875 |
|    clip_fraction        | 0.145      |
|    clip_range           | 0.2        |
|    entropy_loss         | -35.3      |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.606     |
|    n_updates            | 5505       |
|    policy_gradient_loss | -0.0196    |
|    std                  | 12.3       |
|    value_loss           | 0.348      |
----------------------------------------
[ADAPTIVE] Episode 297 reward: -0.017639
[ADAPTIVE] Mean reward over last 20 episodes: -0.001909
[ADAPTIVE] Plateau counter: 28/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9372226   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 292         |
|    time_elapsed         | 972         |
|    total_timesteps      | 1196032     |
| train/                  |             |
|    approx_kl            | 0.017424323 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.4       |
|    explained_variance   | 0.533       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.664      |
|    n_updates            | 5520        |
|    policy_gradient_loss | -0.0253     |
|    std                  | 12.4        |
|    value_loss           | 0.255       |
-----------------------------------------
[ADAPTIVE] Episode 298 reward: -0.077363
[ADAPTIVE] Mean reward over last 20 episodes: -0.005489
[ADAPTIVE] Plateau counter: 29/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.96121466 |
| time/                   |            |
|    fps                  | 1229       |
|    iterations           | 293        |
|    time_elapsed         | 975        |
|    total_timesteps      | 1200128    |
| train/                  |            |
|    approx_kl            | 0.0115842  |
|    clip_fraction        | 0.141      |
|    clip_range           | 0.2        |
|    entropy_loss         | -35.4      |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.698     |
|    n_updates            | 5535       |
|    policy_gradient_loss | -0.0257    |
|    std                  | 12.5       |
|    value_loss           | 0.129      |
----------------------------------------
[ADAPTIVE] Episode 299 reward: 0.052603
[ADAPTIVE] Mean reward over last 20 episodes: -0.001777
[ADAPTIVE] Plateau counter: 30/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.87929416 |
| time/                   |            |
|    fps                  | 1229       |
|    iterations           | 294        |
|    time_elapsed         | 979        |
|    total_timesteps      | 1204224    |
| train/                  |            |
|    approx_kl            | 0.0176868  |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -35.5      |
|    explained_variance   | 0.666      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.682     |
|    n_updates            | 5550       |
|    policy_gradient_loss | -0.0266    |
|    std                  | 12.6       |
|    value_loss           | 0.195      |
----------------------------------------
[ADAPTIVE] Episode 300 reward: 0.010028
[ADAPTIVE] Mean reward over last 20 episodes: -0.004969
[ADAPTIVE] Plateau counter: 31/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.85407823  |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 295         |
|    time_elapsed         | 982         |
|    total_timesteps      | 1208320     |
| train/                  |             |
|    approx_kl            | 0.011898338 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.5       |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.69       |
|    n_updates            | 5565        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 12.7        |
|    value_loss           | 0.152       |
-----------------------------------------
[ADAPTIVE] Episode 301 reward: -0.107357
[ADAPTIVE] Mean reward over last 20 episodes: -0.011713
[ADAPTIVE] Plateau counter: 32/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.89696383 |
| time/                   |            |
|    fps                  | 1229       |
|    iterations           | 296        |
|    time_elapsed         | 985        |
|    total_timesteps      | 1212416    |
| train/                  |            |
|    approx_kl            | 0.01142503 |
|    clip_fraction        | 0.0972     |
|    clip_range           | 0.2        |
|    entropy_loss         | -35.6      |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.698     |
|    n_updates            | 5580       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 12.7       |
|    value_loss           | 0.125      |
----------------------------------------
[ADAPTIVE] Episode 302 reward: -0.051430
[ADAPTIVE] Mean reward over last 20 episodes: -0.014753
[ADAPTIVE] Plateau counter: 33/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8612619   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 297         |
|    time_elapsed         | 989         |
|    total_timesteps      | 1216512     |
| train/                  |             |
|    approx_kl            | 0.013944086 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.6       |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.708      |
|    n_updates            | 5595        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 12.7        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 303 reward: -0.083884
[ADAPTIVE] Mean reward over last 20 episodes: -0.015330
[ADAPTIVE] Plateau counter: 34/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.8588723  |
| time/                   |            |
|    fps                  | 1229       |
|    iterations           | 298        |
|    time_elapsed         | 992        |
|    total_timesteps      | 1220608    |
| train/                  |            |
|    approx_kl            | 0.01695837 |
|    clip_fraction        | 0.168      |
|    clip_range           | 0.2        |
|    entropy_loss         | -35.6      |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.711     |
|    n_updates            | 5610       |
|    policy_gradient_loss | -0.0284    |
|    std                  | 12.8       |
|    value_loss           | 0.0939     |
----------------------------------------
[ADAPTIVE] Episode 304 reward: 0.081901
[ADAPTIVE] Mean reward over last 20 episodes: -0.010392
[ADAPTIVE] Plateau counter: 35/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.96163803  |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 299         |
|    time_elapsed         | 995         |
|    total_timesteps      | 1224704     |
| train/                  |             |
|    approx_kl            | 0.013558001 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.7       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.714      |
|    n_updates            | 5625        |
|    policy_gradient_loss | -0.0253     |
|    std                  | 12.8        |
|    value_loss           | 0.12        |
-----------------------------------------
[ADAPTIVE] Episode 305 reward: -0.025667
[ADAPTIVE] Mean reward over last 20 episodes: -0.014487
[ADAPTIVE] Plateau counter: 36/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1034555   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 300         |
|    time_elapsed         | 998         |
|    total_timesteps      | 1228800     |
| train/                  |             |
|    approx_kl            | 0.015242858 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.8       |
|    explained_variance   | 0.578       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.714      |
|    n_updates            | 5640        |
|    policy_gradient_loss | -0.0264     |
|    std                  | 13          |
|    value_loss           | 0.0994      |
-----------------------------------------
[ADAPTIVE] Episode 306 reward: -0.006948
[ADAPTIVE] Mean reward over last 20 episodes: -0.015635
[ADAPTIVE] Plateau counter: 37/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1528085   |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 301         |
|    time_elapsed         | 1001        |
|    total_timesteps      | 1232896     |
| train/                  |             |
|    approx_kl            | 0.011882674 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.8       |
|    explained_variance   | 0.587       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.717      |
|    n_updates            | 5655        |
|    policy_gradient_loss | -0.0244     |
|    std                  | 13          |
|    value_loss           | 0.0984      |
-----------------------------------------
[ADAPTIVE] Episode 307 reward: -0.058591
[ADAPTIVE] Mean reward over last 20 episodes: -0.018154
[ADAPTIVE] Plateau counter: 38/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 308 reward: -0.005304
[ADAPTIVE] Mean reward over last 20 episodes: -0.017689
[ADAPTIVE] Plateau counter: 39/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1920239   |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 302         |
|    time_elapsed         | 1004        |
|    total_timesteps      | 1236992     |
| train/                  |             |
|    approx_kl            | 0.013080281 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.9       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.732      |
|    n_updates            | 5670        |
|    policy_gradient_loss | -0.0281     |
|    std                  | 13.1        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 309 reward: 0.036691
[ADAPTIVE] Mean reward over last 20 episodes: -0.014454
[ADAPTIVE] Plateau counter: 40/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0531797   |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 303         |
|    time_elapsed         | 1008        |
|    total_timesteps      | 1241088     |
| train/                  |             |
|    approx_kl            | 0.011366635 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -35.9       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.721      |
|    n_updates            | 5685        |
|    policy_gradient_loss | -0.0261     |
|    std                  | 13.2        |
|    value_loss           | 0.0827      |
-----------------------------------------
[ADAPTIVE] Episode 310 reward: 0.038667
[ADAPTIVE] Mean reward over last 20 episodes: -0.012852
[ADAPTIVE] Plateau counter: 41/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1438303   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 304         |
|    time_elapsed         | 1011        |
|    total_timesteps      | 1245184     |
| train/                  |             |
|    approx_kl            | 0.014096396 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36         |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.707      |
|    n_updates            | 5700        |
|    policy_gradient_loss | -0.0274     |
|    std                  | 13.3        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 311 reward: -0.000586
[ADAPTIVE] Mean reward over last 20 episodes: -0.013091
[ADAPTIVE] Plateau counter: 42/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9715652   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 305         |
|    time_elapsed         | 1015        |
|    total_timesteps      | 1249280     |
| train/                  |             |
|    approx_kl            | 0.011970468 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36         |
|    explained_variance   | 0.601       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.729      |
|    n_updates            | 5715        |
|    policy_gradient_loss | -0.0288     |
|    std                  | 13.3        |
|    value_loss           | 0.0942      |
-----------------------------------------
[ADAPTIVE] Episode 312 reward: 0.033928
[ADAPTIVE] Mean reward over last 20 episodes: -0.003125
[ADAPTIVE] Plateau counter: 43/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.98640436 |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 306        |
|    time_elapsed         | 1018       |
|    total_timesteps      | 1253376    |
| train/                  |            |
|    approx_kl            | 0.01367146 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -36.1      |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.7       |
|    n_updates            | 5730       |
|    policy_gradient_loss | -0.0227    |
|    std                  | 13.4       |
|    value_loss           | 0.179      |
----------------------------------------
[ADAPTIVE] Episode 313 reward: -0.038184
[ADAPTIVE] Mean reward over last 20 episodes: -0.005767
[ADAPTIVE] Plateau counter: 44/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.95210695  |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 307         |
|    time_elapsed         | 1021        |
|    total_timesteps      | 1257472     |
| train/                  |             |
|    approx_kl            | 0.009172471 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.1       |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.679      |
|    n_updates            | 5745        |
|    policy_gradient_loss | -0.0214     |
|    std                  | 13.5        |
|    value_loss           | 0.14        |
-----------------------------------------
[ADAPTIVE] Episode 314 reward: 0.096019
[ADAPTIVE] Mean reward over last 20 episodes: 0.001753
[ADAPTIVE] Plateau counter: 45/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9509757   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 308         |
|    time_elapsed         | 1024        |
|    total_timesteps      | 1261568     |
| train/                  |             |
|    approx_kl            | 0.010835321 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.1       |
|    explained_variance   | 0.486       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.684      |
|    n_updates            | 5760        |
|    policy_gradient_loss | -0.017      |
|    std                  | 13.5        |
|    value_loss           | 0.238       |
-----------------------------------------
[ADAPTIVE] Episode 315 reward: 0.024447
[ADAPTIVE] Mean reward over last 20 episodes: -0.001092
[ADAPTIVE] Plateau counter: 46/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98667645  |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 309         |
|    time_elapsed         | 1028        |
|    total_timesteps      | 1265664     |
| train/                  |             |
|    approx_kl            | 0.013943146 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.2       |
|    explained_variance   | 0.536       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.691      |
|    n_updates            | 5775        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 13.6        |
|    value_loss           | 0.175       |
-----------------------------------------
[ADAPTIVE] Episode 316 reward: -0.031616
[ADAPTIVE] Mean reward over last 20 episodes: -0.006514
[ADAPTIVE] Plateau counter: 47/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.951112    |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 310         |
|    time_elapsed         | 1031        |
|    total_timesteps      | 1269760     |
| train/                  |             |
|    approx_kl            | 0.012461274 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.3       |
|    explained_variance   | 0.609       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.703      |
|    n_updates            | 5790        |
|    policy_gradient_loss | -0.0256     |
|    std                  | 13.8        |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 317 reward: -0.041125
[ADAPTIVE] Mean reward over last 20 episodes: -0.007689
[ADAPTIVE] Plateau counter: 48/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1657544  |
| time/                   |            |
|    fps                  | 1231       |
|    iterations           | 311        |
|    time_elapsed         | 1034       |
|    total_timesteps      | 1273856    |
| train/                  |            |
|    approx_kl            | 0.00996118 |
|    clip_fraction        | 0.138      |
|    clip_range           | 0.2        |
|    entropy_loss         | -36.3      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.704     |
|    n_updates            | 5805       |
|    policy_gradient_loss | -0.0214    |
|    std                  | 13.8       |
|    value_loss           | 0.154      |
----------------------------------------
[ADAPTIVE] Episode 318 reward: -0.001258
[ADAPTIVE] Mean reward over last 20 episodes: -0.003883
[ADAPTIVE] Plateau counter: 49/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.172156   |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 312        |
|    time_elapsed         | 1038       |
|    total_timesteps      | 1277952    |
| train/                  |            |
|    approx_kl            | 0.01132834 |
|    clip_fraction        | 0.142      |
|    clip_range           | 0.2        |
|    entropy_loss         | -36.4      |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.737     |
|    n_updates            | 5820       |
|    policy_gradient_loss | -0.0245    |
|    std                  | 13.8       |
|    value_loss           | 0.0887     |
----------------------------------------
[ADAPTIVE] Episode 319 reward: -0.127401
[ADAPTIVE] Mean reward over last 20 episodes: -0.012884
[ADAPTIVE] Plateau counter: 50/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2660351   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 313         |
|    time_elapsed         | 1041        |
|    total_timesteps      | 1282048     |
| train/                  |             |
|    approx_kl            | 0.012419783 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.4       |
|    explained_variance   | 0.761       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.733      |
|    n_updates            | 5835        |
|    policy_gradient_loss | -0.0267     |
|    std                  | 13.9        |
|    value_loss           | 0.0878      |
-----------------------------------------
[ADAPTIVE] Episode 320 reward: 0.060654
[ADAPTIVE] Mean reward over last 20 episodes: -0.010352
[ADAPTIVE] Plateau counter: 51/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4315453   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 314         |
|    time_elapsed         | 1045        |
|    total_timesteps      | 1286144     |
| train/                  |             |
|    approx_kl            | 0.011935895 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.5       |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.709      |
|    n_updates            | 5850        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 14          |
|    value_loss           | 0.156       |
-----------------------------------------
[ADAPTIVE] Episode 321 reward: 0.045561
[ADAPTIVE] Mean reward over last 20 episodes: -0.002706
[ADAPTIVE] Plateau counter: 52/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4419953   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 315         |
|    time_elapsed         | 1048        |
|    total_timesteps      | 1290240     |
| train/                  |             |
|    approx_kl            | 0.011247296 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.5       |
|    explained_variance   | 0.65        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.738      |
|    n_updates            | 5865        |
|    policy_gradient_loss | -0.0263     |
|    std                  | 14.1        |
|    value_loss           | 0.0854      |
-----------------------------------------
[ADAPTIVE] Episode 322 reward: -0.055040
[ADAPTIVE] Mean reward over last 20 episodes: -0.002887
[ADAPTIVE] Plateau counter: 53/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5686206   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 316         |
|    time_elapsed         | 1051        |
|    total_timesteps      | 1294336     |
| train/                  |             |
|    approx_kl            | 0.011470066 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.6       |
|    explained_variance   | 0.667       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.707      |
|    n_updates            | 5880        |
|    policy_gradient_loss | -0.0236     |
|    std                  | 14.2        |
|    value_loss           | 0.173       |
-----------------------------------------
[ADAPTIVE] Episode 323 reward: -0.079096
[ADAPTIVE] Mean reward over last 20 episodes: -0.002647
[ADAPTIVE] Plateau counter: 54/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4937215   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 317         |
|    time_elapsed         | 1054        |
|    total_timesteps      | 1298432     |
| train/                  |             |
|    approx_kl            | 0.010858512 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.6       |
|    explained_variance   | 0.524       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.561      |
|    n_updates            | 5895        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 14.2        |
|    value_loss           | 0.405       |
-----------------------------------------
[ADAPTIVE] Episode 324 reward: 0.004559
[ADAPTIVE] Mean reward over last 20 episodes: -0.006515
[ADAPTIVE] Plateau counter: 55/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5969447   |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 318         |
|    time_elapsed         | 1058        |
|    total_timesteps      | 1302528     |
| train/                  |             |
|    approx_kl            | 0.015105223 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.6       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.72       |
|    n_updates            | 5910        |
|    policy_gradient_loss | -0.0267     |
|    std                  | 14.2        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 325 reward: -0.061853
[ADAPTIVE] Mean reward over last 20 episodes: -0.008324
[ADAPTIVE] Plateau counter: 56/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5928394   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 319         |
|    time_elapsed         | 1061        |
|    total_timesteps      | 1306624     |
| train/                  |             |
|    approx_kl            | 0.013759423 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.7       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.734      |
|    n_updates            | 5925        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 14.4        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 326 reward: -0.169585
[ADAPTIVE] Mean reward over last 20 episodes: -0.016456
[ADAPTIVE] Plateau counter: 57/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4903935  |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 320        |
|    time_elapsed         | 1064       |
|    total_timesteps      | 1310720    |
| train/                  |            |
|    approx_kl            | 0.01316312 |
|    clip_fraction        | 0.129      |
|    clip_range           | 0.2        |
|    entropy_loss         | -36.7      |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.734     |
|    n_updates            | 5940       |
|    policy_gradient_loss | -0.0262    |
|    std                  | 14.5       |
|    value_loss           | 0.104      |
----------------------------------------
[ADAPTIVE] Episode 327 reward: -0.044930
[ADAPTIVE] Mean reward over last 20 episodes: -0.015773
[ADAPTIVE] Plateau counter: 58/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3793184   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 321         |
|    time_elapsed         | 1068        |
|    total_timesteps      | 1314816     |
| train/                  |             |
|    approx_kl            | 0.011074556 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.8       |
|    explained_variance   | 0.696       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.723      |
|    n_updates            | 5955        |
|    policy_gradient_loss | -0.0244     |
|    std                  | 14.5        |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 328 reward: -0.030501
[ADAPTIVE] Mean reward over last 20 episodes: -0.017033
[ADAPTIVE] Plateau counter: 59/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4881291   |
| time/                   |             |
|    fps                  | 1231        |
|    iterations           | 322         |
|    time_elapsed         | 1071        |
|    total_timesteps      | 1318912     |
| train/                  |             |
|    approx_kl            | 0.009494712 |
|    clip_fraction        | 0.0987      |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.8       |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.708      |
|    n_updates            | 5970        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 14.6        |
|    value_loss           | 0.152       |
-----------------------------------------
[ADAPTIVE] Episode 329 reward: 0.016703
[ADAPTIVE] Mean reward over last 20 episodes: -0.018032
[ADAPTIVE] Plateau counter: 60/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4883981  |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 323        |
|    time_elapsed         | 1074       |
|    total_timesteps      | 1323008    |
| train/                  |            |
|    approx_kl            | 0.01155072 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -36.9      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.711     |
|    n_updates            | 5985       |
|    policy_gradient_loss | -0.0211    |
|    std                  | 14.7       |
|    value_loss           | 0.148      |
----------------------------------------
[ADAPTIVE] Episode 330 reward: -0.044097
[ADAPTIVE] Mean reward over last 20 episodes: -0.022170
[ADAPTIVE] Plateau counter: 61/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4742111   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 324         |
|    time_elapsed         | 1078        |
|    total_timesteps      | 1327104     |
| train/                  |             |
|    approx_kl            | 0.011595519 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -36.9       |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.691      |
|    n_updates            | 6000        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 14.7        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 331 reward: 0.001429
[ADAPTIVE] Mean reward over last 20 episodes: -0.022069
[ADAPTIVE] Plateau counter: 62/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4572276   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 325         |
|    time_elapsed         | 1081        |
|    total_timesteps      | 1331200     |
| train/                  |             |
|    approx_kl            | 0.013741206 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37         |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.728      |
|    n_updates            | 6015        |
|    policy_gradient_loss | -0.0244     |
|    std                  | 14.8        |
|    value_loss           | 0.071       |
-----------------------------------------
[ADAPTIVE] Episode 332 reward: -0.093332
[ADAPTIVE] Mean reward over last 20 episodes: -0.028432
[ADAPTIVE] Plateau counter: 63/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.505711    |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 326         |
|    time_elapsed         | 1085        |
|    total_timesteps      | 1335296     |
| train/                  |             |
|    approx_kl            | 0.012331914 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37         |
|    explained_variance   | 0.641       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.661      |
|    n_updates            | 6030        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 14.9        |
|    value_loss           | 0.193       |
-----------------------------------------
[ADAPTIVE] Episode 333 reward: -0.035629
[ADAPTIVE] Mean reward over last 20 episodes: -0.028305
[ADAPTIVE] Plateau counter: 64/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.5804352  |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 327        |
|    time_elapsed         | 1088       |
|    total_timesteps      | 1339392    |
| train/                  |            |
|    approx_kl            | 0.01073185 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.1      |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.708     |
|    n_updates            | 6045       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 15         |
|    value_loss           | 0.159      |
----------------------------------------
[ADAPTIVE] Episode 334 reward: -0.034896
[ADAPTIVE] Mean reward over last 20 episodes: -0.034850
[ADAPTIVE] Plateau counter: 65/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4651891  |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 328        |
|    time_elapsed         | 1091       |
|    total_timesteps      | 1343488    |
| train/                  |            |
|    approx_kl            | 0.01399368 |
|    clip_fraction        | 0.145      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.1      |
|    explained_variance   | 0.605      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.712     |
|    n_updates            | 6060       |
|    policy_gradient_loss | -0.0217    |
|    std                  | 15.1       |
|    value_loss           | 0.161      |
----------------------------------------
[ADAPTIVE] Episode 335 reward: -0.108342
[ADAPTIVE] Mean reward over last 20 episodes: -0.041490
[ADAPTIVE] Plateau counter: 66/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4535214  |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 329        |
|    time_elapsed         | 1094       |
|    total_timesteps      | 1347584    |
| train/                  |            |
|    approx_kl            | 0.01264097 |
|    clip_fraction        | 0.169      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.1      |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.685     |
|    n_updates            | 6075       |
|    policy_gradient_loss | -0.0216    |
|    std                  | 15.1       |
|    value_loss           | 0.233      |
----------------------------------------
[ADAPTIVE] Episode 336 reward: -0.154954
[ADAPTIVE] Mean reward over last 20 episodes: -0.047657
[ADAPTIVE] Plateau counter: 67/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.4318973    |
| time/                   |              |
|    fps                  | 1231         |
|    iterations           | 330          |
|    time_elapsed         | 1097         |
|    total_timesteps      | 1351680      |
| train/                  |              |
|    approx_kl            | 0.0113198925 |
|    clip_fraction        | 0.102        |
|    clip_range           | 0.2          |
|    entropy_loss         | -37.2        |
|    explained_variance   | 0.623        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.737       |
|    n_updates            | 6090         |
|    policy_gradient_loss | -0.0202      |
|    std                  | 15.1         |
|    value_loss           | 0.123        |
------------------------------------------
[ADAPTIVE] Episode 337 reward: 0.043348
[ADAPTIVE] Mean reward over last 20 episodes: -0.043433
[ADAPTIVE] Plateau counter: 68/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.442266    |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 331         |
|    time_elapsed         | 1101        |
|    total_timesteps      | 1355776     |
| train/                  |             |
|    approx_kl            | 0.012206022 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.2       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.735      |
|    n_updates            | 6105        |
|    policy_gradient_loss | -0.0244     |
|    std                  | 15.2        |
|    value_loss           | 0.121       |
-----------------------------------------
[ADAPTIVE] Episode 338 reward: -0.026528
[ADAPTIVE] Mean reward over last 20 episodes: -0.044697
[ADAPTIVE] Plateau counter: 69/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.623029    |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 332         |
|    time_elapsed         | 1104        |
|    total_timesteps      | 1359872     |
| train/                  |             |
|    approx_kl            | 0.014072164 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.2       |
|    explained_variance   | 0.715       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.736      |
|    n_updates            | 6120        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 15.3        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 339 reward: 0.020043
[ADAPTIVE] Mean reward over last 20 episodes: -0.037324
[ADAPTIVE] Plateau counter: 70/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.7548022   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 333         |
|    time_elapsed         | 1108        |
|    total_timesteps      | 1363968     |
| train/                  |             |
|    approx_kl            | 0.010128312 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.3       |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.736      |
|    n_updates            | 6135        |
|    policy_gradient_loss | -0.0193     |
|    std                  | 15.4        |
|    value_loss           | 0.0984      |
-----------------------------------------
[ADAPTIVE] Episode 340 reward: -0.034024
[ADAPTIVE] Mean reward over last 20 episodes: -0.042058
[ADAPTIVE] Plateau counter: 71/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9075389   |
| time/                   |             |
|    fps                  | 1230        |
|    iterations           | 334         |
|    time_elapsed         | 1112        |
|    total_timesteps      | 1368064     |
| train/                  |             |
|    approx_kl            | 0.012410301 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.3       |
|    explained_variance   | 0.794       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.752      |
|    n_updates            | 6150        |
|    policy_gradient_loss | -0.0251     |
|    std                  | 15.5        |
|    value_loss           | 0.0852      |
-----------------------------------------
[ADAPTIVE] Episode 341 reward: -0.060508
[ADAPTIVE] Mean reward over last 20 episodes: -0.047362
[ADAPTIVE] Plateau counter: 72/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.856339   |
| time/                   |            |
|    fps                  | 1230       |
|    iterations           | 335        |
|    time_elapsed         | 1115       |
|    total_timesteps      | 1372160    |
| train/                  |            |
|    approx_kl            | 0.01338201 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -37.4      |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.742     |
|    n_updates            | 6165       |
|    policy_gradient_loss | -0.0232    |
|    std                  | 15.5       |
|    value_loss           | 0.116      |
----------------------------------------
[ADAPTIVE] Episode 342 reward: 0.108346
[ADAPTIVE] Mean reward over last 20 episodes: -0.039192
[ADAPTIVE] Plateau counter: 73/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8196797   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 336         |
|    time_elapsed         | 1118        |
|    total_timesteps      | 1376256     |
| train/                  |             |
|    approx_kl            | 0.010733749 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.4       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.764      |
|    n_updates            | 6180        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 15.6        |
|    value_loss           | 0.077       |
-----------------------------------------
[ADAPTIVE] Episode 343 reward: 0.032325
[ADAPTIVE] Mean reward over last 20 episodes: -0.033621
[ADAPTIVE] Plateau counter: 74/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6088154   |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 337         |
|    time_elapsed         | 1122        |
|    total_timesteps      | 1380352     |
| train/                  |             |
|    approx_kl            | 0.010168696 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.4       |
|    explained_variance   | 0.673       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.728      |
|    n_updates            | 6195        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 15.6        |
|    value_loss           | 0.129       |
-----------------------------------------
[ADAPTIVE] Episode 344 reward: -0.086915
[ADAPTIVE] Mean reward over last 20 episodes: -0.038195
[ADAPTIVE] Plateau counter: 75/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.540509    |
| time/                   |             |
|    fps                  | 1229        |
|    iterations           | 338         |
|    time_elapsed         | 1126        |
|    total_timesteps      | 1384448     |
| train/                  |             |
|    approx_kl            | 0.013832078 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.5       |
|    explained_variance   | 0.696       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.722      |
|    n_updates            | 6210        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 15.7        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 345 reward: 0.068603
[ADAPTIVE] Mean reward over last 20 episodes: -0.031672
[ADAPTIVE] Plateau counter: 76/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1597098   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 339         |
|    time_elapsed         | 1129        |
|    total_timesteps      | 1388544     |
| train/                  |             |
|    approx_kl            | 0.014279382 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.5       |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.731      |
|    n_updates            | 6225        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 15.8        |
|    value_loss           | 0.0989      |
-----------------------------------------
[ADAPTIVE] Episode 346 reward: -0.011224
[ADAPTIVE] Mean reward over last 20 episodes: -0.023754
[ADAPTIVE] Plateau counter: 77/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1970437   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 340         |
|    time_elapsed         | 1133        |
|    total_timesteps      | 1392640     |
| train/                  |             |
|    approx_kl            | 0.010805229 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.6       |
|    explained_variance   | 0.579       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.723      |
|    n_updates            | 6240        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 15.9        |
|    value_loss           | 0.205       |
-----------------------------------------
[ADAPTIVE] Episode 347 reward: -0.124975
[ADAPTIVE] Mean reward over last 20 episodes: -0.027756
[ADAPTIVE] Plateau counter: 78/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1333287   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 341         |
|    time_elapsed         | 1136        |
|    total_timesteps      | 1396736     |
| train/                  |             |
|    approx_kl            | 0.013826393 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.6       |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.738      |
|    n_updates            | 6255        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 16          |
|    value_loss           | 0.141       |
-----------------------------------------
[ADAPTIVE] Episode 348 reward: -0.088455
[ADAPTIVE] Mean reward over last 20 episodes: -0.030654
[ADAPTIVE] Plateau counter: 79/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3194373   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 342         |
|    time_elapsed         | 1139        |
|    total_timesteps      | 1400832     |
| train/                  |             |
|    approx_kl            | 0.009451189 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.6       |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.721      |
|    n_updates            | 6270        |
|    policy_gradient_loss | -0.0208     |
|    std                  | 16          |
|    value_loss           | 0.146       |
-----------------------------------------
[ADAPTIVE] Episode 349 reward: 0.011581
[ADAPTIVE] Mean reward over last 20 episodes: -0.030910
[ADAPTIVE] Plateau counter: 80/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.38768     |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 343         |
|    time_elapsed         | 1143        |
|    total_timesteps      | 1404928     |
| train/                  |             |
|    approx_kl            | 0.015024953 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.7       |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.747      |
|    n_updates            | 6285        |
|    policy_gradient_loss | -0.0241     |
|    std                  | 16.1        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 350 reward: 0.011358
[ADAPTIVE] Mean reward over last 20 episodes: -0.028137
[ADAPTIVE] Plateau counter: 81/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4694093   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 344         |
|    time_elapsed         | 1147        |
|    total_timesteps      | 1409024     |
| train/                  |             |
|    approx_kl            | 0.014050661 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.8       |
|    explained_variance   | 0.616       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.672      |
|    n_updates            | 6300        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 16.3        |
|    value_loss           | 0.269       |
-----------------------------------------
[ADAPTIVE] Episode 351 reward: -0.004210
[ADAPTIVE] Mean reward over last 20 episodes: -0.028419
[ADAPTIVE] Plateau counter: 82/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.6811652    |
| time/                   |              |
|    fps                  | 1228         |
|    iterations           | 345          |
|    time_elapsed         | 1150         |
|    total_timesteps      | 1413120      |
| train/                  |              |
|    approx_kl            | 0.0108343065 |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.2          |
|    entropy_loss         | -37.8        |
|    explained_variance   | 0.77         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.75        |
|    n_updates            | 6315         |
|    policy_gradient_loss | -0.0215      |
|    std                  | 16.3         |
|    value_loss           | 0.123        |
------------------------------------------
[ADAPTIVE] Episode 352 reward: 0.022981
[ADAPTIVE] Mean reward over last 20 episodes: -0.022604
[ADAPTIVE] Plateau counter: 83/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5913599   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 346         |
|    time_elapsed         | 1153        |
|    total_timesteps      | 1417216     |
| train/                  |             |
|    approx_kl            | 0.010154916 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.8       |
|    explained_variance   | 0.689       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.718      |
|    n_updates            | 6330        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 16.4        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 353 reward: 0.055945
[ADAPTIVE] Mean reward over last 20 episodes: -0.018025
[ADAPTIVE] Plateau counter: 84/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5263305   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 347         |
|    time_elapsed         | 1157        |
|    total_timesteps      | 1421312     |
| train/                  |             |
|    approx_kl            | 0.011633012 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.9       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.719      |
|    n_updates            | 6345        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 16.5        |
|    value_loss           | 0.184       |
-----------------------------------------
[ADAPTIVE] Episode 354 reward: 0.009680
[ADAPTIVE] Mean reward over last 20 episodes: -0.015796
[ADAPTIVE] Plateau counter: 85/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4654088   |
| time/                   |             |
|    fps                  | 1228        |
|    iterations           | 348         |
|    time_elapsed         | 1160        |
|    total_timesteps      | 1425408     |
| train/                  |             |
|    approx_kl            | 0.012932921 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -37.9       |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.745      |
|    n_updates            | 6360        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 16.5        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 355 reward: -0.005558
[ADAPTIVE] Mean reward over last 20 episodes: -0.010657
[ADAPTIVE] Plateau counter: 86/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4321704   |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 349         |
|    time_elapsed         | 1164        |
|    total_timesteps      | 1429504     |
| train/                  |             |
|    approx_kl            | 0.007741821 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -38         |
|    explained_variance   | 0.799       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.744      |
|    n_updates            | 6375        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 16.6        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 356 reward: -0.051651
[ADAPTIVE] Mean reward over last 20 episodes: -0.005492
[ADAPTIVE] Plateau counter: 87/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4090391   |
| time/                   |             |
|    fps                  | 1227        |
|    iterations           | 350         |
|    time_elapsed         | 1168        |
|    total_timesteps      | 1433600     |
| train/                  |             |
|    approx_kl            | 0.009982657 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38         |
|    explained_variance   | 0.688       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.749      |
|    n_updates            | 6390        |
|    policy_gradient_loss | -0.0225     |
|    std                  | 16.7        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 357 reward: 0.063778
[ADAPTIVE] Mean reward over last 20 episodes: -0.004470
[ADAPTIVE] Plateau counter: 88/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4298548   |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 351         |
|    time_elapsed         | 1171        |
|    total_timesteps      | 1437696     |
| train/                  |             |
|    approx_kl            | 0.011079231 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38         |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.754      |
|    n_updates            | 6405        |
|    policy_gradient_loss | -0.0241     |
|    std                  | 16.8        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 358 reward: 0.026754
[ADAPTIVE] Mean reward over last 20 episodes: -0.001806
[ADAPTIVE] Plateau counter: 89/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 359 reward: -0.035700
[ADAPTIVE] Mean reward over last 20 episodes: -0.004593
[ADAPTIVE] Plateau counter: 90/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4100412   |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 352         |
|    time_elapsed         | 1175        |
|    total_timesteps      | 1441792     |
| train/                  |             |
|    approx_kl            | 0.011926457 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.1       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.771      |
|    n_updates            | 6420        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 16.8        |
|    value_loss           | 0.0821      |
-----------------------------------------
[ADAPTIVE] Episode 360 reward: -0.012771
[ADAPTIVE] Mean reward over last 20 episodes: -0.003531
[ADAPTIVE] Plateau counter: 91/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3210675   |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 353         |
|    time_elapsed         | 1178        |
|    total_timesteps      | 1445888     |
| train/                  |             |
|    approx_kl            | 0.010511672 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.1       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.765      |
|    n_updates            | 6435        |
|    policy_gradient_loss | -0.0225     |
|    std                  | 16.9        |
|    value_loss           | 0.086       |
-----------------------------------------
[ADAPTIVE] Episode 361 reward: -0.059907
[ADAPTIVE] Mean reward over last 20 episodes: -0.003501
[ADAPTIVE] Plateau counter: 92/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2851744   |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 354         |
|    time_elapsed         | 1181        |
|    total_timesteps      | 1449984     |
| train/                  |             |
|    approx_kl            | 0.010879085 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.2       |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.774      |
|    n_updates            | 6450        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 17          |
|    value_loss           | 0.0711      |
-----------------------------------------
[ADAPTIVE] Episode 362 reward: 0.046918
[ADAPTIVE] Mean reward over last 20 episodes: -0.006572
[ADAPTIVE] Plateau counter: 93/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.381675    |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 355         |
|    time_elapsed         | 1185        |
|    total_timesteps      | 1454080     |
| train/                  |             |
|    approx_kl            | 0.013582097 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.2       |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.764      |
|    n_updates            | 6465        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 17.1        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 363 reward: 0.063435
[ADAPTIVE] Mean reward over last 20 episodes: -0.005017
[ADAPTIVE] Plateau counter: 94/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3169299    |
| time/                   |              |
|    fps                  | 1226         |
|    iterations           | 356          |
|    time_elapsed         | 1189         |
|    total_timesteps      | 1458176      |
| train/                  |              |
|    approx_kl            | 0.0114872325 |
|    clip_fraction        | 0.144        |
|    clip_range           | 0.2          |
|    entropy_loss         | -38.3        |
|    explained_variance   | 0.687        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.766       |
|    n_updates            | 6480         |
|    policy_gradient_loss | -0.0258      |
|    std                  | 17.2         |
|    value_loss           | 0.0903       |
------------------------------------------
[ADAPTIVE] Episode 364 reward: -0.005024
[ADAPTIVE] Mean reward over last 20 episodes: -0.000922
[ADAPTIVE] Plateau counter: 95/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4516671  |
| time/                   |            |
|    fps                  | 1226       |
|    iterations           | 357        |
|    time_elapsed         | 1192       |
|    total_timesteps      | 1462272    |
| train/                  |            |
|    approx_kl            | 0.01097684 |
|    clip_fraction        | 0.12       |
|    clip_range           | 0.2        |
|    entropy_loss         | -38.3      |
|    explained_variance   | 0.779      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.765     |
|    n_updates            | 6495       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 17.3       |
|    value_loss           | 0.101      |
----------------------------------------
[ADAPTIVE] Episode 365 reward: -0.083846
[ADAPTIVE] Mean reward over last 20 episodes: -0.008545
[ADAPTIVE] Plateau counter: 96/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5531813   |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 358         |
|    time_elapsed         | 1195        |
|    total_timesteps      | 1466368     |
| train/                  |             |
|    approx_kl            | 0.010680119 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.4       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.762      |
|    n_updates            | 6510        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 17.4        |
|    value_loss           | 0.0952      |
-----------------------------------------
[ADAPTIVE] Episode 366 reward: -0.041892
[ADAPTIVE] Mean reward over last 20 episodes: -0.010078
[ADAPTIVE] Plateau counter: 97/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.7478018   |
| time/                   |             |
|    fps                  | 1226        |
|    iterations           | 359         |
|    time_elapsed         | 1199        |
|    total_timesteps      | 1470464     |
| train/                  |             |
|    approx_kl            | 0.010409959 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.4       |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.756      |
|    n_updates            | 6525        |
|    policy_gradient_loss | -0.0225     |
|    std                  | 17.4        |
|    value_loss           | 0.0908      |
-----------------------------------------
[ADAPTIVE] Episode 367 reward: -0.010739
[ADAPTIVE] Mean reward over last 20 episodes: -0.004366
[ADAPTIVE] Plateau counter: 98/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.7210116    |
| time/                   |              |
|    fps                  | 1225         |
|    iterations           | 360          |
|    time_elapsed         | 1203         |
|    total_timesteps      | 1474560      |
| train/                  |              |
|    approx_kl            | 0.0104321875 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.2          |
|    entropy_loss         | -38.4        |
|    explained_variance   | 0.773        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.76        |
|    n_updates            | 6540         |
|    policy_gradient_loss | -0.0219      |
|    std                  | 17.5         |
|    value_loss           | 0.096        |
------------------------------------------
[ADAPTIVE] Episode 368 reward: -0.064521
[ADAPTIVE] Mean reward over last 20 episodes: -0.003169
[ADAPTIVE] Plateau counter: 99/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5074841   |
| time/                   |             |
|    fps                  | 1225        |
|    iterations           | 361         |
|    time_elapsed         | 1206        |
|    total_timesteps      | 1478656     |
| train/                  |             |
|    approx_kl            | 0.010335464 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.5       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.767      |
|    n_updates            | 6555        |
|    policy_gradient_loss | -0.0174     |
|    std                  | 17.5        |
|    value_loss           | 0.0674      |
-----------------------------------------
[ADAPTIVE] Episode 369 reward: 0.090358
[ADAPTIVE] Mean reward over last 20 episodes: 0.000769
[ADAPTIVE] Plateau counter: 100/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3389914   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 362         |
|    time_elapsed         | 1210        |
|    total_timesteps      | 1482752     |
| train/                  |             |
|    approx_kl            | 0.009134037 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.5       |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.747      |
|    n_updates            | 6570        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 17.7        |
|    value_loss           | 0.143       |
-----------------------------------------
[ADAPTIVE] Episode 370 reward: -0.032361
[ADAPTIVE] Mean reward over last 20 episodes: -0.001416
[ADAPTIVE] Plateau counter: 101/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1147625   |
| time/                   |             |
|    fps                  | 1225        |
|    iterations           | 363         |
|    time_elapsed         | 1213        |
|    total_timesteps      | 1486848     |
| train/                  |             |
|    approx_kl            | 0.009688279 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.6       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.759      |
|    n_updates            | 6585        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 17.8        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 371 reward: -0.024345
[ADAPTIVE] Mean reward over last 20 episodes: -0.002423
[ADAPTIVE] Plateau counter: 102/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.010935    |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 364         |
|    time_elapsed         | 1217        |
|    total_timesteps      | 1490944     |
| train/                  |             |
|    approx_kl            | 0.009548705 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.6       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.718      |
|    n_updates            | 6600        |
|    policy_gradient_loss | -0.018      |
|    std                  | 17.9        |
|    value_loss           | 0.241       |
-----------------------------------------
[ADAPTIVE] Episode 372 reward: 0.025015
[ADAPTIVE] Mean reward over last 20 episodes: -0.002322
[ADAPTIVE] Plateau counter: 103/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0576874   |
| time/                   |             |
|    fps                  | 1225        |
|    iterations           | 365         |
|    time_elapsed         | 1220        |
|    total_timesteps      | 1495040     |
| train/                  |             |
|    approx_kl            | 0.012090007 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.7       |
|    explained_variance   | 0.712       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.725      |
|    n_updates            | 6615        |
|    policy_gradient_loss | -0.0203     |
|    std                  | 18          |
|    value_loss           | 0.211       |
-----------------------------------------
[ADAPTIVE] Episode 373 reward: 0.014872
[ADAPTIVE] Mean reward over last 20 episodes: -0.004375
[ADAPTIVE] Plateau counter: 104/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9658429   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 366         |
|    time_elapsed         | 1224        |
|    total_timesteps      | 1499136     |
| train/                  |             |
|    approx_kl            | 0.010329574 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.7       |
|    explained_variance   | 0.619       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.732      |
|    n_updates            | 6630        |
|    policy_gradient_loss | -0.017      |
|    std                  | 18          |
|    value_loss           | 0.218       |
-----------------------------------------
[ADAPTIVE] Episode 374 reward: 0.006898
[ADAPTIVE] Mean reward over last 20 episodes: -0.004514
[ADAPTIVE] Plateau counter: 105/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1700704   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 367         |
|    time_elapsed         | 1227        |
|    total_timesteps      | 1503232     |
| train/                  |             |
|    approx_kl            | 0.012959849 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.7       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.778      |
|    n_updates            | 6645        |
|    policy_gradient_loss | -0.021      |
|    std                  | 18.1        |
|    value_loss           | 0.0899      |
-----------------------------------------
[ADAPTIVE] Episode 375 reward: -0.004850
[ADAPTIVE] Mean reward over last 20 episodes: -0.004479
[ADAPTIVE] Plateau counter: 106/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3621646   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 368         |
|    time_elapsed         | 1231        |
|    total_timesteps      | 1507328     |
| train/                  |             |
|    approx_kl            | 0.012655823 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.8       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.782      |
|    n_updates            | 6660        |
|    policy_gradient_loss | -0.0211     |
|    std                  | 18.2        |
|    value_loss           | 0.0938      |
-----------------------------------------
[ADAPTIVE] Episode 376 reward: 0.016580
[ADAPTIVE] Mean reward over last 20 episodes: -0.001067
[ADAPTIVE] Plateau counter: 107/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5141339   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 369         |
|    time_elapsed         | 1234        |
|    total_timesteps      | 1511424     |
| train/                  |             |
|    approx_kl            | 0.008669179 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.8       |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.762      |
|    n_updates            | 6675        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 18.3        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 377 reward: 0.119438
[ADAPTIVE] Mean reward over last 20 episodes: 0.001716
[ADAPTIVE] Plateau counter: 108/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6370003   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 370         |
|    time_elapsed         | 1238        |
|    total_timesteps      | 1515520     |
| train/                  |             |
|    approx_kl            | 0.007730192 |
|    clip_fraction        | 0.0913      |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.9       |
|    explained_variance   | 0.657       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.743      |
|    n_updates            | 6690        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 18.4        |
|    value_loss           | 0.147       |
-----------------------------------------
[ADAPTIVE] Episode 378 reward: 0.013023
[ADAPTIVE] Mean reward over last 20 episodes: 0.001029
[ADAPTIVE] Plateau counter: 109/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5108268   |
| time/                   |             |
|    fps                  | 1224        |
|    iterations           | 371         |
|    time_elapsed         | 1241        |
|    total_timesteps      | 1519616     |
| train/                  |             |
|    approx_kl            | 0.011076671 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -38.9       |
|    explained_variance   | 0.777       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.774      |
|    n_updates            | 6705        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 18.5        |
|    value_loss           | 0.0868      |
-----------------------------------------
[ADAPTIVE] Episode 379 reward: -0.086281
[ADAPTIVE] Mean reward over last 20 episodes: -0.001500
[ADAPTIVE] Plateau counter: 110/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4113665  |
| time/                   |            |
|    fps                  | 1223       |
|    iterations           | 372        |
|    time_elapsed         | 1245       |
|    total_timesteps      | 1523712    |
| train/                  |            |
|    approx_kl            | 0.00889748 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.2        |
|    entropy_loss         | -39        |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.742     |
|    n_updates            | 6720       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 18.6       |
|    value_loss           | 0.177      |
----------------------------------------
[ADAPTIVE] Episode 380 reward: -0.023357
[ADAPTIVE] Mean reward over last 20 episodes: -0.002029
[ADAPTIVE] Plateau counter: 111/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4111158   |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 373         |
|    time_elapsed         | 1248        |
|    total_timesteps      | 1527808     |
| train/                  |             |
|    approx_kl            | 0.010148015 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39         |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.769      |
|    n_updates            | 6735        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 18.7        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 381 reward: -0.035067
[ADAPTIVE] Mean reward over last 20 episodes: -0.000787
[ADAPTIVE] Plateau counter: 112/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4735416   |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 374         |
|    time_elapsed         | 1252        |
|    total_timesteps      | 1531904     |
| train/                  |             |
|    approx_kl            | 0.013424694 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.1       |
|    explained_variance   | 0.697       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.76       |
|    n_updates            | 6750        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 18.8        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 382 reward: -0.006208
[ADAPTIVE] Mean reward over last 20 episodes: -0.003444
[ADAPTIVE] Plateau counter: 113/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.342885    |
| time/                   |             |
|    fps                  | 1223        |
|    iterations           | 375         |
|    time_elapsed         | 1255        |
|    total_timesteps      | 1536000     |
| train/                  |             |
|    approx_kl            | 0.013410252 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.2       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.804      |
|    n_updates            | 6765        |
|    policy_gradient_loss | -0.027      |
|    std                  | 19          |
|    value_loss           | 0.0638      |
-----------------------------------------
[ADAPTIVE] Episode 383 reward: 0.044217
[ADAPTIVE] Mean reward over last 20 episodes: -0.004405
[ADAPTIVE] Plateau counter: 114/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3692018   |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 376         |
|    time_elapsed         | 1259        |
|    total_timesteps      | 1540096     |
| train/                  |             |
|    approx_kl            | 0.010246124 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.2       |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.764      |
|    n_updates            | 6780        |
|    policy_gradient_loss | -0.021      |
|    std                  | 19.1        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 384 reward: 0.049510
[ADAPTIVE] Mean reward over last 20 episodes: -0.001678
[ADAPTIVE] Plateau counter: 115/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4923702   |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 377         |
|    time_elapsed         | 1262        |
|    total_timesteps      | 1544192     |
| train/                  |             |
|    approx_kl            | 0.011771761 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.3       |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.774      |
|    n_updates            | 6795        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 19.2        |
|    value_loss           | 0.121       |
-----------------------------------------
[ADAPTIVE] Episode 385 reward: 0.040123
[ADAPTIVE] Mean reward over last 20 episodes: 0.004521
[ADAPTIVE] Plateau counter: 116/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.5140281  |
| time/                   |            |
|    fps                  | 1222       |
|    iterations           | 378        |
|    time_elapsed         | 1266       |
|    total_timesteps      | 1548288    |
| train/                  |            |
|    approx_kl            | 0.01086855 |
|    clip_fraction        | 0.146      |
|    clip_range           | 0.2        |
|    entropy_loss         | -39.3      |
|    explained_variance   | 0.782      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.782     |
|    n_updates            | 6810       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 19.3       |
|    value_loss           | 0.092      |
----------------------------------------
[ADAPTIVE] Episode 386 reward: -0.006497
[ADAPTIVE] Mean reward over last 20 episodes: 0.006290
[ADAPTIVE] Plateau counter: 117/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.6190132    |
| time/                   |              |
|    fps                  | 1222         |
|    iterations           | 379          |
|    time_elapsed         | 1269         |
|    total_timesteps      | 1552384      |
| train/                  |              |
|    approx_kl            | 0.0077618225 |
|    clip_fraction        | 0.0921       |
|    clip_range           | 0.2          |
|    entropy_loss         | -39.3        |
|    explained_variance   | 0.719        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.743       |
|    n_updates            | 6825         |
|    policy_gradient_loss | -0.0216      |
|    std                  | 19.3         |
|    value_loss           | 0.11         |
------------------------------------------
[ADAPTIVE] Episode 387 reward: 0.068694
[ADAPTIVE] Mean reward over last 20 episodes: 0.010262
[ADAPTIVE] Plateau counter: 118/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6827672   |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 380         |
|    time_elapsed         | 1273        |
|    total_timesteps      | 1556480     |
| train/                  |             |
|    approx_kl            | 0.013588419 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.4       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.746      |
|    n_updates            | 6840        |
|    policy_gradient_loss | -0.019      |
|    std                  | 19.5        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 388 reward: 0.081051
[ADAPTIVE] Mean reward over last 20 episodes: 0.017541
[ADAPTIVE] Plateau counter: 119/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.9012336   |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 381         |
|    time_elapsed         | 1276        |
|    total_timesteps      | 1560576     |
| train/                  |             |
|    approx_kl            | 0.008899677 |
|    clip_fraction        | 0.0987      |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.4       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.761      |
|    n_updates            | 6855        |
|    policy_gradient_loss | -0.0178     |
|    std                  | 19.5        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 389 reward: 0.057025
[ADAPTIVE] Mean reward over last 20 episodes: 0.015874
[ADAPTIVE] Plateau counter: 120/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.8157828   |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 382         |
|    time_elapsed         | 1280        |
|    total_timesteps      | 1564672     |
| train/                  |             |
|    approx_kl            | 0.011663476 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.4       |
|    explained_variance   | 0.619       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.761      |
|    n_updates            | 6870        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 19.6        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 390 reward: -0.025675
[ADAPTIVE] Mean reward over last 20 episodes: 0.016208
[ADAPTIVE] Plateau counter: 121/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.8285866    |
| time/                   |              |
|    fps                  | 1222         |
|    iterations           | 383          |
|    time_elapsed         | 1283         |
|    total_timesteps      | 1568768      |
| train/                  |              |
|    approx_kl            | 0.0095820045 |
|    clip_fraction        | 0.116        |
|    clip_range           | 0.2          |
|    entropy_loss         | -39.5        |
|    explained_variance   | 0.688        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.741       |
|    n_updates            | 6885         |
|    policy_gradient_loss | -0.0208      |
|    std                  | 19.7         |
|    value_loss           | 0.126        |
------------------------------------------
[ADAPTIVE] Episode 391 reward: -0.091082
[ADAPTIVE] Mean reward over last 20 episodes: 0.012871
[ADAPTIVE] Plateau counter: 122/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.8756202  |
| time/                   |            |
|    fps                  | 1222       |
|    iterations           | 384        |
|    time_elapsed         | 1286       |
|    total_timesteps      | 1572864    |
| train/                  |            |
|    approx_kl            | 0.01126915 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -39.6      |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.802     |
|    n_updates            | 6900       |
|    policy_gradient_loss | -0.0197    |
|    std                  | 19.9       |
|    value_loss           | 0.0853     |
----------------------------------------
[ADAPTIVE] Episode 392 reward: -0.014903
[ADAPTIVE] Mean reward over last 20 episodes: 0.010876
[ADAPTIVE] Plateau counter: 123/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6273252   |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 385         |
|    time_elapsed         | 1290        |
|    total_timesteps      | 1576960     |
| train/                  |             |
|    approx_kl            | 0.010088442 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.6       |
|    explained_variance   | 0.667       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.799      |
|    n_updates            | 6915        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 20          |
|    value_loss           | 0.0926      |
-----------------------------------------
[ADAPTIVE] Episode 393 reward: 0.024780
[ADAPTIVE] Mean reward over last 20 episodes: 0.011371
[ADAPTIVE] Plateau counter: 124/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5702353   |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 386         |
|    time_elapsed         | 1293        |
|    total_timesteps      | 1581056     |
| train/                  |             |
|    approx_kl            | 0.012728466 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.6       |
|    explained_variance   | 0.653       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.775      |
|    n_updates            | 6930        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 20.1        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 394 reward: -0.025053
[ADAPTIVE] Mean reward over last 20 episodes: 0.009773
[ADAPTIVE] Plateau counter: 125/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3829862   |
| time/                   |             |
|    fps                  | 1222        |
|    iterations           | 387         |
|    time_elapsed         | 1297        |
|    total_timesteps      | 1585152     |
| train/                  |             |
|    approx_kl            | 0.010124535 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.7       |
|    explained_variance   | 0.703       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.764      |
|    n_updates            | 6945        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 20.2        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 395 reward: 0.008363
[ADAPTIVE] Mean reward over last 20 episodes: 0.010434
[ADAPTIVE] Plateau counter: 126/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5115962   |
| time/                   |             |
|    fps                  | 1221        |
|    iterations           | 388         |
|    time_elapsed         | 1300        |
|    total_timesteps      | 1589248     |
| train/                  |             |
|    approx_kl            | 0.009544004 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.7       |
|    explained_variance   | 0.685       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.778      |
|    n_updates            | 6960        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 20.2        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 396 reward: -0.052661
[ADAPTIVE] Mean reward over last 20 episodes: 0.006972
[ADAPTIVE] Plateau counter: 127/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4922568  |
| time/                   |            |
|    fps                  | 1221       |
|    iterations           | 389        |
|    time_elapsed         | 1304       |
|    total_timesteps      | 1593344    |
| train/                  |            |
|    approx_kl            | 0.01285273 |
|    clip_fraction        | 0.115      |
|    clip_range           | 0.2        |
|    entropy_loss         | -39.8      |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.756     |
|    n_updates            | 6975       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 20.4       |
|    value_loss           | 0.199      |
----------------------------------------
[ADAPTIVE] Episode 397 reward: -0.039994
[ADAPTIVE] Mean reward over last 20 episodes: -0.001000
[ADAPTIVE] Plateau counter: 128/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.3189042  |
| time/                   |            |
|    fps                  | 1221       |
|    iterations           | 390        |
|    time_elapsed         | 1307       |
|    total_timesteps      | 1597440    |
| train/                  |            |
|    approx_kl            | 0.01338934 |
|    clip_fraction        | 0.131      |
|    clip_range           | 0.2        |
|    entropy_loss         | -39.8      |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.733     |
|    n_updates            | 6990       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 20.5       |
|    value_loss           | 0.194      |
----------------------------------------
[ADAPTIVE] Episode 398 reward: 0.042137
[ADAPTIVE] Mean reward over last 20 episodes: 0.000456
[ADAPTIVE] Plateau counter: 129/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  UserWarning,
Eval num_timesteps=1600000, episode_reward=2.48 +/- 0.00
Episode length: 251.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 251         |
|    mean_reward          | 2.48        |
| time/                   |             |
|    total_timesteps      | 1600000     |
| train/                  |             |
|    approx_kl            | 0.010268604 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.9       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.778      |
|    n_updates            | 7005        |
|    policy_gradient_loss | -0.0202     |
|    std                  | 20.6        |
|    value_loss           | 0.124       |
-----------------------------------------
New best mean reward!
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 251       |
|    ep_rew_mean     | 1.4613273 |
| time/              |           |
|    fps             | 1217      |
|    iterations      | 391       |
|    time_elapsed    | 1315      |
|    total_timesteps | 1601536   |
----------------------------------
[ADAPTIVE] Episode 399 reward: -0.052670
[ADAPTIVE] Mean reward over last 20 episodes: 0.002137
[ADAPTIVE] Plateau counter: 130/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4511954   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 392         |
|    time_elapsed         | 1319        |
|    total_timesteps      | 1605632     |
| train/                  |             |
|    approx_kl            | 0.009303406 |
|    clip_fraction        | 0.0961      |
|    clip_range           | 0.2         |
|    entropy_loss         | -39.9       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.788      |
|    n_updates            | 7020        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 20.7        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 400 reward: 0.006906
[ADAPTIVE] Mean reward over last 20 episodes: 0.003650
[ADAPTIVE] Plateau counter: 131/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4922644   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 393         |
|    time_elapsed         | 1322        |
|    total_timesteps      | 1609728     |
| train/                  |             |
|    approx_kl            | 0.012176375 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40         |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.795      |
|    n_updates            | 7035        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 20.8        |
|    value_loss           | 0.0999      |
-----------------------------------------
[ADAPTIVE] Episode 401 reward: -0.029752
[ADAPTIVE] Mean reward over last 20 episodes: 0.003916
[ADAPTIVE] Plateau counter: 132/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3988485   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 394         |
|    time_elapsed         | 1325        |
|    total_timesteps      | 1613824     |
| train/                  |             |
|    approx_kl            | 0.011094893 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40         |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.796      |
|    n_updates            | 7050        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 21          |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 402 reward: -0.012682
[ADAPTIVE] Mean reward over last 20 episodes: 0.003592
[ADAPTIVE] Plateau counter: 133/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.4389719    |
| time/                   |              |
|    fps                  | 1217         |
|    iterations           | 395          |
|    time_elapsed         | 1329         |
|    total_timesteps      | 1617920      |
| train/                  |              |
|    approx_kl            | 0.0112173855 |
|    clip_fraction        | 0.121        |
|    clip_range           | 0.2          |
|    entropy_loss         | -40.1        |
|    explained_variance   | 0.692        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.785       |
|    n_updates            | 7065         |
|    policy_gradient_loss | -0.0189      |
|    std                  | 21           |
|    value_loss           | 0.0996       |
------------------------------------------
[ADAPTIVE] Episode 403 reward: 0.089455
[ADAPTIVE] Mean reward over last 20 episodes: 0.005854
[ADAPTIVE] Plateau counter: 134/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5113876   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 396         |
|    time_elapsed         | 1332        |
|    total_timesteps      | 1622016     |
| train/                  |             |
|    approx_kl            | 0.008383817 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.1       |
|    explained_variance   | 0.708       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.773      |
|    n_updates            | 7080        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 21.1        |
|    value_loss           | 0.155       |
-----------------------------------------
[ADAPTIVE] Episode 404 reward: -0.015881
[ADAPTIVE] Mean reward over last 20 episodes: 0.002584
[ADAPTIVE] Plateau counter: 135/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3983066   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 397         |
|    time_elapsed         | 1335        |
|    total_timesteps      | 1626112     |
| train/                  |             |
|    approx_kl            | 0.011665439 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.1       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.785      |
|    n_updates            | 7095        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 21.2        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 405 reward: 0.021088
[ADAPTIVE] Mean reward over last 20 episodes: 0.001632
[ADAPTIVE] Plateau counter: 136/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5027838   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 398         |
|    time_elapsed         | 1339        |
|    total_timesteps      | 1630208     |
| train/                  |             |
|    approx_kl            | 0.009125887 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.2       |
|    explained_variance   | 0.735       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.786      |
|    n_updates            | 7110        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 21.3        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 406 reward: 0.019623
[ADAPTIVE] Mean reward over last 20 episodes: 0.002938
[ADAPTIVE] Plateau counter: 137/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3430667   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 399         |
|    time_elapsed         | 1342        |
|    total_timesteps      | 1634304     |
| train/                  |             |
|    approx_kl            | 0.010233957 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.2       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.796      |
|    n_updates            | 7125        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 21.4        |
|    value_loss           | 0.13        |
-----------------------------------------
[ADAPTIVE] Episode 407 reward: -0.025819
[ADAPTIVE] Mean reward over last 20 episodes: -0.001787
[ADAPTIVE] Plateau counter: 138/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3173239   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 400         |
|    time_elapsed         | 1346        |
|    total_timesteps      | 1638400     |
| train/                  |             |
|    approx_kl            | 0.013163113 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.3       |
|    explained_variance   | 0.678       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.781      |
|    n_updates            | 7140        |
|    policy_gradient_loss | -0.0202     |
|    std                  | 21.6        |
|    value_loss           | 0.188       |
-----------------------------------------
[ADAPTIVE] Episode 408 reward: -0.058638
[ADAPTIVE] Mean reward over last 20 episodes: -0.008772
[ADAPTIVE] Plateau counter: 139/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1374592  |
| time/                   |            |
|    fps                  | 1217       |
|    iterations           | 401        |
|    time_elapsed         | 1349       |
|    total_timesteps      | 1642496    |
| train/                  |            |
|    approx_kl            | 0.00876656 |
|    clip_fraction        | 0.118      |
|    clip_range           | 0.2        |
|    entropy_loss         | -40.3      |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.793     |
|    n_updates            | 7155       |
|    policy_gradient_loss | -0.0233    |
|    std                  | 21.6       |
|    value_loss           | 0.114      |
----------------------------------------
[ADAPTIVE] Episode 409 reward: 0.007901
[ADAPTIVE] Mean reward over last 20 episodes: -0.011228
[ADAPTIVE] Plateau counter: 140/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 410 reward: 0.009615
[ADAPTIVE] Mean reward over last 20 episodes: -0.009463
[ADAPTIVE] Plateau counter: 141/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2066159   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 402         |
|    time_elapsed         | 1352        |
|    total_timesteps      | 1646592     |
| train/                  |             |
|    approx_kl            | 0.011872539 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.3       |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.783      |
|    n_updates            | 7170        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 21.7        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 411 reward: -0.017786
[ADAPTIVE] Mean reward over last 20 episodes: -0.005799
[ADAPTIVE] Plateau counter: 142/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1566552  |
| time/                   |            |
|    fps                  | 1217       |
|    iterations           | 403        |
|    time_elapsed         | 1356       |
|    total_timesteps      | 1650688    |
| train/                  |            |
|    approx_kl            | 0.00905136 |
|    clip_fraction        | 0.0806     |
|    clip_range           | 0.2        |
|    entropy_loss         | -40.4      |
|    explained_variance   | 0.714      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.757     |
|    n_updates            | 7185       |
|    policy_gradient_loss | -0.0139    |
|    std                  | 21.7       |
|    value_loss           | 0.183      |
----------------------------------------
[ADAPTIVE] Episode 412 reward: 0.031864
[ADAPTIVE] Mean reward over last 20 episodes: -0.003460
[ADAPTIVE] Plateau counter: 143/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2779106    |
| time/                   |              |
|    fps                  | 1216         |
|    iterations           | 404          |
|    time_elapsed         | 1360         |
|    total_timesteps      | 1654784      |
| train/                  |              |
|    approx_kl            | 0.0156226745 |
|    clip_fraction        | 0.132        |
|    clip_range           | 0.2          |
|    entropy_loss         | -40.4        |
|    explained_variance   | 0.743        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.78        |
|    n_updates            | 7200         |
|    policy_gradient_loss | -0.019       |
|    std                  | 21.9         |
|    value_loss           | 0.11         |
------------------------------------------
[ADAPTIVE] Episode 413 reward: 0.114957
[ADAPTIVE] Mean reward over last 20 episodes: 0.001049
[ADAPTIVE] Plateau counter: 144/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2449007   |
| time/                   |             |
|    fps                  | 1217        |
|    iterations           | 405         |
|    time_elapsed         | 1363        |
|    total_timesteps      | 1658880     |
| train/                  |             |
|    approx_kl            | 0.011058682 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.5       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.799      |
|    n_updates            | 7215        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 22          |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 414 reward: -0.007275
[ADAPTIVE] Mean reward over last 20 episodes: 0.001938
[ADAPTIVE] Plateau counter: 145/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3988837   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 406         |
|    time_elapsed         | 1366        |
|    total_timesteps      | 1662976     |
| train/                  |             |
|    approx_kl            | 0.012683188 |
|    clip_fraction        | 0.0941      |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.5       |
|    explained_variance   | 0.72        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.743      |
|    n_updates            | 7230        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 22.1        |
|    value_loss           | 0.166       |
-----------------------------------------
[ADAPTIVE] Episode 415 reward: 0.105888
[ADAPTIVE] Mean reward over last 20 episodes: 0.006814
[ADAPTIVE] Plateau counter: 146/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4344214   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 407         |
|    time_elapsed         | 1369        |
|    total_timesteps      | 1667072     |
| train/                  |             |
|    approx_kl            | 0.009838858 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.5       |
|    explained_variance   | 0.761       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.804      |
|    n_updates            | 7245        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 22.3        |
|    value_loss           | 0.129       |
-----------------------------------------
[ADAPTIVE] Episode 416 reward: 0.092457
[ADAPTIVE] Mean reward over last 20 episodes: 0.014070
[ADAPTIVE] Plateau counter: 147/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4734874  |
| time/                   |            |
|    fps                  | 1217       |
|    iterations           | 408        |
|    time_elapsed         | 1373       |
|    total_timesteps      | 1671168    |
| train/                  |            |
|    approx_kl            | 0.01219467 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -40.6      |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.799     |
|    n_updates            | 7260       |
|    policy_gradient_loss | -0.019     |
|    std                  | 22.4       |
|    value_loss           | 0.0962     |
----------------------------------------
[ADAPTIVE] Episode 417 reward: 0.108221
[ADAPTIVE] Mean reward over last 20 episodes: 0.021480
[ADAPTIVE] Plateau counter: 148/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5255806   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 409         |
|    time_elapsed         | 1376        |
|    total_timesteps      | 1675264     |
| train/                  |             |
|    approx_kl            | 0.011144333 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.7       |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.793      |
|    n_updates            | 7275        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 22.6        |
|    value_loss           | 0.12        |
-----------------------------------------
[ADAPTIVE] Episode 418 reward: -0.030847
[ADAPTIVE] Mean reward over last 20 episodes: 0.017831
[ADAPTIVE] Plateau counter: 149/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.438401    |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 410         |
|    time_elapsed         | 1380        |
|    total_timesteps      | 1679360     |
| train/                  |             |
|    approx_kl            | 0.010139873 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.7       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.806      |
|    n_updates            | 7290        |
|    policy_gradient_loss | -0.0178     |
|    std                  | 22.7        |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 419 reward: -0.032140
[ADAPTIVE] Mean reward over last 20 episodes: 0.018858
[ADAPTIVE] Plateau counter: 150/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3726443   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 411         |
|    time_elapsed         | 1383        |
|    total_timesteps      | 1683456     |
| train/                  |             |
|    approx_kl            | 0.012183985 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.8       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.816      |
|    n_updates            | 7305        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 22.9        |
|    value_loss           | 0.1         |
-----------------------------------------
[ADAPTIVE] Episode 420 reward: -0.106760
[ADAPTIVE] Mean reward over last 20 episodes: 0.013174
[ADAPTIVE] Plateau counter: 151/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3588864   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 412         |
|    time_elapsed         | 1387        |
|    total_timesteps      | 1687552     |
| train/                  |             |
|    approx_kl            | 0.014108705 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.9       |
|    explained_variance   | 0.694       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.784      |
|    n_updates            | 7320        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 23          |
|    value_loss           | 0.173       |
-----------------------------------------
[ADAPTIVE] Episode 421 reward: 0.011140
[ADAPTIVE] Mean reward over last 20 episodes: 0.015219
[ADAPTIVE] Plateau counter: 152/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6243106   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 413         |
|    time_elapsed         | 1390        |
|    total_timesteps      | 1691648     |
| train/                  |             |
|    approx_kl            | 0.014630271 |
|    clip_fraction        | 0.0961      |
|    clip_range           | 0.2         |
|    entropy_loss         | -40.9       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.79       |
|    n_updates            | 7335        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 23.1        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 422 reward: 0.072525
[ADAPTIVE] Mean reward over last 20 episodes: 0.019479
[ADAPTIVE] Plateau counter: 153/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5299529   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 414         |
|    time_elapsed         | 1394        |
|    total_timesteps      | 1695744     |
| train/                  |             |
|    approx_kl            | 0.010571614 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41         |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.803      |
|    n_updates            | 7350        |
|    policy_gradient_loss | -0.0203     |
|    std                  | 23.2        |
|    value_loss           | 0.144       |
-----------------------------------------
[ADAPTIVE] Episode 423 reward: -0.052585
[ADAPTIVE] Mean reward over last 20 episodes: 0.012377
[ADAPTIVE] Plateau counter: 154/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4298004  |
| time/                   |            |
|    fps                  | 1216       |
|    iterations           | 415        |
|    time_elapsed         | 1397       |
|    total_timesteps      | 1699840    |
| train/                  |            |
|    approx_kl            | 0.01178728 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -41        |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.824     |
|    n_updates            | 7365       |
|    policy_gradient_loss | -0.0235    |
|    std                  | 23.3       |
|    value_loss           | 0.106      |
----------------------------------------
[ADAPTIVE] Episode 424 reward: -0.059666
[ADAPTIVE] Mean reward over last 20 episodes: 0.010188
[ADAPTIVE] Plateau counter: 155/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3887794   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 416         |
|    time_elapsed         | 1400        |
|    total_timesteps      | 1703936     |
| train/                  |             |
|    approx_kl            | 0.011583612 |
|    clip_fraction        | 0.0969      |
|    clip_range           | 0.2         |
|    entropy_loss         | -41         |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.783      |
|    n_updates            | 7380        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 23.5        |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 425 reward: -0.100782
[ADAPTIVE] Mean reward over last 20 episodes: 0.004095
[ADAPTIVE] Plateau counter: 156/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4071828   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 417         |
|    time_elapsed         | 1403        |
|    total_timesteps      | 1708032     |
| train/                  |             |
|    approx_kl            | 0.008981459 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.1       |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.814      |
|    n_updates            | 7395        |
|    policy_gradient_loss | -0.0203     |
|    std                  | 23.6        |
|    value_loss           | 0.0953      |
-----------------------------------------
[ADAPTIVE] Episode 426 reward: 0.046792
[ADAPTIVE] Mean reward over last 20 episodes: 0.005453
[ADAPTIVE] Plateau counter: 157/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.452498     |
| time/                   |              |
|    fps                  | 1216         |
|    iterations           | 418          |
|    time_elapsed         | 1406         |
|    total_timesteps      | 1712128      |
| train/                  |              |
|    approx_kl            | 0.0093001705 |
|    clip_fraction        | 0.0904       |
|    clip_range           | 0.2          |
|    entropy_loss         | -41.1        |
|    explained_variance   | 0.81         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.829       |
|    n_updates            | 7410         |
|    policy_gradient_loss | -0.0174      |
|    std                  | 23.7         |
|    value_loss           | 0.0756       |
------------------------------------------
[ADAPTIVE] Episode 427 reward: 0.110470
[ADAPTIVE] Mean reward over last 20 episodes: 0.012268
[ADAPTIVE] Plateau counter: 158/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.287191     |
| time/                   |              |
|    fps                  | 1216         |
|    iterations           | 419          |
|    time_elapsed         | 1410         |
|    total_timesteps      | 1716224      |
| train/                  |              |
|    approx_kl            | 0.0076635545 |
|    clip_fraction        | 0.122        |
|    clip_range           | 0.2          |
|    entropy_loss         | -41.2        |
|    explained_variance   | 0.744        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.799       |
|    n_updates            | 7425         |
|    policy_gradient_loss | -0.0188      |
|    std                  | 23.7         |
|    value_loss           | 0.099        |
------------------------------------------
[ADAPTIVE] Episode 428 reward: 0.009388
[ADAPTIVE] Mean reward over last 20 episodes: 0.015669
[ADAPTIVE] Plateau counter: 159/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2001339   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 420         |
|    time_elapsed         | 1413        |
|    total_timesteps      | 1720320     |
| train/                  |             |
|    approx_kl            | 0.011311274 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.2       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.82       |
|    n_updates            | 7440        |
|    policy_gradient_loss | -0.022      |
|    std                  | 24          |
|    value_loss           | 0.0722      |
-----------------------------------------
[ADAPTIVE] Episode 429 reward: -0.016916
[ADAPTIVE] Mean reward over last 20 episodes: 0.014428
[ADAPTIVE] Plateau counter: 160/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.305675    |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 421         |
|    time_elapsed         | 1417        |
|    total_timesteps      | 1724416     |
| train/                  |             |
|    approx_kl            | 0.008426587 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.3       |
|    explained_variance   | 0.776       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.829      |
|    n_updates            | 7455        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 24          |
|    value_loss           | 0.0843      |
-----------------------------------------
[ADAPTIVE] Episode 430 reward: -0.023397
[ADAPTIVE] Mean reward over last 20 episodes: 0.012777
[ADAPTIVE] Plateau counter: 161/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3480393   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 422         |
|    time_elapsed         | 1420        |
|    total_timesteps      | 1728512     |
| train/                  |             |
|    approx_kl            | 0.011744011 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.3       |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.82       |
|    n_updates            | 7470        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 24.2        |
|    value_loss           | 0.0875      |
-----------------------------------------
[ADAPTIVE] Episode 431 reward: -0.032989
[ADAPTIVE] Mean reward over last 20 episodes: 0.012017
[ADAPTIVE] Plateau counter: 162/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3127741   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 423         |
|    time_elapsed         | 1424        |
|    total_timesteps      | 1732608     |
| train/                  |             |
|    approx_kl            | 0.011854457 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.4       |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.827      |
|    n_updates            | 7485        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 24.4        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 432 reward: 0.104896
[ADAPTIVE] Mean reward over last 20 episodes: 0.015669
[ADAPTIVE] Plateau counter: 163/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1932454   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 424         |
|    time_elapsed         | 1428        |
|    total_timesteps      | 1736704     |
| train/                  |             |
|    approx_kl            | 0.012578731 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.4       |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.787      |
|    n_updates            | 7500        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 24.5        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 433 reward: -0.073131
[ADAPTIVE] Mean reward over last 20 episodes: 0.006264
[ADAPTIVE] Plateau counter: 164/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3135892   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 425         |
|    time_elapsed         | 1431        |
|    total_timesteps      | 1740800     |
| train/                  |             |
|    approx_kl            | 0.010753446 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.5       |
|    explained_variance   | 0.726       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.81       |
|    n_updates            | 7515        |
|    policy_gradient_loss | -0.0178     |
|    std                  | 24.7        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 434 reward: 0.024319
[ADAPTIVE] Mean reward over last 20 episodes: 0.007844
[ADAPTIVE] Plateau counter: 165/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1939132   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 426         |
|    time_elapsed         | 1435        |
|    total_timesteps      | 1744896     |
| train/                  |             |
|    approx_kl            | 0.010157973 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.5       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.827      |
|    n_updates            | 7530        |
|    policy_gradient_loss | -0.024      |
|    std                  | 24.8        |
|    value_loss           | 0.0749      |
-----------------------------------------
[ADAPTIVE] Episode 435 reward: -0.065782
[ADAPTIVE] Mean reward over last 20 episodes: -0.000739
[ADAPTIVE] Plateau counter: 166/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2039664  |
| time/                   |            |
|    fps                  | 1216       |
|    iterations           | 427        |
|    time_elapsed         | 1438       |
|    total_timesteps      | 1748992    |
| train/                  |            |
|    approx_kl            | 0.01014244 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -41.6      |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.818     |
|    n_updates            | 7545       |
|    policy_gradient_loss | -0.0226    |
|    std                  | 25         |
|    value_loss           | 0.106      |
----------------------------------------
[ADAPTIVE] Episode 436 reward: 0.011428
[ADAPTIVE] Mean reward over last 20 episodes: -0.004791
[ADAPTIVE] Plateau counter: 167/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0805976   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 428         |
|    time_elapsed         | 1441        |
|    total_timesteps      | 1753088     |
| train/                  |             |
|    approx_kl            | 0.011219416 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.6       |
|    explained_variance   | 0.631       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.809      |
|    n_updates            | 7560        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 25.1        |
|    value_loss           | 0.138       |
-----------------------------------------
[ADAPTIVE] Episode 437 reward: -0.052177
[ADAPTIVE] Mean reward over last 20 episodes: -0.012811
[ADAPTIVE] Plateau counter: 168/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1860071    |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 429          |
|    time_elapsed         | 1445         |
|    total_timesteps      | 1757184      |
| train/                  |              |
|    approx_kl            | 0.0102211395 |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.2          |
|    entropy_loss         | -41.7        |
|    explained_variance   | 0.676        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.809       |
|    n_updates            | 7575         |
|    policy_gradient_loss | -0.0178      |
|    std                  | 25.2         |
|    value_loss           | 0.123        |
------------------------------------------
[ADAPTIVE] Episode 438 reward: -0.032525
[ADAPTIVE] Mean reward over last 20 episodes: -0.012895
[ADAPTIVE] Plateau counter: 169/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4977684   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 430         |
|    time_elapsed         | 1448        |
|    total_timesteps      | 1761280     |
| train/                  |             |
|    approx_kl            | 0.011459292 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.7       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.837      |
|    n_updates            | 7590        |
|    policy_gradient_loss | -0.018      |
|    std                  | 25.4        |
|    value_loss           | 0.119       |
-----------------------------------------
[ADAPTIVE] Episode 439 reward: 0.012034
[ADAPTIVE] Mean reward over last 20 episodes: -0.010686
[ADAPTIVE] Plateau counter: 170/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.386167    |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 431         |
|    time_elapsed         | 1452        |
|    total_timesteps      | 1765376     |
| train/                  |             |
|    approx_kl            | 0.009749765 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.8       |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.811      |
|    n_updates            | 7605        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 25.7        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 440 reward: 0.010171
[ADAPTIVE] Mean reward over last 20 episodes: -0.004839
[ADAPTIVE] Plateau counter: 171/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4086848  |
| time/                   |            |
|    fps                  | 1215       |
|    iterations           | 432        |
|    time_elapsed         | 1455       |
|    total_timesteps      | 1769472    |
| train/                  |            |
|    approx_kl            | 0.01049269 |
|    clip_fraction        | 0.119      |
|    clip_range           | 0.2        |
|    entropy_loss         | -41.9      |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.826     |
|    n_updates            | 7620       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 25.8       |
|    value_loss           | 0.103      |
----------------------------------------
[ADAPTIVE] Episode 441 reward: -0.047089
[ADAPTIVE] Mean reward over last 20 episodes: -0.007751
[ADAPTIVE] Plateau counter: 172/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.436082    |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 433         |
|    time_elapsed         | 1459        |
|    total_timesteps      | 1773568     |
| train/                  |             |
|    approx_kl            | 0.010021926 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -41.9       |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.815      |
|    n_updates            | 7635        |
|    policy_gradient_loss | -0.0188     |
|    std                  | 25.9        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 442 reward: -0.195874
[ADAPTIVE] Mean reward over last 20 episodes: -0.021171
[ADAPTIVE] Plateau counter: 173/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5700809   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 434         |
|    time_elapsed         | 1462        |
|    total_timesteps      | 1777664     |
| train/                  |             |
|    approx_kl            | 0.009011926 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42         |
|    explained_variance   | 0.795       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.833      |
|    n_updates            | 7650        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 26.1        |
|    value_loss           | 0.0965      |
-----------------------------------------
[ADAPTIVE] Episode 443 reward: 0.030956
[ADAPTIVE] Mean reward over last 20 episodes: -0.016994
[ADAPTIVE] Plateau counter: 174/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4735583   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 435         |
|    time_elapsed         | 1465        |
|    total_timesteps      | 1781760     |
| train/                  |             |
|    approx_kl            | 0.008312093 |
|    clip_fraction        | 0.0964      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42         |
|    explained_variance   | 0.682       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.819      |
|    n_updates            | 7665        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 26.2        |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 444 reward: -0.008058
[ADAPTIVE] Mean reward over last 20 episodes: -0.014413
[ADAPTIVE] Plateau counter: 175/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3481431   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 436         |
|    time_elapsed         | 1468        |
|    total_timesteps      | 1785856     |
| train/                  |             |
|    approx_kl            | 0.007929697 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42         |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.83       |
|    n_updates            | 7680        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 26.2        |
|    value_loss           | 0.0871      |
-----------------------------------------
[ADAPTIVE] Episode 445 reward: -0.031240
[ADAPTIVE] Mean reward over last 20 episodes: -0.010936
[ADAPTIVE] Plateau counter: 176/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2828292   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 437         |
|    time_elapsed         | 1471        |
|    total_timesteps      | 1789952     |
| train/                  |             |
|    approx_kl            | 0.008283453 |
|    clip_fraction        | 0.0951      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42         |
|    explained_variance   | 0.779       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.843      |
|    n_updates            | 7695        |
|    policy_gradient_loss | -0.0153     |
|    std                  | 26.3        |
|    value_loss           | 0.0787      |
-----------------------------------------
[ADAPTIVE] Episode 446 reward: 0.024971
[ADAPTIVE] Mean reward over last 20 episodes: -0.012027
[ADAPTIVE] Plateau counter: 177/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2123386   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 438         |
|    time_elapsed         | 1475        |
|    total_timesteps      | 1794048     |
| train/                  |             |
|    approx_kl            | 0.011565197 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.1       |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.821      |
|    n_updates            | 7710        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 26.4        |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 447 reward: -0.044132
[ADAPTIVE] Mean reward over last 20 episodes: -0.019757
[ADAPTIVE] Plateau counter: 178/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2901523  |
| time/                   |            |
|    fps                  | 1216       |
|    iterations           | 439        |
|    time_elapsed         | 1478       |
|    total_timesteps      | 1798144    |
| train/                  |            |
|    approx_kl            | 0.00948959 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -42.1      |
|    explained_variance   | 0.783      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.839     |
|    n_updates            | 7725       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 26.5       |
|    value_loss           | 0.105      |
----------------------------------------
[ADAPTIVE] Episode 448 reward: 0.011048
[ADAPTIVE] Mean reward over last 20 episodes: -0.019674
[ADAPTIVE] Plateau counter: 179/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2803397   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 440         |
|    time_elapsed         | 1481        |
|    total_timesteps      | 1802240     |
| train/                  |             |
|    approx_kl            | 0.011762721 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.2       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.826      |
|    n_updates            | 7740        |
|    policy_gradient_loss | -0.02       |
|    std                  | 26.6        |
|    value_loss           | 0.0886      |
-----------------------------------------
[ADAPTIVE] Episode 449 reward: 0.067899
[ADAPTIVE] Mean reward over last 20 episodes: -0.015434
[ADAPTIVE] Plateau counter: 180/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2501377   |
| time/                   |             |
|    fps                  | 1216        |
|    iterations           | 441         |
|    time_elapsed         | 1484        |
|    total_timesteps      | 1806336     |
| train/                  |             |
|    approx_kl            | 0.009376201 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.2       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.845      |
|    n_updates            | 7755        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 26.7        |
|    value_loss           | 0.0872      |
-----------------------------------------
[ADAPTIVE] Episode 450 reward: -0.023105
[ADAPTIVE] Mean reward over last 20 episodes: -0.015419
[ADAPTIVE] Plateau counter: 181/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.37238    |
| time/                   |            |
|    fps                  | 1216       |
|    iterations           | 442        |
|    time_elapsed         | 1487       |
|    total_timesteps      | 1810432    |
| train/                  |            |
|    approx_kl            | 0.00920674 |
|    clip_fraction        | 0.112      |
|    clip_range           | 0.2        |
|    entropy_loss         | -42.2      |
|    explained_variance   | 0.753      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.841     |
|    n_updates            | 7770       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 26.7       |
|    value_loss           | 0.09       |
----------------------------------------
[ADAPTIVE] Episode 451 reward: -0.038341
[ADAPTIVE] Mean reward over last 20 episodes: -0.015687
[ADAPTIVE] Plateau counter: 182/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3347071   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 443         |
|    time_elapsed         | 1492        |
|    total_timesteps      | 1814528     |
| train/                  |             |
|    approx_kl            | 0.013220586 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.2       |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.826      |
|    n_updates            | 7785        |
|    policy_gradient_loss | -0.0218     |
|    std                  | 26.9        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 452 reward: -0.043908
[ADAPTIVE] Mean reward over last 20 episodes: -0.023127
[ADAPTIVE] Plateau counter: 183/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4473971   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 444         |
|    time_elapsed         | 1495        |
|    total_timesteps      | 1818624     |
| train/                  |             |
|    approx_kl            | 0.007537858 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.3       |
|    explained_variance   | 0.7         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.795      |
|    n_updates            | 7800        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 27          |
|    value_loss           | 0.19        |
-----------------------------------------
[ADAPTIVE] Episode 453 reward: 0.078643
[ADAPTIVE] Mean reward over last 20 episodes: -0.015538
[ADAPTIVE] Plateau counter: 184/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3767362    |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 445          |
|    time_elapsed         | 1499         |
|    total_timesteps      | 1822720      |
| train/                  |              |
|    approx_kl            | 0.0071805096 |
|    clip_fraction        | 0.093        |
|    clip_range           | 0.2          |
|    entropy_loss         | -42.3        |
|    explained_variance   | 0.62         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.81        |
|    n_updates            | 7815         |
|    policy_gradient_loss | -0.0148      |
|    std                  | 27.1         |
|    value_loss           | 0.18         |
------------------------------------------
[ADAPTIVE] Episode 454 reward: 0.051754
[ADAPTIVE] Mean reward over last 20 episodes: -0.014166
[ADAPTIVE] Plateau counter: 185/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2344797    |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 446          |
|    time_elapsed         | 1502         |
|    total_timesteps      | 1826816      |
| train/                  |              |
|    approx_kl            | 0.0063983053 |
|    clip_fraction        | 0.0628       |
|    clip_range           | 0.2          |
|    entropy_loss         | -42.4        |
|    explained_variance   | 0.737        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.809       |
|    n_updates            | 7830         |
|    policy_gradient_loss | -0.0121      |
|    std                  | 27.2         |
|    value_loss           | 0.143        |
------------------------------------------
[ADAPTIVE] Episode 455 reward: 0.004131
[ADAPTIVE] Mean reward over last 20 episodes: -0.010671
[ADAPTIVE] Plateau counter: 186/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1763681  |
| time/                   |            |
|    fps                  | 1215       |
|    iterations           | 447        |
|    time_elapsed         | 1506       |
|    total_timesteps      | 1830912    |
| train/                  |            |
|    approx_kl            | 0.01034013 |
|    clip_fraction        | 0.0942     |
|    clip_range           | 0.2        |
|    entropy_loss         | -42.4      |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.842     |
|    n_updates            | 7845       |
|    policy_gradient_loss | -0.0174    |
|    std                  | 27.3       |
|    value_loss           | 0.0839     |
----------------------------------------
[ADAPTIVE] Episode 456 reward: 0.095259
[ADAPTIVE] Mean reward over last 20 episodes: -0.006479
[ADAPTIVE] Plateau counter: 187/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.97857195   |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 448          |
|    time_elapsed         | 1509         |
|    total_timesteps      | 1835008      |
| train/                  |              |
|    approx_kl            | 0.0095682535 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.2          |
|    entropy_loss         | -42.4        |
|    explained_variance   | 0.62         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.811       |
|    n_updates            | 7860         |
|    policy_gradient_loss | -0.0163      |
|    std                  | 27.5         |
|    value_loss           | 0.191        |
------------------------------------------
[ADAPTIVE] Episode 457 reward: 0.028365
[ADAPTIVE] Mean reward over last 20 episodes: -0.002452
[ADAPTIVE] Plateau counter: 188/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0817802   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 449         |
|    time_elapsed         | 1512        |
|    total_timesteps      | 1839104     |
| train/                  |             |
|    approx_kl            | 0.009048642 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.5       |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.82       |
|    n_updates            | 7875        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 27.6        |
|    value_loss           | 0.155       |
-----------------------------------------
[ADAPTIVE] Episode 458 reward: -0.055064
[ADAPTIVE] Mean reward over last 20 episodes: -0.003579
[ADAPTIVE] Plateau counter: 189/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0513539   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 450         |
|    time_elapsed         | 1516        |
|    total_timesteps      | 1843200     |
| train/                  |             |
|    approx_kl            | 0.009166976 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.5       |
|    explained_variance   | 0.777       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.854      |
|    n_updates            | 7890        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 27.7        |
|    value_loss           | 0.0738      |
-----------------------------------------
[ADAPTIVE] Episode 459 reward: 0.011214
[ADAPTIVE] Mean reward over last 20 episodes: -0.003620
[ADAPTIVE] Plateau counter: 190/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.95162046   |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 451          |
|    time_elapsed         | 1519         |
|    total_timesteps      | 1847296      |
| train/                  |              |
|    approx_kl            | 0.0091462955 |
|    clip_fraction        | 0.127        |
|    clip_range           | 0.2          |
|    entropy_loss         | -42.6        |
|    explained_variance   | 0.769        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.831       |
|    n_updates            | 7905         |
|    policy_gradient_loss | -0.0201      |
|    std                  | 27.8         |
|    value_loss           | 0.114        |
------------------------------------------
[ADAPTIVE] Episode 460 reward: -0.023149
[ADAPTIVE] Mean reward over last 20 episodes: -0.005286
[ADAPTIVE] Plateau counter: 191/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 461 reward: 0.020352
[ADAPTIVE] Mean reward over last 20 episodes: -0.001914
[ADAPTIVE] Plateau counter: 192/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0678257    |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 452          |
|    time_elapsed         | 1523         |
|    total_timesteps      | 1851392      |
| train/                  |              |
|    approx_kl            | 0.0072859935 |
|    clip_fraction        | 0.0678       |
|    clip_range           | 0.2          |
|    entropy_loss         | -42.6        |
|    explained_variance   | 0.782        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.842       |
|    n_updates            | 7920         |
|    policy_gradient_loss | -0.0131      |
|    std                  | 27.9         |
|    value_loss           | 0.121        |
------------------------------------------
[ADAPTIVE] Episode 462 reward: -0.035500
[ADAPTIVE] Mean reward over last 20 episodes: 0.006105
[ADAPTIVE] Plateau counter: 193/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2585669   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 453         |
|    time_elapsed         | 1526        |
|    total_timesteps      | 1855488     |
| train/                  |             |
|    approx_kl            | 0.010508783 |
|    clip_fraction        | 0.0864      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.6       |
|    explained_variance   | 0.614       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.782      |
|    n_updates            | 7935        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 28.1        |
|    value_loss           | 0.201       |
-----------------------------------------
[ADAPTIVE] Episode 463 reward: -0.031807
[ADAPTIVE] Mean reward over last 20 episodes: 0.002967
[ADAPTIVE] Plateau counter: 194/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0645179   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 454         |
|    time_elapsed         | 1529        |
|    total_timesteps      | 1859584     |
| train/                  |             |
|    approx_kl            | 0.012143144 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.7       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.827      |
|    n_updates            | 7950        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 28.2        |
|    value_loss           | 0.0749      |
-----------------------------------------
[ADAPTIVE] Episode 464 reward: 0.129594
[ADAPTIVE] Mean reward over last 20 episodes: 0.009849
[ADAPTIVE] Plateau counter: 195/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0657508  |
| time/                   |            |
|    fps                  | 1215       |
|    iterations           | 455        |
|    time_elapsed         | 1533       |
|    total_timesteps      | 1863680    |
| train/                  |            |
|    approx_kl            | 0.00713009 |
|    clip_fraction        | 0.0798     |
|    clip_range           | 0.2        |
|    entropy_loss         | -42.7      |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.833     |
|    n_updates            | 7965       |
|    policy_gradient_loss | -0.016     |
|    std                  | 28.3       |
|    value_loss           | 0.119      |
----------------------------------------
[ADAPTIVE] Episode 465 reward: 0.067333
[ADAPTIVE] Mean reward over last 20 episodes: 0.014778
[ADAPTIVE] Plateau counter: 196/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0877994   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 456         |
|    time_elapsed         | 1537        |
|    total_timesteps      | 1867776     |
| train/                  |             |
|    approx_kl            | 0.011330179 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.8       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.853      |
|    n_updates            | 7980        |
|    policy_gradient_loss | -0.015      |
|    std                  | 28.4        |
|    value_loss           | 0.0775      |
-----------------------------------------
[ADAPTIVE] Episode 466 reward: 0.000564
[ADAPTIVE] Mean reward over last 20 episodes: 0.013558
[ADAPTIVE] Plateau counter: 197/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2045246   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 457         |
|    time_elapsed         | 1540        |
|    total_timesteps      | 1871872     |
| train/                  |             |
|    approx_kl            | 0.009225156 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.8       |
|    explained_variance   | 0.807       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.83       |
|    n_updates            | 7995        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 28.6        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 467 reward: -0.162533
[ADAPTIVE] Mean reward over last 20 episodes: 0.007637
[ADAPTIVE] Plateau counter: 198/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2228974   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 458         |
|    time_elapsed         | 1543        |
|    total_timesteps      | 1875968     |
| train/                  |             |
|    approx_kl            | 0.010468552 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.9       |
|    explained_variance   | 0.608       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.811      |
|    n_updates            | 8010        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 28.7        |
|    value_loss           | 0.177       |
-----------------------------------------
[ADAPTIVE] Episode 468 reward: 0.053897
[ADAPTIVE] Mean reward over last 20 episodes: 0.009780
[ADAPTIVE] Plateau counter: 199/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2028632   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 459         |
|    time_elapsed         | 1547        |
|    total_timesteps      | 1880064     |
| train/                  |             |
|    approx_kl            | 0.008308425 |
|    clip_fraction        | 0.0876      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.9       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.828      |
|    n_updates            | 8025        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 28.8        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 469 reward: 0.010927
[ADAPTIVE] Mean reward over last 20 episodes: 0.006931
[ADAPTIVE] Plateau counter: 200/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2217089   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 460         |
|    time_elapsed         | 1551        |
|    total_timesteps      | 1884160     |
| train/                  |             |
|    approx_kl            | 0.009745027 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.9       |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.847      |
|    n_updates            | 8040        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 28.9        |
|    value_loss           | 0.097       |
-----------------------------------------
[ADAPTIVE] Episode 470 reward: 0.045671
[ADAPTIVE] Mean reward over last 20 episodes: 0.010370
[ADAPTIVE] Plateau counter: 201/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3546855   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 461         |
|    time_elapsed         | 1554        |
|    total_timesteps      | 1888256     |
| train/                  |             |
|    approx_kl            | 0.008651706 |
|    clip_fraction        | 0.0947      |
|    clip_range           | 0.2         |
|    entropy_loss         | -42.9       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.841      |
|    n_updates            | 8055        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 29          |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 471 reward: -0.063789
[ADAPTIVE] Mean reward over last 20 episodes: 0.009098
[ADAPTIVE] Plateau counter: 202/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4599581   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 462         |
|    time_elapsed         | 1558        |
|    total_timesteps      | 1892352     |
| train/                  |             |
|    approx_kl            | 0.009462139 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43         |
|    explained_variance   | 0.776       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.854      |
|    n_updates            | 8070        |
|    policy_gradient_loss | -0.0178     |
|    std                  | 29.3        |
|    value_loss           | 0.0886      |
-----------------------------------------
[ADAPTIVE] Episode 472 reward: -0.025840
[ADAPTIVE] Mean reward over last 20 episodes: 0.010001
[ADAPTIVE] Plateau counter: 203/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4076926   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 463         |
|    time_elapsed         | 1561        |
|    total_timesteps      | 1896448     |
| train/                  |             |
|    approx_kl            | 0.010119898 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43         |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.852      |
|    n_updates            | 8085        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 29.3        |
|    value_loss           | 0.0711      |
-----------------------------------------
[ADAPTIVE] Episode 473 reward: -0.051319
[ADAPTIVE] Mean reward over last 20 episodes: 0.003503
[ADAPTIVE] Plateau counter: 204/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5952452   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 464         |
|    time_elapsed         | 1565        |
|    total_timesteps      | 1900544     |
| train/                  |             |
|    approx_kl            | 0.007870195 |
|    clip_fraction        | 0.0916      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.1       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.845      |
|    n_updates            | 8100        |
|    policy_gradient_loss | -0.019      |
|    std                  | 29.5        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 474 reward: -0.109122
[ADAPTIVE] Mean reward over last 20 episodes: -0.004541
[ADAPTIVE] Plateau counter: 205/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.477752    |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 465         |
|    time_elapsed         | 1569        |
|    total_timesteps      | 1904640     |
| train/                  |             |
|    approx_kl            | 0.009102584 |
|    clip_fraction        | 0.0951      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.1       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.833      |
|    n_updates            | 8115        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 29.7        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 475 reward: 0.017734
[ADAPTIVE] Mean reward over last 20 episodes: -0.003861
[ADAPTIVE] Plateau counter: 206/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5163949   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 466         |
|    time_elapsed         | 1572        |
|    total_timesteps      | 1908736     |
| train/                  |             |
|    approx_kl            | 0.009518314 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.2       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.87       |
|    n_updates            | 8130        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 29.8        |
|    value_loss           | 0.089       |
-----------------------------------------
[ADAPTIVE] Episode 476 reward: 0.053399
[ADAPTIVE] Mean reward over last 20 episodes: -0.005954
[ADAPTIVE] Plateau counter: 207/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5663751   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 467         |
|    time_elapsed         | 1576        |
|    total_timesteps      | 1912832     |
| train/                  |             |
|    approx_kl            | 0.007513244 |
|    clip_fraction        | 0.0854      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.2       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.857      |
|    n_updates            | 8145        |
|    policy_gradient_loss | -0.017      |
|    std                  | 29.9        |
|    value_loss           | 0.0799      |
-----------------------------------------
[ADAPTIVE] Episode 477 reward: 0.039487
[ADAPTIVE] Mean reward over last 20 episodes: -0.005398
[ADAPTIVE] Plateau counter: 208/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.6138899    |
| time/                   |              |
|    fps                  | 1213         |
|    iterations           | 468          |
|    time_elapsed         | 1579         |
|    total_timesteps      | 1916928      |
| train/                  |              |
|    approx_kl            | 0.0072807735 |
|    clip_fraction        | 0.0868       |
|    clip_range           | 0.2          |
|    entropy_loss         | -43.2        |
|    explained_variance   | 0.744        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.853       |
|    n_updates            | 8160         |
|    policy_gradient_loss | -0.0182      |
|    std                  | 30           |
|    value_loss           | 0.107        |
------------------------------------------
[ADAPTIVE] Episode 478 reward: -0.077651
[ADAPTIVE] Mean reward over last 20 episodes: -0.006527
[ADAPTIVE] Plateau counter: 209/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6864341   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 469         |
|    time_elapsed         | 1583        |
|    total_timesteps      | 1921024     |
| train/                  |             |
|    approx_kl            | 0.010152316 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.3       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.837      |
|    n_updates            | 8175        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 30.2        |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 479 reward: -0.027282
[ADAPTIVE] Mean reward over last 20 episodes: -0.008452
[ADAPTIVE] Plateau counter: 210/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6043947   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 470         |
|    time_elapsed         | 1586        |
|    total_timesteps      | 1925120     |
| train/                  |             |
|    approx_kl            | 0.009493018 |
|    clip_fraction        | 0.0997      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.3       |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.856      |
|    n_updates            | 8190        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 30.3        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 480 reward: -0.027969
[ADAPTIVE] Mean reward over last 20 episodes: -0.008693
[ADAPTIVE] Plateau counter: 211/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5799061   |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 471         |
|    time_elapsed         | 1590        |
|    total_timesteps      | 1929216     |
| train/                  |             |
|    approx_kl            | 0.011146257 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.4       |
|    explained_variance   | 0.711       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.868      |
|    n_updates            | 8205        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 30.5        |
|    value_loss           | 0.0929      |
-----------------------------------------
[ADAPTIVE] Episode 481 reward: 0.025729
[ADAPTIVE] Mean reward over last 20 episodes: -0.008424
[ADAPTIVE] Plateau counter: 212/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.521699    |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 472         |
|    time_elapsed         | 1593        |
|    total_timesteps      | 1933312     |
| train/                  |             |
|    approx_kl            | 0.010002291 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.4       |
|    explained_variance   | 0.613       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.86       |
|    n_updates            | 8220        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 30.7        |
|    value_loss           | 0.095       |
-----------------------------------------
[ADAPTIVE] Episode 482 reward: 0.018869
[ADAPTIVE] Mean reward over last 20 episodes: -0.005705
[ADAPTIVE] Plateau counter: 213/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.40931     |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 473         |
|    time_elapsed         | 1597        |
|    total_timesteps      | 1937408     |
| train/                  |             |
|    approx_kl            | 0.014169328 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.5       |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.878      |
|    n_updates            | 8235        |
|    policy_gradient_loss | -0.0208     |
|    std                  | 31          |
|    value_loss           | 0.0769      |
-----------------------------------------
[ADAPTIVE] Episode 483 reward: -0.084927
[ADAPTIVE] Mean reward over last 20 episodes: -0.008361
[ADAPTIVE] Plateau counter: 214/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3662481   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 474         |
|    time_elapsed         | 1600        |
|    total_timesteps      | 1941504     |
| train/                  |             |
|    approx_kl            | 0.007039586 |
|    clip_fraction        | 0.0652      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.5       |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.865      |
|    n_updates            | 8250        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 31.1        |
|    value_loss           | 0.0758      |
-----------------------------------------
[ADAPTIVE] Episode 484 reward: 0.017368
[ADAPTIVE] Mean reward over last 20 episodes: -0.013973
[ADAPTIVE] Plateau counter: 215/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2936697   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 475         |
|    time_elapsed         | 1603        |
|    total_timesteps      | 1945600     |
| train/                  |             |
|    approx_kl            | 0.007830596 |
|    clip_fraction        | 0.0871      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.6       |
|    explained_variance   | 0.651       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.811      |
|    n_updates            | 8265        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 31.3        |
|    value_loss           | 0.202       |
-----------------------------------------
[ADAPTIVE] Episode 485 reward: -0.022118
[ADAPTIVE] Mean reward over last 20 episodes: -0.018445
[ADAPTIVE] Plateau counter: 216/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.067511    |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 476         |
|    time_elapsed         | 1606        |
|    total_timesteps      | 1949696     |
| train/                  |             |
|    approx_kl            | 0.009838655 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.7       |
|    explained_variance   | 0.675       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.837      |
|    n_updates            | 8280        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 31.5        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 486 reward: 0.028313
[ADAPTIVE] Mean reward over last 20 episodes: -0.017058
[ADAPTIVE] Plateau counter: 217/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2340049  |
| time/                   |            |
|    fps                  | 1213       |
|    iterations           | 477        |
|    time_elapsed         | 1609       |
|    total_timesteps      | 1953792    |
| train/                  |            |
|    approx_kl            | 0.01439555 |
|    clip_fraction        | 0.101      |
|    clip_range           | 0.2        |
|    entropy_loss         | -43.7      |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.847     |
|    n_updates            | 8295       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 31.6       |
|    value_loss           | 0.121      |
----------------------------------------
[ADAPTIVE] Episode 487 reward: 0.040471
[ADAPTIVE] Mean reward over last 20 episodes: -0.006908
[ADAPTIVE] Plateau counter: 218/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3006623   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 478         |
|    time_elapsed         | 1613        |
|    total_timesteps      | 1957888     |
| train/                  |             |
|    approx_kl            | 0.011600323 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.8       |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.827      |
|    n_updates            | 8310        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 31.9        |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 488 reward: -0.037127
[ADAPTIVE] Mean reward over last 20 episodes: -0.011459
[ADAPTIVE] Plateau counter: 219/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1580304   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 479         |
|    time_elapsed         | 1616        |
|    total_timesteps      | 1961984     |
| train/                  |             |
|    approx_kl            | 0.007427552 |
|    clip_fraction        | 0.0887      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.8       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.85       |
|    n_updates            | 8325        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 32          |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 489 reward: 0.021753
[ADAPTIVE] Mean reward over last 20 episodes: -0.010918
[ADAPTIVE] Plateau counter: 220/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.197381    |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 480         |
|    time_elapsed         | 1620        |
|    total_timesteps      | 1966080     |
| train/                  |             |
|    approx_kl            | 0.008774998 |
|    clip_fraction        | 0.0913      |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.8       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.85       |
|    n_updates            | 8340        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 32.2        |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 490 reward: -0.026404
[ADAPTIVE] Mean reward over last 20 episodes: -0.014521
[ADAPTIVE] Plateau counter: 221/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1716999   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 481         |
|    time_elapsed         | 1623        |
|    total_timesteps      | 1970176     |
| train/                  |             |
|    approx_kl            | 0.008236555 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.9       |
|    explained_variance   | 0.761       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.853      |
|    n_updates            | 8355        |
|    policy_gradient_loss | -0.0174     |
|    std                  | 32.2        |
|    value_loss           | 0.101       |
-----------------------------------------
[ADAPTIVE] Episode 491 reward: -0.008322
[ADAPTIVE] Mean reward over last 20 episodes: -0.011748
[ADAPTIVE] Plateau counter: 222/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2464615   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 482         |
|    time_elapsed         | 1626        |
|    total_timesteps      | 1974272     |
| train/                  |             |
|    approx_kl            | 0.013039549 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -43.9       |
|    explained_variance   | 0.813       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.884      |
|    n_updates            | 8370        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 32.5        |
|    value_loss           | 0.0626      |
-----------------------------------------
[ADAPTIVE] Episode 492 reward: -0.030010
[ADAPTIVE] Mean reward over last 20 episodes: -0.011956
[ADAPTIVE] Plateau counter: 223/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2189428   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 483         |
|    time_elapsed         | 1630        |
|    total_timesteps      | 1978368     |
| train/                  |             |
|    approx_kl            | 0.009689119 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44         |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.854      |
|    n_updates            | 8385        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 32.6        |
|    value_loss           | 0.147       |
-----------------------------------------
[ADAPTIVE] Episode 493 reward: 0.045636
[ADAPTIVE] Mean reward over last 20 episodes: -0.007109
[ADAPTIVE] Plateau counter: 224/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9997132   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 484         |
|    time_elapsed         | 1633        |
|    total_timesteps      | 1982464     |
| train/                  |             |
|    approx_kl            | 0.010004786 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -44         |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.876      |
|    n_updates            | 8400        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 32.8        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 494 reward: 0.045981
[ADAPTIVE] Mean reward over last 20 episodes: 0.000647
[ADAPTIVE] Plateau counter: 225/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0628296   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 485         |
|    time_elapsed         | 1636        |
|    total_timesteps      | 1986560     |
| train/                  |             |
|    approx_kl            | 0.014162162 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.1       |
|    explained_variance   | 0.553       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.834      |
|    n_updates            | 8415        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 33.1        |
|    value_loss           | 0.175       |
-----------------------------------------
[ADAPTIVE] Episode 495 reward: -0.019050
[ADAPTIVE] Mean reward over last 20 episodes: -0.001193
[ADAPTIVE] Plateau counter: 226/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9260262   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 486         |
|    time_elapsed         | 1639        |
|    total_timesteps      | 1990656     |
| train/                  |             |
|    approx_kl            | 0.008595591 |
|    clip_fraction        | 0.0875      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.1       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.875      |
|    n_updates            | 8430        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 33.3        |
|    value_loss           | 0.0953      |
-----------------------------------------
[ADAPTIVE] Episode 496 reward: 0.078527
[ADAPTIVE] Mean reward over last 20 episodes: 0.000064
[ADAPTIVE] Plateau counter: 227/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.9006948  |
| time/                   |            |
|    fps                  | 1214       |
|    iterations           | 487        |
|    time_elapsed         | 1643       |
|    total_timesteps      | 1994752    |
| train/                  |            |
|    approx_kl            | 0.00843972 |
|    clip_fraction        | 0.0871     |
|    clip_range           | 0.2        |
|    entropy_loss         | -44.2      |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.00025    |
|    loss                 | -0.875     |
|    n_updates            | 8445       |
|    policy_gradient_loss | -0.0134    |
|    std                  | 33.4       |
|    value_loss           | 0.117      |
----------------------------------------
[ADAPTIVE] Episode 497 reward: -0.042203
[ADAPTIVE] Mean reward over last 20 episodes: -0.004021
[ADAPTIVE] Plateau counter: 228/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8640804   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 488         |
|    time_elapsed         | 1645        |
|    total_timesteps      | 1998848     |
| train/                  |             |
|    approx_kl            | 0.010739404 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.2       |
|    explained_variance   | 0.641       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.82       |
|    n_updates            | 8460        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 33.6        |
|    value_loss           | 0.192       |
-----------------------------------------
[ADAPTIVE] Episode 498 reward: -0.058615
[ADAPTIVE] Mean reward over last 20 episodes: -0.003069
[ADAPTIVE] Plateau counter: 229/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.76889277  |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 489         |
|    time_elapsed         | 1649        |
|    total_timesteps      | 2002944     |
| train/                  |             |
|    approx_kl            | 0.008848833 |
|    clip_fraction        | 0.0886      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.3       |
|    explained_variance   | 0.597       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.848      |
|    n_updates            | 8475        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 33.7        |
|    value_loss           | 0.162       |
-----------------------------------------
[ADAPTIVE] Episode 499 reward: -0.000219
[ADAPTIVE] Mean reward over last 20 episodes: -0.001716
[ADAPTIVE] Plateau counter: 230/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.89862853  |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 490         |
|    time_elapsed         | 1652        |
|    total_timesteps      | 2007040     |
| train/                  |             |
|    approx_kl            | 0.009662692 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.3       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.881      |
|    n_updates            | 8490        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 33.9        |
|    value_loss           | 0.0985      |
-----------------------------------------
[ADAPTIVE] Episode 500 reward: -0.295704
[ADAPTIVE] Mean reward over last 20 episodes: -0.015103
[ADAPTIVE] Plateau counter: 231/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.088819    |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 491         |
|    time_elapsed         | 1655        |
|    total_timesteps      | 2011136     |
| train/                  |             |
|    approx_kl            | 0.006992217 |
|    clip_fraction        | 0.0896      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.3       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.861      |
|    n_updates            | 8505        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 34          |
|    value_loss           | 0.0959      |
-----------------------------------------
[ADAPTIVE] Episode 501 reward: 0.023175
[ADAPTIVE] Mean reward over last 20 episodes: -0.015230
[ADAPTIVE] Plateau counter: 232/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 0.98053527 |
| time/                   |            |
|    fps                  | 1214       |
|    iterations           | 492        |
|    time_elapsed         | 1659       |
|    total_timesteps      | 2015232    |
| train/                  |            |
|    approx_kl            | 0.01299692 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -44.4      |
|    explained_variance   | 0.561      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.845     |
|    n_updates            | 8520       |
|    policy_gradient_loss | -0.0166    |
|    std                  | 34.3       |
|    value_loss           | 0.187      |
----------------------------------------
[ADAPTIVE] Episode 502 reward: 0.113635
[ADAPTIVE] Mean reward over last 20 episodes: -0.010492
[ADAPTIVE] Plateau counter: 233/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.94338536  |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 493         |
|    time_elapsed         | 1662        |
|    total_timesteps      | 2019328     |
| train/                  |             |
|    approx_kl            | 0.009403609 |
|    clip_fraction        | 0.0752      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.5       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.82       |
|    n_updates            | 8535        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 34.6        |
|    value_loss           | 0.215       |
-----------------------------------------
[ADAPTIVE] Episode 503 reward: -0.089897
[ADAPTIVE] Mean reward over last 20 episodes: -0.010740
[ADAPTIVE] Plateau counter: 234/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.033899     |
| time/                   |              |
|    fps                  | 1214         |
|    iterations           | 494          |
|    time_elapsed         | 1665         |
|    total_timesteps      | 2023424      |
| train/                  |              |
|    approx_kl            | 0.0092109125 |
|    clip_fraction        | 0.0649       |
|    clip_range           | 0.2          |
|    entropy_loss         | -44.5        |
|    explained_variance   | 0.741        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.853       |
|    n_updates            | 8550         |
|    policy_gradient_loss | -0.0107      |
|    std                  | 34.8         |
|    value_loss           | 0.129        |
------------------------------------------
[ADAPTIVE] Episode 504 reward: -0.068628
[ADAPTIVE] Mean reward over last 20 episodes: -0.015040
[ADAPTIVE] Plateau counter: 235/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1018398   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 495         |
|    time_elapsed         | 1668        |
|    total_timesteps      | 2027520     |
| train/                  |             |
|    approx_kl            | 0.009843089 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.6       |
|    explained_variance   | 0.774       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.868      |
|    n_updates            | 8565        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 35          |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 505 reward: -0.007355
[ADAPTIVE] Mean reward over last 20 episodes: -0.014302
[ADAPTIVE] Plateau counter: 236/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1718197   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 496         |
|    time_elapsed         | 1672        |
|    total_timesteps      | 2031616     |
| train/                  |             |
|    approx_kl            | 0.009438657 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.6       |
|    explained_variance   | 0.813       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.887      |
|    n_updates            | 8580        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 35.2        |
|    value_loss           | 0.0815      |
-----------------------------------------
[ADAPTIVE] Episode 506 reward: 0.010747
[ADAPTIVE] Mean reward over last 20 episodes: -0.015180
[ADAPTIVE] Plateau counter: 237/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1900097   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 497         |
|    time_elapsed         | 1675        |
|    total_timesteps      | 2035712     |
| train/                  |             |
|    approx_kl            | 0.008731086 |
|    clip_fraction        | 0.0867      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.7       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.903      |
|    n_updates            | 8595        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 35.4        |
|    value_loss           | 0.077       |
-----------------------------------------
[ADAPTIVE] Episode 507 reward: -0.090784
[ADAPTIVE] Mean reward over last 20 episodes: -0.021743
[ADAPTIVE] Plateau counter: 238/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.3755574  |
| time/                   |            |
|    fps                  | 1214       |
|    iterations           | 498        |
|    time_elapsed         | 1678       |
|    total_timesteps      | 2039808    |
| train/                  |            |
|    approx_kl            | 0.00906482 |
|    clip_fraction        | 0.11       |
|    clip_range           | 0.2        |
|    entropy_loss         | -44.7      |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.881     |
|    n_updates            | 8610       |
|    policy_gradient_loss | -0.019     |
|    std                  | 35.6       |
|    value_loss           | 0.0775     |
----------------------------------------
[ADAPTIVE] Episode 508 reward: 0.031925
[ADAPTIVE] Mean reward over last 20 episodes: -0.018291
[ADAPTIVE] Plateau counter: 239/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.451234    |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 499         |
|    time_elapsed         | 1682        |
|    total_timesteps      | 2043904     |
| train/                  |             |
|    approx_kl            | 0.010543184 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.8       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.912      |
|    n_updates            | 8625        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 35.7        |
|    value_loss           | 0.0737      |
-----------------------------------------
[ADAPTIVE] Episode 509 reward: -0.234436
[ADAPTIVE] Mean reward over last 20 episodes: -0.031100
[ADAPTIVE] Plateau counter: 240/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3873388   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 500         |
|    time_elapsed         | 1685        |
|    total_timesteps      | 2048000     |
| train/                  |             |
|    approx_kl            | 0.009561086 |
|    clip_fraction        | 0.0904      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.8       |
|    explained_variance   | 0.636       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.851      |
|    n_updates            | 8640        |
|    policy_gradient_loss | -0.014      |
|    std                  | 35.9        |
|    value_loss           | 0.155       |
-----------------------------------------
[ADAPTIVE] Episode 510 reward: 0.046861
[ADAPTIVE] Mean reward over last 20 episodes: -0.027437
[ADAPTIVE] Plateau counter: 241/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4673935   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 501         |
|    time_elapsed         | 1689        |
|    total_timesteps      | 2052096     |
| train/                  |             |
|    approx_kl            | 0.009708218 |
|    clip_fraction        | 0.0829      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.9       |
|    explained_variance   | 0.761       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.881      |
|    n_updates            | 8655        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 36.1        |
|    value_loss           | 0.078       |
-----------------------------------------
[ADAPTIVE] Episode 511 reward: -0.073621
[ADAPTIVE] Mean reward over last 20 episodes: -0.030702
[ADAPTIVE] Plateau counter: 242/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 512 reward: 0.104150
[ADAPTIVE] Mean reward over last 20 episodes: -0.023994
[ADAPTIVE] Plateau counter: 243/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2690432   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 502         |
|    time_elapsed         | 1692        |
|    total_timesteps      | 2056192     |
| train/                  |             |
|    approx_kl            | 0.005574828 |
|    clip_fraction        | 0.0642      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.9       |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.888      |
|    n_updates            | 8670        |
|    policy_gradient_loss | -0.0133     |
|    std                  | 36.2        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 513 reward: 0.023497
[ADAPTIVE] Mean reward over last 20 episodes: -0.025101
[ADAPTIVE] Plateau counter: 244/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2040874   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 503         |
|    time_elapsed         | 1695        |
|    total_timesteps      | 2060288     |
| train/                  |             |
|    approx_kl            | 0.009086758 |
|    clip_fraction        | 0.0964      |
|    clip_range           | 0.2         |
|    entropy_loss         | -44.9       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.861      |
|    n_updates            | 8685        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 36.5        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 514 reward: 0.016932
[ADAPTIVE] Mean reward over last 20 episodes: -0.026553
[ADAPTIVE] Plateau counter: 245/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3719635    |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 504          |
|    time_elapsed         | 1698         |
|    total_timesteps      | 2064384      |
| train/                  |              |
|    approx_kl            | 0.0073706843 |
|    clip_fraction        | 0.0701       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45          |
|    explained_variance   | 0.782        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.891       |
|    n_updates            | 8700         |
|    policy_gradient_loss | -0.0157      |
|    std                  | 36.7         |
|    value_loss           | 0.11         |
------------------------------------------
[ADAPTIVE] Episode 515 reward: -0.069064
[ADAPTIVE] Mean reward over last 20 episodes: -0.029054
[ADAPTIVE] Plateau counter: 246/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2614868   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 505         |
|    time_elapsed         | 1702        |
|    total_timesteps      | 2068480     |
| train/                  |             |
|    approx_kl            | 0.007906407 |
|    clip_fraction        | 0.0783      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45         |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.89       |
|    n_updates            | 8715        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 36.7        |
|    value_loss           | 0.0966      |
-----------------------------------------
[ADAPTIVE] Episode 516 reward: -0.054623
[ADAPTIVE] Mean reward over last 20 episodes: -0.035711
[ADAPTIVE] Plateau counter: 247/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2332873    |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 506          |
|    time_elapsed         | 1705         |
|    total_timesteps      | 2072576      |
| train/                  |              |
|    approx_kl            | 0.0073523475 |
|    clip_fraction        | 0.0752       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45          |
|    explained_variance   | 0.683        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.884       |
|    n_updates            | 8730         |
|    policy_gradient_loss | -0.0144      |
|    std                  | 37           |
|    value_loss           | 0.113        |
------------------------------------------
[ADAPTIVE] Episode 517 reward: -0.049618
[ADAPTIVE] Mean reward over last 20 episodes: -0.036082
[ADAPTIVE] Plateau counter: 248/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2598131   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 507         |
|    time_elapsed         | 1708        |
|    total_timesteps      | 2076672     |
| train/                  |             |
|    approx_kl            | 0.009693828 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.1       |
|    explained_variance   | 0.774       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.874      |
|    n_updates            | 8745        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 37.2        |
|    value_loss           | 0.0799      |
-----------------------------------------
[ADAPTIVE] Episode 518 reward: 0.060205
[ADAPTIVE] Mean reward over last 20 episodes: -0.030141
[ADAPTIVE] Plateau counter: 249/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3421681   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 508         |
|    time_elapsed         | 1712        |
|    total_timesteps      | 2080768     |
| train/                  |             |
|    approx_kl            | 0.009891666 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.2       |
|    explained_variance   | 0.674       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.884      |
|    n_updates            | 8760        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 37.4        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 519 reward: -0.113236
[ADAPTIVE] Mean reward over last 20 episodes: -0.035792
[ADAPTIVE] Plateau counter: 250/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 1.5170575 |
| time/                   |           |
|    fps                  | 1215      |
|    iterations           | 509       |
|    time_elapsed         | 1715      |
|    total_timesteps      | 2084864   |
| train/                  |           |
|    approx_kl            | 0.009609  |
|    clip_fraction        | 0.109     |
|    clip_range           | 0.2       |
|    entropy_loss         | -45.2     |
|    explained_variance   | 0.734     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.894    |
|    n_updates            | 8775      |
|    policy_gradient_loss | -0.0163   |
|    std                  | 37.6      |
|    value_loss           | 0.119     |
---------------------------------------
[ADAPTIVE] Episode 520 reward: -0.028690
[ADAPTIVE] Mean reward over last 20 episodes: -0.022441
[ADAPTIVE] Plateau counter: 251/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2748169   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 510         |
|    time_elapsed         | 1719        |
|    total_timesteps      | 2088960     |
| train/                  |             |
|    approx_kl            | 0.010552806 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.2       |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.868      |
|    n_updates            | 8790        |
|    policy_gradient_loss | -0.017      |
|    std                  | 37.8        |
|    value_loss           | 0.169       |
-----------------------------------------
[ADAPTIVE] Episode 521 reward: 0.053456
[ADAPTIVE] Mean reward over last 20 episodes: -0.020927
[ADAPTIVE] Plateau counter: 252/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2400188    |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 511          |
|    time_elapsed         | 1722         |
|    total_timesteps      | 2093056      |
| train/                  |              |
|    approx_kl            | 0.0076402584 |
|    clip_fraction        | 0.107        |
|    clip_range           | 0.2          |
|    entropy_loss         | -45.3        |
|    explained_variance   | 0.769        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.879       |
|    n_updates            | 8805         |
|    policy_gradient_loss | -0.0174      |
|    std                  | 37.9         |
|    value_loss           | 0.104        |
------------------------------------------
[ADAPTIVE] Episode 522 reward: -0.042639
[ADAPTIVE] Mean reward over last 20 episodes: -0.028741
[ADAPTIVE] Plateau counter: 253/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2172267   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 512         |
|    time_elapsed         | 1725        |
|    total_timesteps      | 2097152     |
| train/                  |             |
|    approx_kl            | 0.008693381 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.3       |
|    explained_variance   | 0.77        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.907      |
|    n_updates            | 8820        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 38.1        |
|    value_loss           | 0.0812      |
-----------------------------------------
[ADAPTIVE] Episode 523 reward: -0.034856
[ADAPTIVE] Mean reward over last 20 episodes: -0.025989
[ADAPTIVE] Plateau counter: 254/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2421569   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 513         |
|    time_elapsed         | 1728        |
|    total_timesteps      | 2101248     |
| train/                  |             |
|    approx_kl            | 0.008241276 |
|    clip_fraction        | 0.0952      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.4       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.893      |
|    n_updates            | 8835        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 38.3        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 524 reward: -0.041191
[ADAPTIVE] Mean reward over last 20 episodes: -0.024617
[ADAPTIVE] Plateau counter: 255/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.240439   |
| time/                   |            |
|    fps                  | 1215       |
|    iterations           | 514        |
|    time_elapsed         | 1732       |
|    total_timesteps      | 2105344    |
| train/                  |            |
|    approx_kl            | 0.00805754 |
|    clip_fraction        | 0.0795     |
|    clip_range           | 0.2        |
|    entropy_loss         | -45.4      |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.896     |
|    n_updates            | 8850       |
|    policy_gradient_loss | -0.0129    |
|    std                  | 38.4       |
|    value_loss           | 0.113      |
----------------------------------------
[ADAPTIVE] Episode 525 reward: 0.003589
[ADAPTIVE] Mean reward over last 20 episodes: -0.024070
[ADAPTIVE] Plateau counter: 256/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1436039   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 515         |
|    time_elapsed         | 1735        |
|    total_timesteps      | 2109440     |
| train/                  |             |
|    approx_kl            | 0.008774879 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.5       |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.901      |
|    n_updates            | 8865        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 38.7        |
|    value_loss           | 0.0846      |
-----------------------------------------
[ADAPTIVE] Episode 526 reward: 0.025907
[ADAPTIVE] Mean reward over last 20 episodes: -0.023312
[ADAPTIVE] Plateau counter: 257/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1735249   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 516         |
|    time_elapsed         | 1738        |
|    total_timesteps      | 2113536     |
| train/                  |             |
|    approx_kl            | 0.009678347 |
|    clip_fraction        | 0.0939      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.5       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.904      |
|    n_updates            | 8880        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 38.9        |
|    value_loss           | 0.0814      |
-----------------------------------------
[ADAPTIVE] Episode 527 reward: -0.110936
[ADAPTIVE] Mean reward over last 20 episodes: -0.024320
[ADAPTIVE] Plateau counter: 258/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2106202   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 517         |
|    time_elapsed         | 1742        |
|    total_timesteps      | 2117632     |
| train/                  |             |
|    approx_kl            | 0.010609731 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.6       |
|    explained_variance   | 0.8         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.919      |
|    n_updates            | 8895        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 39.3        |
|    value_loss           | 0.073       |
-----------------------------------------
[ADAPTIVE] Episode 528 reward: 0.027116
[ADAPTIVE] Mean reward over last 20 episodes: -0.024560
[ADAPTIVE] Plateau counter: 259/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3893564   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 518         |
|    time_elapsed         | 1745        |
|    total_timesteps      | 2121728     |
| train/                  |             |
|    approx_kl            | 0.008390361 |
|    clip_fraction        | 0.0893      |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.7       |
|    explained_variance   | 0.79        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.898      |
|    n_updates            | 8910        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 39.6        |
|    value_loss           | 0.0906      |
-----------------------------------------
[ADAPTIVE] Episode 529 reward: -0.017851
[ADAPTIVE] Mean reward over last 20 episodes: -0.013731
[ADAPTIVE] Plateau counter: 260/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3247272   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 519         |
|    time_elapsed         | 1748        |
|    total_timesteps      | 2125824     |
| train/                  |             |
|    approx_kl            | 0.010859521 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.7       |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.914      |
|    n_updates            | 8925        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 39.7        |
|    value_loss           | 0.0813      |
-----------------------------------------
[ADAPTIVE] Episode 530 reward: 0.054593
[ADAPTIVE] Mean reward over last 20 episodes: -0.013344
[ADAPTIVE] Plateau counter: 261/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.165579     |
| time/                   |              |
|    fps                  | 1215         |
|    iterations           | 520          |
|    time_elapsed         | 1752         |
|    total_timesteps      | 2129920      |
| train/                  |              |
|    approx_kl            | 0.0073379064 |
|    clip_fraction        | 0.0602       |
|    clip_range           | 0.2          |
|    entropy_loss         | -45.7        |
|    explained_variance   | 0.704        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.861       |
|    n_updates            | 8940         |
|    policy_gradient_loss | -0.0119      |
|    std                  | 39.8         |
|    value_loss           | 0.193        |
------------------------------------------
[ADAPTIVE] Episode 531 reward: 0.046772
[ADAPTIVE] Mean reward over last 20 episodes: -0.007324
[ADAPTIVE] Plateau counter: 262/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2680556   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 521         |
|    time_elapsed         | 1755        |
|    total_timesteps      | 2134016     |
| train/                  |             |
|    approx_kl            | 0.010109063 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.8       |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.865      |
|    n_updates            | 8955        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 40.2        |
|    value_loss           | 0.205       |
-----------------------------------------
[ADAPTIVE] Episode 532 reward: 0.004818
[ADAPTIVE] Mean reward over last 20 episodes: -0.012291
[ADAPTIVE] Plateau counter: 263/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2227757   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 522         |
|    time_elapsed         | 1759        |
|    total_timesteps      | 2138112     |
| train/                  |             |
|    approx_kl            | 0.009026189 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.8       |
|    explained_variance   | 0.774       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.906      |
|    n_updates            | 8970        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 40.3        |
|    value_loss           | 0.0759      |
-----------------------------------------
[ADAPTIVE] Episode 533 reward: -0.010232
[ADAPTIVE] Mean reward over last 20 episodes: -0.013977
[ADAPTIVE] Plateau counter: 264/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3546976   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 523         |
|    time_elapsed         | 1762        |
|    total_timesteps      | 2142208     |
| train/                  |             |
|    approx_kl            | 0.009441253 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.9       |
|    explained_variance   | 0.657       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.897      |
|    n_updates            | 8985        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 40.6        |
|    value_loss           | 0.117       |
-----------------------------------------
[ADAPTIVE] Episode 534 reward: -0.003977
[ADAPTIVE] Mean reward over last 20 episodes: -0.015023
[ADAPTIVE] Plateau counter: 265/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3071656   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 524         |
|    time_elapsed         | 1766        |
|    total_timesteps      | 2146304     |
| train/                  |             |
|    approx_kl            | 0.007137857 |
|    clip_fraction        | 0.075       |
|    clip_range           | 0.2         |
|    entropy_loss         | -45.9       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.892      |
|    n_updates            | 9000        |
|    policy_gradient_loss | -0.0174     |
|    std                  | 40.6        |
|    value_loss           | 0.0856      |
-----------------------------------------
[ADAPTIVE] Episode 535 reward: 0.012055
[ADAPTIVE] Mean reward over last 20 episodes: -0.010967
[ADAPTIVE] Plateau counter: 266/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3282325   |
| time/                   |             |
|    fps                  | 1215        |
|    iterations           | 525         |
|    time_elapsed         | 1769        |
|    total_timesteps      | 2150400     |
| train/                  |             |
|    approx_kl            | 0.006939348 |
|    clip_fraction        | 0.0693      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46         |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.911      |
|    n_updates            | 9015        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 40.8        |
|    value_loss           | 0.0933      |
-----------------------------------------
[ADAPTIVE] Episode 536 reward: -0.196156
[ADAPTIVE] Mean reward over last 20 episodes: -0.018044
[ADAPTIVE] Plateau counter: 267/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3953212   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 526         |
|    time_elapsed         | 1773        |
|    total_timesteps      | 2154496     |
| train/                  |             |
|    approx_kl            | 0.008492554 |
|    clip_fraction        | 0.08        |
|    clip_range           | 0.2         |
|    entropy_loss         | -46         |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.901      |
|    n_updates            | 9030        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 41.1        |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 537 reward: -0.004517
[ADAPTIVE] Mean reward over last 20 episodes: -0.015789
[ADAPTIVE] Plateau counter: 268/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.303728    |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 527         |
|    time_elapsed         | 1776        |
|    total_timesteps      | 2158592     |
| train/                  |             |
|    approx_kl            | 0.009722172 |
|    clip_fraction        | 0.0875      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46         |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.917      |
|    n_updates            | 9045        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 41.2        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 538 reward: 0.031545
[ADAPTIVE] Mean reward over last 20 episodes: -0.017222
[ADAPTIVE] Plateau counter: 269/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3304019   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 528         |
|    time_elapsed         | 1780        |
|    total_timesteps      | 2162688     |
| train/                  |             |
|    approx_kl            | 0.009499852 |
|    clip_fraction        | 0.0952      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.1       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.879      |
|    n_updates            | 9060        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 41.3        |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 539 reward: -0.060411
[ADAPTIVE] Mean reward over last 20 episodes: -0.014580
[ADAPTIVE] Plateau counter: 270/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1958513    |
| time/                   |              |
|    fps                  | 1214         |
|    iterations           | 529          |
|    time_elapsed         | 1783         |
|    total_timesteps      | 2166784      |
| train/                  |              |
|    approx_kl            | 0.0084166825 |
|    clip_fraction        | 0.0813       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.1        |
|    explained_variance   | 0.695        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.876       |
|    n_updates            | 9075         |
|    policy_gradient_loss | -0.0147      |
|    std                  | 41.5         |
|    value_loss           | 0.17         |
------------------------------------------
[ADAPTIVE] Episode 540 reward: -0.060521
[ADAPTIVE] Mean reward over last 20 episodes: -0.016172
[ADAPTIVE] Plateau counter: 271/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1635681   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 530         |
|    time_elapsed         | 1787        |
|    total_timesteps      | 2170880     |
| train/                  |             |
|    approx_kl            | 0.009435262 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.1       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.914      |
|    n_updates            | 9090        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 41.7        |
|    value_loss           | 0.098       |
-----------------------------------------
[ADAPTIVE] Episode 541 reward: -0.039464
[ADAPTIVE] Mean reward over last 20 episodes: -0.020818
[ADAPTIVE] Plateau counter: 272/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1555015   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 531         |
|    time_elapsed         | 1791        |
|    total_timesteps      | 2174976     |
| train/                  |             |
|    approx_kl            | 0.008070858 |
|    clip_fraction        | 0.0918      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.2       |
|    explained_variance   | 0.761       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.906      |
|    n_updates            | 9105        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 42          |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 542 reward: -0.134557
[ADAPTIVE] Mean reward over last 20 episodes: -0.025414
[ADAPTIVE] Plateau counter: 273/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2303199   |
| time/                   |             |
|    fps                  | 1214        |
|    iterations           | 532         |
|    time_elapsed         | 1794        |
|    total_timesteps      | 2179072     |
| train/                  |             |
|    approx_kl            | 0.009712903 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.2       |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.922      |
|    n_updates            | 9120        |
|    policy_gradient_loss | -0.0178     |
|    std                  | 42.3        |
|    value_loss           | 0.0881      |
-----------------------------------------
[ADAPTIVE] Episode 543 reward: -0.029088
[ADAPTIVE] Mean reward over last 20 episodes: -0.025125
[ADAPTIVE] Plateau counter: 274/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1883739   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 533         |
|    time_elapsed         | 1798        |
|    total_timesteps      | 2183168     |
| train/                  |             |
|    approx_kl            | 0.009298625 |
|    clip_fraction        | 0.0753      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.3       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.905      |
|    n_updates            | 9135        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 42.5        |
|    value_loss           | 0.0935      |
-----------------------------------------
[ADAPTIVE] Episode 544 reward: -0.018891
[ADAPTIVE] Mean reward over last 20 episodes: -0.024010
[ADAPTIVE] Plateau counter: 275/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1998582   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 534         |
|    time_elapsed         | 1802        |
|    total_timesteps      | 2187264     |
| train/                  |             |
|    approx_kl            | 0.012779878 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.4       |
|    explained_variance   | 0.794       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.921      |
|    n_updates            | 9150        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 42.8        |
|    value_loss           | 0.0717      |
-----------------------------------------
[ADAPTIVE] Episode 545 reward: 0.046232
[ADAPTIVE] Mean reward over last 20 episodes: -0.021878
[ADAPTIVE] Plateau counter: 276/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1963608   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 535         |
|    time_elapsed         | 1805        |
|    total_timesteps      | 2191360     |
| train/                  |             |
|    approx_kl            | 0.010052463 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.4       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.916      |
|    n_updates            | 9165        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 43.1        |
|    value_loss           | 0.0824      |
-----------------------------------------
[ADAPTIVE] Episode 546 reward: -0.041835
[ADAPTIVE] Mean reward over last 20 episodes: -0.025265
[ADAPTIVE] Plateau counter: 277/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1770703   |
| time/                   |             |
|    fps                  | 1213        |
|    iterations           | 536         |
|    time_elapsed         | 1809        |
|    total_timesteps      | 2195456     |
| train/                  |             |
|    approx_kl            | 0.007750116 |
|    clip_fraction        | 0.0681      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.5       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.913      |
|    n_updates            | 9180        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 43.3        |
|    value_loss           | 0.112       |
-----------------------------------------
[ADAPTIVE] Episode 547 reward: 0.025165
[ADAPTIVE] Mean reward over last 20 episodes: -0.018460
[ADAPTIVE] Plateau counter: 278/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2899595    |
| time/                   |              |
|    fps                  | 1213         |
|    iterations           | 537          |
|    time_elapsed         | 1813         |
|    total_timesteps      | 2199552      |
| train/                  |              |
|    approx_kl            | 0.0057525416 |
|    clip_fraction        | 0.0812       |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.5        |
|    explained_variance   | 0.762        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.881       |
|    n_updates            | 9195         |
|    policy_gradient_loss | -0.0139      |
|    std                  | 43.5         |
|    value_loss           | 0.114        |
------------------------------------------
[ADAPTIVE] Episode 548 reward: 0.040744
[ADAPTIVE] Mean reward over last 20 episodes: -0.017779
[ADAPTIVE] Plateau counter: 279/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.330606    |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 538         |
|    time_elapsed         | 1816        |
|    total_timesteps      | 2203648     |
| train/                  |             |
|    approx_kl            | 0.008399612 |
|    clip_fraction        | 0.0796      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.6       |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.881      |
|    n_updates            | 9210        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 43.7        |
|    value_loss           | 0.153       |
-----------------------------------------
[ADAPTIVE] Episode 549 reward: 0.086802
[ADAPTIVE] Mean reward over last 20 episodes: -0.012546
[ADAPTIVE] Plateau counter: 280/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.358712    |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 539         |
|    time_elapsed         | 1820        |
|    total_timesteps      | 2207744     |
| train/                  |             |
|    approx_kl            | 0.008125753 |
|    clip_fraction        | 0.076       |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.6       |
|    explained_variance   | 0.841       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.924      |
|    n_updates            | 9225        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 44          |
|    value_loss           | 0.0772      |
-----------------------------------------
[ADAPTIVE] Episode 550 reward: -0.030809
[ADAPTIVE] Mean reward over last 20 episodes: -0.016816
[ADAPTIVE] Plateau counter: 281/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4658685   |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 540         |
|    time_elapsed         | 1824        |
|    total_timesteps      | 2211840     |
| train/                  |             |
|    approx_kl            | 0.007849839 |
|    clip_fraction        | 0.0808      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.6       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.922      |
|    n_updates            | 9240        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 44.1        |
|    value_loss           | 0.0878      |
-----------------------------------------
[ADAPTIVE] Episode 551 reward: 0.016546
[ADAPTIVE] Mean reward over last 20 episodes: -0.018328
[ADAPTIVE] Plateau counter: 282/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4511828   |
| time/                   |             |
|    fps                  | 1212        |
|    iterations           | 541         |
|    time_elapsed         | 1828        |
|    total_timesteps      | 2215936     |
| train/                  |             |
|    approx_kl            | 0.007524587 |
|    clip_fraction        | 0.0706      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.7       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.918      |
|    n_updates            | 9255        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 44.3        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 552 reward: 0.047107
[ADAPTIVE] Mean reward over last 20 episodes: -0.016213
[ADAPTIVE] Plateau counter: 283/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.4960479  |
| time/                   |            |
|    fps                  | 1211       |
|    iterations           | 542        |
|    time_elapsed         | 1831       |
|    total_timesteps      | 2220032    |
| train/                  |            |
|    approx_kl            | 0.00980497 |
|    clip_fraction        | 0.0979     |
|    clip_range           | 0.2        |
|    entropy_loss         | -46.7      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.911     |
|    n_updates            | 9270       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 44.5       |
|    value_loss           | 0.121      |
----------------------------------------
[ADAPTIVE] Episode 553 reward: -0.049629
[ADAPTIVE] Mean reward over last 20 episodes: -0.018183
[ADAPTIVE] Plateau counter: 284/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3610431   |
| time/                   |             |
|    fps                  | 1211        |
|    iterations           | 543         |
|    time_elapsed         | 1835        |
|    total_timesteps      | 2224128     |
| train/                  |             |
|    approx_kl            | 0.008224397 |
|    clip_fraction        | 0.0954      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.8       |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.917      |
|    n_updates            | 9285        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 44.7        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 554 reward: -0.013522
[ADAPTIVE] Mean reward over last 20 episodes: -0.018660
[ADAPTIVE] Plateau counter: 285/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.4083954    |
| time/                   |              |
|    fps                  | 1211         |
|    iterations           | 544          |
|    time_elapsed         | 1839         |
|    total_timesteps      | 2228224      |
| train/                  |              |
|    approx_kl            | 0.0093685435 |
|    clip_fraction        | 0.113        |
|    clip_range           | 0.2          |
|    entropy_loss         | -46.8        |
|    explained_variance   | 0.712        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.924       |
|    n_updates            | 9300         |
|    policy_gradient_loss | -0.0177      |
|    std                  | 45.1         |
|    value_loss           | 0.138        |
------------------------------------------
[ADAPTIVE] Episode 555 reward: -0.008616
[ADAPTIVE] Mean reward over last 20 episodes: -0.019694
[ADAPTIVE] Plateau counter: 286/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5356692   |
| time/                   |             |
|    fps                  | 1211        |
|    iterations           | 545         |
|    time_elapsed         | 1842        |
|    total_timesteps      | 2232320     |
| train/                  |             |
|    approx_kl            | 0.011347135 |
|    clip_fraction        | 0.0971      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.9       |
|    explained_variance   | 0.799       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.926      |
|    n_updates            | 9315        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 45.4        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 556 reward: -0.033672
[ADAPTIVE] Mean reward over last 20 episodes: -0.011570
[ADAPTIVE] Plateau counter: 287/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3816767   |
| time/                   |             |
|    fps                  | 1211        |
|    iterations           | 546         |
|    time_elapsed         | 1845        |
|    total_timesteps      | 2236416     |
| train/                  |             |
|    approx_kl            | 0.009254596 |
|    clip_fraction        | 0.0889      |
|    clip_range           | 0.2         |
|    entropy_loss         | -46.9       |
|    explained_variance   | 0.762       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.913      |
|    n_updates            | 9330        |
|    policy_gradient_loss | -0.013      |
|    std                  | 45.7        |
|    value_loss           | 0.144       |
-----------------------------------------
[ADAPTIVE] Episode 557 reward: 0.100303
[ADAPTIVE] Mean reward over last 20 episodes: -0.006329
[ADAPTIVE] Plateau counter: 288/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.5661511    |
| time/                   |              |
|    fps                  | 1211         |
|    iterations           | 547          |
|    time_elapsed         | 1849         |
|    total_timesteps      | 2240512      |
| train/                  |              |
|    approx_kl            | 0.0076897517 |
|    clip_fraction        | 0.077        |
|    clip_range           | 0.2          |
|    entropy_loss         | -47          |
|    explained_variance   | 0.746        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.895       |
|    n_updates            | 9345         |
|    policy_gradient_loss | -0.0108      |
|    std                  | 45.8         |
|    value_loss           | 0.199        |
------------------------------------------
[ADAPTIVE] Episode 558 reward: 0.058511
[ADAPTIVE] Mean reward over last 20 episodes: -0.004980
[ADAPTIVE] Plateau counter: 289/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6119477   |
| time/                   |             |
|    fps                  | 1211        |
|    iterations           | 548         |
|    time_elapsed         | 1852        |
|    total_timesteps      | 2244608     |
| train/                  |             |
|    approx_kl            | 0.008232287 |
|    clip_fraction        | 0.0875      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47         |
|    explained_variance   | 0.793       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.912      |
|    n_updates            | 9360        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 46.1        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 559 reward: -0.075414
[ADAPTIVE] Mean reward over last 20 episodes: -0.005730
[ADAPTIVE] Plateau counter: 290/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6205688   |
| time/                   |             |
|    fps                  | 1211        |
|    iterations           | 549         |
|    time_elapsed         | 1856        |
|    total_timesteps      | 2248704     |
| train/                  |             |
|    approx_kl            | 0.009153269 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.1       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.82       |
|    n_updates            | 9375        |
|    policy_gradient_loss | -0.0133     |
|    std                  | 46.5        |
|    value_loss           | 0.27        |
-----------------------------------------
[ADAPTIVE] Episode 560 reward: 0.048682
[ADAPTIVE] Mean reward over last 20 episodes: -0.000270
[ADAPTIVE] Plateau counter: 291/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5576252   |
| time/                   |             |
|    fps                  | 1211        |
|    iterations           | 550         |
|    time_elapsed         | 1860        |
|    total_timesteps      | 2252800     |
| train/                  |             |
|    approx_kl            | 0.010333575 |
|    clip_fraction        | 0.0918      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.1       |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.895      |
|    n_updates            | 9390        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 46.6        |
|    value_loss           | 0.136       |
-----------------------------------------
[ADAPTIVE] Episode 561 reward: 0.041192
[ADAPTIVE] Mean reward over last 20 episodes: 0.003762
[ADAPTIVE] Plateau counter: 292/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3067096   |
| time/                   |             |
|    fps                  | 1210        |
|    iterations           | 551         |
|    time_elapsed         | 1864        |
|    total_timesteps      | 2256896     |
| train/                  |             |
|    approx_kl            | 0.007028205 |
|    clip_fraction        | 0.0909      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.2       |
|    explained_variance   | 0.745       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.923      |
|    n_updates            | 9405        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 46.9        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 562 reward: 0.034890
[ADAPTIVE] Mean reward over last 20 episodes: 0.012235
[ADAPTIVE] Plateau counter: 293/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4754364   |
| time/                   |             |
|    fps                  | 1210        |
|    iterations           | 552         |
|    time_elapsed         | 1867        |
|    total_timesteps      | 2260992     |
| train/                  |             |
|    approx_kl            | 0.009537345 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.2       |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.946      |
|    n_updates            | 9420        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 47.1        |
|    value_loss           | 0.079       |
-----------------------------------------
[ADAPTIVE] Episode 563 reward: -0.017547
[ADAPTIVE] Mean reward over last 20 episodes: 0.012812
[ADAPTIVE] Plateau counter: 294/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 564 reward: -0.044067
[ADAPTIVE] Mean reward over last 20 episodes: 0.011553
[ADAPTIVE] Plateau counter: 295/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1906002    |
| time/                   |              |
|    fps                  | 1210         |
|    iterations           | 553          |
|    time_elapsed         | 1871         |
|    total_timesteps      | 2265088      |
| train/                  |              |
|    approx_kl            | 0.0120255295 |
|    clip_fraction        | 0.111        |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.3        |
|    explained_variance   | 0.796        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.934       |
|    n_updates            | 9435         |
|    policy_gradient_loss | -0.0148      |
|    std                  | 47.6         |
|    value_loss           | 0.0771       |
------------------------------------------
[ADAPTIVE] Episode 565 reward: -0.015415
[ADAPTIVE] Mean reward over last 20 episodes: 0.008471
[ADAPTIVE] Plateau counter: 296/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1415612   |
| time/                   |             |
|    fps                  | 1210        |
|    iterations           | 554         |
|    time_elapsed         | 1874        |
|    total_timesteps      | 2269184     |
| train/                  |             |
|    approx_kl            | 0.011099789 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.4       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.926      |
|    n_updates            | 9450        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 47.9        |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 566 reward: -0.190070
[ADAPTIVE] Mean reward over last 20 episodes: 0.001059
[ADAPTIVE] Plateau counter: 297/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1187168   |
| time/                   |             |
|    fps                  | 1210        |
|    iterations           | 555         |
|    time_elapsed         | 1878        |
|    total_timesteps      | 2273280     |
| train/                  |             |
|    approx_kl            | 0.007468108 |
|    clip_fraction        | 0.0777      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.4       |
|    explained_variance   | 0.793       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.931      |
|    n_updates            | 9465        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 48.1        |
|    value_loss           | 0.0967      |
-----------------------------------------
[ADAPTIVE] Episode 567 reward: 0.054690
[ADAPTIVE] Mean reward over last 20 episodes: 0.002535
[ADAPTIVE] Plateau counter: 298/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3147713   |
| time/                   |             |
|    fps                  | 1209        |
|    iterations           | 556         |
|    time_elapsed         | 1882        |
|    total_timesteps      | 2277376     |
| train/                  |             |
|    approx_kl            | 0.008303307 |
|    clip_fraction        | 0.0806      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.4       |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.914      |
|    n_updates            | 9480        |
|    policy_gradient_loss | -0.0135     |
|    std                  | 48.5        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 568 reward: -0.008018
[ADAPTIVE] Mean reward over last 20 episodes: 0.000097
[ADAPTIVE] Plateau counter: 299/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3269026   |
| time/                   |             |
|    fps                  | 1209        |
|    iterations           | 557         |
|    time_elapsed         | 1885        |
|    total_timesteps      | 2281472     |
| train/                  |             |
|    approx_kl            | 0.012071076 |
|    clip_fraction        | 0.0919      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.5       |
|    explained_variance   | 0.77        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.941      |
|    n_updates            | 9495        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 48.7        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 569 reward: 0.027844
[ADAPTIVE] Mean reward over last 20 episodes: -0.002851
[ADAPTIVE] Plateau counter: 300/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4435818   |
| time/                   |             |
|    fps                  | 1209        |
|    iterations           | 558         |
|    time_elapsed         | 1889        |
|    total_timesteps      | 2285568     |
| train/                  |             |
|    approx_kl            | 0.008148232 |
|    clip_fraction        | 0.0818      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.5       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.926      |
|    n_updates            | 9510        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 48.8        |
|    value_loss           | 0.135       |
-----------------------------------------
[ADAPTIVE] Episode 570 reward: -0.017037
[ADAPTIVE] Mean reward over last 20 episodes: -0.002162
[ADAPTIVE] Plateau counter: 301/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3985561   |
| time/                   |             |
|    fps                  | 1209        |
|    iterations           | 559         |
|    time_elapsed         | 1893        |
|    total_timesteps      | 2289664     |
| train/                  |             |
|    approx_kl            | 0.009442584 |
|    clip_fraction        | 0.0957      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.6       |
|    explained_variance   | 0.783       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.934      |
|    n_updates            | 9525        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 49.1        |
|    value_loss           | 0.0975      |
-----------------------------------------
[ADAPTIVE] Episode 571 reward: 0.046898
[ADAPTIVE] Mean reward over last 20 episodes: -0.000644
[ADAPTIVE] Plateau counter: 302/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2804064   |
| time/                   |             |
|    fps                  | 1209        |
|    iterations           | 560         |
|    time_elapsed         | 1897        |
|    total_timesteps      | 2293760     |
| train/                  |             |
|    approx_kl            | 0.008436563 |
|    clip_fraction        | 0.0666      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.6       |
|    explained_variance   | 0.776       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.926      |
|    n_updates            | 9540        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 49.3        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 572 reward: -0.018445
[ADAPTIVE] Mean reward over last 20 episodes: -0.003922
[ADAPTIVE] Plateau counter: 303/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 1.1959789 |
| time/                   |           |
|    fps                  | 1208      |
|    iterations           | 561       |
|    time_elapsed         | 1900      |
|    total_timesteps      | 2297856   |
| train/                  |           |
|    approx_kl            | 0.0078129 |
|    clip_fraction        | 0.0867    |
|    clip_range           | 0.2       |
|    entropy_loss         | -47.7     |
|    explained_variance   | 0.838     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.943    |
|    n_updates            | 9555      |
|    policy_gradient_loss | -0.0156   |
|    std                  | 49.5      |
|    value_loss           | 0.11      |
---------------------------------------
[ADAPTIVE] Episode 573 reward: 0.029125
[ADAPTIVE] Mean reward over last 20 episodes: 0.000016
[ADAPTIVE] Plateau counter: 304/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1181681   |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 562         |
|    time_elapsed         | 1904        |
|    total_timesteps      | 2301952     |
| train/                  |             |
|    approx_kl            | 0.007598771 |
|    clip_fraction        | 0.0978      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.7       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.951      |
|    n_updates            | 9570        |
|    policy_gradient_loss | -0.0153     |
|    std                  | 49.8        |
|    value_loss           | 0.0807      |
-----------------------------------------
[ADAPTIVE] Episode 574 reward: 0.047411
[ADAPTIVE] Mean reward over last 20 episodes: 0.003062
[ADAPTIVE] Plateau counter: 305/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1352192   |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 563         |
|    time_elapsed         | 1907        |
|    total_timesteps      | 2306048     |
| train/                  |             |
|    approx_kl            | 0.009591136 |
|    clip_fraction        | 0.0937      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.8       |
|    explained_variance   | 0.687       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.952      |
|    n_updates            | 9585        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 50.1        |
|    value_loss           | 0.12        |
-----------------------------------------
[ADAPTIVE] Episode 575 reward: 0.123583
[ADAPTIVE] Mean reward over last 20 episodes: 0.009672
[ADAPTIVE] Plateau counter: 306/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3454074    |
| time/                   |              |
|    fps                  | 1208         |
|    iterations           | 564          |
|    time_elapsed         | 1912         |
|    total_timesteps      | 2310144      |
| train/                  |              |
|    approx_kl            | 0.0084801745 |
|    clip_fraction        | 0.0689       |
|    clip_range           | 0.2          |
|    entropy_loss         | -47.8        |
|    explained_variance   | 0.826        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.952       |
|    n_updates            | 9600         |
|    policy_gradient_loss | -0.0169      |
|    std                  | 50.4         |
|    value_loss           | 0.092        |
------------------------------------------
[ADAPTIVE] Episode 576 reward: 0.070223
[ADAPTIVE] Mean reward over last 20 episodes: 0.014867
[ADAPTIVE] Plateau counter: 307/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3485011   |
| time/                   |             |
|    fps                  | 1208        |
|    iterations           | 565         |
|    time_elapsed         | 1915        |
|    total_timesteps      | 2314240     |
| train/                  |             |
|    approx_kl            | 0.008004752 |
|    clip_fraction        | 0.0765      |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.8       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.951      |
|    n_updates            | 9615        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 50.6        |
|    value_loss           | 0.0801      |
-----------------------------------------
[ADAPTIVE] Episode 577 reward: 0.012343
[ADAPTIVE] Mean reward over last 20 episodes: 0.010469
[ADAPTIVE] Plateau counter: 308/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4308275   |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 566         |
|    time_elapsed         | 1919        |
|    total_timesteps      | 2318336     |
| train/                  |             |
|    approx_kl            | 0.008981958 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -47.9       |
|    explained_variance   | 0.816       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.956      |
|    n_updates            | 9630        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 51          |
|    value_loss           | 0.0714      |
-----------------------------------------
[ADAPTIVE] Episode 578 reward: -0.053910
[ADAPTIVE] Mean reward over last 20 episodes: 0.004848
[ADAPTIVE] Plateau counter: 309/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5991691   |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 567         |
|    time_elapsed         | 1923        |
|    total_timesteps      | 2322432     |
| train/                  |             |
|    approx_kl            | 0.007696978 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -48         |
|    explained_variance   | 0.705       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.897      |
|    n_updates            | 9645        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 51.3        |
|    value_loss           | 0.165       |
-----------------------------------------
[ADAPTIVE] Episode 579 reward: -0.066650
[ADAPTIVE] Mean reward over last 20 episodes: 0.005286
[ADAPTIVE] Plateau counter: 310/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5894264   |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 568         |
|    time_elapsed         | 1926        |
|    total_timesteps      | 2326528     |
| train/                  |             |
|    approx_kl            | 0.005381743 |
|    clip_fraction        | 0.0476      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48         |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.93       |
|    n_updates            | 9660        |
|    policy_gradient_loss | -0.0112     |
|    std                  | 51.5        |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 580 reward: 0.071404
[ADAPTIVE] Mean reward over last 20 episodes: 0.006422
[ADAPTIVE] Plateau counter: 311/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.682217    |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 569         |
|    time_elapsed         | 1930        |
|    total_timesteps      | 2330624     |
| train/                  |             |
|    approx_kl            | 0.007942306 |
|    clip_fraction        | 0.0806      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.1       |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.956      |
|    n_updates            | 9675        |
|    policy_gradient_loss | -0.0153     |
|    std                  | 51.8        |
|    value_loss           | 0.0805      |
-----------------------------------------
[ADAPTIVE] Episode 581 reward: 0.036468
[ADAPTIVE] Mean reward over last 20 episodes: 0.006186
[ADAPTIVE] Plateau counter: 312/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.505898    |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 570         |
|    time_elapsed         | 1934        |
|    total_timesteps      | 2334720     |
| train/                  |             |
|    approx_kl            | 0.010642065 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.1       |
|    explained_variance   | 0.69        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.938      |
|    n_updates            | 9690        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 51.9        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 582 reward: -0.003459
[ADAPTIVE] Mean reward over last 20 episodes: 0.004269
[ADAPTIVE] Plateau counter: 313/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.669457    |
| time/                   |             |
|    fps                  | 1207        |
|    iterations           | 571         |
|    time_elapsed         | 1937        |
|    total_timesteps      | 2338816     |
| train/                  |             |
|    approx_kl            | 0.011604862 |
|    clip_fraction        | 0.0891      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.1       |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.937      |
|    n_updates            | 9705        |
|    policy_gradient_loss | -0.0125     |
|    std                  | 52.2        |
|    value_loss           | 0.0939      |
-----------------------------------------
[ADAPTIVE] Episode 583 reward: 0.138151
[ADAPTIVE] Mean reward over last 20 episodes: 0.012053
[ADAPTIVE] Plateau counter: 314/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.731324    |
| time/                   |             |
|    fps                  | 1206        |
|    iterations           | 572         |
|    time_elapsed         | 1941        |
|    total_timesteps      | 2342912     |
| train/                  |             |
|    approx_kl            | 0.010047384 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.1       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.946      |
|    n_updates            | 9720        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 52.3        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 584 reward: 0.043083
[ADAPTIVE] Mean reward over last 20 episodes: 0.016411
[ADAPTIVE] Plateau counter: 315/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6171486   |
| time/                   |             |
|    fps                  | 1206        |
|    iterations           | 573         |
|    time_elapsed         | 1945        |
|    total_timesteps      | 2347008     |
| train/                  |             |
|    approx_kl            | 0.009077653 |
|    clip_fraction        | 0.0958      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.2       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.934      |
|    n_updates            | 9735        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 52.8        |
|    value_loss           | 0.0909      |
-----------------------------------------
[ADAPTIVE] Episode 585 reward: 0.056928
[ADAPTIVE] Mean reward over last 20 episodes: 0.020028
[ADAPTIVE] Plateau counter: 316/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5730138   |
| time/                   |             |
|    fps                  | 1206        |
|    iterations           | 574         |
|    time_elapsed         | 1948        |
|    total_timesteps      | 2351104     |
| train/                  |             |
|    approx_kl            | 0.008684846 |
|    clip_fraction        | 0.0604      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.2       |
|    explained_variance   | 0.694       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.917      |
|    n_updates            | 9750        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 52.9        |
|    value_loss           | 0.156       |
-----------------------------------------
[ADAPTIVE] Episode 586 reward: 0.057933
[ADAPTIVE] Mean reward over last 20 episodes: 0.032428
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4710351   |
| time/                   |             |
|    fps                  | 1206        |
|    iterations           | 575         |
|    time_elapsed         | 1952        |
|    total_timesteps      | 2355200     |
| train/                  |             |
|    approx_kl            | 0.008289314 |
|    clip_fraction        | 0.0618      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.3       |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.954      |
|    n_updates            | 9765        |
|    policy_gradient_loss | -0.0135     |
|    std                  | 53.2        |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 587 reward: 0.005743
[ADAPTIVE] Mean reward over last 20 episodes: 0.029981
[ADAPTIVE] Plateau counter: 1/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.4233146    |
| time/                   |              |
|    fps                  | 1206         |
|    iterations           | 576          |
|    time_elapsed         | 1955         |
|    total_timesteps      | 2359296      |
| train/                  |              |
|    approx_kl            | 0.0072402954 |
|    clip_fraction        | 0.0643       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.3        |
|    explained_variance   | 0.747        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.938       |
|    n_updates            | 9780         |
|    policy_gradient_loss | -0.0138      |
|    std                  | 53.3         |
|    value_loss           | 0.104        |
------------------------------------------
[ADAPTIVE] Episode 588 reward: -0.028950
[ADAPTIVE] Mean reward over last 20 episodes: 0.028934
[ADAPTIVE] Plateau counter: 2/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3413892    |
| time/                   |              |
|    fps                  | 1206         |
|    iterations           | 577          |
|    time_elapsed         | 1959         |
|    total_timesteps      | 2363392      |
| train/                  |              |
|    approx_kl            | 0.0072797257 |
|    clip_fraction        | 0.0967       |
|    clip_range           | 0.2          |
|    entropy_loss         | -48.3        |
|    explained_variance   | 0.691        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.93        |
|    n_updates            | 9795         |
|    policy_gradient_loss | -0.0151      |
|    std                  | 53.4         |
|    value_loss           | 0.116        |
------------------------------------------
[ADAPTIVE] Episode 589 reward: -0.075989
[ADAPTIVE] Mean reward over last 20 episodes: 0.023743
[ADAPTIVE] Plateau counter: 3/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0825402   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 578         |
|    time_elapsed         | 1963        |
|    total_timesteps      | 2367488     |
| train/                  |             |
|    approx_kl            | 0.007264551 |
|    clip_fraction        | 0.0721      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.4       |
|    explained_variance   | 0.688       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.944      |
|    n_updates            | 9810        |
|    policy_gradient_loss | -0.0134     |
|    std                  | 53.7        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 590 reward: -0.007492
[ADAPTIVE] Mean reward over last 20 episodes: 0.024220
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1995938   |
| time/                   |             |
|    fps                  | 1206        |
|    iterations           | 579         |
|    time_elapsed         | 1966        |
|    total_timesteps      | 2371584     |
| train/                  |             |
|    approx_kl            | 0.009232258 |
|    clip_fraction        | 0.0811      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.4       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.954      |
|    n_updates            | 9825        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 54          |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 591 reward: -0.061396
[ADAPTIVE] Mean reward over last 20 episodes: 0.018805
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0628314   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 580         |
|    time_elapsed         | 1970        |
|    total_timesteps      | 2375680     |
| train/                  |             |
|    approx_kl            | 0.008401217 |
|    clip_fraction        | 0.0833      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.5       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.946      |
|    n_updates            | 9840        |
|    policy_gradient_loss | -0.019      |
|    std                  | 54.4        |
|    value_loss           | 0.102       |
-----------------------------------------
[ADAPTIVE] Episode 592 reward: 0.011388
[ADAPTIVE] Mean reward over last 20 episodes: 0.020297
[ADAPTIVE] Plateau counter: 6/10
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0240531  |
| time/                   |            |
|    fps                  | 1205       |
|    iterations           | 581        |
|    time_elapsed         | 1973       |
|    total_timesteps      | 2379776    |
| train/                  |            |
|    approx_kl            | 0.01137884 |
|    clip_fraction        | 0.0892     |
|    clip_range           | 0.2        |
|    entropy_loss         | -48.5      |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.97      |
|    n_updates            | 9855       |
|    policy_gradient_loss | -0.0153    |
|    std                  | 54.7       |
|    value_loss           | 0.104      |
----------------------------------------
[ADAPTIVE] Episode 593 reward: -0.005544
[ADAPTIVE] Mean reward over last 20 episodes: 0.018563
[ADAPTIVE] Plateau counter: 7/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1042484   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 582         |
|    time_elapsed         | 1977        |
|    total_timesteps      | 2383872     |
| train/                  |             |
|    approx_kl            | 0.008134953 |
|    clip_fraction        | 0.0707      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.6       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.944      |
|    n_updates            | 9870        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 54.8        |
|    value_loss           | 0.089       |
-----------------------------------------
[ADAPTIVE] Episode 594 reward: 0.077105
[ADAPTIVE] Mean reward over last 20 episodes: 0.020048
[ADAPTIVE] Plateau counter: 8/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.302143    |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 583         |
|    time_elapsed         | 1980        |
|    total_timesteps      | 2387968     |
| train/                  |             |
|    approx_kl            | 0.011658179 |
|    clip_fraction        | 0.0813      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.6       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.925      |
|    n_updates            | 9885        |
|    policy_gradient_loss | -0.0115     |
|    std                  | 55.1        |
|    value_loss           | 0.18        |
-----------------------------------------
[ADAPTIVE] Episode 595 reward: 0.014007
[ADAPTIVE] Mean reward over last 20 episodes: 0.014569
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.447463    |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 584         |
|    time_elapsed         | 1984        |
|    total_timesteps      | 2392064     |
| train/                  |             |
|    approx_kl            | 0.007167379 |
|    clip_fraction        | 0.0945      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.7       |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.946      |
|    n_updates            | 9900        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 55.5        |
|    value_loss           | 0.109       |
-----------------------------------------
[ADAPTIVE] Episode 596 reward: 0.060211
[ADAPTIVE] Mean reward over last 20 episodes: 0.014069
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3652089   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 585         |
|    time_elapsed         | 1987        |
|    total_timesteps      | 2396160     |
| train/                  |             |
|    approx_kl            | 0.008250872 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.7       |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.931      |
|    n_updates            | 9915        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 55.7        |
|    value_loss           | 0.0904      |
-----------------------------------------
[ADAPTIVE] Episode 597 reward: -0.062289
[ADAPTIVE] Mean reward over last 20 episodes: 0.010337
[ADAPTIVE] Plateau counter: 11/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4761493   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 586         |
|    time_elapsed         | 1991        |
|    total_timesteps      | 2400256     |
| train/                  |             |
|    approx_kl            | 0.008171609 |
|    clip_fraction        | 0.085       |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.7       |
|    explained_variance   | 0.836       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.958      |
|    n_updates            | 9930        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 56          |
|    value_loss           | 0.0775      |
-----------------------------------------
[ADAPTIVE] Episode 598 reward: 0.074371
[ADAPTIVE] Mean reward over last 20 episodes: 0.016751
[ADAPTIVE] Plateau counter: 12/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4878772   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 587         |
|    time_elapsed         | 1995        |
|    total_timesteps      | 2404352     |
| train/                  |             |
|    approx_kl            | 0.007951713 |
|    clip_fraction        | 0.0846      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.8       |
|    explained_variance   | 0.77        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.946      |
|    n_updates            | 9945        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 56.2        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 599 reward: 0.062612
[ADAPTIVE] Mean reward over last 20 episodes: 0.023214
[ADAPTIVE] Plateau counter: 13/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4738803   |
| time/                   |             |
|    fps                  | 1205        |
|    iterations           | 588         |
|    time_elapsed         | 1998        |
|    total_timesteps      | 2408448     |
| train/                  |             |
|    approx_kl            | 0.007332176 |
|    clip_fraction        | 0.078       |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.8       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.931      |
|    n_updates            | 9960        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 56.3        |
|    value_loss           | 0.159       |
-----------------------------------------
[ADAPTIVE] Episode 600 reward: 0.080006
[ADAPTIVE] Mean reward over last 20 episodes: 0.023644
[ADAPTIVE] Plateau counter: 14/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 251      |
|    ep_rew_mean          | 1.395625 |
| time/                   |          |
|    fps                  | 1204     |
|    iterations           | 589      |
|    time_elapsed         | 2002     |
|    total_timesteps      | 2412544  |
| train/                  |          |
|    approx_kl            | 0.010842 |
|    clip_fraction        | 0.0927   |
|    clip_range           | 0.2      |
|    entropy_loss         | -48.8    |
|    explained_variance   | 0.799    |
|    learning_rate        | 0.00025  |
|    loss                 | -0.966   |
|    n_updates            | 9975     |
|    policy_gradient_loss | -0.0144  |
|    std                  | 56.8     |
|    value_loss           | 0.112    |
--------------------------------------
[ADAPTIVE] Episode 601 reward: 0.058555
[ADAPTIVE] Mean reward over last 20 episodes: 0.024749
[ADAPTIVE] Plateau counter: 15/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2707793   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 590         |
|    time_elapsed         | 2005        |
|    total_timesteps      | 2416640     |
| train/                  |             |
|    approx_kl            | 0.009128628 |
|    clip_fraction        | 0.0818      |
|    clip_range           | 0.2         |
|    entropy_loss         | -48.9       |
|    explained_variance   | 0.703       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.947      |
|    n_updates            | 9990        |
|    policy_gradient_loss | -0.014      |
|    std                  | 57.3        |
|    value_loss           | 0.16        |
-----------------------------------------
[ADAPTIVE] Episode 602 reward: -0.024414
[ADAPTIVE] Mean reward over last 20 episodes: 0.023701
[ADAPTIVE] Plateau counter: 16/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2534459   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 591         |
|    time_elapsed         | 2009        |
|    total_timesteps      | 2420736     |
| train/                  |             |
|    approx_kl            | 0.008760886 |
|    clip_fraction        | 0.0783      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49         |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.958      |
|    n_updates            | 10005       |
|    policy_gradient_loss | -0.0137     |
|    std                  | 57.6        |
|    value_loss           | 0.106       |
-----------------------------------------
[ADAPTIVE] Episode 603 reward: -0.058713
[ADAPTIVE] Mean reward over last 20 episodes: 0.013858
[ADAPTIVE] Plateau counter: 17/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2207627   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 592         |
|    time_elapsed         | 2012        |
|    total_timesteps      | 2424832     |
| train/                  |             |
|    approx_kl            | 0.008240921 |
|    clip_fraction        | 0.0807      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49         |
|    explained_variance   | 0.775       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.963      |
|    n_updates            | 10020       |
|    policy_gradient_loss | -0.0127     |
|    std                  | 57.8        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 604 reward: 0.004419
[ADAPTIVE] Mean reward over last 20 episodes: 0.011925
[ADAPTIVE] Plateau counter: 18/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2260385   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 593         |
|    time_elapsed         | 2016        |
|    total_timesteps      | 2428928     |
| train/                  |             |
|    approx_kl            | 0.011341182 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.1       |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.965      |
|    n_updates            | 10035       |
|    policy_gradient_loss | -0.0177     |
|    std                  | 58.2        |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 605 reward: -0.034142
[ADAPTIVE] Mean reward over last 20 episodes: 0.007371
[ADAPTIVE] Plateau counter: 19/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1886195    |
| time/                   |              |
|    fps                  | 1204         |
|    iterations           | 594          |
|    time_elapsed         | 2020         |
|    total_timesteps      | 2433024      |
| train/                  |              |
|    approx_kl            | 0.0070925523 |
|    clip_fraction        | 0.0588       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.1        |
|    explained_variance   | 0.587        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.925       |
|    n_updates            | 10050        |
|    policy_gradient_loss | -0.0104      |
|    std                  | 58.4         |
|    value_loss           | 0.205        |
------------------------------------------
[ADAPTIVE] Episode 606 reward: 0.048563
[ADAPTIVE] Mean reward over last 20 episodes: 0.006903
[ADAPTIVE] Plateau counter: 20/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.239078    |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 595         |
|    time_elapsed         | 2023        |
|    total_timesteps      | 2437120     |
| train/                  |             |
|    approx_kl            | 0.008940005 |
|    clip_fraction        | 0.0828      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.1       |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.954      |
|    n_updates            | 10065       |
|    policy_gradient_loss | -0.0146     |
|    std                  | 58.7        |
|    value_loss           | 0.159       |
-----------------------------------------
[ADAPTIVE] Episode 607 reward: -0.062628
[ADAPTIVE] Mean reward over last 20 episodes: 0.003484
[ADAPTIVE] Plateau counter: 21/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2786525   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 596         |
|    time_elapsed         | 2027        |
|    total_timesteps      | 2441216     |
| train/                  |             |
|    approx_kl            | 0.010415707 |
|    clip_fraction        | 0.0936      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.2       |
|    explained_variance   | 0.696       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.972      |
|    n_updates            | 10080       |
|    policy_gradient_loss | -0.0159     |
|    std                  | 59          |
|    value_loss           | 0.127       |
-----------------------------------------
[ADAPTIVE] Episode 608 reward: -0.150421
[ADAPTIVE] Mean reward over last 20 episodes: -0.002590
[ADAPTIVE] Plateau counter: 22/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2666711   |
| time/                   |             |
|    fps                  | 1204        |
|    iterations           | 597         |
|    time_elapsed         | 2030        |
|    total_timesteps      | 2445312     |
| train/                  |             |
|    approx_kl            | 0.007701681 |
|    clip_fraction        | 0.0948      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.2       |
|    explained_variance   | 0.609       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.961      |
|    n_updates            | 10095       |
|    policy_gradient_loss | -0.0151     |
|    std                  | 59.3        |
|    value_loss           | 0.164       |
-----------------------------------------
[ADAPTIVE] Episode 609 reward: -0.064134
[ADAPTIVE] Mean reward over last 20 episodes: -0.001997
[ADAPTIVE] Plateau counter: 23/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2644178   |
| time/                   |             |
|    fps                  | 1203        |
|    iterations           | 598         |
|    time_elapsed         | 2034        |
|    total_timesteps      | 2449408     |
| train/                  |             |
|    approx_kl            | 0.008551578 |
|    clip_fraction        | 0.0844      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.3       |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.966      |
|    n_updates            | 10110       |
|    policy_gradient_loss | -0.0137     |
|    std                  | 59.5        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 610 reward: 0.060606
[ADAPTIVE] Mean reward over last 20 episodes: 0.001408
[ADAPTIVE] Plateau counter: 24/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.3175911  |
| time/                   |            |
|    fps                  | 1203       |
|    iterations           | 599        |
|    time_elapsed         | 2037       |
|    total_timesteps      | 2453504    |
| train/                  |            |
|    approx_kl            | 0.00813292 |
|    clip_fraction        | 0.0884     |
|    clip_range           | 0.2        |
|    entropy_loss         | -49.3      |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.00025    |
|    loss                 | -0.977     |
|    n_updates            | 10125      |
|    policy_gradient_loss | -0.0183    |
|    std                  | 59.8       |
|    value_loss           | 0.0904     |
----------------------------------------
[ADAPTIVE] Episode 611 reward: 0.028728
[ADAPTIVE] Mean reward over last 20 episodes: 0.005914
[ADAPTIVE] Plateau counter: 25/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.428525     |
| time/                   |              |
|    fps                  | 1203         |
|    iterations           | 600          |
|    time_elapsed         | 2041         |
|    total_timesteps      | 2457600      |
| train/                  |              |
|    approx_kl            | 0.0065024113 |
|    clip_fraction        | 0.0603       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.4        |
|    explained_variance   | 0.802        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.96        |
|    n_updates            | 10140        |
|    policy_gradient_loss | -0.0139      |
|    std                  | 60.1         |
|    value_loss           | 0.104        |
------------------------------------------
[ADAPTIVE] Episode 612 reward: -0.139288
[ADAPTIVE] Mean reward over last 20 episodes: -0.001620
[ADAPTIVE] Plateau counter: 26/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5497689   |
| time/                   |             |
|    fps                  | 1203        |
|    iterations           | 601         |
|    time_elapsed         | 2045        |
|    total_timesteps      | 2461696     |
| train/                  |             |
|    approx_kl            | 0.009057284 |
|    clip_fraction        | 0.0833      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.4       |
|    explained_variance   | 0.78        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.972      |
|    n_updates            | 10155       |
|    policy_gradient_loss | -0.0141     |
|    std                  | 60.6        |
|    value_loss           | 0.112       |
-----------------------------------------
[ADAPTIVE] Episode 613 reward: 0.136011
[ADAPTIVE] Mean reward over last 20 episodes: 0.005458
[ADAPTIVE] Plateau counter: 27/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.5104947    |
| time/                   |              |
|    fps                  | 1203         |
|    iterations           | 602          |
|    time_elapsed         | 2049         |
|    total_timesteps      | 2465792      |
| train/                  |              |
|    approx_kl            | 0.0068596746 |
|    clip_fraction        | 0.0716       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.5        |
|    explained_variance   | 0.752        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.962       |
|    n_updates            | 10170        |
|    policy_gradient_loss | -0.0132      |
|    std                  | 61.1         |
|    value_loss           | 0.137        |
------------------------------------------
[ADAPTIVE] Episode 614 reward: 0.027349
[ADAPTIVE] Mean reward over last 20 episodes: 0.002970
[ADAPTIVE] Plateau counter: 28/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 615 reward: 0.085170
[ADAPTIVE] Mean reward over last 20 episodes: 0.006529
[ADAPTIVE] Plateau counter: 29/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4972528   |
| time/                   |             |
|    fps                  | 1203        |
|    iterations           | 603         |
|    time_elapsed         | 2052        |
|    total_timesteps      | 2469888     |
| train/                  |             |
|    approx_kl            | 0.010821855 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.5       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.968      |
|    n_updates            | 10185       |
|    policy_gradient_loss | -0.0155     |
|    std                  | 61.4        |
|    value_loss           | 0.131       |
-----------------------------------------
[ADAPTIVE] Episode 616 reward: 0.056464
[ADAPTIVE] Mean reward over last 20 episodes: 0.006341
[ADAPTIVE] Plateau counter: 30/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2506607  |
| time/                   |            |
|    fps                  | 1202       |
|    iterations           | 604        |
|    time_elapsed         | 2056       |
|    total_timesteps      | 2473984    |
| train/                  |            |
|    approx_kl            | 0.00833307 |
|    clip_fraction        | 0.0645     |
|    clip_range           | 0.2        |
|    entropy_loss         | -49.6      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.968     |
|    n_updates            | 10200      |
|    policy_gradient_loss | -0.0125    |
|    std                  | 62         |
|    value_loss           | 0.129      |
----------------------------------------
[ADAPTIVE] Episode 617 reward: 0.077891
[ADAPTIVE] Mean reward over last 20 episodes: 0.013350
[ADAPTIVE] Plateau counter: 31/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1268803   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 605         |
|    time_elapsed         | 2059        |
|    total_timesteps      | 2478080     |
| train/                  |             |
|    approx_kl            | 0.008260814 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.7       |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.965      |
|    n_updates            | 10215       |
|    policy_gradient_loss | -0.0134     |
|    std                  | 62.3        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 618 reward: 0.010389
[ADAPTIVE] Mean reward over last 20 episodes: 0.010151
[ADAPTIVE] Plateau counter: 32/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8995021   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 606         |
|    time_elapsed         | 2063        |
|    total_timesteps      | 2482176     |
| train/                  |             |
|    approx_kl            | 0.007842559 |
|    clip_fraction        | 0.0953      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.7       |
|    explained_variance   | 0.65        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.958      |
|    n_updates            | 10230       |
|    policy_gradient_loss | -0.0146     |
|    std                  | 62.5        |
|    value_loss           | 0.15        |
-----------------------------------------
[ADAPTIVE] Episode 619 reward: 0.060189
[ADAPTIVE] Mean reward over last 20 episodes: 0.010030
[ADAPTIVE] Plateau counter: 33/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8782768   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 607         |
|    time_elapsed         | 2067        |
|    total_timesteps      | 2486272     |
| train/                  |             |
|    approx_kl            | 0.009998932 |
|    clip_fraction        | 0.0659      |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.7       |
|    explained_variance   | 0.7         |
|    learning_rate        | 0.00025     |
|    loss                 | -0.953      |
|    n_updates            | 10245       |
|    policy_gradient_loss | -0.0115     |
|    std                  | 62.5        |
|    value_loss           | 0.164       |
-----------------------------------------
[ADAPTIVE] Episode 620 reward: -0.045812
[ADAPTIVE] Mean reward over last 20 episodes: 0.003739
[ADAPTIVE] Plateau counter: 34/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8334985    |
| time/                   |              |
|    fps                  | 1202         |
|    iterations           | 608          |
|    time_elapsed         | 2070         |
|    total_timesteps      | 2490368      |
| train/                  |              |
|    approx_kl            | 0.0067123706 |
|    clip_fraction        | 0.0541       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.8        |
|    explained_variance   | 0.674        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.968       |
|    n_updates            | 10260        |
|    policy_gradient_loss | -0.0124      |
|    std                  | 62.8         |
|    value_loss           | 0.14         |
------------------------------------------
[ADAPTIVE] Episode 621 reward: 0.002423
[ADAPTIVE] Mean reward over last 20 episodes: 0.000932
[ADAPTIVE] Plateau counter: 35/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.81603646   |
| time/                   |              |
|    fps                  | 1202         |
|    iterations           | 609          |
|    time_elapsed         | 2074         |
|    total_timesteps      | 2494464      |
| train/                  |              |
|    approx_kl            | 0.0075599714 |
|    clip_fraction        | 0.0949       |
|    clip_range           | 0.2          |
|    entropy_loss         | -49.8        |
|    explained_variance   | 0.705        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.966       |
|    n_updates            | 10275        |
|    policy_gradient_loss | -0.0144      |
|    std                  | 63           |
|    value_loss           | 0.137        |
------------------------------------------
[ADAPTIVE] Episode 622 reward: 0.015093
[ADAPTIVE] Mean reward over last 20 episodes: 0.002908
[ADAPTIVE] Plateau counter: 36/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 1.013182  |
| time/                   |           |
|    fps                  | 1202      |
|    iterations           | 610       |
|    time_elapsed         | 2077      |
|    total_timesteps      | 2498560   |
| train/                  |           |
|    approx_kl            | 0.0084398 |
|    clip_fraction        | 0.0744    |
|    clip_range           | 0.2       |
|    entropy_loss         | -49.9     |
|    explained_variance   | 0.729     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.971    |
|    n_updates            | 10290     |
|    policy_gradient_loss | -0.0124   |
|    std                  | 63.7      |
|    value_loss           | 0.146     |
---------------------------------------
[ADAPTIVE] Episode 623 reward: 0.052174
[ADAPTIVE] Mean reward over last 20 episodes: 0.008452
[ADAPTIVE] Plateau counter: 37/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0480844   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 611         |
|    time_elapsed         | 2081        |
|    total_timesteps      | 2502656     |
| train/                  |             |
|    approx_kl            | 0.009571102 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -49.9       |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.976      |
|    n_updates            | 10305       |
|    policy_gradient_loss | -0.0136     |
|    std                  | 64          |
|    value_loss           | 0.107       |
-----------------------------------------
[ADAPTIVE] Episode 624 reward: -0.002493
[ADAPTIVE] Mean reward over last 20 episodes: 0.008107
[ADAPTIVE] Plateau counter: 38/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2268871   |
| time/                   |             |
|    fps                  | 1202        |
|    iterations           | 612         |
|    time_elapsed         | 2084        |
|    total_timesteps      | 2506752     |
| train/                  |             |
|    approx_kl            | 0.008426005 |
|    clip_fraction        | 0.0961      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50         |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.967      |
|    n_updates            | 10320       |
|    policy_gradient_loss | -0.0114     |
|    std                  | 64.2        |
|    value_loss           | 0.144       |
-----------------------------------------
[ADAPTIVE] Episode 625 reward: -0.039735
[ADAPTIVE] Mean reward over last 20 episodes: 0.007827
[ADAPTIVE] Plateau counter: 39/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3167692    |
| time/                   |              |
|    fps                  | 1201         |
|    iterations           | 613          |
|    time_elapsed         | 2089         |
|    total_timesteps      | 2510848      |
| train/                  |              |
|    approx_kl            | 0.0064064665 |
|    clip_fraction        | 0.0725       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50          |
|    explained_variance   | 0.79         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.993       |
|    n_updates            | 10335        |
|    policy_gradient_loss | -0.0144      |
|    std                  | 64.5         |
|    value_loss           | 0.0851       |
------------------------------------------
[ADAPTIVE] Episode 626 reward: -0.020379
[ADAPTIVE] Mean reward over last 20 episodes: 0.004380
[ADAPTIVE] Plateau counter: 40/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2918456    |
| time/                   |              |
|    fps                  | 1202         |
|    iterations           | 614          |
|    time_elapsed         | 2091         |
|    total_timesteps      | 2514944      |
| train/                  |              |
|    approx_kl            | 0.0076781455 |
|    clip_fraction        | 0.0833       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50          |
|    explained_variance   | 0.677        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.95        |
|    n_updates            | 10350        |
|    policy_gradient_loss | -0.0132      |
|    std                  | 64.8         |
|    value_loss           | 0.142        |
------------------------------------------
[ADAPTIVE] Episode 627 reward: 0.009380
[ADAPTIVE] Mean reward over last 20 episodes: 0.007980
[ADAPTIVE] Plateau counter: 41/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4094118   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 615         |
|    time_elapsed         | 2096        |
|    total_timesteps      | 2519040     |
| train/                  |             |
|    approx_kl            | 0.009688107 |
|    clip_fraction        | 0.0909      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.1       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.985      |
|    n_updates            | 10365       |
|    policy_gradient_loss | -0.0147     |
|    std                  | 65.2        |
|    value_loss           | 0.0951      |
-----------------------------------------
[ADAPTIVE] Episode 628 reward: 0.021637
[ADAPTIVE] Mean reward over last 20 episodes: 0.016583
[ADAPTIVE] Plateau counter: 42/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2217872   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 616         |
|    time_elapsed         | 2099        |
|    total_timesteps      | 2523136     |
| train/                  |             |
|    approx_kl            | 0.009257606 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.1       |
|    explained_variance   | 0.579       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.982      |
|    n_updates            | 10380       |
|    policy_gradient_loss | -0.0138     |
|    std                  | 65.5        |
|    value_loss           | 0.121       |
-----------------------------------------
[ADAPTIVE] Episode 629 reward: 0.035958
[ADAPTIVE] Mean reward over last 20 episodes: 0.021588
[ADAPTIVE] Plateau counter: 43/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2408922    |
| time/                   |              |
|    fps                  | 1201         |
|    iterations           | 617          |
|    time_elapsed         | 2103         |
|    total_timesteps      | 2527232      |
| train/                  |              |
|    approx_kl            | 0.0068355566 |
|    clip_fraction        | 0.0618       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.2        |
|    explained_variance   | 0.4          |
|    learning_rate        | 0.00025      |
|    loss                 | -0.879       |
|    n_updates            | 10395        |
|    policy_gradient_loss | -0.00872     |
|    std                  | 65.7         |
|    value_loss           | 0.249        |
------------------------------------------
[ADAPTIVE] Episode 630 reward: -0.029667
[ADAPTIVE] Mean reward over last 20 episodes: 0.017074
[ADAPTIVE] Plateau counter: 44/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1950815    |
| time/                   |              |
|    fps                  | 1201         |
|    iterations           | 618          |
|    time_elapsed         | 2106         |
|    total_timesteps      | 2531328      |
| train/                  |              |
|    approx_kl            | 0.0066882875 |
|    clip_fraction        | 0.0678       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.2        |
|    explained_variance   | 0.67         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.973       |
|    n_updates            | 10410        |
|    policy_gradient_loss | -0.0125      |
|    std                  | 66           |
|    value_loss           | 0.136        |
------------------------------------------
[ADAPTIVE] Episode 631 reward: -0.049620
[ADAPTIVE] Mean reward over last 20 episodes: 0.013157
[ADAPTIVE] Plateau counter: 45/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1948527    |
| time/                   |              |
|    fps                  | 1201         |
|    iterations           | 619          |
|    time_elapsed         | 2110         |
|    total_timesteps      | 2535424      |
| train/                  |              |
|    approx_kl            | 0.0077828662 |
|    clip_fraction        | 0.0846       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.3        |
|    explained_variance   | 0.684        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.968       |
|    n_updates            | 10425        |
|    policy_gradient_loss | -0.0134      |
|    std                  | 66.4         |
|    value_loss           | 0.143        |
------------------------------------------
[ADAPTIVE] Episode 632 reward: 0.177156
[ADAPTIVE] Mean reward over last 20 episodes: 0.028979
[ADAPTIVE] Plateau counter: 46/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1925006    |
| time/                   |              |
|    fps                  | 1201         |
|    iterations           | 620          |
|    time_elapsed         | 2113         |
|    total_timesteps      | 2539520      |
| train/                  |              |
|    approx_kl            | 0.0066069444 |
|    clip_fraction        | 0.0672       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.3        |
|    explained_variance   | 0.725        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.994       |
|    n_updates            | 10440        |
|    policy_gradient_loss | -0.0137      |
|    std                  | 66.6         |
|    value_loss           | 0.0869       |
------------------------------------------
[ADAPTIVE] Episode 633 reward: 0.001444
[ADAPTIVE] Mean reward over last 20 episodes: 0.022251
[ADAPTIVE] Plateau counter: 47/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1682962   |
| time/                   |             |
|    fps                  | 1201        |
|    iterations           | 621         |
|    time_elapsed         | 2117        |
|    total_timesteps      | 2543616     |
| train/                  |             |
|    approx_kl            | 0.009282381 |
|    clip_fraction        | 0.0892      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.3       |
|    explained_variance   | 0.719       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.983      |
|    n_updates            | 10455       |
|    policy_gradient_loss | -0.0123     |
|    std                  | 66.8        |
|    value_loss           | 0.112       |
-----------------------------------------
[ADAPTIVE] Episode 634 reward: -0.044528
[ADAPTIVE] Mean reward over last 20 episodes: 0.018657
[ADAPTIVE] Plateau counter: 48/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.299458    |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 622         |
|    time_elapsed         | 2121        |
|    total_timesteps      | 2547712     |
| train/                  |             |
|    approx_kl            | 0.005666306 |
|    clip_fraction        | 0.0606      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.4       |
|    explained_variance   | 0.702       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.977      |
|    n_updates            | 10470       |
|    policy_gradient_loss | -0.0109     |
|    std                  | 67          |
|    value_loss           | 0.1         |
-----------------------------------------
[ADAPTIVE] Episode 635 reward: 0.043952
[ADAPTIVE] Mean reward over last 20 episodes: 0.016596
[ADAPTIVE] Plateau counter: 49/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4688967   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 623         |
|    time_elapsed         | 2125        |
|    total_timesteps      | 2551808     |
| train/                  |             |
|    approx_kl            | 0.008422792 |
|    clip_fraction        | 0.0789      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.4       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.966      |
|    n_updates            | 10485       |
|    policy_gradient_loss | -0.0141     |
|    std                  | 67.3        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 636 reward: 0.021710
[ADAPTIVE] Mean reward over last 20 episodes: 0.014858
[ADAPTIVE] Plateau counter: 50/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4468342   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 624         |
|    time_elapsed         | 2128        |
|    total_timesteps      | 2555904     |
| train/                  |             |
|    approx_kl            | 0.007875622 |
|    clip_fraction        | 0.0992      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.4       |
|    explained_variance   | 0.658       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.953      |
|    n_updates            | 10500       |
|    policy_gradient_loss | -0.0144     |
|    std                  | 67.6        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 637 reward: -0.006884
[ADAPTIVE] Mean reward over last 20 episodes: 0.010619
[ADAPTIVE] Plateau counter: 51/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4448377   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 625         |
|    time_elapsed         | 2132        |
|    total_timesteps      | 2560000     |
| train/                  |             |
|    approx_kl            | 0.008173861 |
|    clip_fraction        | 0.0858      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.5       |
|    explained_variance   | 0.711       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.965      |
|    n_updates            | 10515       |
|    policy_gradient_loss | -0.0118     |
|    std                  | 67.8        |
|    value_loss           | 0.137       |
-----------------------------------------
[ADAPTIVE] Episode 638 reward: 0.119542
[ADAPTIVE] Mean reward over last 20 episodes: 0.016077
[ADAPTIVE] Plateau counter: 52/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.4867561    |
| time/                   |              |
|    fps                  | 1200         |
|    iterations           | 626          |
|    time_elapsed         | 2136         |
|    total_timesteps      | 2564096      |
| train/                  |              |
|    approx_kl            | 0.0067830584 |
|    clip_fraction        | 0.0659       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.5        |
|    explained_variance   | 0.678        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.982       |
|    n_updates            | 10530        |
|    policy_gradient_loss | -0.0115      |
|    std                  | 68.1         |
|    value_loss           | 0.156        |
------------------------------------------
[ADAPTIVE] Episode 639 reward: 0.001511
[ADAPTIVE] Mean reward over last 20 episodes: 0.013143
[ADAPTIVE] Plateau counter: 53/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4217987   |
| time/                   |             |
|    fps                  | 1200        |
|    iterations           | 627         |
|    time_elapsed         | 2139        |
|    total_timesteps      | 2568192     |
| train/                  |             |
|    approx_kl            | 0.010213114 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.6       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 10545       |
|    policy_gradient_loss | -0.0166     |
|    std                  | 68.4        |
|    value_loss           | 0.0871      |
-----------------------------------------
[ADAPTIVE] Episode 640 reward: 0.039377
[ADAPTIVE] Mean reward over last 20 episodes: 0.017403
[ADAPTIVE] Plateau counter: 54/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3375534   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 628         |
|    time_elapsed         | 2144        |
|    total_timesteps      | 2572288     |
| train/                  |             |
|    approx_kl            | 0.010029729 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.6       |
|    explained_variance   | 0.69        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.989      |
|    n_updates            | 10560       |
|    policy_gradient_loss | -0.0173     |
|    std                  | 68.8        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 641 reward: 0.083937
[ADAPTIVE] Mean reward over last 20 episodes: 0.021478
[ADAPTIVE] Plateau counter: 55/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2978554   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 629         |
|    time_elapsed         | 2147        |
|    total_timesteps      | 2576384     |
| train/                  |             |
|    approx_kl            | 0.009627974 |
|    clip_fraction        | 0.0676      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.6       |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.961      |
|    n_updates            | 10575       |
|    policy_gradient_loss | -0.0121     |
|    std                  | 69.2        |
|    value_loss           | 0.132       |
-----------------------------------------
[ADAPTIVE] Episode 642 reward: 0.065584
[ADAPTIVE] Mean reward over last 20 episodes: 0.024003
[ADAPTIVE] Plateau counter: 56/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3024944    |
| time/                   |              |
|    fps                  | 1199         |
|    iterations           | 630          |
|    time_elapsed         | 2151         |
|    total_timesteps      | 2580480      |
| train/                  |              |
|    approx_kl            | 0.0083808545 |
|    clip_fraction        | 0.0855       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.7        |
|    explained_variance   | 0.607        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.961       |
|    n_updates            | 10590        |
|    policy_gradient_loss | -0.0103      |
|    std                  | 69.6         |
|    value_loss           | 0.179        |
------------------------------------------
[ADAPTIVE] Episode 643 reward: -0.008302
[ADAPTIVE] Mean reward over last 20 episodes: 0.020979
[ADAPTIVE] Plateau counter: 57/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2444254   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 631         |
|    time_elapsed         | 2154        |
|    total_timesteps      | 2584576     |
| train/                  |             |
|    approx_kl            | 0.007960366 |
|    clip_fraction        | 0.0716      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.8       |
|    explained_variance   | 0.761       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.994      |
|    n_updates            | 10605       |
|    policy_gradient_loss | -0.0122     |
|    std                  | 70.2        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 644 reward: 0.124164
[ADAPTIVE] Mean reward over last 20 episodes: 0.027312
[ADAPTIVE] Plateau counter: 58/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4286445   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 632         |
|    time_elapsed         | 2158        |
|    total_timesteps      | 2588672     |
| train/                  |             |
|    approx_kl            | 0.009616211 |
|    clip_fraction        | 0.0997      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.8       |
|    explained_variance   | 0.673       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.985      |
|    n_updates            | 10620       |
|    policy_gradient_loss | -0.0139     |
|    std                  | 70.7        |
|    value_loss           | 0.158       |
-----------------------------------------
[ADAPTIVE] Episode 645 reward: -0.003791
[ADAPTIVE] Mean reward over last 20 episodes: 0.029109
[ADAPTIVE] Plateau counter: 59/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.5172774    |
| time/                   |              |
|    fps                  | 1199         |
|    iterations           | 633          |
|    time_elapsed         | 2161         |
|    total_timesteps      | 2592768      |
| train/                  |              |
|    approx_kl            | 0.0060603935 |
|    clip_fraction        | 0.0565       |
|    clip_range           | 0.2          |
|    entropy_loss         | -50.9        |
|    explained_variance   | 0.71         |
|    learning_rate        | 0.00025      |
|    loss                 | -0.974       |
|    n_updates            | 10635        |
|    policy_gradient_loss | -0.00991     |
|    std                  | 71.1         |
|    value_loss           | 0.134        |
------------------------------------------
[ADAPTIVE] Episode 646 reward: 0.050265
[ADAPTIVE] Mean reward over last 20 episodes: 0.032641
[ADAPTIVE] Plateau counter: 60/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4784027   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 634         |
|    time_elapsed         | 2165        |
|    total_timesteps      | 2596864     |
| train/                  |             |
|    approx_kl            | 0.007909279 |
|    clip_fraction        | 0.0559      |
|    clip_range           | 0.2         |
|    entropy_loss         | -50.9       |
|    explained_variance   | 0.643       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 10650       |
|    policy_gradient_loss | -0.0142     |
|    std                  | 71.5        |
|    value_loss           | 0.134       |
-----------------------------------------
[ADAPTIVE] Episode 647 reward: 0.055999
[ADAPTIVE] Mean reward over last 20 episodes: 0.034972
[ADAPTIVE] Plateau counter: 61/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3594807   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 635         |
|    time_elapsed         | 2169        |
|    total_timesteps      | 2600960     |
| train/                  |             |
|    approx_kl            | 0.008215607 |
|    clip_fraction        | 0.0848      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51         |
|    explained_variance   | 0.69        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.981      |
|    n_updates            | 10665       |
|    policy_gradient_loss | -0.0113     |
|    std                  | 71.7        |
|    value_loss           | 0.124       |
-----------------------------------------
[ADAPTIVE] Episode 648 reward: 0.009009
[ADAPTIVE] Mean reward over last 20 episodes: 0.034341
[ADAPTIVE] Plateau counter: 62/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2331258   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 636         |
|    time_elapsed         | 2172        |
|    total_timesteps      | 2605056     |
| train/                  |             |
|    approx_kl            | 0.009086908 |
|    clip_fraction        | 0.0773      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51         |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.975      |
|    n_updates            | 10680       |
|    policy_gradient_loss | -0.0145     |
|    std                  | 72          |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 649 reward: 0.002030
[ADAPTIVE] Mean reward over last 20 episodes: 0.032644
[ADAPTIVE] Plateau counter: 63/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2480557  |
| time/                   |            |
|    fps                  | 1198       |
|    iterations           | 637        |
|    time_elapsed         | 2176       |
|    total_timesteps      | 2609152    |
| train/                  |            |
|    approx_kl            | 0.00808783 |
|    clip_fraction        | 0.0816     |
|    clip_range           | 0.2        |
|    entropy_loss         | -51        |
|    explained_variance   | 0.687      |
|    learning_rate        | 0.00025    |
|    loss                 | -1         |
|    n_updates            | 10695      |
|    policy_gradient_loss | -0.0115    |
|    std                  | 72.1       |
|    value_loss           | 0.114      |
----------------------------------------
[ADAPTIVE] Episode 650 reward: -0.077684
[ADAPTIVE] Mean reward over last 20 episodes: 0.030244
[ADAPTIVE] Plateau counter: 64/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1780148   |
| time/                   |             |
|    fps                  | 1199        |
|    iterations           | 638         |
|    time_elapsed         | 2179        |
|    total_timesteps      | 2613248     |
| train/                  |             |
|    approx_kl            | 0.009876488 |
|    clip_fraction        | 0.0667      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.1       |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 10710       |
|    policy_gradient_loss | -0.0118     |
|    std                  | 72.4        |
|    value_loss           | 0.0859      |
-----------------------------------------
[ADAPTIVE] Episode 651 reward: 0.055021
[ADAPTIVE] Mean reward over last 20 episodes: 0.035476
[ADAPTIVE] Plateau counter: 65/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1719939    |
| time/                   |              |
|    fps                  | 1198         |
|    iterations           | 639          |
|    time_elapsed         | 2183         |
|    total_timesteps      | 2617344      |
| train/                  |              |
|    approx_kl            | 0.0056732916 |
|    clip_fraction        | 0.0726       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.1        |
|    explained_variance   | 0.726        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.996       |
|    n_updates            | 10725        |
|    policy_gradient_loss | -0.0101      |
|    std                  | 72.6         |
|    value_loss           | 0.14         |
------------------------------------------
[ADAPTIVE] Episode 652 reward: 0.108571
[ADAPTIVE] Mean reward over last 20 episodes: 0.032046
[ADAPTIVE] Plateau counter: 66/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.089774     |
| time/                   |              |
|    fps                  | 1199         |
|    iterations           | 640          |
|    time_elapsed         | 2186         |
|    total_timesteps      | 2621440      |
| train/                  |              |
|    approx_kl            | 0.0060851905 |
|    clip_fraction        | 0.0415       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.1        |
|    explained_variance   | 0.609        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.976       |
|    n_updates            | 10740        |
|    policy_gradient_loss | -0.0102      |
|    std                  | 72.9         |
|    value_loss           | 0.166        |
------------------------------------------
[ADAPTIVE] Episode 653 reward: -0.002505
[ADAPTIVE] Mean reward over last 20 episodes: 0.031849
[ADAPTIVE] Plateau counter: 67/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3453319   |
| time/                   |             |
|    fps                  | 1198        |
|    iterations           | 641         |
|    time_elapsed         | 2190        |
|    total_timesteps      | 2625536     |
| train/                  |             |
|    approx_kl            | 0.010722471 |
|    clip_fraction        | 0.0771      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.2       |
|    explained_variance   | 0.662       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.975      |
|    n_updates            | 10755       |
|    policy_gradient_loss | -0.0125     |
|    std                  | 73.2        |
|    value_loss           | 0.111       |
-----------------------------------------
[ADAPTIVE] Episode 654 reward: 0.062749
[ADAPTIVE] Mean reward over last 20 episodes: 0.037213
[ADAPTIVE] Plateau counter: 68/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5584009   |
| time/                   |             |
|    fps                  | 1198        |
|    iterations           | 642         |
|    time_elapsed         | 2193        |
|    total_timesteps      | 2629632     |
| train/                  |             |
|    approx_kl            | 0.012452813 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.2       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 10770       |
|    policy_gradient_loss | -0.0142     |
|    std                  | 73.5        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 655 reward: 0.021881
[ADAPTIVE] Mean reward over last 20 episodes: 0.036109
[ADAPTIVE] Plateau counter: 69/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5856329   |
| time/                   |             |
|    fps                  | 1198        |
|    iterations           | 643         |
|    time_elapsed         | 2197        |
|    total_timesteps      | 2633728     |
| train/                  |             |
|    approx_kl            | 0.010309163 |
|    clip_fraction        | 0.0957      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.2       |
|    explained_variance   | 0.664       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.976      |
|    n_updates            | 10785       |
|    policy_gradient_loss | -0.0126     |
|    std                  | 73.9        |
|    value_loss           | 0.167       |
-----------------------------------------
[ADAPTIVE] Episode 656 reward: 0.007518
[ADAPTIVE] Mean reward over last 20 episodes: 0.035399
[ADAPTIVE] Plateau counter: 70/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2790227   |
| time/                   |             |
|    fps                  | 1198        |
|    iterations           | 644         |
|    time_elapsed         | 2200        |
|    total_timesteps      | 2637824     |
| train/                  |             |
|    approx_kl            | 0.008727303 |
|    clip_fraction        | 0.0621      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.3       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.951      |
|    n_updates            | 10800       |
|    policy_gradient_loss | -0.0104     |
|    std                  | 74.3        |
|    value_loss           | 0.172       |
-----------------------------------------
[ADAPTIVE] Episode 657 reward: 0.018523
[ADAPTIVE] Mean reward over last 20 episodes: 0.036670
[ADAPTIVE] Plateau counter: 71/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.1806383  |
| time/                   |            |
|    fps                  | 1198       |
|    iterations           | 645        |
|    time_elapsed         | 2204       |
|    total_timesteps      | 2641920    |
| train/                  |            |
|    approx_kl            | 0.00867838 |
|    clip_fraction        | 0.0629     |
|    clip_range           | 0.2        |
|    entropy_loss         | -51.3      |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.01      |
|    n_updates            | 10815      |
|    policy_gradient_loss | -0.00908   |
|    std                  | 74.7       |
|    value_loss           | 0.139      |
----------------------------------------
[ADAPTIVE] Episode 658 reward: -0.013776
[ADAPTIVE] Mean reward over last 20 episodes: 0.030004
[ADAPTIVE] Plateau counter: 72/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 251       |
|    ep_rew_mean          | 1.2504203 |
| time/                   |           |
|    fps                  | 1198      |
|    iterations           | 646       |
|    time_elapsed         | 2208      |
|    total_timesteps      | 2646016   |
| train/                  |           |
|    approx_kl            | 0.007379  |
|    clip_fraction        | 0.0763    |
|    clip_range           | 0.2       |
|    entropy_loss         | -51.4     |
|    explained_variance   | 0.722     |
|    learning_rate        | 0.00025   |
|    loss                 | -0.973    |
|    n_updates            | 10830     |
|    policy_gradient_loss | -0.0121   |
|    std                  | 75        |
|    value_loss           | 0.14      |
---------------------------------------
[ADAPTIVE] Episode 659 reward: -0.040739
[ADAPTIVE] Mean reward over last 20 episodes: 0.027891
[ADAPTIVE] Plateau counter: 73/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1532235    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 647          |
|    time_elapsed         | 2212         |
|    total_timesteps      | 2650112      |
| train/                  |              |
|    approx_kl            | 0.0074469917 |
|    clip_fraction        | 0.0796       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.4        |
|    explained_variance   | 0.561        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.976       |
|    n_updates            | 10845        |
|    policy_gradient_loss | -0.0126      |
|    std                  | 75.6         |
|    value_loss           | 0.15         |
------------------------------------------
[ADAPTIVE] Episode 660 reward: 0.029321
[ADAPTIVE] Mean reward over last 20 episodes: 0.027389
[ADAPTIVE] Plateau counter: 74/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1353621   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 648         |
|    time_elapsed         | 2215        |
|    total_timesteps      | 2654208     |
| train/                  |             |
|    approx_kl            | 0.005895503 |
|    clip_fraction        | 0.0551      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.5       |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 10860       |
|    policy_gradient_loss | -0.0118     |
|    std                  | 75.9        |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 661 reward: -0.014455
[ADAPTIVE] Mean reward over last 20 episodes: 0.022469
[ADAPTIVE] Plateau counter: 75/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.98192143  |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 649         |
|    time_elapsed         | 2219        |
|    total_timesteps      | 2658304     |
| train/                  |             |
|    approx_kl            | 0.008182554 |
|    clip_fraction        | 0.0852      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.5       |
|    explained_variance   | 0.776       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 10875       |
|    policy_gradient_loss | -0.0123     |
|    std                  | 76.4        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 662 reward: -0.001631
[ADAPTIVE] Mean reward over last 20 episodes: 0.019108
[ADAPTIVE] Plateau counter: 76/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.079841    |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 650         |
|    time_elapsed         | 2223        |
|    total_timesteps      | 2662400     |
| train/                  |             |
|    approx_kl            | 0.009710411 |
|    clip_fraction        | 0.0802      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.6       |
|    explained_variance   | 0.694       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 10890       |
|    policy_gradient_loss | -0.0112     |
|    std                  | 77.1        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 663 reward: -0.246088
[ADAPTIVE] Mean reward over last 20 episodes: 0.007219
[ADAPTIVE] Plateau counter: 77/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.9754422   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 651         |
|    time_elapsed         | 2226        |
|    total_timesteps      | 2666496     |
| train/                  |             |
|    approx_kl            | 0.007711192 |
|    clip_fraction        | 0.0784      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.6       |
|    explained_variance   | 0.758       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.997      |
|    n_updates            | 10905       |
|    policy_gradient_loss | -0.0141     |
|    std                  | 77.4        |
|    value_loss           | 0.115       |
-----------------------------------------
[ADAPTIVE] Episode 664 reward: -0.039299
[ADAPTIVE] Mean reward over last 20 episodes: -0.000954
[ADAPTIVE] Plateau counter: 78/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.93173957  |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 652         |
|    time_elapsed         | 2230        |
|    total_timesteps      | 2670592     |
| train/                  |             |
|    approx_kl            | 0.009448098 |
|    clip_fraction        | 0.0963      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.7       |
|    explained_variance   | 0.789       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 10920       |
|    policy_gradient_loss | -0.0152     |
|    std                  | 77.9        |
|    value_loss           | 0.0825      |
-----------------------------------------
[ADAPTIVE] Episode 665 reward: -0.065300
[ADAPTIVE] Mean reward over last 20 episodes: -0.004030
[ADAPTIVE] Plateau counter: 79/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 666 reward: 0.014417
[ADAPTIVE] Mean reward over last 20 episodes: -0.005822
[ADAPTIVE] Plateau counter: 80/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9096639    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 653          |
|    time_elapsed         | 2233         |
|    total_timesteps      | 2674688      |
| train/                  |              |
|    approx_kl            | 0.0067676664 |
|    clip_fraction        | 0.0623       |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.7        |
|    explained_variance   | 0.801        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 10935        |
|    policy_gradient_loss | -0.0117      |
|    std                  | 78.1         |
|    value_loss           | 0.0843       |
------------------------------------------
[ADAPTIVE] Episode 667 reward: 0.013002
[ADAPTIVE] Mean reward over last 20 episodes: -0.007972
[ADAPTIVE] Plateau counter: 81/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.84436363  |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 654         |
|    time_elapsed         | 2237        |
|    total_timesteps      | 2678784     |
| train/                  |             |
|    approx_kl            | 0.006207906 |
|    clip_fraction        | 0.0509      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.8       |
|    explained_variance   | 0.75        |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 10950       |
|    policy_gradient_loss | -0.0139     |
|    std                  | 78.5        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 668 reward: 0.054737
[ADAPTIVE] Mean reward over last 20 episodes: -0.005685
[ADAPTIVE] Plateau counter: 82/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8866362   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 655         |
|    time_elapsed         | 2240        |
|    total_timesteps      | 2682880     |
| train/                  |             |
|    approx_kl            | 0.006230559 |
|    clip_fraction        | 0.0569      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.8       |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.999      |
|    n_updates            | 10965       |
|    policy_gradient_loss | -0.0116     |
|    std                  | 78.9        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 669 reward: -0.120922
[ADAPTIVE] Mean reward over last 20 episodes: -0.011833
[ADAPTIVE] Plateau counter: 83/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0355325   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 656         |
|    time_elapsed         | 2244        |
|    total_timesteps      | 2686976     |
| train/                  |             |
|    approx_kl            | 0.010837166 |
|    clip_fraction        | 0.0961      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.9       |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.04       |
|    n_updates            | 10980       |
|    policy_gradient_loss | -0.0134     |
|    std                  | 79.5        |
|    value_loss           | 0.0718      |
-----------------------------------------
[ADAPTIVE] Episode 670 reward: -0.071437
[ADAPTIVE] Mean reward over last 20 episodes: -0.011521
[ADAPTIVE] Plateau counter: 84/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0447798    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 657          |
|    time_elapsed         | 2248         |
|    total_timesteps      | 2691072      |
| train/                  |              |
|    approx_kl            | 0.0113787325 |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.2          |
|    entropy_loss         | -51.9        |
|    explained_variance   | 0.655        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.95        |
|    n_updates            | 10995        |
|    policy_gradient_loss | -0.012       |
|    std                  | 79.8         |
|    value_loss           | 0.242        |
------------------------------------------
[ADAPTIVE] Episode 671 reward: 0.022848
[ADAPTIVE] Mean reward over last 20 episodes: -0.013129
[ADAPTIVE] Plateau counter: 85/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1589073   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 658         |
|    time_elapsed         | 2251        |
|    total_timesteps      | 2695168     |
| train/                  |             |
|    approx_kl            | 0.007463386 |
|    clip_fraction        | 0.0781      |
|    clip_range           | 0.2         |
|    entropy_loss         | -51.9       |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11010       |
|    policy_gradient_loss | -0.0143     |
|    std                  | 80          |
|    value_loss           | 0.118       |
-----------------------------------------
[ADAPTIVE] Episode 672 reward: -0.008559
[ADAPTIVE] Mean reward over last 20 episodes: -0.018986
[ADAPTIVE] Plateau counter: 86/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1986221   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 659         |
|    time_elapsed         | 2255        |
|    total_timesteps      | 2699264     |
| train/                  |             |
|    approx_kl            | 0.006102039 |
|    clip_fraction        | 0.0648      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52         |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.00025     |
|    loss                 | -0.995      |
|    n_updates            | 11025       |
|    policy_gradient_loss | -0.00966    |
|    std                  | 80.4        |
|    value_loss           | 0.179       |
-----------------------------------------
[ADAPTIVE] Episode 673 reward: -0.016846
[ADAPTIVE] Mean reward over last 20 episodes: -0.019703
[ADAPTIVE] Plateau counter: 87/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2260025   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 660         |
|    time_elapsed         | 2258        |
|    total_timesteps      | 2703360     |
| train/                  |             |
|    approx_kl            | 0.008658864 |
|    clip_fraction        | 0.0588      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52         |
|    explained_variance   | 0.634       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11040       |
|    policy_gradient_loss | -0.0101     |
|    std                  | 80.8        |
|    value_loss           | 0.157       |
-----------------------------------------
[ADAPTIVE] Episode 674 reward: -0.046924
[ADAPTIVE] Mean reward over last 20 episodes: -0.025186
[ADAPTIVE] Plateau counter: 88/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.3244874  |
| time/                   |            |
|    fps                  | 1196       |
|    iterations           | 661        |
|    time_elapsed         | 2262       |
|    total_timesteps      | 2707456    |
| train/                  |            |
|    approx_kl            | 0.00681504 |
|    clip_fraction        | 0.0493     |
|    clip_range           | 0.2        |
|    entropy_loss         | -52.1      |
|    explained_variance   | 0.666      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.02      |
|    n_updates            | 11055      |
|    policy_gradient_loss | -0.0104    |
|    std                  | 81.6       |
|    value_loss           | 0.138      |
----------------------------------------
[ADAPTIVE] Episode 675 reward: 0.053395
[ADAPTIVE] Mean reward over last 20 episodes: -0.023611
[ADAPTIVE] Plateau counter: 89/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1995872   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 662         |
|    time_elapsed         | 2265        |
|    total_timesteps      | 2711552     |
| train/                  |             |
|    approx_kl            | 0.009029656 |
|    clip_fraction        | 0.0855      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.1       |
|    explained_variance   | 0.578       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 11070       |
|    policy_gradient_loss | -0.0125     |
|    std                  | 81.9        |
|    value_loss           | 0.133       |
-----------------------------------------
[ADAPTIVE] Episode 676 reward: 0.042080
[ADAPTIVE] Mean reward over last 20 episodes: -0.021883
[ADAPTIVE] Plateau counter: 90/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2216839   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 663         |
|    time_elapsed         | 2268        |
|    total_timesteps      | 2715648     |
| train/                  |             |
|    approx_kl            | 0.008399329 |
|    clip_fraction        | 0.0801      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.2       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11085       |
|    policy_gradient_loss | -0.0115     |
|    std                  | 82.2        |
|    value_loss           | 0.11        |
-----------------------------------------
[ADAPTIVE] Episode 677 reward: 0.072579
[ADAPTIVE] Mean reward over last 20 episodes: -0.019180
[ADAPTIVE] Plateau counter: 91/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0705005   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 664         |
|    time_elapsed         | 2272        |
|    total_timesteps      | 2719744     |
| train/                  |             |
|    approx_kl            | 0.008273087 |
|    clip_fraction        | 0.0831      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.2       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11100       |
|    policy_gradient_loss | -0.0143     |
|    std                  | 82.6        |
|    value_loss           | 0.088       |
-----------------------------------------
[ADAPTIVE] Episode 678 reward: 0.003636
[ADAPTIVE] Mean reward over last 20 episodes: -0.018309
[ADAPTIVE] Plateau counter: 92/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.9957523    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 665          |
|    time_elapsed         | 2276         |
|    total_timesteps      | 2723840      |
| train/                  |              |
|    approx_kl            | 0.0076482887 |
|    clip_fraction        | 0.0826       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.3        |
|    explained_variance   | 0.726        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11115        |
|    policy_gradient_loss | -0.0162      |
|    std                  | 83.2         |
|    value_loss           | 0.118        |
------------------------------------------
[ADAPTIVE] Episode 679 reward: -0.042617
[ADAPTIVE] Mean reward over last 20 episodes: -0.018403
[ADAPTIVE] Plateau counter: 93/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1370102   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 666         |
|    time_elapsed         | 2279        |
|    total_timesteps      | 2727936     |
| train/                  |             |
|    approx_kl            | 0.005953805 |
|    clip_fraction        | 0.0759      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.3       |
|    explained_variance   | 0.629       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.976      |
|    n_updates            | 11130       |
|    policy_gradient_loss | -0.0106     |
|    std                  | 83.6        |
|    value_loss           | 0.204       |
-----------------------------------------
[ADAPTIVE] Episode 680 reward: 0.291221
[ADAPTIVE] Mean reward over last 20 episodes: -0.005308
[ADAPTIVE] Plateau counter: 94/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0522499    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 667          |
|    time_elapsed         | 2283         |
|    total_timesteps      | 2732032      |
| train/                  |              |
|    approx_kl            | 0.0060790563 |
|    clip_fraction        | 0.053        |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.3        |
|    explained_variance   | 0.77         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11145        |
|    policy_gradient_loss | -0.00994     |
|    std                  | 83.9         |
|    value_loss           | 0.111        |
------------------------------------------
[ADAPTIVE] Episode 681 reward: 0.114562
[ADAPTIVE] Mean reward over last 20 episodes: 0.001143
[ADAPTIVE] Plateau counter: 95/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1520133    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 668          |
|    time_elapsed         | 2286         |
|    total_timesteps      | 2736128      |
| train/                  |              |
|    approx_kl            | 0.0053789597 |
|    clip_fraction        | 0.0665       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.4        |
|    explained_variance   | 0.771        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 11160        |
|    policy_gradient_loss | -0.00994     |
|    std                  | 84.1         |
|    value_loss           | 0.0954       |
------------------------------------------
[ADAPTIVE] Episode 682 reward: -0.006376
[ADAPTIVE] Mean reward over last 20 episodes: 0.000906
[ADAPTIVE] Plateau counter: 96/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1135645   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 669         |
|    time_elapsed         | 2290        |
|    total_timesteps      | 2740224     |
| train/                  |             |
|    approx_kl            | 0.006600478 |
|    clip_fraction        | 0.0757      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.4       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11175       |
|    policy_gradient_loss | -0.0117     |
|    std                  | 84.6        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 683 reward: 0.060088
[ADAPTIVE] Mean reward over last 20 episodes: 0.016214
[ADAPTIVE] Plateau counter: 97/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0992085    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 670          |
|    time_elapsed         | 2294         |
|    total_timesteps      | 2744320      |
| train/                  |              |
|    approx_kl            | 0.0072289845 |
|    clip_fraction        | 0.0782       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.4        |
|    explained_variance   | 0.696        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 11190        |
|    policy_gradient_loss | -0.0104      |
|    std                  | 85           |
|    value_loss           | 0.122        |
------------------------------------------
[ADAPTIVE] Episode 684 reward: -0.180254
[ADAPTIVE] Mean reward over last 20 episodes: 0.009167
[ADAPTIVE] Plateau counter: 98/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2031739    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 671          |
|    time_elapsed         | 2297         |
|    total_timesteps      | 2748416      |
| train/                  |              |
|    approx_kl            | 0.0063141044 |
|    clip_fraction        | 0.0718       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.5        |
|    explained_variance   | 0.742        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.999       |
|    n_updates            | 11205        |
|    policy_gradient_loss | -0.0115      |
|    std                  | 85.5         |
|    value_loss           | 0.117        |
------------------------------------------
[ADAPTIVE] Episode 685 reward: 0.125237
[ADAPTIVE] Mean reward over last 20 episodes: 0.018693
[ADAPTIVE] Plateau counter: 99/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3219082   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 672         |
|    time_elapsed         | 2301        |
|    total_timesteps      | 2752512     |
| train/                  |             |
|    approx_kl            | 0.007873913 |
|    clip_fraction        | 0.0826      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.5       |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.03       |
|    n_updates            | 11220       |
|    policy_gradient_loss | -0.0143     |
|    std                  | 85.9        |
|    value_loss           | 0.0961      |
-----------------------------------------
[ADAPTIVE] Episode 686 reward: 0.171127
[ADAPTIVE] Mean reward over last 20 episodes: 0.026529
[ADAPTIVE] Plateau counter: 100/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2090685    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 673          |
|    time_elapsed         | 2304         |
|    total_timesteps      | 2756608      |
| train/                  |              |
|    approx_kl            | 0.0071791774 |
|    clip_fraction        | 0.0653       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.6        |
|    explained_variance   | 0.694        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 11235        |
|    policy_gradient_loss | -0.0107      |
|    std                  | 86.4         |
|    value_loss           | 0.112        |
------------------------------------------
[ADAPTIVE] Episode 687 reward: 0.012108
[ADAPTIVE] Mean reward over last 20 episodes: 0.026484
[ADAPTIVE] Plateau counter: 101/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0719382   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 674         |
|    time_elapsed         | 2307        |
|    total_timesteps      | 2760704     |
| train/                  |             |
|    approx_kl            | 0.012670104 |
|    clip_fraction        | 0.0798      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.6       |
|    explained_variance   | 0.7         |
|    learning_rate        | 0.00025     |
|    loss                 | -1.04       |
|    n_updates            | 11250       |
|    policy_gradient_loss | -0.0117     |
|    std                  | 86.7        |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 688 reward: -0.016375
[ADAPTIVE] Mean reward over last 20 episodes: 0.022929
[ADAPTIVE] Plateau counter: 102/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1763446    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 675          |
|    time_elapsed         | 2310         |
|    total_timesteps      | 2764800      |
| train/                  |              |
|    approx_kl            | 0.0061631305 |
|    clip_fraction        | 0.0659       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.6        |
|    explained_variance   | 0.672        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11265        |
|    policy_gradient_loss | -0.00849     |
|    std                  | 87.1         |
|    value_loss           | 0.0958       |
------------------------------------------
[ADAPTIVE] Episode 689 reward: 0.071751
[ADAPTIVE] Mean reward over last 20 episodes: 0.032562
[ADAPTIVE] Plateau counter: 103/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2616066   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 676         |
|    time_elapsed         | 2314        |
|    total_timesteps      | 2768896     |
| train/                  |             |
|    approx_kl            | 0.006008895 |
|    clip_fraction        | 0.0428      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.7       |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11280       |
|    policy_gradient_loss | -0.00876    |
|    std                  | 87.3        |
|    value_loss           | 0.104       |
-----------------------------------------
[ADAPTIVE] Episode 690 reward: -0.031827
[ADAPTIVE] Mean reward over last 20 episodes: 0.034543
[ADAPTIVE] Plateau counter: 104/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.4606785    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 677          |
|    time_elapsed         | 2317         |
|    total_timesteps      | 2772992      |
| train/                  |              |
|    approx_kl            | 0.0073666465 |
|    clip_fraction        | 0.065        |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.7        |
|    explained_variance   | 0.751        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 11295        |
|    policy_gradient_loss | -0.0104      |
|    std                  | 87.5         |
|    value_loss           | 0.103        |
------------------------------------------
[ADAPTIVE] Episode 691 reward: 0.006225
[ADAPTIVE] Mean reward over last 20 episodes: 0.033712
[ADAPTIVE] Plateau counter: 105/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3794141   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 678         |
|    time_elapsed         | 2320        |
|    total_timesteps      | 2777088     |
| train/                  |             |
|    approx_kl            | 0.008458702 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.7       |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 11310       |
|    policy_gradient_loss | -0.0157     |
|    std                  | 88.4        |
|    value_loss           | 0.0816      |
-----------------------------------------
[ADAPTIVE] Episode 692 reward: 0.039515
[ADAPTIVE] Mean reward over last 20 episodes: 0.036115
[ADAPTIVE] Plateau counter: 106/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3727309    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 679          |
|    time_elapsed         | 2323         |
|    total_timesteps      | 2781184      |
| train/                  |              |
|    approx_kl            | 0.0066719465 |
|    clip_fraction        | 0.0896       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.8        |
|    explained_variance   | 0.752        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 11325        |
|    policy_gradient_loss | -0.0105      |
|    std                  | 89.1         |
|    value_loss           | 0.1          |
------------------------------------------
[ADAPTIVE] Episode 693 reward: 0.060784
[ADAPTIVE] Mean reward over last 20 episodes: 0.039997
[ADAPTIVE] Plateau counter: 107/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.4048167   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 680         |
|    time_elapsed         | 2327        |
|    total_timesteps      | 2785280     |
| train/                  |             |
|    approx_kl            | 0.009103606 |
|    clip_fraction        | 0.088       |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.9       |
|    explained_variance   | 0.621       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.992      |
|    n_updates            | 11340       |
|    policy_gradient_loss | -0.00975    |
|    std                  | 89.3        |
|    value_loss           | 0.21        |
-----------------------------------------
[ADAPTIVE] Episode 694 reward: 0.043723
[ADAPTIVE] Mean reward over last 20 episodes: 0.044529
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2992771    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 681          |
|    time_elapsed         | 2330         |
|    total_timesteps      | 2789376      |
| train/                  |              |
|    approx_kl            | 0.0076000793 |
|    clip_fraction        | 0.0722       |
|    clip_range           | 0.2          |
|    entropy_loss         | -52.9        |
|    explained_variance   | 0.706        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 11355        |
|    policy_gradient_loss | -0.0118      |
|    std                  | 89.7         |
|    value_loss           | 0.113        |
------------------------------------------
[ADAPTIVE] Episode 695 reward: -0.048968
[ADAPTIVE] Mean reward over last 20 episodes: 0.039411
[ADAPTIVE] Plateau counter: 1/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2331043   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 682         |
|    time_elapsed         | 2333        |
|    total_timesteps      | 2793472     |
| train/                  |             |
|    approx_kl            | 0.006419308 |
|    clip_fraction        | 0.0745      |
|    clip_range           | 0.2         |
|    entropy_loss         | -52.9       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 11370       |
|    policy_gradient_loss | -0.0121     |
|    std                  | 90          |
|    value_loss           | 0.0805      |
-----------------------------------------
[ADAPTIVE] Episode 696 reward: -0.024088
[ADAPTIVE] Mean reward over last 20 episodes: 0.036103
[ADAPTIVE] Plateau counter: 2/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2472633   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 683         |
|    time_elapsed         | 2337        |
|    total_timesteps      | 2797568     |
| train/                  |             |
|    approx_kl            | 0.010122736 |
|    clip_fraction        | 0.0801      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53         |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.02       |
|    n_updates            | 11385       |
|    policy_gradient_loss | -0.0085     |
|    std                  | 90.5        |
|    value_loss           | 0.155       |
-----------------------------------------
[ADAPTIVE] Episode 697 reward: -0.065891
[ADAPTIVE] Mean reward over last 20 episodes: 0.029179
[ADAPTIVE] Plateau counter: 3/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0881721    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 684          |
|    time_elapsed         | 2340         |
|    total_timesteps      | 2801664      |
| train/                  |              |
|    approx_kl            | 0.0067538023 |
|    clip_fraction        | 0.0698       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53          |
|    explained_variance   | 0.666        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.02        |
|    n_updates            | 11400        |
|    policy_gradient_loss | -0.0117      |
|    std                  | 91           |
|    value_loss           | 0.13         |
------------------------------------------
[ADAPTIVE] Episode 698 reward: -0.034816
[ADAPTIVE] Mean reward over last 20 episodes: 0.027256
[ADAPTIVE] Plateau counter: 4/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1260711   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 685         |
|    time_elapsed         | 2343        |
|    total_timesteps      | 2805760     |
| train/                  |             |
|    approx_kl            | 0.008308582 |
|    clip_fraction        | 0.0751      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.1       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11415       |
|    policy_gradient_loss | -0.00965    |
|    std                  | 91.7        |
|    value_loss           | 0.191       |
-----------------------------------------
[ADAPTIVE] Episode 699 reward: 0.169138
[ADAPTIVE] Mean reward over last 20 episodes: 0.037844
[ADAPTIVE] Plateau counter: 5/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.308058    |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 686         |
|    time_elapsed         | 2346        |
|    total_timesteps      | 2809856     |
| train/                  |             |
|    approx_kl            | 0.009878226 |
|    clip_fraction        | 0.0894      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.1       |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 11430       |
|    policy_gradient_loss | -0.0108     |
|    std                  | 92          |
|    value_loss           | 0.0761      |
-----------------------------------------
[ADAPTIVE] Episode 700 reward: -0.011530
[ADAPTIVE] Mean reward over last 20 episodes: 0.022707
[ADAPTIVE] Plateau counter: 6/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1065595   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 687         |
|    time_elapsed         | 2350        |
|    total_timesteps      | 2813952     |
| train/                  |             |
|    approx_kl            | 0.008640946 |
|    clip_fraction        | 0.0661      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.2       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 11445       |
|    policy_gradient_loss | -0.0119     |
|    std                  | 92.5        |
|    value_loss           | 0.0933      |
-----------------------------------------
[ADAPTIVE] Episode 701 reward: -0.060553
[ADAPTIVE] Mean reward over last 20 episodes: 0.013951
[ADAPTIVE] Plateau counter: 7/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2387316    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 688          |
|    time_elapsed         | 2353         |
|    total_timesteps      | 2818048      |
| train/                  |              |
|    approx_kl            | 0.0065711616 |
|    clip_fraction        | 0.0734       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.2        |
|    explained_variance   | 0.595        |
|    learning_rate        | 0.00025      |
|    loss                 | -0.964       |
|    n_updates            | 11460        |
|    policy_gradient_loss | -0.0104      |
|    std                  | 92.8         |
|    value_loss           | 0.217        |
------------------------------------------
[ADAPTIVE] Episode 702 reward: -0.058284
[ADAPTIVE] Mean reward over last 20 episodes: 0.011355
[ADAPTIVE] Plateau counter: 8/10
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.3230976    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 689          |
|    time_elapsed         | 2356         |
|    total_timesteps      | 2822144      |
| train/                  |              |
|    approx_kl            | 0.0067562256 |
|    clip_fraction        | 0.0585       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.2        |
|    explained_variance   | 0.802        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 11475        |
|    policy_gradient_loss | -0.00855     |
|    std                  | 93           |
|    value_loss           | 0.123        |
------------------------------------------
[ADAPTIVE] Episode 703 reward: -0.027928
[ADAPTIVE] Mean reward over last 20 episodes: 0.006955
[ADAPTIVE] Plateau counter: 9/10
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2574922   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 690         |
|    time_elapsed         | 2359        |
|    total_timesteps      | 2826240     |
| train/                  |             |
|    approx_kl            | 0.008058324 |
|    clip_fraction        | 0.0723      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.3       |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 11490       |
|    policy_gradient_loss | -0.0119     |
|    std                  | 93.8        |
|    value_loss           | 0.0645      |
-----------------------------------------
[ADAPTIVE] Episode 704 reward: 0.023772
[ADAPTIVE] Mean reward over last 20 episodes: 0.017156
[ADAPTIVE] Plateau counter: 10/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2235403    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 691          |
|    time_elapsed         | 2363         |
|    total_timesteps      | 2830336      |
| train/                  |              |
|    approx_kl            | 0.0077229976 |
|    clip_fraction        | 0.0902       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.3        |
|    explained_variance   | 0.724        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11505        |
|    policy_gradient_loss | -0.0159      |
|    std                  | 94.4         |
|    value_loss           | 0.0882       |
------------------------------------------
[ADAPTIVE] Episode 705 reward: -0.002041
[ADAPTIVE] Mean reward over last 20 episodes: 0.010792
[ADAPTIVE] Plateau counter: 11/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.1531543    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 692          |
|    time_elapsed         | 2366         |
|    total_timesteps      | 2834432      |
| train/                  |              |
|    approx_kl            | 0.0068027372 |
|    clip_fraction        | 0.0717       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.4        |
|    explained_variance   | 0.69         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.04        |
|    n_updates            | 11520        |
|    policy_gradient_loss | -0.0124      |
|    std                  | 95           |
|    value_loss           | 0.126        |
------------------------------------------
[ADAPTIVE] Episode 706 reward: -0.109600
[ADAPTIVE] Mean reward over last 20 episodes: -0.003244
[ADAPTIVE] Plateau counter: 12/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.2738698  |
| time/                   |            |
|    fps                  | 1197       |
|    iterations           | 693        |
|    time_elapsed         | 2369       |
|    total_timesteps      | 2838528    |
| train/                  |            |
|    approx_kl            | 0.00730698 |
|    clip_fraction        | 0.0787     |
|    clip_range           | 0.2        |
|    entropy_loss         | -53.4      |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.05      |
|    n_updates            | 11535      |
|    policy_gradient_loss | -0.0127    |
|    std                  | 95.3       |
|    value_loss           | 0.108      |
----------------------------------------
[ADAPTIVE] Episode 707 reward: -0.033778
[ADAPTIVE] Mean reward over last 20 episodes: -0.005539
[ADAPTIVE] Plateau counter: 13/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2929913   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 694         |
|    time_elapsed         | 2373        |
|    total_timesteps      | 2842624     |
| train/                  |             |
|    approx_kl            | 0.006739389 |
|    clip_fraction        | 0.0702      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.5       |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.01       |
|    n_updates            | 11550       |
|    policy_gradient_loss | -0.0106     |
|    std                  | 95.6        |
|    value_loss           | 0.151       |
-----------------------------------------
[ADAPTIVE] Episode 708 reward: 0.032612
[ADAPTIVE] Mean reward over last 20 episodes: -0.003089
[ADAPTIVE] Plateau counter: 14/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3050934   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 695         |
|    time_elapsed         | 2376        |
|    total_timesteps      | 2846720     |
| train/                  |             |
|    approx_kl            | 0.007599923 |
|    clip_fraction        | 0.0606      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.5       |
|    explained_variance   | 0.807       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 11565       |
|    policy_gradient_loss | -0.013      |
|    std                  | 96.6        |
|    value_loss           | 0.0663      |
-----------------------------------------
[ADAPTIVE] Episode 709 reward: -0.075776
[ADAPTIVE] Mean reward over last 20 episodes: -0.010466
[ADAPTIVE] Plateau counter: 15/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3867612   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 696         |
|    time_elapsed         | 2380        |
|    total_timesteps      | 2850816     |
| train/                  |             |
|    approx_kl            | 0.006192821 |
|    clip_fraction        | 0.0722      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.6       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 11580       |
|    policy_gradient_loss | -0.0103     |
|    std                  | 97.2        |
|    value_loss           | 0.0989      |
-----------------------------------------
[ADAPTIVE] Episode 710 reward: 0.025174
[ADAPTIVE] Mean reward over last 20 episodes: -0.007616
[ADAPTIVE] Plateau counter: 16/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.5531964   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 697         |
|    time_elapsed         | 2383        |
|    total_timesteps      | 2854912     |
| train/                  |             |
|    approx_kl            | 0.006653409 |
|    clip_fraction        | 0.044       |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.7       |
|    explained_variance   | 0.688       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.03       |
|    n_updates            | 11595       |
|    policy_gradient_loss | -0.00942    |
|    std                  | 97.8        |
|    value_loss           | 0.147       |
-----------------------------------------
[ADAPTIVE] Episode 711 reward: -0.057019
[ADAPTIVE] Mean reward over last 20 episodes: -0.010778
[ADAPTIVE] Plateau counter: 17/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.568248    |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 698         |
|    time_elapsed         | 2387        |
|    total_timesteps      | 2859008     |
| train/                  |             |
|    approx_kl            | 0.007520415 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.7       |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 11610       |
|    policy_gradient_loss | -0.0111     |
|    std                  | 97.7        |
|    value_loss           | 0.123       |
-----------------------------------------
[ADAPTIVE] Episode 712 reward: 0.021582
[ADAPTIVE] Mean reward over last 20 episodes: -0.011674
[ADAPTIVE] Plateau counter: 18/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.4541785    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 699          |
|    time_elapsed         | 2390         |
|    total_timesteps      | 2863104      |
| train/                  |              |
|    approx_kl            | 0.0085070105 |
|    clip_fraction        | 0.0642       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.7        |
|    explained_variance   | 0.759        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11625        |
|    policy_gradient_loss | -0.0102      |
|    std                  | 97.7         |
|    value_loss           | 0.107        |
------------------------------------------
[ADAPTIVE] Episode 713 reward: 0.047291
[ADAPTIVE] Mean reward over last 20 episodes: -0.012349
[ADAPTIVE] Plateau counter: 19/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2425543   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 700         |
|    time_elapsed         | 2394        |
|    total_timesteps      | 2867200     |
| train/                  |             |
|    approx_kl            | 0.010539157 |
|    clip_fraction        | 0.09        |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.7       |
|    explained_variance   | 0.764       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 11640       |
|    policy_gradient_loss | -0.0105     |
|    std                  | 98          |
|    value_loss           | 0.108       |
-----------------------------------------
[ADAPTIVE] Episode 714 reward: -0.000688
[ADAPTIVE] Mean reward over last 20 episodes: -0.014570
[ADAPTIVE] Plateau counter: 20/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2726603    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 701          |
|    time_elapsed         | 2397         |
|    total_timesteps      | 2871296      |
| train/                  |              |
|    approx_kl            | 0.0088391965 |
|    clip_fraction        | 0.0723       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.7        |
|    explained_variance   | 0.682        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11655        |
|    policy_gradient_loss | -0.0115      |
|    std                  | 98.2         |
|    value_loss           | 0.117        |
------------------------------------------
[ADAPTIVE] Episode 715 reward: 0.018558
[ADAPTIVE] Mean reward over last 20 episodes: -0.011193
[ADAPTIVE] Plateau counter: 21/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.2627428    |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 702          |
|    time_elapsed         | 2401         |
|    total_timesteps      | 2875392      |
| train/                  |              |
|    approx_kl            | 0.0086325165 |
|    clip_fraction        | 0.0647       |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.7        |
|    explained_variance   | 0.783        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 11670        |
|    policy_gradient_loss | -0.00887     |
|    std                  | 98.4         |
|    value_loss           | 0.144        |
------------------------------------------
[ADAPTIVE] Episode 716 reward: 0.042746
[ADAPTIVE] Mean reward over last 20 episodes: -0.007852
[ADAPTIVE] Plateau counter: 22/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
[ADAPTIVE] Episode 717 reward: 0.011705
[ADAPTIVE] Mean reward over last 20 episodes: -0.003972
[ADAPTIVE] Plateau counter: 23/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.228563     |
| time/                   |              |
|    fps                  | 1197         |
|    iterations           | 703          |
|    time_elapsed         | 2405         |
|    total_timesteps      | 2879488      |
| train/                  |              |
|    approx_kl            | 0.0065857917 |
|    clip_fraction        | 0.061        |
|    clip_range           | 0.2          |
|    entropy_loss         | -53.8        |
|    explained_variance   | 0.773        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 11685        |
|    policy_gradient_loss | -0.0101      |
|    std                  | 98.6         |
|    value_loss           | 0.104        |
------------------------------------------
[ADAPTIVE] Episode 718 reward: -0.003792
[ADAPTIVE] Mean reward over last 20 episodes: -0.002421
[ADAPTIVE] Plateau counter: 24/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.2758112   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 704         |
|    time_elapsed         | 2408        |
|    total_timesteps      | 2883584     |
| train/                  |             |
|    approx_kl            | 0.006875488 |
|    clip_fraction        | 0.0556      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.8       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 11700       |
|    policy_gradient_loss | -0.0122     |
|    std                  | 99.2        |
|    value_loss           | 0.128       |
-----------------------------------------
[ADAPTIVE] Episode 719 reward: -0.074068
[ADAPTIVE] Mean reward over last 20 episodes: -0.014581
[ADAPTIVE] Plateau counter: 25/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3870295   |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 705         |
|    time_elapsed         | 2412        |
|    total_timesteps      | 2887680     |
| train/                  |             |
|    approx_kl            | 0.008882912 |
|    clip_fraction        | 0.0678      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.8       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 11715       |
|    policy_gradient_loss | -0.0106     |
|    std                  | 99.7        |
|    value_loss           | 0.103       |
-----------------------------------------
[ADAPTIVE] Episode 720 reward: 0.012743
[ADAPTIVE] Mean reward over last 20 episodes: -0.013367
[ADAPTIVE] Plateau counter: 26/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.384044    |
| time/                   |             |
|    fps                  | 1197        |
|    iterations           | 706         |
|    time_elapsed         | 2415        |
|    total_timesteps      | 2891776     |
| train/                  |             |
|    approx_kl            | 0.007530179 |
|    clip_fraction        | 0.0661      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.9       |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.08       |
|    n_updates            | 11730       |
|    policy_gradient_loss | -0.0115     |
|    std                  | 101         |
|    value_loss           | 0.0873      |
-----------------------------------------
[ADAPTIVE] Episode 721 reward: -0.041320
[ADAPTIVE] Mean reward over last 20 episodes: -0.012406
[ADAPTIVE] Plateau counter: 27/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.3418378   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 707         |
|    time_elapsed         | 2419        |
|    total_timesteps      | 2895872     |
| train/                  |             |
|    approx_kl            | 0.008882812 |
|    clip_fraction        | 0.0913      |
|    clip_range           | 0.2         |
|    entropy_loss         | -53.9       |
|    explained_variance   | 0.57        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 11745       |
|    policy_gradient_loss | -0.0132     |
|    std                  | 101         |
|    value_loss           | 0.167       |
-----------------------------------------
[ADAPTIVE] Episode 722 reward: -0.028193
[ADAPTIVE] Mean reward over last 20 episodes: -0.010901
[ADAPTIVE] Plateau counter: 28/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.1846334   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 708         |
|    time_elapsed         | 2423        |
|    total_timesteps      | 2899968     |
| train/                  |             |
|    approx_kl            | 0.007172079 |
|    clip_fraction        | 0.0789      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54         |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 11760       |
|    policy_gradient_loss | -0.011      |
|    std                  | 101         |
|    value_loss           | 0.0954      |
-----------------------------------------
[ADAPTIVE] Episode 723 reward: -0.128572
[ADAPTIVE] Mean reward over last 20 episodes: -0.015933
[ADAPTIVE] Plateau counter: 29/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.180013    |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 709         |
|    time_elapsed         | 2426        |
|    total_timesteps      | 2904064     |
| train/                  |             |
|    approx_kl            | 0.005995186 |
|    clip_fraction        | 0.0514      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54         |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.00025     |
|    loss                 | -1          |
|    n_updates            | 11775       |
|    policy_gradient_loss | -0.00919    |
|    std                  | 102         |
|    value_loss           | 0.164       |
-----------------------------------------
[ADAPTIVE] Episode 724 reward: 0.005356
[ADAPTIVE] Mean reward over last 20 episodes: -0.016854
[ADAPTIVE] Plateau counter: 30/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0552024    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 710          |
|    time_elapsed         | 2430         |
|    total_timesteps      | 2908160      |
| train/                  |              |
|    approx_kl            | 0.0066604577 |
|    clip_fraction        | 0.0511       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.1        |
|    explained_variance   | 0.689        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 11790        |
|    policy_gradient_loss | -0.00988     |
|    std                  | 103          |
|    value_loss           | 0.113        |
------------------------------------------
[ADAPTIVE] Episode 725 reward: 0.055492
[ADAPTIVE] Mean reward over last 20 episodes: -0.013977
[ADAPTIVE] Plateau counter: 31/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0596884    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 711          |
|    time_elapsed         | 2433         |
|    total_timesteps      | 2912256      |
| train/                  |              |
|    approx_kl            | 0.0061996565 |
|    clip_fraction        | 0.0456       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.1        |
|    explained_variance   | 0.754        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.05        |
|    n_updates            | 11805        |
|    policy_gradient_loss | -0.00884     |
|    std                  | 103          |
|    value_loss           | 0.11         |
------------------------------------------
[ADAPTIVE] Episode 726 reward: 0.085750
[ADAPTIVE] Mean reward over last 20 episodes: -0.004210
[ADAPTIVE] Plateau counter: 32/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0879616    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 712          |
|    time_elapsed         | 2437         |
|    total_timesteps      | 2916352      |
| train/                  |              |
|    approx_kl            | 0.0069215046 |
|    clip_fraction        | 0.0621       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.1        |
|    explained_variance   | 0.733        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.07        |
|    n_updates            | 11820        |
|    policy_gradient_loss | -0.0105      |
|    std                  | 104          |
|    value_loss           | 0.0831       |
------------------------------------------
[ADAPTIVE] Episode 727 reward: -0.053450
[ADAPTIVE] Mean reward over last 20 episodes: -0.005193
[ADAPTIVE] Plateau counter: 33/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0420756  |
| time/                   |            |
|    fps                  | 1196       |
|    iterations           | 713        |
|    time_elapsed         | 2440       |
|    total_timesteps      | 2920448    |
| train/                  |            |
|    approx_kl            | 0.01062798 |
|    clip_fraction        | 0.0637     |
|    clip_range           | 0.2        |
|    entropy_loss         | -54.2      |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.05      |
|    n_updates            | 11835      |
|    policy_gradient_loss | -0.00964   |
|    std                  | 104        |
|    value_loss           | 0.105      |
----------------------------------------
[ADAPTIVE] Episode 728 reward: 0.030002
[ADAPTIVE] Mean reward over last 20 episodes: -0.005324
[ADAPTIVE] Plateau counter: 34/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0924054    |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 714          |
|    time_elapsed         | 2445         |
|    total_timesteps      | 2924544      |
| train/                  |              |
|    approx_kl            | 0.0064516957 |
|    clip_fraction        | 0.0407       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.3        |
|    explained_variance   | 0.69         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 11850        |
|    policy_gradient_loss | -0.0087      |
|    std                  | 105          |
|    value_loss           | 0.131        |
------------------------------------------
[ADAPTIVE] Episode 729 reward: 0.031182
[ADAPTIVE] Mean reward over last 20 episodes: 0.000024
[ADAPTIVE] Plateau counter: 35/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0105939   |
| time/                   |             |
|    fps                  | 1196        |
|    iterations           | 715         |
|    time_elapsed         | 2448        |
|    total_timesteps      | 2928640     |
| train/                  |             |
|    approx_kl            | 0.005933378 |
|    clip_fraction        | 0.0769      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54.3       |
|    explained_variance   | 0.774       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.07       |
|    n_updates            | 11865       |
|    policy_gradient_loss | -0.00957    |
|    std                  | 105         |
|    value_loss           | 0.0958      |
-----------------------------------------
[ADAPTIVE] Episode 730 reward: 0.050088
[ADAPTIVE] Mean reward over last 20 episodes: 0.001270
[ADAPTIVE] Plateau counter: 36/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0623685   |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 716         |
|    time_elapsed         | 2452        |
|    total_timesteps      | 2932736     |
| train/                  |             |
|    approx_kl            | 0.007159461 |
|    clip_fraction        | 0.0695      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54.4       |
|    explained_variance   | 0.631       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.05       |
|    n_updates            | 11880       |
|    policy_gradient_loss | -0.0109     |
|    std                  | 106         |
|    value_loss           | 0.139       |
-----------------------------------------
[ADAPTIVE] Episode 731 reward: 0.115791
[ADAPTIVE] Mean reward over last 20 episodes: 0.009910
[ADAPTIVE] Plateau counter: 37/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 1.0352684  |
| time/                   |            |
|    fps                  | 1196       |
|    iterations           | 717        |
|    time_elapsed         | 2455       |
|    total_timesteps      | 2936832    |
| train/                  |            |
|    approx_kl            | 0.00953727 |
|    clip_fraction        | 0.0802     |
|    clip_range           | 0.2        |
|    entropy_loss         | -54.4      |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.00025    |
|    loss                 | -1.08      |
|    n_updates            | 11895      |
|    policy_gradient_loss | -0.0119    |
|    std                  | 107        |
|    value_loss           | 0.0937     |
----------------------------------------
[ADAPTIVE] Episode 732 reward: 0.046304
[ADAPTIVE] Mean reward over last 20 episodes: 0.011146
[ADAPTIVE] Plateau counter: 38/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 1.0202492    |
| time/                   |              |
|    fps                  | 1195         |
|    iterations           | 718          |
|    time_elapsed         | 2459         |
|    total_timesteps      | 2940928      |
| train/                  |              |
|    approx_kl            | 0.0070147756 |
|    clip_fraction        | 0.0673       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.5        |
|    explained_variance   | 0.687        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.07        |
|    n_updates            | 11910        |
|    policy_gradient_loss | -0.00973     |
|    std                  | 107          |
|    value_loss           | 0.0789       |
------------------------------------------
[ADAPTIVE] Episode 733 reward: -0.051938
[ADAPTIVE] Mean reward over last 20 episodes: 0.006185
[ADAPTIVE] Plateau counter: 39/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8151981   |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 719         |
|    time_elapsed         | 2462        |
|    total_timesteps      | 2945024     |
| train/                  |             |
|    approx_kl            | 0.007095642 |
|    clip_fraction        | 0.0402      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54.6       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 11925       |
|    policy_gradient_loss | -0.00929    |
|    std                  | 108         |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 734 reward: 0.024228
[ADAPTIVE] Mean reward over last 20 episodes: 0.007431
[ADAPTIVE] Plateau counter: 40/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.85907936  |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 720         |
|    time_elapsed         | 2466        |
|    total_timesteps      | 2949120     |
| train/                  |             |
|    approx_kl            | 0.007962156 |
|    clip_fraction        | 0.0787      |
|    clip_range           | 0.2         |
|    entropy_loss         | -54.6       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.08       |
|    n_updates            | 11940       |
|    policy_gradient_loss | -0.0138     |
|    std                  | 109         |
|    value_loss           | 0.105       |
-----------------------------------------
[ADAPTIVE] Episode 735 reward: 0.023302
[ADAPTIVE] Mean reward over last 20 episodes: 0.007668
[ADAPTIVE] Plateau counter: 41/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.922314     |
| time/                   |              |
|    fps                  | 1195         |
|    iterations           | 721          |
|    time_elapsed         | 2469         |
|    total_timesteps      | 2953216      |
| train/                  |              |
|    approx_kl            | 0.0043347417 |
|    clip_fraction        | 0.0429       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.7        |
|    explained_variance   | 0.657        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.03        |
|    n_updates            | 11955        |
|    policy_gradient_loss | -0.00716     |
|    std                  | 110          |
|    value_loss           | 0.202        |
------------------------------------------
[ADAPTIVE] Episode 736 reward: -0.054440
[ADAPTIVE] Mean reward over last 20 episodes: 0.002809
[ADAPTIVE] Plateau counter: 42/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8427557    |
| time/                   |              |
|    fps                  | 1195         |
|    iterations           | 722          |
|    time_elapsed         | 2473         |
|    total_timesteps      | 2957312      |
| train/                  |              |
|    approx_kl            | 0.0064008282 |
|    clip_fraction        | 0.0587       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.7        |
|    explained_variance   | 0.548        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.01        |
|    n_updates            | 11970        |
|    policy_gradient_loss | -0.00836     |
|    std                  | 110          |
|    value_loss           | 0.221        |
------------------------------------------
[ADAPTIVE] Episode 737 reward: -1.658003
[ADAPTIVE] Mean reward over last 20 episodes: -0.080677
[ADAPTIVE] Plateau counter: 43/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.8073158    |
| time/                   |              |
|    fps                  | 1195         |
|    iterations           | 723          |
|    time_elapsed         | 2476         |
|    total_timesteps      | 2961408      |
| train/                  |              |
|    approx_kl            | 0.0050776624 |
|    clip_fraction        | 0.0581       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.7        |
|    explained_variance   | 0.775        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.08        |
|    n_updates            | 11985        |
|    policy_gradient_loss | -0.0103      |
|    std                  | 110          |
|    value_loss           | 0.0967       |
------------------------------------------
[ADAPTIVE] Episode 738 reward: 0.009650
[ADAPTIVE] Mean reward over last 20 episodes: -0.080005
[ADAPTIVE] Plateau counter: 44/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.7854955    |
| time/                   |              |
|    fps                  | 1195         |
|    iterations           | 724          |
|    time_elapsed         | 2479         |
|    total_timesteps      | 2965504      |
| train/                  |              |
|    approx_kl            | 0.0053528016 |
|    clip_fraction        | 0.0572       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.8        |
|    explained_variance   | 0.737        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.06        |
|    n_updates            | 12000        |
|    policy_gradient_loss | -0.00753     |
|    std                  | 111          |
|    value_loss           | 0.145        |
------------------------------------------
[ADAPTIVE] Episode 739 reward: 0.017027
[ADAPTIVE] Mean reward over last 20 episodes: -0.075450
[ADAPTIVE] Plateau counter: 45/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.94561136   |
| time/                   |              |
|    fps                  | 1196         |
|    iterations           | 725          |
|    time_elapsed         | 2482         |
|    total_timesteps      | 2969600      |
| train/                  |              |
|    approx_kl            | 0.0072996486 |
|    clip_fraction        | 0.0748       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.9        |
|    explained_variance   | 0.764        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.07        |
|    n_updates            | 12015        |
|    policy_gradient_loss | -0.0101      |
|    std                  | 112          |
|    value_loss           | 0.0974       |
------------------------------------------
[ADAPTIVE] Episode 740 reward: 0.023059
[ADAPTIVE] Mean reward over last 20 episodes: -0.074934
[ADAPTIVE] Plateau counter: 46/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.91980624   |
| time/                   |              |
|    fps                  | 1195         |
|    iterations           | 726          |
|    time_elapsed         | 2487         |
|    total_timesteps      | 2973696      |
| train/                  |              |
|    approx_kl            | 0.0048102513 |
|    clip_fraction        | 0.0462       |
|    clip_range           | 0.2          |
|    entropy_loss         | -54.9        |
|    explained_variance   | 0.72         |
|    learning_rate        | 0.00025      |
|    loss                 | -1.08        |
|    n_updates            | 12030        |
|    policy_gradient_loss | -0.00806     |
|    std                  | 113          |
|    value_loss           | 0.107        |
------------------------------------------
[ADAPTIVE] Episode 741 reward: -0.084127
[ADAPTIVE] Mean reward over last 20 episodes: -0.077075
[ADAPTIVE] Plateau counter: 47/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.8620289   |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 727         |
|    time_elapsed         | 2489        |
|    total_timesteps      | 2977792     |
| train/                  |             |
|    approx_kl            | 0.007302538 |
|    clip_fraction        | 0.0818      |
|    clip_range           | 0.2         |
|    entropy_loss         | -55         |
|    explained_variance   | 0.719       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.08       |
|    n_updates            | 12045       |
|    policy_gradient_loss | -0.009      |
|    std                  | 114         |
|    value_loss           | 0.0784      |
-----------------------------------------
[ADAPTIVE] Episode 742 reward: -0.009253
[ADAPTIVE] Mean reward over last 20 episodes: -0.076128
[ADAPTIVE] Plateau counter: 48/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.97763205  |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 728         |
|    time_elapsed         | 2493        |
|    total_timesteps      | 2981888     |
| train/                  |             |
|    approx_kl            | 0.006914889 |
|    clip_fraction        | 0.0608      |
|    clip_range           | 0.2         |
|    entropy_loss         | -55         |
|    explained_variance   | 0.615       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.06       |
|    n_updates            | 12060       |
|    policy_gradient_loss | -0.00878    |
|    std                  | 114         |
|    value_loss           | 0.114       |
-----------------------------------------
[ADAPTIVE] Episode 743 reward: -0.136016
[ADAPTIVE] Mean reward over last 20 episodes: -0.076500
[ADAPTIVE] Plateau counter: 49/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.88165915  |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 729         |
|    time_elapsed         | 2497        |
|    total_timesteps      | 2985984     |
| train/                  |             |
|    approx_kl            | 0.006578346 |
|    clip_fraction        | 0.0664      |
|    clip_range           | 0.2         |
|    entropy_loss         | -55.1       |
|    explained_variance   | 0.636       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.04       |
|    n_updates            | 12075       |
|    policy_gradient_loss | -0.0105     |
|    std                  | 115         |
|    value_loss           | 0.125       |
-----------------------------------------
[ADAPTIVE] Episode 744 reward: -0.002383
[ADAPTIVE] Mean reward over last 20 episodes: -0.076887
[ADAPTIVE] Plateau counter: 50/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 0.93291616  |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 730         |
|    time_elapsed         | 2500        |
|    total_timesteps      | 2990080     |
| train/                  |             |
|    approx_kl            | 0.006644074 |
|    clip_fraction        | 0.0613      |
|    clip_range           | 0.2         |
|    entropy_loss         | -55.1       |
|    explained_variance   | 0.712       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.08       |
|    n_updates            | 12090       |
|    policy_gradient_loss | -0.00932    |
|    std                  | 115         |
|    value_loss           | 0.116       |
-----------------------------------------
[ADAPTIVE] Episode 745 reward: -0.088389
[ADAPTIVE] Mean reward over last 20 episodes: -0.084081
[ADAPTIVE] Plateau counter: 51/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0754751   |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 731         |
|    time_elapsed         | 2504        |
|    total_timesteps      | 2994176     |
| train/                  |             |
|    approx_kl            | 0.005817181 |
|    clip_fraction        | 0.0685      |
|    clip_range           | 0.2         |
|    entropy_loss         | -55.1       |
|    explained_variance   | 0.727       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.1        |
|    n_updates            | 12105       |
|    policy_gradient_loss | -0.0098     |
|    std                  | 116         |
|    value_loss           | 0.0959      |
-----------------------------------------
[ADAPTIVE] Episode 746 reward: 0.078129
[ADAPTIVE] Mean reward over last 20 episodes: -0.084462
[ADAPTIVE] Plateau counter: 52/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.0194383   |
| time/                   |             |
|    fps                  | 1195        |
|    iterations           | 732         |
|    time_elapsed         | 2508        |
|    total_timesteps      | 2998272     |
| train/                  |             |
|    approx_kl            | 0.005867378 |
|    clip_fraction        | 0.0442      |
|    clip_range           | 0.2         |
|    entropy_loss         | -55.2       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00025     |
|    loss                 | -1.07       |
|    n_updates            | 12120       |
|    policy_gradient_loss | -0.00797    |
|    std                  | 116         |
|    value_loss           | 0.113       |
-----------------------------------------
[ADAPTIVE] Episode 747 reward: 0.048083
[ADAPTIVE] Mean reward over last 20 episodes: -0.079385
[ADAPTIVE] Plateau counter: 53/10
[ADAPTIVE] Curriculum complete.
[ADAPTIVE] Curriculum advanced to intervention 5
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 251          |
|    ep_rew_mean          | 0.97977126   |
| time/                   |              |
|    fps                  | 1195         |
|    iterations           | 733          |
|    time_elapsed         | 2511         |
|    total_timesteps      | 3002368      |
| train/                  |              |
|    approx_kl            | 0.0068623647 |
|    clip_fraction        | 0.0572       |
|    clip_range           | 0.2          |
|    entropy_loss         | -55.2        |
|    explained_variance   | 0.668        |
|    learning_rate        | 0.00025      |
|    loss                 | -1.08        |
|    n_updates            | 12135        |
|    policy_gradient_loss | -0.0091      |
|    std                  | 117          |
|    value_loss           | 0.107        |
------------------------------------------
2025-07-08 15:48:20,687 1941474 INFO [TRAIN] Training complete.
2025-07-08 15:48:20,710 1941474 INFO [SAVE] Model saved to: adaptive_curriculum_on_ppo/adaptive_curriculum_on_ppo
