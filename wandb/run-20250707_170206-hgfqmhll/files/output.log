Logging to autocalcdual_pushing/autocalc_curriculum_dualphase_1
/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/stable_baselines3/common/callbacks.py:337: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_monitor.VecMonitor object at 0x7f9cee3faad0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f9cd4ebff50>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 251       |
|    ep_rew_mean     | 1.6786245 |
| time/              |           |
|    fps             | 1153      |
|    iterations      | 1         |
|    time_elapsed    | 3         |
|    total_timesteps | 4096      |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.6902169   |
| time/                   |             |
|    fps                  | 981         |
|    iterations           | 2           |
|    time_elapsed         | 8           |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.018917445 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -21.6       |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.00025     |
|    loss                 | -0.453      |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.0357     |
|    std                  | 2.67        |
|    value_loss           | 0.0919      |
-----------------------------------------
Traceback (most recent call last):
  File "autocalc_curriculum_dualphase.py", line 1216, in <module>
    main()
  File "autocalc_curriculum_dualphase.py", line 1212, in main
    wandb_config=wandb_config
  File "autocalc_curriculum_dualphase.py", line 923, in train_autocalc_curriculum
    tb_log_name="autocalc_curriculum_dualphase"
  File "/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py", line 308, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 270, in learn
    self.train()
  File "/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py", line 262, in train
    self.policy.optimizer.step()
  File "/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/torch/optim/optimizer.py", line 140, in wrapper
    out = func(*args, **kwargs)
  File "/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/torch/optim/optimizer.py", line 23, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/torch/optim/adam.py", line 252, in step
    found_inf=found_inf)
  File "/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/torch/optim/adam.py", line 316, in adam
    found_inf=found_inf)
  File "/home/kpatherya3/anaconda3/envs/causal_env/lib/python3.7/site-packages/torch/optim/adam.py", line 364, in _single_tensor_adam
    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)
KeyboardInterrupt
