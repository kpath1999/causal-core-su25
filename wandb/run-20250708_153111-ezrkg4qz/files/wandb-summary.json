{"adaptive/mean_reward":-0.0015261883351408018,"train/clip_fraction":0.17234701,"_runtime":109.393239856,"adaptive/episode":30,"train/value_loss":0.07481357,"adaptive/intervention_idx":0,"train/policy_gradient_loss":-0.032683123,"rollout/ep_rew_mean":1.2044342,"train/entropy_loss":-22.920237,"train/std":3.1007009,"_timestamp":1.7520031806999195e+09,"train/learning_rate":0.00025,"time/fps":1208,"rollout/ep_len_mean":251,"_wandb":{"runtime":109},"adaptive/episode_reward":-0.025975108034026435,"train/explained_variance":0.78571045,"adaptive/current_intervention":"GoalInterventionActorPolicy","train/loss":-0.4832523,"train/clip_range":0.2,"_step":396,"train/approx_kl":0.015171533,"global_step":118784}